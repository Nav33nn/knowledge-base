{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cab-Driver Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Importing libraries\n",
    "import numpy as np\n",
    "import random\n",
    "import math\n",
    "from collections import deque\n",
    "import collections\n",
    "import pickle\n",
    "import os\n",
    "# for building DQN model\n",
    "from keras import layers\n",
    "from keras import Sequential\n",
    "from keras.layers import Dense, Activation, Flatten\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "# for plotting graphs\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Import the environment\n",
    "#from Env import CabDriver\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import routines\n",
    "\n",
    "import numpy as np\n",
    "import math\n",
    "import random\n",
    "from itertools import permutations,product\n",
    "\n",
    "# Defining hyperparameters\n",
    "m = 5 # number of cities, ranges from 1 ..... m\n",
    "t = 24 # number of hours, ranges from 0 .... t-1\n",
    "d = 7  # number of days, ranges from 0 ... d-1\n",
    "C = 5 # Per hour fuel and other costs\n",
    "R = 9 # per hour revenue from a passenger\n",
    "\n",
    "\n",
    "class CabDriver():\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"initialise your state and define your action space and state space\"\"\"\n",
    "        action_list = list(permutations(range(0,m) ,2))\n",
    "        action_list.append((0,0))\n",
    "        self.action_space = np.array(action_list) #action space is unique 2 values(source & destination) + the no op\n",
    "        self.state_space = list(product(*[list(range(0,m)), list(range(0,t)), list(range(0,d))])) #State space from MDP:\n",
    "        #𝑠=𝑋𝑖𝑇𝑗𝐷𝑘 𝑤ℎ𝑒𝑟𝑒 𝑖=0…𝑚−1;𝑗=0….𝑡−1;𝑘=0…..𝑑−1, Where 𝑋𝑖 represents a driver’s current location, 𝑇𝑗 represents time component (more specifically hour of the day), 𝐷𝑘 represents the day of the week\n",
    "        self.state_size = len(self.state_space)\n",
    "        self.action_size = len(self.action_space)\n",
    "        self.state_init = random.choice(self.state_space) #Initialises to any random self_space\n",
    "        self.encode_vector = np.array([24*7, 7, 1]).reshape(3, 1)\n",
    "\n",
    "\n",
    "        # Start the first round\n",
    "        self.reset()\n",
    "\n",
    "\n",
    "    ## Encoding state (or state-action) for NN input\n",
    "\n",
    "    def state_encod_arch1(self, curr_state, batch_size=1):\n",
    "        \"\"\"convert the state into a vector so that it can be fed to the NN. This method converts a given state into a vector format. Hint: The vector is of size m + t + d.\"\"\"\n",
    "       \n",
    "        #Encoded values of m + t + d\n",
    "        \n",
    "        curr_state = np.array(curr_state).reshape(1, 3)\n",
    "        #print(curr_state.shape)\n",
    "        #enc_mat = self.encode_vector\n",
    "        # pos = (state[0]*24*7) + (state[1]*7) + state[2]\n",
    "        \n",
    "        pos_mat = np.dot(curr_state, self.encode_vector)\n",
    "        state_encod =  np.zeros((1, self.state_size))\n",
    "        # state_encod[pos] = 1\n",
    "        for i in range(batch_size):\n",
    "            state_encod[i][pos_mat[i]] = 1\n",
    "\n",
    "        return np.reshape(state_encod, [1, env.state_size])\n",
    "    \n",
    "\n",
    "\n",
    "    # Use this function if you are using architecture-2 \n",
    "    # def state_encod_arch2(self, state, action):\n",
    "    #     \"\"\"convert the (state-action) into a vector so that it can be fed to the NN. This method converts a given state-action pair into a vector format. Hint: The vector is of size m + t + d + m + m.\"\"\"\n",
    "\n",
    "        \n",
    "    #     return state_encod\n",
    "\n",
    "\n",
    "    ## Getting number of requests\n",
    "\n",
    "    def requests(self, state):\n",
    "        \"\"\"Determining the number of requests basis the location. \n",
    "        Use the table specified in the MDP and complete for rest of the locations\"\"\"\n",
    "        location = state[0]\n",
    "        requests = 0\n",
    "        if location == 0:\n",
    "            requests = np.random.poisson(2)\n",
    "\n",
    "        if location == 1:\n",
    "            requests = np.random.poisson(12)   #MDP Poisson distribution\n",
    "        \n",
    "        if location == 2:\n",
    "            requests = np.random.poisson(4)    #MDP Poisson distribution\n",
    "            \n",
    "        if location == 3:\n",
    "            requests = np.random.poisson(7)    #MDP Poisson distribution\n",
    "\n",
    "        if location == 4:\n",
    "            requests = np.random.poisson(8)    #MDP Poisson distribution  \n",
    "            \n",
    "        if requests > 15:\n",
    "            requests = 15\n",
    "\n",
    "        possible_actions_index = random.sample(range(0, (m-1)*m), requests) # (0,0) is not considered as customer request\n",
    "        possible_actions_index.append(20) #add the index of No-OP action (0, 0)\n",
    "        actions = [self.action_space[i] for i in possible_actions_index]\n",
    "\n",
    "        print('Number of actions available', len(actions))\n",
    "        return possible_actions_index, actions   \n",
    "\n",
    "\n",
    "\n",
    "    def reward_func(self, state, action, Time_matrix):\n",
    "        \"\"\"Takes in state, action and Time-matrix and returns the reward\"\"\"\n",
    "        if action[0] == action[1]:\n",
    "            reward = -C \n",
    "            return reward\n",
    "\n",
    "        #print('reward:' ,state, action)\n",
    "        p = action[0]\n",
    "        q = action[1]\n",
    "        i = state[0]\n",
    "        time = state[1]\n",
    "        day = state[2]\n",
    "        #print('reward vals:', (p, q, i, time, day))\n",
    "        t_pq = Time_matrix[p][q][time][day]\n",
    "        t_ip = Time_matrix[i][p][time][day]\n",
    "        \n",
    "        \n",
    "        reward = (R*t_pq)-(C*(t_pq+t_ip))\n",
    "        return reward\n",
    "\n",
    "\n",
    "    def next_state_func(self, state, action, Time_matrix):\n",
    "        \"\"\"Takes state and action as input and returns next state\"\"\"\n",
    "        \n",
    "        #print('next_state :', state, action)\n",
    "        p = action[0]\n",
    "        q = action[1]\n",
    "        i = state[0]\n",
    "        time_curr = state[1]\n",
    "        day_curr = state[2]\n",
    "        #print('next_state_vals :', (p, q, i, time_curr, day_curr))\n",
    "        time_next = time_curr + Time_matrix[p][q][time_curr][day_curr]\n",
    "\n",
    "        day_next = int((day_curr+int(time_next/24)) % 7)\n",
    "        time_next = int(time_next % 24)\n",
    "            \n",
    "        next_state = (q,time_next,day_next)\n",
    "        return next_state\n",
    "\n",
    "\n",
    "    def reset(self):\n",
    "        return self.action_space, self.state_space, self.state_init\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining Time Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the time matrix provided\n",
    "Time_matrix = np.load(\"TM.npy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tracking the state-action pairs for checking convergence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining a function to save the Q-dictionary as a pickle file\n",
    "def save_pickle(obj, name ):\n",
    "    with open(name + '.pkl', 'wb') as f:\n",
    "        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agent Class\n",
    "\n",
    "If you are using this framework, you need to fill the following to complete the following code block:\n",
    "1. State and Action Size\n",
    "2. Hyperparameters\n",
    "3. Create a neural-network model in function 'build_model()'\n",
    "4. Define epsilon-greedy strategy in function 'get_action()'\n",
    "5. Complete the function 'append_sample()'. This function appends the recent experience tuple <state, action, reward, new-state> to the memory\n",
    "6. Complete the 'train_model()' function with following logic:\n",
    "   - If the memory size is greater than mini-batch size, you randomly sample experiences from memory as per the mini-batch size and do the following:\n",
    "      - Initialise your input and output batch for training the model\n",
    "      - Calculate the target Q value for each sample: reward + gamma*max(Q(s'a,))\n",
    "      - Get Q(s', a) values from the last trained model\n",
    "      - Update the input batch as your encoded state and output batch as your Q-values\n",
    "      - Then fit your DQN model using the updated input and output batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQNAgent:\n",
    "    def __init__(self, state_size, action_size, discount_factor=0.95, learning_rate=0.01,\n",
    "                       epsilon=0.99, epsilon_decay=0.99, epsilon_min=0.01):\n",
    "        # Define size of state and action\n",
    "        self.state_size = state_size\n",
    "        self.action_size = action_size\n",
    "\n",
    "        # Write here: Specify you hyper parameters for the DQN\n",
    "        self.discount_factor = discount_factor\n",
    "        self.learning_rate = learning_rate        \n",
    "        self.epsilon_max = epsilon\n",
    "        self.epsilon_decay = epsilon_decay\n",
    "        self.epsilon_min = epsilon_min\n",
    "        self.model_history = None\n",
    "        \n",
    "        self.batch_size = 32\n",
    "        #self.batch_size = 1\n",
    "        # create replay memory using deque\n",
    "        self.memory = deque(maxlen=2000)\n",
    "\n",
    "        # create main model and target model\n",
    "        self.model = self.build_model()\n",
    "    \n",
    "\n",
    "    # approximate Q function using Neural Network\n",
    "    def build_model(self):\n",
    "        model = Sequential()\n",
    "        # Write your code here: Add layers to your neural nets       \n",
    "\n",
    "        # hidden layers\n",
    "        model.add(Dense(32, input_dim=self.state_size, activation='relu', kernel_initializer='he_uniform'))\n",
    "        model.add(Dense(32, activation='relu', kernel_initializer='he_uniform'))\n",
    "\n",
    "        # the output layer: output is of size num_actions\n",
    "        model.add(Dense(self.action_size, activation='relu', kernel_initializer='he_uniform'))     \n",
    "        model.compile(loss='mse',optimizer=Adam(lr=self.learning_rate))\n",
    "        model.summary()\n",
    "        return model\n",
    "\n",
    "\n",
    "    def get_action(self, cstate, all_actions, pos_act_ind):\n",
    "    # Write your code here:\n",
    "    # get action from model using epsilon-greedy policy\n",
    "    # Decay in ε after we generate each sample from the environment\n",
    "        actions = all_actions[pos_act_ind]\n",
    "        q_value = 0\n",
    "        if np.random.rand() <= self.epsilon_max:\n",
    "            # explore: choose a random action from all possible actions\n",
    "            print('Exploring')\n",
    "            action = random.choice(actions)\n",
    "        else:\n",
    "            # choose the action with the highest q(s, a)\n",
    "            # the first index corresponds to the batch size, so\n",
    "            # reshape state to (1, state_size) so that the first index corresponds to the batch size\n",
    "            print('Exploiting')\n",
    "            #cstate = cstate.reshape(1, self.state_size) \n",
    "            q_value = self.model.predict(x=cstate)\n",
    "            max_index = np.argmax(q_value[0])\n",
    "            action = all_actions[max_index] if max_index in pos_act_ind else random.choice(actions)\n",
    "        print('Selected action ', action)    \n",
    "        return action, q_value\n",
    "        \n",
    "\n",
    "    def append_sample(self, state, action, reward, next_state, done):\n",
    "    # Write your code here:\n",
    "    # save sample <s,a,r,s'> to the replay memory\n",
    "        self.memory.append((state, action, reward, next_state, done))\n",
    "    \n",
    "    \n",
    "    # pick samples randomly from replay memory (with batch_size) and train the network\n",
    "    def train_model(self):\n",
    "        if len(self.memory) > self.batch_size:\n",
    "            # Sample batch from the memory\n",
    "            mini_batch = random.sample(self.memory, self.batch_size)\n",
    "            update_input = np.zeros((self.batch_size, self.state_size))\n",
    "            update_output = np.zeros((self.batch_size, self.state_size))\n",
    "            \n",
    "            actions, rewards, done = [], [], []\n",
    "            \n",
    "            for i in range(self.batch_size):\n",
    "                state, action, reward, next_state, done_boolean = mini_batch[i]\n",
    "                \n",
    "                # Write your code from here\n",
    "                # 1. Predict the target from earlier model\n",
    "                update_input[i] = env.state_encod_arch1(state)\n",
    "                actions.append(action)\n",
    "                rewards.append(reward)\n",
    "                update_output[i] = env.state_encod_arch1(next_state)\n",
    "                done.append(done_boolean)\n",
    "                \n",
    "            # 2. Get the target for the Q-network\n",
    "            \n",
    "            target = self.model.predict(update_input)\n",
    "            target_qval = self.model.predict(update_output)\n",
    "            #print(target, target.shape)\n",
    "            #print(target.shape, target_qval.shape)\n",
    "\n",
    "            #3. Update your 'update_output' and 'update_input' batch\n",
    "            for i in range(self.batch_size):\n",
    "                #print(i, actions[i])\n",
    "                if done[i]:\n",
    "                    #target[i][actions[i]] = rewards[i]\n",
    "                    target[i] = rewards[i]\n",
    "                else: # non-terminal state\n",
    "                    #target[i][actions[i]] = rewards[i] + self.discount_factor * np.max(target_qval[i])\n",
    "                    target[i] = rewards[i] + self.discount_factor * np.max(target_qval[i])\n",
    "                \n",
    "        # 4. Fit your model and track the loss values\n",
    "            return self.model.fit(update_input, target, batch_size=self.batch_size, epochs=1, verbose=1)\n",
    "            \n",
    "            \n",
    "    def save(self, name):\n",
    "        self.model.save(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to store rewards in each episode\n",
    "rewards_per_episode, episodes, q_vals_per_episode, loss = [], [], [], []\n",
    "\n",
    "# make dir to store model weights\n",
    "if not os.path.exists(\"saved_model_weights\"):\n",
    "    os.mkdir(\"saved_model_weights\")\n",
    "\n",
    "# n_episodes\n",
    "n_episodes = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DQN block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_4 (Dense)              (None, 32)                26912     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 21)                693       \n",
      "=================================================================\n",
      "Total params: 28,661\n",
      "Trainable params: 28,661\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Number of actions available 13\n",
      "Episode : 0\n",
      "Exploring\n",
      "Selected action  [3 0]\n",
      "[3 0]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Exploring\n",
      "Selected action  [1 2]\n",
      "[1 2]\n",
      "Exploring\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Exploring\n",
      "Selected action  [1 2]\n",
      "[1 2]\n",
      "Exploring\n",
      "Selected action  [4 2]\n",
      "[4 2]\n",
      "Exploring\n",
      "Selected action  [1 2]\n",
      "[1 2]\n",
      "Exploring\n",
      "Selected action  [4 2]\n",
      "[4 2]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Exploring\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Exploring\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Exploring\n",
      "Selected action  [4 2]\n",
      "[4 2]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Exploring\n",
      "Selected action  [0 2]\n",
      "[0 2]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Exploring\n",
      "Selected action  [3 0]\n",
      "[3 0]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Exploring\n",
      "Selected action  [0 4]\n",
      "[0 4]\n",
      "Exploiting\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Exploring\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Exploring\n",
      "Selected action  [2 1]\n",
      "[2 1]\n",
      "Exploring\n",
      "Selected action  [2 1]\n",
      "[2 1]\n",
      "Exploring\n",
      "Selected action  [2 1]\n",
      "[2 1]\n",
      "Exploring\n",
      "Selected action  [3 2]\n",
      "[3 2]\n",
      "Exploring\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Exploring\n",
      "Selected action  [1 2]\n",
      "[1 2]\n",
      "Exploring\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Exploring\n",
      "Selected action  [0 4]\n",
      "[0 4]\n",
      "Exploring\n",
      "Selected action  [4 2]\n",
      "[4 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 2517.8843\n",
      "rewards:  -34.0 q-value:  0\n",
      "loss: [2517.88427734375]\n",
      "Exploring\n",
      "Selected action  [3 2]\n",
      "[3 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 57us/step - loss: 2463.1841\n",
      "rewards:  -38.0 q-value:  0\n",
      "loss: [2463.18408203125]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 42us/step - loss: 2569.9927\n",
      "rewards:  -43.0 q-value:  0\n",
      "loss: [2569.99267578125]\n",
      "Exploring\n",
      "Selected action  [3 2]\n",
      "[3 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 62us/step - loss: 2523.3174\n",
      "rewards:  -48.0 q-value:  0\n",
      "loss: [2523.3173828125]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 42us/step - loss: 2689.9441\n",
      "rewards:  -53.0 q-value:  0\n",
      "loss: [2689.944091796875]\n",
      "Exploring\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 36us/step - loss: 2412.2783\n",
      "rewards:  -33.0 q-value:  0\n",
      "loss: [2412.2783203125]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 41us/step - loss: 2556.7288\n",
      "rewards:  -5.0 q-value:  0\n",
      "loss: [2556.728759765625]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 41us/step - loss: 2218.4487\n",
      "rewards:  -9.0 q-value:  0\n",
      "loss: [2218.44873046875]\n",
      "Exploring\n",
      "Selected action  [3 2]\n",
      "[3 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 77us/step - loss: 2297.4575\n",
      "rewards:  -24.0 q-value:  0\n",
      "loss: [2297.45751953125]\n",
      "Exploring\n",
      "Selected action  [2 1]\n",
      "[2 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 64us/step - loss: 2055.1763\n",
      "rewards:  8.0 q-value:  0\n",
      "loss: [2055.17626953125]\n",
      "Exploring\n",
      "Selected action  [0 4]\n",
      "[0 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 69us/step - loss: 2351.1450\n",
      "rewards:  -23.0 q-value:  0\n",
      "loss: [2351.14501953125]\n",
      "Exploring\n",
      "Selected action  [3 0]\n",
      "[3 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 53us/step - loss: 1967.6360\n",
      "rewards:  -44.0 q-value:  0\n",
      "loss: [1967.635986328125]\n",
      "Exploring\n",
      "Selected action  [2 1]\n",
      "[2 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 60us/step - loss: 2342.4351\n",
      "rewards:  -41.0 q-value:  0\n",
      "loss: [2342.43505859375]\n",
      "Exploring\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 56us/step - loss: 2255.9197\n",
      "rewards:  -37.0 q-value:  0\n",
      "loss: [2255.919677734375]\n",
      "Exploring\n",
      "Selected action  [3 2]\n",
      "[3 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 48us/step - loss: 2219.8923\n",
      "rewards:  -5.0 q-value:  0\n",
      "loss: [2219.892333984375]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 55us/step - loss: 2206.1929\n",
      "rewards:  -27.0 q-value:  0\n",
      "loss: [2206.19287109375]\n",
      "Exploring\n",
      "Selected action  [1 2]\n",
      "[1 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 46us/step - loss: 2346.3196\n",
      "rewards:  -8.0 q-value:  0\n",
      "loss: [2346.319580078125]\n",
      "Exploring\n",
      "Selected action  [4 2]\n",
      "[4 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 49us/step - loss: 2252.4155\n",
      "rewards:  -8.0 q-value:  0\n",
      "loss: [2252.41552734375]\n",
      "Exploring\n",
      "Selected action  [3 0]\n",
      "[3 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 42us/step - loss: 1876.0527\n",
      "rewards:  -32.0 q-value:  0\n",
      "loss: [1876.052734375]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 47us/step - loss: 1844.2572\n",
      "rewards:  -36.0 q-value:  0\n",
      "loss: [1844.2572021484375]\n",
      "Exploring\n",
      "Selected action  [0 4]\n",
      "[0 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 46us/step - loss: 1976.9878\n",
      "rewards:  -32.0 q-value:  0\n",
      "loss: [1976.98779296875]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 49us/step - loss: 2042.5730\n",
      "rewards:  -18.0 q-value:  0\n",
      "loss: [2042.572998046875]\n",
      "Exploring\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 49us/step - loss: 1832.9220\n",
      "rewards:  -24.0 q-value:  0\n",
      "loss: [1832.9219970703125]\n",
      "Exploring\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 66us/step - loss: 2018.5100\n",
      "rewards:  -27.0 q-value:  0\n",
      "loss: [2018.510009765625]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 56us/step - loss: 1927.0957\n",
      "rewards:  -42.0 q-value:  0\n",
      "loss: [1927.095703125]\n",
      "Exploring\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 70us/step - loss: 2094.1948\n",
      "rewards:  -52.0 q-value:  0\n",
      "loss: [2094.19482421875]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 69us/step - loss: 2000.0212\n",
      "rewards:  -57.0 q-value:  0\n",
      "loss: [2000.021240234375]\n",
      "Exploring\n",
      "Selected action  [4 2]\n",
      "[4 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 54us/step - loss: 1866.8167\n",
      "rewards:  -62.0 q-value:  0\n",
      "loss: [1866.816650390625]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 49us/step - loss: 1839.8893\n",
      "rewards:  -62.0 q-value:  0\n",
      "loss: [1839.8892822265625]\n",
      "Exploring\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 70us/step - loss: 1806.4199\n",
      "rewards:  -50.0 q-value:  0\n",
      "loss: [1806.419921875]\n",
      "Exploring\n",
      "Selected action  [4 2]\n",
      "[4 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 52us/step - loss: 2431.6255\n",
      "rewards:  -82.0 q-value:  0\n",
      "loss: [2431.62548828125]\n",
      "Exploring\n",
      "Selected action  [0 2]\n",
      "[0 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 60us/step - loss: 2095.0898\n",
      "rewards:  -87.0 q-value:  0\n",
      "loss: [2095.08984375]\n",
      "Exploring\n",
      "Selected action  [0 2]\n",
      "[0 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 72us/step - loss: 1983.7886\n",
      "rewards:  -89.0 q-value:  0\n",
      "loss: [1983.78857421875]\n",
      "Exploring\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 53us/step - loss: 2322.9436\n",
      "rewards:  -94.0 q-value:  0\n",
      "loss: [2322.943603515625]\n",
      "Exploring\n",
      "Selected action  [0 2]\n",
      "[0 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 51us/step - loss: 2402.4343\n",
      "rewards:  -85.0 q-value:  0\n",
      "loss: [2402.434326171875]\n",
      "Exploring\n",
      "Selected action  [4 2]\n",
      "[4 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 58us/step - loss: 2619.3298\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rewards:  -87.0 q-value:  0\n",
      "loss: [2619.329833984375]\n",
      "Exploring\n",
      "Selected action  [1 2]\n",
      "[1 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 58us/step - loss: 3141.4646\n",
      "rewards:  -92.0 q-value:  0\n",
      "loss: [3141.464599609375]\n",
      "Exploring\n",
      "Selected action  [3 2]\n",
      "[3 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 60us/step - loss: 2344.7761\n",
      "rewards:  -95.0 q-value:  0\n",
      "loss: [2344.776123046875]\n",
      "Exploring\n",
      "Selected action  [2 1]\n",
      "[2 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 56us/step - loss: 2387.7559\n",
      "rewards:  -71.0 q-value:  0\n",
      "loss: [2387.755859375]\n",
      "Exploring\n",
      "Selected action  [3 2]\n",
      "[3 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 75us/step - loss: 2557.4382\n",
      "rewards:  -61.0 q-value:  0\n",
      "loss: [2557.438232421875]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 40us/step - loss: 2769.4766\n",
      "rewards:  -48.0 q-value:  0\n",
      "loss: [2769.4765625]\n",
      "Exploring\n",
      "Selected action  [3 0]\n",
      "[3 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 63us/step - loss: 3269.5984\n",
      "rewards:  -49.0 q-value:  0\n",
      "loss: [3269.598388671875]\n",
      "Exploring\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 62us/step - loss: 2326.5312\n",
      "rewards:  -56.0 q-value:  0\n",
      "loss: [2326.53125]\n",
      "Exploring\n",
      "Selected action  [2 1]\n",
      "[2 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 92us/step - loss: 2720.6753\n",
      "rewards:  -32.0 q-value:  0\n",
      "loss: [2720.67529296875]\n",
      "Exploring\n",
      "Selected action  [1 2]\n",
      "[1 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 55us/step - loss: 2776.5193\n",
      "rewards:  -16.0 q-value:  0\n",
      "loss: [2776.519287109375]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 63us/step - loss: 2329.9004\n",
      "rewards:  -8.0 q-value:  0\n",
      "loss: [2329.900390625]\n",
      "Exploring\n",
      "Selected action  [4 2]\n",
      "[4 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 48us/step - loss: 2611.9717\n",
      "rewards:  0.0 q-value:  0\n",
      "loss: [2611.9716796875]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 88us/step - loss: 2257.1863\n",
      "rewards:  -5.0 q-value:  0\n",
      "loss: [2257.186279296875]\n",
      "Exploring\n",
      "Selected action  [1 2]\n",
      "[1 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 80us/step - loss: 2718.9827\n",
      "rewards:  -7.0 q-value:  0\n",
      "loss: [2718.982666015625]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 54us/step - loss: 2454.1963\n",
      "rewards:  -12.0 q-value:  0\n",
      "loss: [2454.1962890625]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 47us/step - loss: 2772.2886\n",
      "rewards:  -17.0 q-value:  0\n",
      "loss: [2772.28857421875]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 62us/step - loss: 2485.0942\n",
      "rewards:  -22.0 q-value:  0\n",
      "loss: [2485.09423828125]\n",
      "Exploring\n",
      "Selected action  [4 2]\n",
      "[4 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 54us/step - loss: 2360.2366\n",
      "rewards:  -14.0 q-value:  0\n",
      "loss: [2360.236572265625]\n",
      "Exploring\n",
      "Selected action  [3 0]\n",
      "[3 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 68us/step - loss: 2821.2664\n",
      "rewards:  -19.0 q-value:  0\n",
      "loss: [2821.266357421875]\n",
      "Exploring\n",
      "Selected action  [3 2]\n",
      "[3 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 62us/step - loss: 2314.5068\n",
      "rewards:  -29.0 q-value:  0\n",
      "loss: [2314.5068359375]\n",
      "Exploring\n",
      "Selected action  [3 0]\n",
      "[3 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 54us/step - loss: 2759.3062\n",
      "rewards:  -39.0 q-value:  0\n",
      "loss: [2759.30615234375]\n",
      "Exploring\n",
      "Selected action  [1 2]\n",
      "[1 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 69us/step - loss: 2534.1760\n",
      "rewards:  -17.0 q-value:  0\n",
      "loss: [2534.176025390625]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 52us/step - loss: 2264.5515\n",
      "rewards:  -13.0 q-value:  0\n",
      "loss: [2264.551513671875]\n",
      "Exploring\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 56us/step - loss: 2083.3860\n",
      "rewards:  -8.0 q-value:  0\n",
      "loss: [2083.385986328125]\n",
      "Exploring\n",
      "Selected action  [3 2]\n",
      "[3 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 81us/step - loss: 2610.7876\n",
      "rewards:  4.0 q-value:  0\n",
      "loss: [2610.78759765625]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 49us/step - loss: 2094.7073\n",
      "rewards:  -1.0 q-value:  0\n",
      "loss: [2094.707275390625]\n",
      "Exploring\n",
      "Selected action  [1 2]\n",
      "[1 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 65us/step - loss: 2193.2695\n",
      "rewards:  -13.0 q-value:  0\n",
      "loss: [2193.26953125]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 52us/step - loss: 1526.1045\n",
      "rewards:  -13.0 q-value:  0\n",
      "loss: [1526.1044921875]\n",
      "Exploring\n",
      "Selected action  [1 2]\n",
      "[1 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 65us/step - loss: 2019.8370\n",
      "rewards:  27.0 q-value:  0\n",
      "loss: [2019.8370361328125]\n",
      "Exploring\n",
      "Selected action  [2 1]\n",
      "[2 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 74us/step - loss: 2371.8828\n",
      "rewards:  63.0 q-value:  0\n",
      "loss: [2371.8828125]\n",
      "Exploring\n",
      "Selected action  [3 2]\n",
      "[3 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 76us/step - loss: 2272.8120\n",
      "rewards:  85.0 q-value:  0\n",
      "loss: [2272.81201171875]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 70us/step - loss: 2596.0137\n",
      "rewards:  80.0 q-value:  0\n",
      "loss: [2596.013671875]\n",
      "Exploring\n",
      "Selected action  [0 2]\n",
      "[0 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 60us/step - loss: 3272.7827\n",
      "rewards:  100.0 q-value:  0\n",
      "loss: [3272.78271484375]\n",
      "Exploiting\n",
      "Selected action  [0 2]\n",
      "[0 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 55us/step - loss: 3453.8774\n",
      "rewards:  93.0 q-value:  [[0.9283041  1.2938455  0.         1.0928619  0.         0.9336303\n",
      "  0.         0.         1.1887553  1.1735191  0.83446306 0.\n",
      "  0.93673575 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.        ]]\n",
      "loss: [3453.87744140625]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 71us/step - loss: 2365.5896\n",
      "rewards:  88.0 q-value:  0\n",
      "loss: [2365.589599609375]\n",
      "Exploring\n",
      "Selected action  [4 2]\n",
      "[4 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 45us/step - loss: 2173.2915\n",
      "rewards:  89.0 q-value:  0\n",
      "loss: [2173.29150390625]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 65us/step - loss: 2745.5791\n",
      "rewards:  84.0 q-value:  0\n",
      "loss: [2745.5791015625]\n",
      "Exploring\n",
      "Selected action  [3 2]\n",
      "[3 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 63us/step - loss: 3021.9136\n",
      "rewards:  116.0 q-value:  0\n",
      "loss: [3021.91357421875]\n",
      "Exploring\n",
      "Selected action  [3 0]\n",
      "[3 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 67us/step - loss: 3246.8486\n",
      "rewards:  118.0 q-value:  0\n",
      "loss: [3246.8486328125]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 68us/step - loss: 3215.1538\n",
      "rewards:  116.0 q-value:  0\n",
      "loss: [3215.15380859375]\n",
      "Exploring\n",
      "Selected action  [3 0]\n",
      "[3 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 89us/step - loss: 2895.8809\n",
      "rewards:  106.0 q-value:  0\n",
      "loss: [2895.880859375]\n",
      "Exploring\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 58us/step - loss: 2480.1421\n",
      "rewards:  104.0 q-value:  0\n",
      "loss: [2480.14208984375]\n",
      "Exploring\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 73us/step - loss: 3338.0771\n",
      "rewards:  88.0 q-value:  0\n",
      "loss: [3338.0771484375]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 72us/step - loss: 2937.1721\n",
      "rewards:  83.0 q-value:  0\n",
      "loss: [2937.172119140625]\n",
      "Exploring\n",
      "Selected action  [2 1]\n",
      "[2 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 73us/step - loss: 2607.1304\n",
      "rewards:  77.0 q-value:  0\n",
      "loss: [2607.13037109375]\n",
      "Exploring\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 72us/step - loss: 2708.0605\n",
      "rewards:  81.0 q-value:  0\n",
      "loss: [2708.060546875]\n",
      "Exploring\n",
      "Selected action  [0 2]\n",
      "[0 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 63us/step - loss: 3940.9434\n",
      "rewards:  79.0 q-value:  0\n",
      "loss: [3940.943359375]\n",
      "Exploring\n",
      "Selected action  [1 2]\n",
      "[1 2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 69us/step - loss: 3435.1157\n",
      "rewards:  74.0 q-value:  0\n",
      "loss: [3435.11572265625]\n",
      "Exploring\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 63us/step - loss: 4009.5186\n",
      "rewards:  68.0 q-value:  0\n",
      "loss: [4009.5185546875]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 54us/step - loss: 3403.7549\n",
      "rewards:  86.0 q-value:  0\n",
      "loss: [3403.7548828125]\n",
      "Exploring\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 62us/step - loss: 5108.9951\n",
      "rewards:  114.0 q-value:  0\n",
      "loss: [5108.9951171875]\n",
      "Number of actions available 7\n",
      "Episode : 1\n",
      "Exploring\n",
      "Selected action  [4 2]\n",
      "[4 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 73us/step - loss: 2993.8853\n",
      "rewards:  10.0 q-value:  0\n",
      "loss: [2993.88525390625]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 80us/step - loss: 2605.1182\n",
      "rewards:  5.0 q-value:  0\n",
      "loss: [2605.1181640625]\n",
      "Exploring\n",
      "Selected action  [4 1]\n",
      "[4 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 70us/step - loss: 4047.5864\n",
      "rewards:  18.0 q-value:  0\n",
      "loss: [4047.58642578125]\n",
      "Exploring\n",
      "Selected action  [0 4]\n",
      "[0 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 58us/step - loss: 4246.8330\n",
      "rewards:  12.0 q-value:  0\n",
      "loss: [4246.8330078125]\n",
      "Exploring\n",
      "Selected action  [4 2]\n",
      "[4 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 62us/step - loss: 4494.9956\n",
      "rewards:  12.0 q-value:  0\n",
      "loss: [4494.99560546875]\n",
      "Exploring\n",
      "Selected action  [3 1]\n",
      "[3 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 46us/step - loss: 3525.0269\n",
      "rewards:  -28.0 q-value:  0\n",
      "loss: [3525.02685546875]\n",
      "Exploring\n",
      "Selected action  [4 1]\n",
      "[4 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 66us/step - loss: 3568.6714\n",
      "rewards:  -30.0 q-value:  0\n",
      "loss: [3568.67138671875]\n",
      "Exploring\n",
      "Selected action  [4 2]\n",
      "[4 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 64us/step - loss: 2625.2354\n",
      "rewards:  -37.0 q-value:  0\n",
      "loss: [2625.2353515625]\n",
      "Exploring\n",
      "Selected action  [4 2]\n",
      "[4 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 74us/step - loss: 3342.0664\n",
      "rewards:  -39.0 q-value:  0\n",
      "loss: [3342.06640625]\n",
      "Exploring\n",
      "Selected action  [4 2]\n",
      "[4 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 59us/step - loss: 5016.6924\n",
      "rewards:  -41.0 q-value:  0\n",
      "loss: [5016.6923828125]\n",
      "Exploring\n",
      "Selected action  [3 1]\n",
      "[3 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 52us/step - loss: 3401.8848\n",
      "rewards:  -51.0 q-value:  0\n",
      "loss: [3401.884765625]\n",
      "Exploring\n",
      "Selected action  [4 2]\n",
      "[4 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 49us/step - loss: 5947.8896\n",
      "rewards:  -67.0 q-value:  0\n",
      "loss: [5947.8896484375]\n",
      "Exploring\n",
      "Selected action  [3 1]\n",
      "[3 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 59us/step - loss: 4956.6108\n",
      "rewards:  -73.0 q-value:  0\n",
      "loss: [4956.61083984375]\n",
      "Exploring\n",
      "Selected action  [3 1]\n",
      "[3 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 64us/step - loss: 5035.3706\n",
      "rewards:  -74.0 q-value:  0\n",
      "loss: [5035.37060546875]\n",
      "Exploring\n",
      "Selected action  [0 4]\n",
      "[0 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 63us/step - loss: 5776.7031\n",
      "rewards:  -115.0 q-value:  0\n",
      "loss: [5776.703125]\n",
      "Exploring\n",
      "Selected action  [4 2]\n",
      "[4 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 57us/step - loss: 6624.1855\n",
      "rewards:  -91.0 q-value:  0\n",
      "loss: [6624.185546875]\n",
      "Exploring\n",
      "Selected action  [4 2]\n",
      "[4 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 61us/step - loss: 6136.1836\n",
      "rewards:  -93.0 q-value:  0\n",
      "loss: [6136.18359375]\n",
      "Exploring\n",
      "Selected action  [0 4]\n",
      "[0 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 50us/step - loss: 4684.2612\n",
      "rewards:  -91.0 q-value:  0\n",
      "loss: [4684.26123046875]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 49us/step - loss: 5861.8379\n",
      "rewards:  -96.0 q-value:  0\n",
      "loss: [5861.837890625]\n",
      "Exploring\n",
      "Selected action  [4 2]\n",
      "[4 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 53us/step - loss: 6416.6816\n",
      "rewards:  -126.0 q-value:  0\n",
      "loss: [6416.681640625]\n",
      "Exploring\n",
      "Selected action  [3 1]\n",
      "[3 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 57us/step - loss: 6584.3281\n",
      "rewards:  -137.0 q-value:  0\n",
      "loss: [6584.328125]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 59us/step - loss: 10862.3848\n",
      "rewards:  -142.0 q-value:  0\n",
      "loss: [10862.384765625]\n",
      "Exploring\n",
      "Selected action  [0 4]\n",
      "[0 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 49us/step - loss: 7278.0918\n",
      "rewards:  -118.0 q-value:  0\n",
      "loss: [7278.091796875]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 67us/step - loss: 5600.4521\n",
      "rewards:  -123.0 q-value:  0\n",
      "loss: [5600.4521484375]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 41us/step - loss: 7720.4517\n",
      "rewards:  -128.0 q-value:  0\n",
      "loss: [7720.45166015625]\n",
      "Exploring\n",
      "Selected action  [2 3]\n",
      "[2 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 71us/step - loss: 8914.2695\n",
      "rewards:  -134.0 q-value:  0\n",
      "loss: [8914.26953125]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 46us/step - loss: 8983.5332\n",
      "rewards:  -139.0 q-value:  0\n",
      "loss: [8983.533203125]\n",
      "Exploring\n",
      "Selected action  [3 1]\n",
      "[3 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 55us/step - loss: 9489.5332\n",
      "rewards:  -146.0 q-value:  0\n",
      "loss: [9489.533203125]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 55us/step - loss: 12437.8730\n",
      "rewards:  -151.0 q-value:  0\n",
      "loss: [12437.873046875]\n",
      "Exploring\n",
      "Selected action  [2 3]\n",
      "[2 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 71us/step - loss: 10548.1113\n",
      "rewards:  -161.0 q-value:  0\n",
      "loss: [10548.111328125]\n",
      "Exploring\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 65us/step - loss: 12825.0645\n",
      "rewards:  -163.0 q-value:  0\n",
      "loss: [12825.064453125]\n",
      "Exploring\n",
      "Selected action  [4 2]\n",
      "[4 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 58us/step - loss: 7130.1016\n",
      "rewards:  -165.0 q-value:  0\n",
      "loss: [7130.1015625]\n",
      "Exploring\n",
      "Selected action  [4 1]\n",
      "[4 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 51us/step - loss: 11093.0859\n",
      "rewards:  -175.0 q-value:  0\n",
      "loss: [11093.0859375]\n",
      "Exploring\n",
      "Selected action  [0 4]\n",
      "[0 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 60us/step - loss: 7142.1953\n",
      "rewards:  -174.0 q-value:  0\n",
      "loss: [7142.1953125]\n",
      "Exploring\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 49us/step - loss: 11491.5527\n",
      "rewards:  -174.0 q-value:  0\n",
      "loss: [11491.552734375]\n",
      "Exploring\n",
      "Selected action  [3 1]\n",
      "[3 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 53us/step - loss: 11321.8066\n",
      "rewards:  -154.0 q-value:  0\n",
      "loss: [11321.806640625]\n",
      "Exploring\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 54us/step - loss: 9607.6826\n",
      "rewards:  -146.0 q-value:  0\n",
      "loss: [9607.6826171875]\n",
      "Exploring\n",
      "Selected action  [0 4]\n",
      "[0 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 59us/step - loss: 12728.3760\n",
      "rewards:  -152.0 q-value:  0\n",
      "loss: [12728.3759765625]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 61us/step - loss: 8221.4023\n",
      "rewards:  -157.0 q-value:  0\n",
      "loss: [8221.40234375]\n",
      "Exploring\n",
      "Selected action  [0 4]\n",
      "[0 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 66us/step - loss: 15865.1992\n",
      "rewards:  -153.0 q-value:  0\n",
      "loss: [15865.19921875]\n",
      "Exploring\n",
      "Selected action  [0 4]\n",
      "[0 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 69us/step - loss: 14391.4805\n",
      "rewards:  -154.0 q-value:  0\n",
      "loss: [14391.48046875]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 63us/step - loss: 13023.0459\n",
      "rewards:  -159.0 q-value:  0\n",
      "loss: [13023.0458984375]\n",
      "Exploring\n",
      "Selected action  [0 4]\n",
      "[0 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 64us/step - loss: 13604.3730\n",
      "rewards:  -155.0 q-value:  0\n",
      "loss: [13604.373046875]\n",
      "Exploring\n",
      "Selected action  [0 4]\n",
      "[0 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 49us/step - loss: 14128.9072\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rewards:  -156.0 q-value:  0\n",
      "loss: [14128.9072265625]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 57us/step - loss: 20098.0508\n",
      "rewards:  -161.0 q-value:  0\n",
      "loss: [20098.05078125]\n",
      "Exploring\n",
      "Selected action  [4 2]\n",
      "[4 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 74us/step - loss: 14830.4756\n",
      "rewards:  -158.0 q-value:  0\n",
      "loss: [14830.4755859375]\n",
      "Exploring\n",
      "Selected action  [4 2]\n",
      "[4 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 69us/step - loss: 15297.3359\n",
      "rewards:  -160.0 q-value:  0\n",
      "loss: [15297.3359375]\n",
      "Exploring\n",
      "Selected action  [3 1]\n",
      "[3 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 67us/step - loss: 19351.1230\n",
      "rewards:  -176.0 q-value:  0\n",
      "loss: [19351.123046875]\n",
      "Exploring\n",
      "Selected action  [3 1]\n",
      "[3 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 56us/step - loss: 13054.6504\n",
      "rewards:  -177.0 q-value:  0\n",
      "loss: [13054.650390625]\n",
      "Exploring\n",
      "Selected action  [3 1]\n",
      "[3 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 64us/step - loss: 12498.2197\n",
      "rewards:  -178.0 q-value:  0\n",
      "loss: [12498.2197265625]\n",
      "Exploring\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 89us/step - loss: 22153.8262\n",
      "rewards:  -166.0 q-value:  0\n",
      "loss: [22153.826171875]\n",
      "Exploring\n",
      "Selected action  [3 1]\n",
      "[3 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 55us/step - loss: 20494.9961\n",
      "rewards:  -154.0 q-value:  0\n",
      "loss: [20494.99609375]\n",
      "Exploring\n",
      "Selected action  [4 1]\n",
      "[4 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 72us/step - loss: 13633.5215\n",
      "rewards:  -160.0 q-value:  0\n",
      "loss: [13633.521484375]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 58us/step - loss: 20261.4277\n",
      "rewards:  -165.0 q-value:  0\n",
      "loss: [20261.427734375]\n",
      "Exploring\n",
      "Selected action  [4 2]\n",
      "[4 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 46us/step - loss: 19134.7559\n",
      "rewards:  -161.0 q-value:  0\n",
      "loss: [19134.755859375]\n",
      "Exploring\n",
      "Selected action  [4 2]\n",
      "[4 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 41us/step - loss: 15618.9473\n",
      "rewards:  -162.0 q-value:  0\n",
      "loss: [15618.947265625]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 69us/step - loss: 14455.6836\n",
      "rewards:  -167.0 q-value:  0\n",
      "loss: [14455.68359375]\n",
      "Exploring\n",
      "Selected action  [4 1]\n",
      "[4 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 49us/step - loss: 20051.8359\n",
      "rewards:  -167.0 q-value:  0\n",
      "loss: [20051.8359375]\n",
      "Exploring\n",
      "Selected action  [4 1]\n",
      "[4 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 64us/step - loss: 21072.9805\n",
      "rewards:  -167.0 q-value:  0\n",
      "loss: [21072.98046875]\n",
      "Exploring\n",
      "Selected action  [3 1]\n",
      "[3 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 74us/step - loss: 13185.6152\n",
      "rewards:  -171.0 q-value:  0\n",
      "loss: [13185.615234375]\n",
      "Exploring\n",
      "Selected action  [4 1]\n",
      "[4 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 59us/step - loss: 14903.1250\n",
      "rewards:  -171.0 q-value:  0\n",
      "loss: [14903.125]\n",
      "Exploring\n",
      "Selected action  [4 1]\n",
      "[4 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 55us/step - loss: 22156.2422\n",
      "rewards:  -171.0 q-value:  0\n",
      "loss: [22156.2421875]\n",
      "Exploring\n",
      "Selected action  [0 4]\n",
      "[0 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 46us/step - loss: 29449.4883\n",
      "rewards:  -157.0 q-value:  0\n",
      "loss: [29449.48828125]\n",
      "Exploring\n",
      "Selected action  [0 4]\n",
      "[0 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 61us/step - loss: 14285.5732\n",
      "rewards:  -158.0 q-value:  0\n",
      "loss: [14285.5732421875]\n",
      "Exploring\n",
      "Selected action  [3 1]\n",
      "[3 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 55us/step - loss: 14440.1602\n",
      "rewards:  -153.0 q-value:  0\n",
      "loss: [14440.16015625]\n",
      "Exploring\n",
      "Selected action  [0 4]\n",
      "[0 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 65us/step - loss: 12312.8633\n",
      "rewards:  -193.0 q-value:  0\n",
      "loss: [12312.86328125]\n",
      "Exploring\n",
      "Selected action  [4 2]\n",
      "[4 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 65us/step - loss: 20851.5781\n",
      "rewards:  -161.0 q-value:  0\n",
      "loss: [20851.578125]\n",
      "Exploring\n",
      "Selected action  [3 1]\n",
      "[3 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 68us/step - loss: 17989.8262\n",
      "rewards:  -197.0 q-value:  0\n",
      "loss: [17989.826171875]\n",
      "Exploring\n",
      "Selected action  [3 1]\n",
      "[3 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 58us/step - loss: 20616.2168\n",
      "rewards:  -198.0 q-value:  0\n",
      "loss: [20616.216796875]\n",
      "Exploring\n",
      "Selected action  [4 1]\n",
      "[4 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 55us/step - loss: 12882.1865\n",
      "rewards:  -200.0 q-value:  0\n",
      "loss: [12882.1865234375]\n",
      "Exploring\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 48us/step - loss: 20727.7070\n",
      "rewards:  -188.0 q-value:  0\n",
      "loss: [20727.70703125]\n",
      "Exploring\n",
      "Selected action  [0 4]\n",
      "[0 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 48us/step - loss: 12855.1953\n",
      "rewards:  -181.0 q-value:  0\n",
      "loss: [12855.1953125]\n",
      "Exploring\n",
      "Selected action  [0 4]\n",
      "[0 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 56us/step - loss: 20680.5430\n",
      "rewards:  -182.0 q-value:  0\n",
      "loss: [20680.54296875]\n",
      "Exploring\n",
      "Selected action  [2 3]\n",
      "[2 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 50us/step - loss: 24548.5918\n",
      "rewards:  -138.0 q-value:  0\n",
      "loss: [24548.591796875]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 62us/step - loss: 17152.3613\n",
      "rewards:  -143.0 q-value:  0\n",
      "loss: [17152.361328125]\n",
      "Exploring\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 55us/step - loss: 19082.4180\n",
      "rewards:  -155.0 q-value:  0\n",
      "loss: [19082.41796875]\n",
      "Exploring\n",
      "Selected action  [4 2]\n",
      "[4 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 59us/step - loss: 15936.8418\n",
      "rewards:  -185.0 q-value:  0\n",
      "loss: [15936.841796875]\n",
      "Exploring\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 61us/step - loss: 25882.7773\n",
      "rewards:  -187.0 q-value:  0\n",
      "loss: [25882.77734375]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 47us/step - loss: 19526.3633\n",
      "rewards:  -192.0 q-value:  0\n",
      "loss: [19526.36328125]\n",
      "Exploring\n",
      "Selected action  [0 4]\n",
      "[0 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 69us/step - loss: 24490.6816\n",
      "rewards:  -192.0 q-value:  0\n",
      "loss: [24490.681640625]\n",
      "Exploring\n",
      "Selected action  [4 1]\n",
      "[4 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 56us/step - loss: 17170.3652\n",
      "rewards:  -192.0 q-value:  0\n",
      "loss: [17170.365234375]\n",
      "Exploring\n",
      "Selected action  [4 2]\n",
      "[4 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 57us/step - loss: 16243.0977\n",
      "rewards:  -192.0 q-value:  0\n",
      "loss: [16243.09765625]\n",
      "Exploring\n",
      "Selected action  [4 2]\n",
      "[4 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 67us/step - loss: 18197.9297\n",
      "rewards:  -192.0 q-value:  0\n",
      "loss: [18197.9296875]\n",
      "Exploring\n",
      "Selected action  [4 1]\n",
      "[4 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 65us/step - loss: 37056.5625\n",
      "rewards:  -192.0 q-value:  0\n",
      "loss: [37056.5625]\n",
      "Exploring\n",
      "Selected action  [4 2]\n",
      "[4 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 54us/step - loss: 24052.8789\n",
      "rewards:  -192.0 q-value:  0\n",
      "loss: [24052.87890625]\n",
      "Exploring\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 49us/step - loss: 23147.8281\n",
      "rewards:  -194.0 q-value:  0\n",
      "loss: [23147.828125]\n",
      "Exploring\n",
      "Selected action  [0 4]\n",
      "[0 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 54us/step - loss: 21048.8574\n",
      "rewards:  -205.0 q-value:  0\n",
      "loss: [21048.857421875]\n",
      "Exploring\n",
      "Selected action  [4 1]\n",
      "[4 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 49us/step - loss: 24905.5977\n",
      "rewards:  -197.0 q-value:  0\n",
      "loss: [24905.59765625]\n",
      "Exploring\n",
      "Selected action  [4 1]\n",
      "[4 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 75us/step - loss: 20264.7480\n",
      "rewards:  -199.0 q-value:  0\n",
      "loss: [20264.748046875]\n",
      "Exploring\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 48us/step - loss: 20708.3594\n",
      "rewards:  -191.0 q-value:  0\n",
      "loss: [20708.359375]\n",
      "Exploring\n",
      "Selected action  [4 1]\n",
      "[4 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 51us/step - loss: 14787.0527\n",
      "rewards:  -193.0 q-value:  0\n",
      "loss: [14787.052734375]\n",
      "Exploring\n",
      "Selected action  [4 1]\n",
      "[4 1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 58us/step - loss: 22205.3438\n",
      "rewards:  -195.0 q-value:  0\n",
      "loss: [22205.34375]\n",
      "Exploring\n",
      "Selected action  [4 2]\n",
      "[4 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 49us/step - loss: 27353.1836\n",
      "rewards:  -185.0 q-value:  0\n",
      "loss: [27353.18359375]\n",
      "Exploring\n",
      "Selected action  [4 1]\n",
      "[4 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 63us/step - loss: 39006.6328\n",
      "rewards:  -177.0 q-value:  0\n",
      "loss: [39006.6328125]\n",
      "Exploring\n",
      "Selected action  [4 1]\n",
      "[4 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 68us/step - loss: 17760.6992\n",
      "rewards:  -179.0 q-value:  0\n",
      "loss: [17760.69921875]\n",
      "Exploring\n",
      "Selected action  [4 2]\n",
      "[4 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 69us/step - loss: 16186.4990\n",
      "rewards:  -186.0 q-value:  0\n",
      "loss: [16186.4990234375]\n",
      "Exploring\n",
      "Selected action  [4 2]\n",
      "[4 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 39us/step - loss: 35986.2578\n",
      "rewards:  -188.0 q-value:  0\n",
      "loss: [35986.2578125]\n",
      "Exploring\n",
      "Selected action  [2 3]\n",
      "[2 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 61us/step - loss: 31172.1094\n",
      "rewards:  -180.0 q-value:  0\n",
      "loss: [31172.109375]\n",
      "Exploring\n",
      "Selected action  [2 3]\n",
      "[2 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 70us/step - loss: 35223.7891\n",
      "rewards:  -186.0 q-value:  0\n",
      "loss: [35223.7890625]\n",
      "Exploiting\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 67us/step - loss: 21058.2852\n",
      "rewards:  -191.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [21058.28515625]\n",
      "Exploring\n",
      "Selected action  [2 3]\n",
      "[2 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 43us/step - loss: 17084.4883\n",
      "rewards:  -213.0 q-value:  0\n",
      "loss: [17084.48828125]\n",
      "Exploring\n",
      "Selected action  [3 1]\n",
      "[3 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 55us/step - loss: 32301.9219\n",
      "rewards:  -209.0 q-value:  0\n",
      "loss: [32301.921875]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 48us/step - loss: 25944.3242\n",
      "rewards:  -214.0 q-value:  0\n",
      "loss: [25944.32421875]\n",
      "Exploring\n",
      "Selected action  [4 1]\n",
      "[4 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 74us/step - loss: 21190.2070\n",
      "rewards:  -207.0 q-value:  0\n",
      "loss: [21190.20703125]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 46us/step - loss: 29936.9863\n",
      "rewards:  -212.0 q-value:  0\n",
      "loss: [29936.986328125]\n",
      "Exploring\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 55us/step - loss: 18749.2539\n",
      "rewards:  -228.0 q-value:  0\n",
      "loss: [18749.25390625]\n",
      "Exploring\n",
      "Selected action  [4 2]\n",
      "[4 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 49us/step - loss: 22436.3711\n",
      "rewards:  -265.0 q-value:  0\n",
      "loss: [22436.37109375]\n",
      "Exploring\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 69us/step - loss: 22886.3320\n",
      "rewards:  -266.0 q-value:  0\n",
      "loss: [22886.33203125]\n",
      "Exploring\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 56us/step - loss: 25230.4141\n",
      "rewards:  -267.0 q-value:  0\n",
      "loss: [25230.4140625]\n",
      "Exploring\n",
      "Selected action  [4 1]\n",
      "[4 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 48us/step - loss: 22301.2227\n",
      "rewards:  -276.0 q-value:  0\n",
      "loss: [22301.22265625]\n",
      "Exploring\n",
      "Selected action  [0 4]\n",
      "[0 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 49us/step - loss: 25687.6055\n",
      "rewards:  -262.0 q-value:  0\n",
      "loss: [25687.60546875]\n",
      "Exploring\n",
      "Selected action  [4 2]\n",
      "[4 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 57us/step - loss: 16714.4102\n",
      "rewards:  -262.0 q-value:  0\n",
      "loss: [16714.41015625]\n",
      "Exploring\n",
      "Selected action  [3 1]\n",
      "[3 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 78us/step - loss: 33365.3516\n",
      "rewards:  -268.0 q-value:  0\n",
      "loss: [33365.3515625]\n",
      "Exploring\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 66us/step - loss: 37964.7891\n",
      "rewards:  -260.0 q-value:  0\n",
      "loss: [37964.7890625]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 55us/step - loss: 22617.0977\n",
      "rewards:  -265.0 q-value:  0\n",
      "loss: [22617.09765625]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 61us/step - loss: 31313.7617\n",
      "rewards:  -270.0 q-value:  0\n",
      "loss: [31313.76171875]\n",
      "Exploring\n",
      "Selected action  [0 4]\n",
      "[0 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 53us/step - loss: 27150.7969\n",
      "rewards:  -266.0 q-value:  0\n",
      "loss: [27150.796875]\n",
      "Exploring\n",
      "Selected action  [4 2]\n",
      "[4 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 76us/step - loss: 33747.6250\n",
      "rewards:  -262.0 q-value:  0\n",
      "loss: [33747.625]\n",
      "Exploring\n",
      "Selected action  [3 1]\n",
      "[3 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 64us/step - loss: 33606.6250\n",
      "rewards:  -269.0 q-value:  0\n",
      "loss: [33606.625]\n",
      "Exploring\n",
      "Selected action  [0 4]\n",
      "[0 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 75us/step - loss: 17701.7266\n",
      "rewards:  -300.0 q-value:  0\n",
      "loss: [17701.7265625]\n",
      "Exploring\n",
      "Selected action  [4 2]\n",
      "[4 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 52us/step - loss: 16104.7314\n",
      "rewards:  -296.0 q-value:  0\n",
      "loss: [16104.7314453125]\n",
      "Exploring\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 58us/step - loss: 26732.2227\n",
      "rewards:  -343.0 q-value:  0\n",
      "loss: [26732.22265625]\n",
      "Exploring\n",
      "Selected action  [2 3]\n",
      "[2 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 63us/step - loss: 19204.2656\n",
      "rewards:  -347.0 q-value:  0\n",
      "loss: [19204.265625]\n",
      "Exploring\n",
      "Selected action  [2 3]\n",
      "[2 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 47us/step - loss: 23230.2227\n",
      "rewards:  -350.0 q-value:  0\n",
      "loss: [23230.22265625]\n",
      "Exploring\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 39us/step - loss: 39220.5859\n",
      "rewards:  -355.0 q-value:  0\n",
      "loss: [39220.5859375]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 54us/step - loss: 27197.4375\n",
      "rewards:  -360.0 q-value:  0\n",
      "loss: [27197.4375]\n",
      "Exploring\n",
      "Selected action  [2 3]\n",
      "[2 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 61us/step - loss: 28014.4648\n",
      "rewards:  -378.0 q-value:  0\n",
      "loss: [28014.46484375]\n",
      "Exploring\n",
      "Selected action  [3 1]\n",
      "[3 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 62us/step - loss: 23884.9551\n",
      "rewards:  -370.0 q-value:  0\n",
      "loss: [23884.955078125]\n",
      "Exploring\n",
      "Selected action  [4 1]\n",
      "[4 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 71us/step - loss: 17968.9727\n",
      "rewards:  -370.0 q-value:  0\n",
      "loss: [17968.97265625]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 56us/step - loss: 36892.6992\n",
      "rewards:  -375.0 q-value:  0\n",
      "loss: [36892.69921875]\n",
      "Exploring\n",
      "Selected action  [2 3]\n",
      "[2 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 75us/step - loss: 30951.8789\n",
      "rewards:  -364.0 q-value:  0\n",
      "loss: [30951.87890625]\n",
      "Exploiting\n",
      "Selected action  [2 3]\n",
      "[2 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 56us/step - loss: 25965.4590\n",
      "rewards:  -368.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [25965.458984375]\n",
      "Exploring\n",
      "Selected action  [3 1]\n",
      "[3 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 57us/step - loss: 24031.4297\n",
      "rewards:  -364.0 q-value:  0\n",
      "loss: [24031.4296875]\n",
      "Exploring\n",
      "Selected action  [3 1]\n",
      "[3 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 84us/step - loss: 25832.9883\n",
      "rewards:  -365.0 q-value:  0\n",
      "loss: [25832.98828125]\n",
      "Exploring\n",
      "Selected action  [4 1]\n",
      "[4 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 71us/step - loss: 26221.0859\n",
      "rewards:  -368.0 q-value:  0\n",
      "loss: [26221.0859375]\n",
      "Exploring\n",
      "Selected action  [0 4]\n",
      "[0 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 47us/step - loss: 19282.0879\n",
      "rewards:  -393.0 q-value:  0\n",
      "loss: [19282.087890625]\n",
      "Exploring\n",
      "Selected action  [0 4]\n",
      "[0 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 56us/step - loss: 19854.0586\n",
      "rewards:  -393.0 q-value:  0\n",
      "loss: [19854.05859375]\n",
      "Exploring\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 60us/step - loss: 22579.6055\n",
      "rewards:  -391.0 q-value:  0\n",
      "loss: [22579.60546875]\n",
      "Exploring\n",
      "Selected action  [2 3]\n",
      "[2 3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 48us/step - loss: 28318.3594\n",
      "rewards:  -396.0 q-value:  0\n",
      "loss: [28318.359375]\n",
      "Exploring\n",
      "Selected action  [2 3]\n",
      "[2 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 65us/step - loss: 39078.4492\n",
      "rewards:  -401.0 q-value:  0\n",
      "loss: [39078.44921875]\n",
      "Exploring\n",
      "Selected action  [4 1]\n",
      "[4 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 42us/step - loss: 30372.0781\n",
      "rewards:  -431.0 q-value:  0\n",
      "loss: [30372.078125]\n",
      "Exploring\n",
      "Selected action  [4 2]\n",
      "[4 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 69us/step - loss: 32530.2070\n",
      "rewards:  -427.0 q-value:  0\n",
      "loss: [32530.20703125]\n",
      "Exploring\n",
      "Selected action  [4 1]\n",
      "[4 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 74us/step - loss: 18169.9980\n",
      "rewards:  -432.0 q-value:  0\n",
      "loss: [18169.998046875]\n",
      "Exploring\n",
      "Selected action  [4 1]\n",
      "[4 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 57us/step - loss: 20846.3711\n",
      "rewards:  -432.0 q-value:  0\n",
      "loss: [20846.37109375]\n",
      "Exploring\n",
      "Selected action  [4 1]\n",
      "[4 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 56us/step - loss: 40392.1875\n",
      "rewards:  -432.0 q-value:  0\n",
      "loss: [40392.1875]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 48us/step - loss: 27385.6738\n",
      "rewards:  -437.0 q-value:  0\n",
      "loss: [27385.673828125]\n",
      "Exploring\n",
      "Selected action  [4 1]\n",
      "[4 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 65us/step - loss: 40680.3516\n",
      "rewards:  -437.0 q-value:  0\n",
      "loss: [40680.3515625]\n",
      "Exploring\n",
      "Selected action  [4 2]\n",
      "[4 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 73us/step - loss: 35958.7812\n",
      "rewards:  -433.0 q-value:  0\n",
      "loss: [35958.78125]\n",
      "Exploring\n",
      "Selected action  [4 1]\n",
      "[4 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 65us/step - loss: 42783.3750\n",
      "rewards:  -438.0 q-value:  0\n",
      "loss: [42783.375]\n",
      "Exploring\n",
      "Selected action  [4 2]\n",
      "[4 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 63us/step - loss: 36273.3125\n",
      "rewards:  -434.0 q-value:  0\n",
      "loss: [36273.3125]\n",
      "Exploring\n",
      "Selected action  [2 3]\n",
      "[2 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 78us/step - loss: 43718.5938\n",
      "rewards:  -434.0 q-value:  0\n",
      "loss: [43718.59375]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 55us/step - loss: 45027.2852\n",
      "rewards:  -439.0 q-value:  0\n",
      "loss: [45027.28515625]\n",
      "Exploring\n",
      "Selected action  [2 3]\n",
      "[2 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 80us/step - loss: 48546.5859\n",
      "rewards:  -464.0 q-value:  0\n",
      "loss: [48546.5859375]\n",
      "Exploring\n",
      "Selected action  [4 1]\n",
      "[4 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 45us/step - loss: 41250.1016\n",
      "rewards:  -494.0 q-value:  0\n",
      "loss: [41250.1015625]\n",
      "Exploring\n",
      "Selected action  [2 3]\n",
      "[2 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 55us/step - loss: 23004.0703\n",
      "rewards:  -534.0 q-value:  0\n",
      "loss: [23004.0703125]\n",
      "Exploring\n",
      "Selected action  [4 2]\n",
      "[4 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 59us/step - loss: 23488.6543\n",
      "rewards:  -564.0 q-value:  0\n",
      "loss: [23488.654296875]\n",
      "Exploring\n",
      "Selected action  [4 1]\n",
      "[4 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 52us/step - loss: 49702.1328\n",
      "rewards:  -564.0 q-value:  0\n",
      "loss: [49702.1328125]\n",
      "Exploring\n",
      "Selected action  [4 2]\n",
      "[4 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 67us/step - loss: 53676.6875\n",
      "rewards:  -564.0 q-value:  0\n",
      "loss: [53676.6875]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 51us/step - loss: 42201.3203\n",
      "rewards:  -569.0 q-value:  0\n",
      "loss: [42201.3203125]\n",
      "Exploring\n",
      "Selected action  [0 4]\n",
      "[0 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 69us/step - loss: 36631.3906\n",
      "rewards:  -545.0 q-value:  0\n",
      "loss: [36631.390625]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 58us/step - loss: 38465.7383\n",
      "rewards:  -550.0 q-value:  0\n",
      "loss: [38465.73828125]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 70us/step - loss: 57781.9453\n",
      "rewards:  -555.0 q-value:  0\n",
      "loss: [57781.9453125]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 60us/step - loss: 33805.1055\n",
      "rewards:  -560.0 q-value:  0\n",
      "loss: [33805.10546875]\n",
      "Exploring\n",
      "Selected action  [0 4]\n",
      "[0 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 61us/step - loss: 35744.5625\n",
      "rewards:  -556.0 q-value:  0\n",
      "loss: [35744.5625]\n",
      "Exploring\n",
      "Selected action  [4 1]\n",
      "[4 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 61us/step - loss: 36400.4922\n",
      "rewards:  -544.0 q-value:  0\n",
      "loss: [36400.4921875]\n",
      "Exploring\n",
      "Selected action  [4 1]\n",
      "[4 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 66us/step - loss: 80358.6094\n",
      "rewards:  -547.0 q-value:  0\n",
      "loss: [80358.609375]\n",
      "Exploring\n",
      "Selected action  [4 2]\n",
      "[4 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 63us/step - loss: 34504.3906\n",
      "rewards:  -545.0 q-value:  0\n",
      "loss: [34504.390625]\n",
      "Exploring\n",
      "Selected action  [0 4]\n",
      "[0 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 68us/step - loss: 65476.7617\n",
      "rewards:  -544.0 q-value:  0\n",
      "loss: [65476.76171875]\n",
      "Exploring\n",
      "Selected action  [2 3]\n",
      "[2 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 53us/step - loss: 46472.3008\n",
      "rewards:  -520.0 q-value:  0\n",
      "loss: [46472.30078125]\n",
      "Number of actions available 5\n",
      "Episode : 2\n",
      "Exploring\n",
      "Selected action  [0 2]\n",
      "[0 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 60us/step - loss: 54112.6758\n",
      "rewards:  -2.0 q-value:  0\n",
      "loss: [54112.67578125]\n",
      "Exploring\n",
      "Selected action  [4 1]\n",
      "[4 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 60us/step - loss: 40345.6328\n",
      "rewards:  6.0 q-value:  0\n",
      "loss: [40345.6328125]\n",
      "Exploring\n",
      "Selected action  [1 2]\n",
      "[1 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 82us/step - loss: 52631.2695\n",
      "rewards:  14.0 q-value:  0\n",
      "loss: [52631.26953125]\n",
      "Exploiting\n",
      "Selected action  [1 2]\n",
      "[1 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 54us/step - loss: 46487.1562\n",
      "rewards:  6.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [46487.15625]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 64us/step - loss: 56411.9023\n",
      "rewards:  1.0 q-value:  0\n",
      "loss: [56411.90234375]\n",
      "Exploring\n",
      "Selected action  [0 2]\n",
      "[0 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 61us/step - loss: 36905.6484\n",
      "rewards:  9.0 q-value:  0\n",
      "loss: [36905.6484375]\n",
      "Exploring\n",
      "Selected action  [1 2]\n",
      "[1 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 55us/step - loss: 58534.8906\n",
      "rewards:  4.0 q-value:  0\n",
      "loss: [58534.890625]\n",
      "Exploiting\n",
      "Selected action  [4 1]\n",
      "[4 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 58us/step - loss: 59732.2930\n",
      "rewards:  -14.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [59732.29296875]\n",
      "Exploring\n",
      "Selected action  [1 2]\n",
      "[1 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 68us/step - loss: 44784.8516\n",
      "rewards:  -10.0 q-value:  0\n",
      "loss: [44784.8515625]\n",
      "Exploring\n",
      "Selected action  [0 2]\n",
      "[0 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 83us/step - loss: 42696.9609\n",
      "rewards:  -12.0 q-value:  0\n",
      "loss: [42696.9609375]\n",
      "Exploring\n",
      "Selected action  [4 1]\n",
      "[4 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 59us/step - loss: 37656.8867\n",
      "rewards:  -22.0 q-value:  0\n",
      "loss: [37656.88671875]\n",
      "Exploring\n",
      "Selected action  [0 2]\n",
      "[0 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 46us/step - loss: 49640.6641\n",
      "rewards:  -34.0 q-value:  0\n",
      "loss: [49640.6640625]\n",
      "Exploiting\n",
      "Selected action  [3 4]\n",
      "[3 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 52us/step - loss: 39845.0312\n",
      "rewards:  -29.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [39845.03125]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 50us/step - loss: 50384.5156\n",
      "rewards:  -34.0 q-value:  0\n",
      "loss: [50384.515625]\n",
      "Exploring\n",
      "Selected action  [1 2]\n",
      "[1 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 60us/step - loss: 56545.4766\n",
      "rewards:  -24.0 q-value:  0\n",
      "loss: [56545.4765625]\n",
      "Exploring\n",
      "Selected action  [0 2]\n",
      "[0 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 63us/step - loss: 59688.8086\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rewards:  -30.0 q-value:  0\n",
      "loss: [59688.80859375]\n",
      "Exploring\n",
      "Selected action  [0 2]\n",
      "[0 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 53us/step - loss: 47449.8438\n",
      "rewards:  -36.0 q-value:  0\n",
      "loss: [47449.84375]\n",
      "Exploring\n",
      "Selected action  [4 1]\n",
      "[4 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 59us/step - loss: 57568.5859\n",
      "rewards:  -41.0 q-value:  0\n",
      "loss: [57568.5859375]\n",
      "Exploring\n",
      "Selected action  [3 4]\n",
      "[3 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 63us/step - loss: 46500.7266\n",
      "rewards:  -27.0 q-value:  0\n",
      "loss: [46500.7265625]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 67us/step - loss: 58281.5859\n",
      "rewards:  -32.0 q-value:  0\n",
      "loss: [58281.5859375]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 66us/step - loss: 32350.9844\n",
      "rewards:  -37.0 q-value:  0\n",
      "loss: [32350.984375]\n",
      "Exploring\n",
      "Selected action  [0 2]\n",
      "[0 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 46us/step - loss: 59393.5625\n",
      "rewards:  -29.0 q-value:  0\n",
      "loss: [59393.5625]\n",
      "Exploring\n",
      "Selected action  [0 2]\n",
      "[0 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 57us/step - loss: 51239.9258\n",
      "rewards:  -34.0 q-value:  0\n",
      "loss: [51239.92578125]\n",
      "Exploring\n",
      "Selected action  [3 4]\n",
      "[3 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 59us/step - loss: 30849.7969\n",
      "rewards:  -45.0 q-value:  0\n",
      "loss: [30849.796875]\n",
      "Exploring\n",
      "Selected action  [3 4]\n",
      "[3 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 53us/step - loss: 44718.4219\n",
      "rewards:  -51.0 q-value:  0\n",
      "loss: [44718.421875]\n",
      "Exploring\n",
      "Selected action  [0 2]\n",
      "[0 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 67us/step - loss: 32298.7773\n",
      "rewards:  -52.0 q-value:  0\n",
      "loss: [32298.77734375]\n",
      "Exploring\n",
      "Selected action  [0 2]\n",
      "[0 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 45us/step - loss: 49578.5117\n",
      "rewards:  -53.0 q-value:  0\n",
      "loss: [49578.51171875]\n",
      "Exploring\n",
      "Selected action  [3 4]\n",
      "[3 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 53us/step - loss: 57102.4258\n",
      "rewards:  -49.0 q-value:  0\n",
      "loss: [57102.42578125]\n",
      "Exploiting\n",
      "Selected action  [0 2]\n",
      "[0 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 62us/step - loss: 58365.7266\n",
      "rewards:  -52.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [58365.7265625]\n",
      "Exploring\n",
      "Selected action  [0 2]\n",
      "[0 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 40us/step - loss: 30958.8203\n",
      "rewards:  -55.0 q-value:  0\n",
      "loss: [30958.8203125]\n",
      "Exploring\n",
      "Selected action  [3 4]\n",
      "[3 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 53us/step - loss: 52136.8516\n",
      "rewards:  -68.0 q-value:  0\n",
      "loss: [52136.8515625]\n",
      "Exploring\n",
      "Selected action  [0 2]\n",
      "[0 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 62us/step - loss: 46344.5234\n",
      "rewards:  -54.0 q-value:  0\n",
      "loss: [46344.5234375]\n",
      "Exploring\n",
      "Selected action  [3 4]\n",
      "[3 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 74us/step - loss: 55057.3047\n",
      "rewards:  -60.0 q-value:  0\n",
      "loss: [55057.3046875]\n",
      "Exploring\n",
      "Selected action  [1 2]\n",
      "[1 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 76us/step - loss: 37608.6875\n",
      "rewards:  -28.0 q-value:  0\n",
      "loss: [37608.6875]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 66us/step - loss: 40255.8984\n",
      "rewards:  -33.0 q-value:  0\n",
      "loss: [40255.8984375]\n",
      "Exploring\n",
      "Selected action  [1 2]\n",
      "[1 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 60us/step - loss: 48300.1172\n",
      "rewards:  -45.0 q-value:  0\n",
      "loss: [48300.1171875]\n",
      "Exploring\n",
      "Selected action  [0 2]\n",
      "[0 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 76us/step - loss: 48788.1367\n",
      "rewards:  -48.0 q-value:  0\n",
      "loss: [48788.13671875]\n",
      "Exploring\n",
      "Selected action  [1 2]\n",
      "[1 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 42us/step - loss: 33736.7734\n",
      "rewards:  -49.0 q-value:  0\n",
      "loss: [33736.7734375]\n",
      "Exploring\n",
      "Selected action  [1 2]\n",
      "[1 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 64us/step - loss: 72108.5000\n",
      "rewards:  -50.0 q-value:  0\n",
      "loss: [72108.5]\n",
      "Exploring\n",
      "Selected action  [4 1]\n",
      "[4 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 46us/step - loss: 26646.3398\n",
      "rewards:  -50.0 q-value:  0\n",
      "loss: [26646.33984375]\n",
      "Exploring\n",
      "Selected action  [0 2]\n",
      "[0 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 59us/step - loss: 51211.3750\n",
      "rewards:  -69.0 q-value:  0\n",
      "loss: [51211.375]\n",
      "Exploring\n",
      "Selected action  [3 4]\n",
      "[3 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 48us/step - loss: 56033.1523\n",
      "rewards:  -83.0 q-value:  0\n",
      "loss: [56033.15234375]\n",
      "Exploring\n",
      "Selected action  [3 4]\n",
      "[3 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 55us/step - loss: 27818.3984\n",
      "rewards:  -85.0 q-value:  0\n",
      "loss: [27818.3984375]\n",
      "Exploring\n",
      "Selected action  [1 2]\n",
      "[1 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 67us/step - loss: 50005.2695\n",
      "rewards:  -54.0 q-value:  0\n",
      "loss: [50005.26953125]\n",
      "Exploiting\n",
      "Selected action  [4 1]\n",
      "[4 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 52us/step - loss: 47695.3906\n",
      "rewards:  -54.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [47695.390625]\n",
      "Exploring\n",
      "Selected action  [1 2]\n",
      "[1 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 58us/step - loss: 47463.1914\n",
      "rewards:  -46.0 q-value:  0\n",
      "loss: [47463.19140625]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 59us/step - loss: 38633.9688\n",
      "rewards:  -51.0 q-value:  0\n",
      "loss: [38633.96875]\n",
      "Exploring\n",
      "Selected action  [1 2]\n",
      "[1 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 57us/step - loss: 70395.0312\n",
      "rewards:  -63.0 q-value:  0\n",
      "loss: [70395.03125]\n",
      "Exploring\n",
      "Selected action  [4 1]\n",
      "[4 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 75us/step - loss: 77381.0625\n",
      "rewards:  -63.0 q-value:  0\n",
      "loss: [77381.0625]\n",
      "Exploring\n",
      "Selected action  [0 2]\n",
      "[0 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 47us/step - loss: 33484.2383\n",
      "rewards:  -67.0 q-value:  0\n",
      "loss: [33484.23828125]\n",
      "Exploring\n",
      "Selected action  [3 4]\n",
      "[3 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 45us/step - loss: 52831.1914\n",
      "rewards:  -68.0 q-value:  0\n",
      "loss: [52831.19140625]\n",
      "Exploring\n",
      "Selected action  [3 4]\n",
      "[3 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 67us/step - loss: 75362.0234\n",
      "rewards:  -70.0 q-value:  0\n",
      "loss: [75362.0234375]\n",
      "Exploring\n",
      "Selected action  [0 2]\n",
      "[0 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 65us/step - loss: 59583.2734\n",
      "rewards:  -47.0 q-value:  0\n",
      "loss: [59583.2734375]\n",
      "Exploring\n",
      "Selected action  [1 2]\n",
      "[1 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 52us/step - loss: 31421.9688\n",
      "rewards:  -49.0 q-value:  0\n",
      "loss: [31421.96875]\n",
      "Exploring\n",
      "Selected action  [3 4]\n",
      "[3 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 43us/step - loss: 27492.2461\n",
      "rewards:  -77.0 q-value:  0\n",
      "loss: [27492.24609375]\n",
      "Exploring\n",
      "Selected action  [3 4]\n",
      "[3 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 58us/step - loss: 44075.6562\n",
      "rewards:  -80.0 q-value:  0\n",
      "loss: [44075.65625]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 52us/step - loss: 30345.2852\n",
      "rewards:  -85.0 q-value:  0\n",
      "loss: [30345.28515625]\n",
      "Exploring\n",
      "Selected action  [0 2]\n",
      "[0 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 61us/step - loss: 57805.1992\n",
      "rewards:  -65.0 q-value:  0\n",
      "loss: [57805.19921875]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 66us/step - loss: 49054.8672\n",
      "rewards:  -70.0 q-value:  0\n",
      "loss: [49054.8671875]\n",
      "Exploring\n",
      "Selected action  [0 2]\n",
      "[0 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 49us/step - loss: 50623.5781\n",
      "rewards:  -62.0 q-value:  0\n",
      "loss: [50623.578125]\n",
      "Exploring\n",
      "Selected action  [3 4]\n",
      "[3 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 57us/step - loss: 69875.8281\n",
      "rewards:  -84.0 q-value:  0\n",
      "loss: [69875.828125]\n",
      "Exploring\n",
      "Selected action  [0 2]\n",
      "[0 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 59us/step - loss: 14144.2891\n",
      "rewards:  -81.0 q-value:  0\n",
      "loss: [14144.2890625]\n",
      "Exploring\n",
      "Selected action  [3 4]\n",
      "[3 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 56us/step - loss: 33099.4492\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rewards:  -63.0 q-value:  0\n",
      "loss: [33099.44921875]\n",
      "Exploring\n",
      "Selected action  [3 4]\n",
      "[3 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 64us/step - loss: 39801.6602\n",
      "rewards:  -72.0 q-value:  0\n",
      "loss: [39801.66015625]\n",
      "Exploring\n",
      "Selected action  [1 2]\n",
      "[1 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 56us/step - loss: 42444.4141\n",
      "rewards:  -72.0 q-value:  0\n",
      "loss: [42444.4140625]\n",
      "Exploring\n",
      "Selected action  [1 2]\n",
      "[1 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 61us/step - loss: 39056.8359\n",
      "rewards:  -78.0 q-value:  0\n",
      "loss: [39056.8359375]\n",
      "Exploring\n",
      "Selected action  [1 2]\n",
      "[1 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 52us/step - loss: 35136.2891\n",
      "rewards:  -87.0 q-value:  0\n",
      "loss: [35136.2890625]\n",
      "Exploring\n",
      "Selected action  [3 4]\n",
      "[3 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 47us/step - loss: 66153.5312\n",
      "rewards:  -99.0 q-value:  0\n",
      "loss: [66153.53125]\n",
      "Exploring\n",
      "Selected action  [1 2]\n",
      "[1 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 67us/step - loss: 37727.8516\n",
      "rewards:  -55.0 q-value:  0\n",
      "loss: [37727.8515625]\n",
      "Exploring\n",
      "Selected action  [1 2]\n",
      "[1 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 74us/step - loss: 30039.2500\n",
      "rewards:  -59.0 q-value:  0\n",
      "loss: [30039.25]\n",
      "Exploring\n",
      "Selected action  [1 2]\n",
      "[1 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 69us/step - loss: 57192.1875\n",
      "rewards:  -60.0 q-value:  0\n",
      "loss: [57192.1875]\n",
      "Exploring\n",
      "Selected action  [4 1]\n",
      "[4 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 47us/step - loss: 22813.0234\n",
      "rewards:  -70.0 q-value:  0\n",
      "loss: [22813.0234375]\n",
      "Exploring\n",
      "Selected action  [3 4]\n",
      "[3 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 66us/step - loss: 60306.2383\n",
      "rewards:  -51.0 q-value:  0\n",
      "loss: [60306.23828125]\n",
      "Exploring\n",
      "Selected action  [4 1]\n",
      "[4 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 69us/step - loss: 39788.7812\n",
      "rewards:  -39.0 q-value:  0\n",
      "loss: [39788.78125]\n",
      "Exploring\n",
      "Selected action  [4 1]\n",
      "[4 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 59us/step - loss: 20478.1348\n",
      "rewards:  -42.0 q-value:  0\n",
      "loss: [20478.134765625]\n",
      "Exploring\n",
      "Selected action  [0 2]\n",
      "[0 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 51us/step - loss: 40056.9531\n",
      "rewards:  -55.0 q-value:  0\n",
      "loss: [40056.953125]\n",
      "Exploring\n",
      "Selected action  [0 2]\n",
      "[0 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 62us/step - loss: 38243.2539\n",
      "rewards:  -58.0 q-value:  0\n",
      "loss: [38243.25390625]\n",
      "Exploring\n",
      "Selected action  [4 1]\n",
      "[4 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 45us/step - loss: 39893.5391\n",
      "rewards:  -59.0 q-value:  0\n",
      "loss: [39893.5390625]\n",
      "Exploring\n",
      "Selected action  [4 1]\n",
      "[4 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 54us/step - loss: 37344.1016\n",
      "rewards:  -59.0 q-value:  0\n",
      "loss: [37344.1015625]\n",
      "Exploring\n",
      "Selected action  [3 4]\n",
      "[3 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 51us/step - loss: 29824.8984\n",
      "rewards:  -55.0 q-value:  0\n",
      "loss: [29824.8984375]\n",
      "Exploring\n",
      "Selected action  [4 1]\n",
      "[4 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 56us/step - loss: 32940.7773\n",
      "rewards:  -55.0 q-value:  0\n",
      "loss: [32940.77734375]\n",
      "Exploring\n",
      "Selected action  [0 2]\n",
      "[0 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 59us/step - loss: 39927.5898\n",
      "rewards:  -45.0 q-value:  0\n",
      "loss: [39927.58984375]\n",
      "Exploring\n",
      "Selected action  [4 1]\n",
      "[4 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 63us/step - loss: 22321.9355\n",
      "rewards:  -38.0 q-value:  0\n",
      "loss: [22321.935546875]\n",
      "Exploring\n",
      "Selected action  [4 1]\n",
      "[4 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 54us/step - loss: 21755.3477\n",
      "rewards:  -41.0 q-value:  0\n",
      "loss: [21755.34765625]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 52us/step - loss: 38020.7812\n",
      "rewards:  -46.0 q-value:  0\n",
      "loss: [38020.78125]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 71us/step - loss: 35086.8906\n",
      "rewards:  -51.0 q-value:  0\n",
      "loss: [35086.890625]\n",
      "Exploiting\n",
      "Selected action  [4 1]\n",
      "[4 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 64us/step - loss: 32540.3633\n",
      "rewards:  -27.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [32540.36328125]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 50us/step - loss: 42940.3984\n",
      "rewards:  -32.0 q-value:  0\n",
      "loss: [42940.3984375]\n",
      "Exploring\n",
      "Selected action  [4 1]\n",
      "[4 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 49us/step - loss: 36500.6172\n",
      "rewards:  -44.0 q-value:  0\n",
      "loss: [36500.6171875]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 49us/step - loss: 16415.0078\n",
      "rewards:  -49.0 q-value:  0\n",
      "loss: [16415.0078125]\n",
      "Exploring\n",
      "Selected action  [4 1]\n",
      "[4 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 57us/step - loss: 41267.5312\n",
      "rewards:  -61.0 q-value:  0\n",
      "loss: [41267.53125]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 49us/step - loss: 38057.9531\n",
      "rewards:  -66.0 q-value:  0\n",
      "loss: [38057.953125]\n",
      "Exploring\n",
      "Selected action  [3 4]\n",
      "[3 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 51us/step - loss: 40820.3438\n",
      "rewards:  -61.0 q-value:  0\n",
      "loss: [40820.34375]\n",
      "Exploring\n",
      "Selected action  [1 2]\n",
      "[1 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 58us/step - loss: 45253.1719\n",
      "rewards:  -21.0 q-value:  0\n",
      "loss: [45253.171875]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 54us/step - loss: 43390.3711\n",
      "rewards:  -26.0 q-value:  0\n",
      "loss: [43390.37109375]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 61us/step - loss: 33400.2891\n",
      "rewards:  -31.0 q-value:  0\n",
      "loss: [33400.2890625]\n",
      "Exploring\n",
      "Selected action  [3 4]\n",
      "[3 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 74us/step - loss: 33351.9844\n",
      "rewards:  -45.0 q-value:  0\n",
      "loss: [33351.984375]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 50us/step - loss: 36288.0977\n",
      "rewards:  -50.0 q-value:  0\n",
      "loss: [36288.09765625]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 44us/step - loss: 55428.5703\n",
      "rewards:  -55.0 q-value:  0\n",
      "loss: [55428.5703125]\n",
      "Exploring\n",
      "Selected action  [0 2]\n",
      "[0 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 60us/step - loss: 37075.1016\n",
      "rewards:  -27.0 q-value:  0\n",
      "loss: [37075.1015625]\n",
      "Exploring\n",
      "Selected action  [3 4]\n",
      "[3 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 77us/step - loss: 39077.6562\n",
      "rewards:  -28.0 q-value:  0\n",
      "loss: [39077.65625]\n",
      "Exploring\n",
      "Selected action  [1 2]\n",
      "[1 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 70us/step - loss: 25473.4941\n",
      "rewards:  -10.0 q-value:  0\n",
      "loss: [25473.494140625]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 61us/step - loss: 46653.2891\n",
      "rewards:  -15.0 q-value:  0\n",
      "loss: [46653.2890625]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 58us/step - loss: 32990.0469\n",
      "rewards:  -20.0 q-value:  0\n",
      "loss: [32990.046875]\n",
      "Exploring\n",
      "Selected action  [0 2]\n",
      "[0 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 54us/step - loss: 43179.9609\n",
      "rewards:  4.0 q-value:  0\n",
      "loss: [43179.9609375]\n",
      "Exploring\n",
      "Selected action  [0 2]\n",
      "[0 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 73us/step - loss: 45118.5547\n",
      "rewards:  1.0 q-value:  0\n",
      "loss: [45118.5546875]\n",
      "Exploring\n",
      "Selected action  [4 1]\n",
      "[4 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 65us/step - loss: 37204.6523\n",
      "rewards:  9.0 q-value:  0\n",
      "loss: [37204.65234375]\n",
      "Exploiting\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 94us/step - loss: 26827.0820\n",
      "rewards:  4.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [26827.08203125]\n",
      "Exploring\n",
      "Selected action  [1 2]\n",
      "[1 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 61us/step - loss: 28793.4785\n",
      "rewards:  26.0 q-value:  0\n",
      "loss: [28793.478515625]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 53us/step - loss: 36890.0156\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rewards:  21.0 q-value:  0\n",
      "loss: [36890.015625]\n",
      "Exploring\n",
      "Selected action  [1 2]\n",
      "[1 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 70us/step - loss: 38477.3125\n",
      "rewards:  31.0 q-value:  0\n",
      "loss: [38477.3125]\n",
      "Exploring\n",
      "Selected action  [4 1]\n",
      "[4 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 68us/step - loss: 32440.3418\n",
      "rewards:  13.0 q-value:  0\n",
      "loss: [32440.341796875]\n",
      "Exploring\n",
      "Selected action  [4 1]\n",
      "[4 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 46us/step - loss: 51025.4648\n",
      "rewards:  10.0 q-value:  0\n",
      "loss: [51025.46484375]\n",
      "Exploring\n",
      "Selected action  [4 1]\n",
      "[4 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 60us/step - loss: 36768.2305\n",
      "rewards:  10.0 q-value:  0\n",
      "loss: [36768.23046875]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 64us/step - loss: 29105.4336\n",
      "rewards:  5.0 q-value:  0\n",
      "loss: [29105.43359375]\n",
      "Exploring\n",
      "Selected action  [0 2]\n",
      "[0 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 83us/step - loss: 38959.7500\n",
      "rewards:  13.0 q-value:  0\n",
      "loss: [38959.75]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 57us/step - loss: 46644.4688\n",
      "rewards:  8.0 q-value:  0\n",
      "loss: [46644.46875]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 84us/step - loss: 44055.2578\n",
      "rewards:  3.0 q-value:  0\n",
      "loss: [44055.2578125]\n",
      "Exploring\n",
      "Selected action  [1 2]\n",
      "[1 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 50us/step - loss: 41445.2109\n",
      "rewards:  -13.0 q-value:  0\n",
      "loss: [41445.2109375]\n",
      "Number of actions available 6\n",
      "Episode : 3\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 69us/step - loss: 24528.8828\n",
      "rewards:  4.0 q-value:  0\n",
      "loss: [24528.8828125]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 56us/step - loss: 42156.6406\n",
      "rewards:  -2.0 q-value:  0\n",
      "loss: [42156.640625]\n",
      "Exploring\n",
      "Selected action  [3 1]\n",
      "[3 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 70us/step - loss: 30291.3516\n",
      "rewards:  -2.0 q-value:  0\n",
      "loss: [30291.3515625]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 56us/step - loss: 49632.9844\n",
      "rewards:  -7.0 q-value:  0\n",
      "loss: [49632.984375]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 71us/step - loss: 20400.1230\n",
      "rewards:  -9.0 q-value:  0\n",
      "loss: [20400.123046875]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 60us/step - loss: 27535.7617\n",
      "rewards:  -11.0 q-value:  0\n",
      "loss: [27535.76171875]\n",
      "Exploring\n",
      "Selected action  [4 1]\n",
      "[4 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 74us/step - loss: 25548.8984\n",
      "rewards:  -39.0 q-value:  0\n",
      "loss: [25548.8984375]\n",
      "Exploring\n",
      "Selected action  [3 2]\n",
      "[3 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 46us/step - loss: 21732.9473\n",
      "rewards:  -31.0 q-value:  0\n",
      "loss: [21732.947265625]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 70us/step - loss: 47359.9180\n",
      "rewards:  -36.0 q-value:  0\n",
      "loss: [47359.91796875]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 51us/step - loss: 37463.4062\n",
      "rewards:  -41.0 q-value:  0\n",
      "loss: [37463.40625]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 38us/step - loss: 41801.3281\n",
      "rewards:  -43.0 q-value:  0\n",
      "loss: [41801.328125]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 60us/step - loss: 26349.0664\n",
      "rewards:  -48.0 q-value:  0\n",
      "loss: [26349.06640625]\n",
      "Exploring\n",
      "Selected action  [4 1]\n",
      "[4 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 61us/step - loss: 34648.0703\n",
      "rewards:  -37.0 q-value:  0\n",
      "loss: [34648.0703125]\n",
      "Exploring\n",
      "Selected action  [3 1]\n",
      "[3 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 55us/step - loss: 48257.7578\n",
      "rewards:  -38.0 q-value:  0\n",
      "loss: [48257.7578125]\n",
      "Exploring\n",
      "Selected action  [3 1]\n",
      "[3 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 68us/step - loss: 17779.4922\n",
      "rewards:  -39.0 q-value:  0\n",
      "loss: [17779.4921875]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 55us/step - loss: 26077.4609\n",
      "rewards:  -3.0 q-value:  0\n",
      "loss: [26077.4609375]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 76us/step - loss: 46744.6172\n",
      "rewards:  -7.0 q-value:  0\n",
      "loss: [46744.6171875]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 64us/step - loss: 33790.4570\n",
      "rewards:  -12.0 q-value:  0\n",
      "loss: [33790.45703125]\n",
      "Exploring\n",
      "Selected action  [3 1]\n",
      "[3 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 70us/step - loss: 30745.5840\n",
      "rewards:  -8.0 q-value:  0\n",
      "loss: [30745.583984375]\n",
      "Exploring\n",
      "Selected action  [3 1]\n",
      "[3 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 50us/step - loss: 33934.1562\n",
      "rewards:  -9.0 q-value:  0\n",
      "loss: [33934.15625]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 57us/step - loss: 38773.3594\n",
      "rewards:  -1.0 q-value:  0\n",
      "loss: [38773.359375]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 88us/step - loss: 26829.3008\n",
      "rewards:  -6.0 q-value:  0\n",
      "loss: [26829.30078125]\n",
      "Exploring\n",
      "Selected action  [3 1]\n",
      "[3 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 55us/step - loss: 8318.3516\n",
      "rewards:  -12.0 q-value:  0\n",
      "loss: [8318.3515625]\n",
      "Exploring\n",
      "Selected action  [3 2]\n",
      "[3 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 46us/step - loss: 40883.9375\n",
      "rewards:  -2.0 q-value:  0\n",
      "loss: [40883.9375]\n",
      "Exploring\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 62us/step - loss: 38329.3906\n",
      "rewards:  -9.0 q-value:  0\n",
      "loss: [38329.390625]\n",
      "Exploring\n",
      "Selected action  [4 1]\n",
      "[4 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 127us/step - loss: 37254.2852\n",
      "rewards:  -39.0 q-value:  0\n",
      "loss: [37254.28515625]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 65us/step - loss: 47254.1250\n",
      "rewards:  -11.0 q-value:  0\n",
      "loss: [47254.125]\n",
      "Exploring\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 50us/step - loss: 43093.0742\n",
      "rewards:  -18.0 q-value:  0\n",
      "loss: [43093.07421875]\n",
      "Exploring\n",
      "Selected action  [4 1]\n",
      "[4 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 54us/step - loss: 55881.7344\n",
      "rewards:  -28.0 q-value:  0\n",
      "loss: [55881.734375]\n",
      "Exploring\n",
      "Selected action  [4 1]\n",
      "[4 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 52us/step - loss: 32101.6875\n",
      "rewards:  -28.0 q-value:  0\n",
      "loss: [32101.6875]\n",
      "Exploring\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 71us/step - loss: 30272.6543\n",
      "rewards:  -20.0 q-value:  0\n",
      "loss: [30272.654296875]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 52us/step - loss: 36614.2227\n",
      "rewards:  -25.0 q-value:  0\n",
      "loss: [36614.22265625]\n",
      "Exploring\n",
      "Selected action  [4 1]\n",
      "[4 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 49us/step - loss: 43488.4062\n",
      "rewards:  -14.0 q-value:  0\n",
      "loss: [43488.40625]\n",
      "Exploring\n",
      "Selected action  [4 1]\n",
      "[4 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 51us/step - loss: 37207.9062\n",
      "rewards:  -18.0 q-value:  0\n",
      "loss: [37207.90625]\n",
      "Exploring\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 52us/step - loss: 32704.0098\n",
      "rewards:  -10.0 q-value:  0\n",
      "loss: [32704.009765625]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 54us/step - loss: 37041.8008\n",
      "rewards:  -15.0 q-value:  0\n",
      "loss: [37041.80078125]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 54us/step - loss: 21590.6680\n",
      "rewards:  -24.0 q-value:  0\n",
      "loss: [21590.66796875]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 50us/step - loss: 30051.5703\n",
      "rewards:  -30.0 q-value:  0\n",
      "loss: [30051.5703125]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 61us/step - loss: 28978.5762\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rewards:  -35.0 q-value:  0\n",
      "loss: [28978.576171875]\n",
      "Exploring\n",
      "Selected action  [4 1]\n",
      "[4 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 44us/step - loss: 46127.5938\n",
      "rewards:  -21.0 q-value:  0\n",
      "loss: [46127.59375]\n",
      "Exploring\n",
      "Selected action  [3 1]\n",
      "[3 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 50us/step - loss: 51118.0586\n",
      "rewards:  -25.0 q-value:  0\n",
      "loss: [51118.05859375]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 49us/step - loss: 42757.2539\n",
      "rewards:  -30.0 q-value:  0\n",
      "loss: [42757.25390625]\n",
      "Exploring\n",
      "Selected action  [4 1]\n",
      "[4 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 66us/step - loss: 26365.8164\n",
      "rewards:  -30.0 q-value:  0\n",
      "loss: [26365.81640625]\n",
      "Exploring\n",
      "Selected action  [4 1]\n",
      "[4 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 55us/step - loss: 15914.4248\n",
      "rewards:  -30.0 q-value:  0\n",
      "loss: [15914.4248046875]\n",
      "Exploring\n",
      "Selected action  [3 2]\n",
      "[3 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 58us/step - loss: 46338.0977\n",
      "rewards:  -26.0 q-value:  0\n",
      "loss: [46338.09765625]\n",
      "Exploring\n",
      "Selected action  [3 2]\n",
      "[3 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 51us/step - loss: 37704.7734\n",
      "rewards:  -26.0 q-value:  0\n",
      "loss: [37704.7734375]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 64us/step - loss: 32253.3691\n",
      "rewards:  -31.0 q-value:  0\n",
      "loss: [32253.369140625]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 62us/step - loss: 31667.5879\n",
      "rewards:  -36.0 q-value:  0\n",
      "loss: [31667.587890625]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 52us/step - loss: 28019.1523\n",
      "rewards:  -41.0 q-value:  0\n",
      "loss: [28019.15234375]\n",
      "Exploring\n",
      "Selected action  [4 1]\n",
      "[4 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 55us/step - loss: 10841.3359\n",
      "rewards:  -71.0 q-value:  0\n",
      "loss: [10841.3359375]\n",
      "Exploring\n",
      "Selected action  [3 1]\n",
      "[3 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 50us/step - loss: 17883.0625\n",
      "rewards:  -72.0 q-value:  0\n",
      "loss: [17883.0625]\n",
      "Exploring\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 44us/step - loss: 20246.8047\n",
      "rewards:  -52.0 q-value:  0\n",
      "loss: [20246.8046875]\n",
      "Exploring\n",
      "Selected action  [3 2]\n",
      "[3 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 51us/step - loss: 29718.9336\n",
      "rewards:  -28.0 q-value:  0\n",
      "loss: [29718.93359375]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 67us/step - loss: 13066.4268\n",
      "rewards:  -33.0 q-value:  0\n",
      "loss: [13066.4267578125]\n",
      "Exploring\n",
      "Selected action  [3 1]\n",
      "[3 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 74us/step - loss: 51033.7266\n",
      "rewards:  -26.0 q-value:  0\n",
      "loss: [51033.7265625]\n",
      "Exploring\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 54us/step - loss: 12214.2305\n",
      "rewards:  -22.0 q-value:  0\n",
      "loss: [12214.23046875]\n",
      "Exploring\n",
      "Selected action  [3 1]\n",
      "[3 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 45us/step - loss: 38414.0391\n",
      "rewards:  -18.0 q-value:  0\n",
      "loss: [38414.0390625]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 56us/step - loss: 35336.1875\n",
      "rewards:  -23.0 q-value:  0\n",
      "loss: [35336.1875]\n",
      "Exploring\n",
      "Selected action  [3 1]\n",
      "[3 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 63us/step - loss: 30647.6582\n",
      "rewards:  -34.0 q-value:  0\n",
      "loss: [30647.658203125]\n",
      "Exploring\n",
      "Selected action  [4 1]\n",
      "[4 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 74us/step - loss: 39615.3320\n",
      "rewards:  -36.0 q-value:  0\n",
      "loss: [39615.33203125]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 94us/step - loss: 23904.4141\n",
      "rewards:  -41.0 q-value:  0\n",
      "loss: [23904.4140625]\n",
      "Exploring\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 75us/step - loss: 20673.8457\n",
      "rewards:  -64.0 q-value:  0\n",
      "loss: [20673.845703125]\n",
      "Exploiting\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 48us/step - loss: 30544.0820\n",
      "rewards:  -51.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [30544.08203125]\n",
      "Exploring\n",
      "Selected action  [3 1]\n",
      "[3 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 64us/step - loss: 28406.0332\n",
      "rewards:  -55.0 q-value:  0\n",
      "loss: [28406.033203125]\n",
      "Exploring\n",
      "Selected action  [3 1]\n",
      "[3 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 57us/step - loss: 28424.6387\n",
      "rewards:  -59.0 q-value:  0\n",
      "loss: [28424.638671875]\n",
      "Exploring\n",
      "Selected action  [3 2]\n",
      "[3 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 83us/step - loss: 25504.6172\n",
      "rewards:  -37.0 q-value:  0\n",
      "loss: [25504.6171875]\n",
      "Exploring\n",
      "Selected action  [4 1]\n",
      "[4 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 71us/step - loss: 26122.4062\n",
      "rewards:  -29.0 q-value:  0\n",
      "loss: [26122.40625]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 51us/step - loss: 27336.4121\n",
      "rewards:  -13.0 q-value:  0\n",
      "loss: [27336.412109375]\n",
      "Exploring\n",
      "Selected action  [3 2]\n",
      "[3 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 44us/step - loss: 13636.3213\n",
      "rewards:  -7.0 q-value:  0\n",
      "loss: [13636.3212890625]\n",
      "Exploring\n",
      "Selected action  [3 1]\n",
      "[3 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 51us/step - loss: 47212.2656\n",
      "rewards:  -47.0 q-value:  0\n",
      "loss: [47212.265625]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 64us/step - loss: 33852.7812\n",
      "rewards:  -39.0 q-value:  0\n",
      "loss: [33852.78125]\n",
      "Exploring\n",
      "Selected action  [3 2]\n",
      "[3 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 71us/step - loss: 35043.3984\n",
      "rewards:  -7.0 q-value:  0\n",
      "loss: [35043.3984375]\n",
      "Exploring\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 53us/step - loss: 44517.5742\n",
      "rewards:  -47.0 q-value:  0\n",
      "loss: [44517.57421875]\n",
      "Exploring\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 96us/step - loss: 31799.8203\n",
      "rewards:  -47.0 q-value:  0\n",
      "loss: [31799.8203125]\n",
      "Exploring\n",
      "Selected action  [3 1]\n",
      "[3 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 59us/step - loss: 40074.6953\n",
      "rewards:  -47.0 q-value:  0\n",
      "loss: [40074.6953125]\n",
      "Exploring\n",
      "Selected action  [4 1]\n",
      "[4 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 65us/step - loss: 49053.0117\n",
      "rewards:  -50.0 q-value:  0\n",
      "loss: [49053.01171875]\n",
      "Exploring\n",
      "Selected action  [4 1]\n",
      "[4 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 72us/step - loss: 34025.2422\n",
      "rewards:  -54.0 q-value:  0\n",
      "loss: [34025.2421875]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 62us/step - loss: 34811.6094\n",
      "rewards:  -46.0 q-value:  0\n",
      "loss: [34811.609375]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 58us/step - loss: 16664.8730\n",
      "rewards:  -51.0 q-value:  0\n",
      "loss: [16664.873046875]\n",
      "Exploring\n",
      "Selected action  [3 2]\n",
      "[3 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 60us/step - loss: 30913.3848\n",
      "rewards:  -58.0 q-value:  0\n",
      "loss: [30913.384765625]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 51us/step - loss: 38394.8477\n",
      "rewards:  -72.0 q-value:  0\n",
      "loss: [38394.84765625]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 60us/step - loss: 21371.2734\n",
      "rewards:  -74.0 q-value:  0\n",
      "loss: [21371.2734375]\n",
      "Exploring\n",
      "Selected action  [3 2]\n",
      "[3 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 57us/step - loss: 30598.4688\n",
      "rewards:  -62.0 q-value:  0\n",
      "loss: [30598.46875]\n",
      "Exploiting\n",
      "Selected action  [4 1]\n",
      "[4 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 65us/step - loss: 22114.1719\n",
      "rewards:  -46.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [22114.171875]\n",
      "Exploring\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 49us/step - loss: 35662.5000\n",
      "rewards:  -22.0 q-value:  0\n",
      "loss: [35662.5]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 43us/step - loss: 43364.3398\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rewards:  -27.0 q-value:  0\n",
      "loss: [43364.33984375]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 69us/step - loss: 39583.9570\n",
      "rewards:  -34.0 q-value:  0\n",
      "loss: [39583.95703125]\n",
      "Exploiting\n",
      "Selected action  [3 2]\n",
      "[3 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 46us/step - loss: 50679.7031\n",
      "rewards:  -27.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [50679.703125]\n",
      "Exploring\n",
      "Selected action  [4 1]\n",
      "[4 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 43us/step - loss: 26920.5215\n",
      "rewards:  -37.0 q-value:  0\n",
      "loss: [26920.521484375]\n",
      "Exploiting\n",
      "Selected action  [3 2]\n",
      "[3 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 66us/step - loss: 26516.8262\n",
      "rewards:  -31.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [26516.826171875]\n",
      "Exploring\n",
      "Selected action  [4 1]\n",
      "[4 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 67us/step - loss: 37602.5391\n",
      "rewards:  -41.0 q-value:  0\n",
      "loss: [37602.5390625]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 48us/step - loss: 26754.2598\n",
      "rewards:  -29.0 q-value:  0\n",
      "loss: [26754.259765625]\n",
      "Exploring\n",
      "Selected action  [3 2]\n",
      "[3 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 89us/step - loss: 28074.5781\n",
      "rewards:  -57.0 q-value:  0\n",
      "loss: [28074.578125]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 61us/step - loss: 15859.5000\n",
      "rewards:  -62.0 q-value:  0\n",
      "loss: [15859.5]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 80us/step - loss: 35284.9180\n",
      "rewards:  -65.0 q-value:  0\n",
      "loss: [35284.91796875]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 51us/step - loss: 31827.8301\n",
      "rewards:  -74.0 q-value:  0\n",
      "loss: [31827.830078125]\n",
      "Exploring\n",
      "Selected action  [4 1]\n",
      "[4 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 59us/step - loss: 33762.6992\n",
      "rewards:  -79.0 q-value:  0\n",
      "loss: [33762.69921875]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 76us/step - loss: 18430.1641\n",
      "rewards:  -55.0 q-value:  0\n",
      "loss: [18430.1640625]\n",
      "Exploring\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 70us/step - loss: 48057.0391\n",
      "rewards:  -81.0 q-value:  0\n",
      "loss: [48057.0390625]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 48us/step - loss: 42372.3047\n",
      "rewards:  -86.0 q-value:  0\n",
      "loss: [42372.3046875]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 57us/step - loss: 15221.8027\n",
      "rewards:  -91.0 q-value:  0\n",
      "loss: [15221.802734375]\n",
      "Exploring\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 53us/step - loss: 36488.7500\n",
      "rewards:  -104.0 q-value:  0\n",
      "loss: [36488.75]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 50us/step - loss: 16707.5469\n",
      "rewards:  -91.0 q-value:  0\n",
      "loss: [16707.546875]\n",
      "Exploring\n",
      "Selected action  [4 1]\n",
      "[4 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 62us/step - loss: 32602.6016\n",
      "rewards:  -91.0 q-value:  0\n",
      "loss: [32602.6015625]\n",
      "Exploring\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 54us/step - loss: 16751.7676\n",
      "rewards:  -75.0 q-value:  0\n",
      "loss: [16751.767578125]\n",
      "Exploring\n",
      "Selected action  [3 1]\n",
      "[3 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 52us/step - loss: 32012.2305\n",
      "rewards:  -71.0 q-value:  0\n",
      "loss: [32012.23046875]\n",
      "Exploring\n",
      "Selected action  [3 1]\n",
      "[3 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 53us/step - loss: 29618.9531\n",
      "rewards:  -72.0 q-value:  0\n",
      "loss: [29618.953125]\n",
      "Exploring\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 57us/step - loss: 28577.8594\n",
      "rewards:  -68.0 q-value:  0\n",
      "loss: [28577.859375]\n",
      "Exploring\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 57us/step - loss: 27216.1523\n",
      "rewards:  -69.0 q-value:  0\n",
      "loss: [27216.15234375]\n",
      "Exploring\n",
      "Selected action  [3 1]\n",
      "[3 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 51us/step - loss: 32851.0469\n",
      "rewards:  -65.0 q-value:  0\n",
      "loss: [32851.046875]\n",
      "Exploring\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 38us/step - loss: 25751.0742\n",
      "rewards:  -45.0 q-value:  0\n",
      "loss: [25751.07421875]\n",
      "Exploring\n",
      "Selected action  [4 1]\n",
      "[4 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 54us/step - loss: 16486.0215\n",
      "rewards:  -48.0 q-value:  0\n",
      "loss: [16486.021484375]\n",
      "Exploring\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 56us/step - loss: 25883.0352\n",
      "rewards:  -36.0 q-value:  0\n",
      "loss: [25883.03515625]\n",
      "Exploring\n",
      "Selected action  [4 1]\n",
      "[4 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 52us/step - loss: 33885.4922\n",
      "rewards:  -37.0 q-value:  0\n",
      "loss: [33885.4921875]\n",
      "Exploring\n",
      "Selected action  [4 1]\n",
      "[4 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 51us/step - loss: 27116.7500\n",
      "rewards:  -39.0 q-value:  0\n",
      "loss: [27116.75]\n",
      "Exploiting\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 63us/step - loss: 11054.4922\n",
      "rewards:  -44.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [11054.4921875]\n",
      "Exploring\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 64us/step - loss: 11289.7988\n",
      "rewards:  -67.0 q-value:  0\n",
      "loss: [11289.798828125]\n",
      "Exploring\n",
      "Selected action  [3 1]\n",
      "[3 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 59us/step - loss: 9353.8711\n",
      "rewards:  -55.0 q-value:  0\n",
      "loss: [9353.87109375]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 60us/step - loss: 23222.0410\n",
      "rewards:  -55.0 q-value:  0\n",
      "loss: [23222.041015625]\n",
      "Exploring\n",
      "Selected action  [4 1]\n",
      "[4 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 38us/step - loss: 28755.8047\n",
      "rewards:  -56.0 q-value:  0\n",
      "loss: [28755.8046875]\n",
      "Exploring\n",
      "Selected action  [3 2]\n",
      "[3 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 78us/step - loss: 18650.5391\n",
      "rewards:  -32.0 q-value:  0\n",
      "loss: [18650.5390625]\n",
      "Exploiting\n",
      "Selected action  [3 1]\n",
      "[3 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 56us/step - loss: 32108.9629\n",
      "rewards:  -64.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [32108.962890625]\n",
      "Exploring\n",
      "Selected action  [3 2]\n",
      "[3 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 72us/step - loss: 46104.9258\n",
      "rewards:  -42.0 q-value:  0\n",
      "loss: [46104.92578125]\n",
      "Exploring\n",
      "Selected action  [3 1]\n",
      "[3 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 45us/step - loss: 34031.4531\n",
      "rewards:  -59.0 q-value:  0\n",
      "loss: [34031.453125]\n",
      "Exploring\n",
      "Selected action  [4 1]\n",
      "[4 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 56us/step - loss: 26488.4062\n",
      "rewards:  -61.0 q-value:  0\n",
      "loss: [26488.40625]\n",
      "Exploiting\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 65us/step - loss: 26033.5352\n",
      "rewards:  -45.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [26033.53515625]\n",
      "Exploring\n",
      "Selected action  [4 1]\n",
      "[4 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 94us/step - loss: 26950.9746\n",
      "rewards:  -52.0 q-value:  0\n",
      "loss: [26950.974609375]\n",
      "Exploring\n",
      "Selected action  [3 1]\n",
      "[3 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 51us/step - loss: 26452.0039\n",
      "rewards:  -52.0 q-value:  0\n",
      "loss: [26452.00390625]\n",
      "Exploring\n",
      "Selected action  [4 1]\n",
      "[4 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 48us/step - loss: 20522.3301\n",
      "rewards:  -54.0 q-value:  0\n",
      "loss: [20522.330078125]\n",
      "Exploring\n",
      "Selected action  [4 1]\n",
      "[4 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 46us/step - loss: 21907.6621\n",
      "rewards:  -56.0 q-value:  0\n",
      "loss: [21907.662109375]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 60us/step - loss: 12916.8750\n",
      "rewards:  -61.0 q-value:  0\n",
      "loss: [12916.875]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 63us/step - loss: 27457.3203\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rewards:  -63.0 q-value:  0\n",
      "loss: [27457.3203125]\n",
      "Exploring\n",
      "Selected action  [3 1]\n",
      "[3 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 68us/step - loss: 27431.6562\n",
      "rewards:  -78.0 q-value:  0\n",
      "loss: [27431.65625]\n",
      "Exploring\n",
      "Selected action  [3 1]\n",
      "[3 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 70us/step - loss: 22057.4375\n",
      "rewards:  -78.0 q-value:  0\n",
      "loss: [22057.4375]\n",
      "Exploring\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 59us/step - loss: 12937.8457\n",
      "rewards:  -78.0 q-value:  0\n",
      "loss: [12937.845703125]\n",
      "Exploring\n",
      "Selected action  [4 1]\n",
      "[4 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 67us/step - loss: 36498.0117\n",
      "rewards:  -81.0 q-value:  0\n",
      "loss: [36498.01171875]\n",
      "Exploring\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 57us/step - loss: 17166.1367\n",
      "rewards:  -81.0 q-value:  0\n",
      "loss: [17166.13671875]\n",
      "Exploring\n",
      "Selected action  [4 1]\n",
      "[4 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 66us/step - loss: 18862.6875\n",
      "rewards:  -84.0 q-value:  0\n",
      "loss: [18862.6875]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 60us/step - loss: 26474.7656\n",
      "rewards:  -89.0 q-value:  0\n",
      "loss: [26474.765625]\n",
      "Exploring\n",
      "Selected action  [3 1]\n",
      "[3 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 62us/step - loss: 16703.3848\n",
      "rewards:  -119.0 q-value:  0\n",
      "loss: [16703.384765625]\n",
      "Number of actions available 11\n",
      "Episode : 4\n",
      "Exploring\n",
      "Selected action  [4 3]\n",
      "[4 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 60us/step - loss: 22304.5977\n",
      "rewards:  -2.0 q-value:  0\n",
      "loss: [22304.59765625]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 71us/step - loss: 65754.8984\n",
      "rewards:  -27.0 q-value:  0\n",
      "loss: [65754.8984375]\n",
      "Exploring\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 51us/step - loss: 42579.8672\n",
      "rewards:  -18.0 q-value:  0\n",
      "loss: [42579.8671875]\n",
      "Exploring\n",
      "Selected action  [3 0]\n",
      "[3 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 57us/step - loss: 14148.1504\n",
      "rewards:  -18.0 q-value:  0\n",
      "loss: [14148.150390625]\n",
      "Exploring\n",
      "Selected action  [3 0]\n",
      "[3 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 87us/step - loss: 30281.6699\n",
      "rewards:  -18.0 q-value:  0\n",
      "loss: [30281.669921875]\n",
      "Exploring\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 55us/step - loss: 17772.7812\n",
      "rewards:  -28.0 q-value:  0\n",
      "loss: [17772.78125]\n",
      "Exploring\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 46us/step - loss: 29222.8594\n",
      "rewards:  -28.0 q-value:  0\n",
      "loss: [29222.859375]\n",
      "Exploring\n",
      "Selected action  [0 2]\n",
      "[0 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 51us/step - loss: 15781.9805\n",
      "rewards:  -16.0 q-value:  0\n",
      "loss: [15781.98046875]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 60us/step - loss: 23297.6328\n",
      "rewards:  -8.0 q-value:  0\n",
      "loss: [23297.6328125]\n",
      "Exploring\n",
      "Selected action  [3 0]\n",
      "[3 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 61us/step - loss: 29304.3066\n",
      "rewards:  -11.0 q-value:  0\n",
      "loss: [29304.306640625]\n",
      "Exploring\n",
      "Selected action  [2 3]\n",
      "[2 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 54us/step - loss: 24724.5000\n",
      "rewards:  3.0 q-value:  0\n",
      "loss: [24724.5]\n",
      "Exploring\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 93us/step - loss: 39052.7344\n",
      "rewards:  24.0 q-value:  0\n",
      "loss: [39052.734375]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 65us/step - loss: 35765.2773\n",
      "rewards:  20.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [35765.27734375]\n",
      "Exploring\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 47us/step - loss: 27077.1602\n",
      "rewards:  18.0 q-value:  0\n",
      "loss: [27077.16015625]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 64us/step - loss: 22514.5801\n",
      "rewards:  -7.0 q-value:  0\n",
      "loss: [22514.580078125]\n",
      "Exploring\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 58us/step - loss: 19116.1875\n",
      "rewards:  -23.0 q-value:  0\n",
      "loss: [19116.1875]\n",
      "Exploring\n",
      "Selected action  [2 3]\n",
      "[2 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 47us/step - loss: 34712.8984\n",
      "rewards:  -26.0 q-value:  0\n",
      "loss: [34712.8984375]\n",
      "Exploring\n",
      "Selected action  [3 0]\n",
      "[3 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 63us/step - loss: 23920.2461\n",
      "rewards:  -2.0 q-value:  0\n",
      "loss: [23920.24609375]\n",
      "Exploring\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 63us/step - loss: 15922.4062\n",
      "rewards:  -29.0 q-value:  0\n",
      "loss: [15922.40625]\n",
      "Exploring\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 69us/step - loss: 13524.0156\n",
      "rewards:  -16.0 q-value:  0\n",
      "loss: [13524.015625]\n",
      "Exploring\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 47us/step - loss: 31001.6055\n",
      "rewards:  -8.0 q-value:  0\n",
      "loss: [31001.60546875]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 43us/step - loss: 25791.6250\n",
      "rewards:  -20.0 q-value:  0\n",
      "loss: [25791.625]\n",
      "Exploring\n",
      "Selected action  [0 2]\n",
      "[0 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 55us/step - loss: 9499.3018\n",
      "rewards:  -32.0 q-value:  0\n",
      "loss: [9499.3017578125]\n",
      "Exploring\n",
      "Selected action  [3 0]\n",
      "[3 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 52us/step - loss: 53223.9688\n",
      "rewards:  -48.0 q-value:  0\n",
      "loss: [53223.96875]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 55us/step - loss: 39848.6875\n",
      "rewards:  -53.0 q-value:  0\n",
      "loss: [39848.6875]\n",
      "Exploring\n",
      "Selected action  [4 2]\n",
      "[4 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 59us/step - loss: 22881.9668\n",
      "rewards:  -65.0 q-value:  0\n",
      "loss: [22881.966796875]\n",
      "Exploring\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 59us/step - loss: 21815.4180\n",
      "rewards:  -70.0 q-value:  0\n",
      "loss: [21815.41796875]\n",
      "Exploring\n",
      "Selected action  [0 2]\n",
      "[0 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 65us/step - loss: 41266.6328\n",
      "rewards:  -86.0 q-value:  0\n",
      "loss: [41266.6328125]\n",
      "Exploring\n",
      "Selected action  [3 0]\n",
      "[3 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 59us/step - loss: 48551.0117\n",
      "rewards:  -98.0 q-value:  0\n",
      "loss: [48551.01171875]\n",
      "Exploring\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 58us/step - loss: 14322.8809\n",
      "rewards:  -124.0 q-value:  0\n",
      "loss: [14322.880859375]\n",
      "Exploring\n",
      "Selected action  [4 3]\n",
      "[4 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 49us/step - loss: 19522.1719\n",
      "rewards:  -130.0 q-value:  0\n",
      "loss: [19522.171875]\n",
      "Exploring\n",
      "Selected action  [0 2]\n",
      "[0 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 58us/step - loss: 40972.9141\n",
      "rewards:  -108.0 q-value:  0\n",
      "loss: [40972.9140625]\n",
      "Exploring\n",
      "Selected action  [4 3]\n",
      "[4 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 55us/step - loss: 31398.7500\n",
      "rewards:  -110.0 q-value:  0\n",
      "loss: [31398.75]\n",
      "Exploring\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 60us/step - loss: 35284.4141\n",
      "rewards:  -112.0 q-value:  0\n",
      "loss: [35284.4140625]\n",
      "Exploring\n",
      "Selected action  [3 1]\n",
      "[3 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 56us/step - loss: 18631.5762\n",
      "rewards:  -116.0 q-value:  0\n",
      "loss: [18631.576171875]\n",
      "Exploring\n",
      "Selected action  [3 2]\n",
      "[3 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 54us/step - loss: 18340.7539\n",
      "rewards:  -121.0 q-value:  0\n",
      "loss: [18340.75390625]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 74us/step - loss: 20490.4023\n",
      "rewards:  -138.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [20490.40234375]\n",
      "Exploring\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 53us/step - loss: 14519.8750\n",
      "rewards:  -140.0 q-value:  0\n",
      "loss: [14519.875]\n",
      "Exploring\n",
      "Selected action  [3 0]\n",
      "[3 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 54us/step - loss: 30222.4766\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rewards:  -133.0 q-value:  0\n",
      "loss: [30222.4765625]\n",
      "Exploring\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 57us/step - loss: 38794.6797\n",
      "rewards:  -148.0 q-value:  0\n",
      "loss: [38794.6796875]\n",
      "Exploring\n",
      "Selected action  [4 3]\n",
      "[4 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 64us/step - loss: 25129.3945\n",
      "rewards:  -153.0 q-value:  0\n",
      "loss: [25129.39453125]\n",
      "Exploring\n",
      "Selected action  [3 1]\n",
      "[3 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 52us/step - loss: 5401.2939\n",
      "rewards:  -141.0 q-value:  0\n",
      "loss: [5401.2939453125]\n",
      "Exploring\n",
      "Selected action  [3 2]\n",
      "[3 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 38us/step - loss: 29784.5703\n",
      "rewards:  -114.0 q-value:  0\n",
      "loss: [29784.5703125]\n",
      "Exploring\n",
      "Selected action  [4 2]\n",
      "[4 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 56us/step - loss: 26785.5117\n",
      "rewards:  -114.0 q-value:  0\n",
      "loss: [26785.51171875]\n",
      "Exploring\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 50us/step - loss: 21581.6504\n",
      "rewards:  -106.0 q-value:  0\n",
      "loss: [21581.650390625]\n",
      "Exploring\n",
      "Selected action  [3 1]\n",
      "[3 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 58us/step - loss: 19844.3086\n",
      "rewards:  -110.0 q-value:  0\n",
      "loss: [19844.30859375]\n",
      "Exploring\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 68us/step - loss: 32801.6328\n",
      "rewards:  -94.0 q-value:  0\n",
      "loss: [32801.6328125]\n",
      "Exploring\n",
      "Selected action  [3 2]\n",
      "[3 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 46us/step - loss: 39564.2734\n",
      "rewards:  -62.0 q-value:  0\n",
      "loss: [39564.2734375]\n",
      "Exploring\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 58us/step - loss: 18455.1836\n",
      "rewards:  -71.0 q-value:  0\n",
      "loss: [18455.18359375]\n",
      "Exploring\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 55us/step - loss: 28266.2070\n",
      "rewards:  -55.0 q-value:  0\n",
      "loss: [28266.20703125]\n",
      "Exploring\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 70us/step - loss: 19046.3750\n",
      "rewards:  -61.0 q-value:  0\n",
      "loss: [19046.375]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 68us/step - loss: 14483.5977\n",
      "rewards:  -66.0 q-value:  0\n",
      "loss: [14483.59765625]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 47us/step - loss: 20262.5898\n",
      "rewards:  -80.0 q-value:  0\n",
      "loss: [20262.58984375]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 52us/step - loss: 13990.7197\n",
      "rewards:  -80.0 q-value:  0\n",
      "loss: [13990.7197265625]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 62us/step - loss: 32401.2578\n",
      "rewards:  -85.0 q-value:  0\n",
      "loss: [32401.2578125]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 68us/step - loss: 39455.2734\n",
      "rewards:  -100.0 q-value:  0\n",
      "loss: [39455.2734375]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 57us/step - loss: 14572.6562\n",
      "rewards:  -105.0 q-value:  0\n",
      "loss: [14572.65625]\n",
      "Exploring\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 54us/step - loss: 29999.7305\n",
      "rewards:  -115.0 q-value:  0\n",
      "loss: [29999.73046875]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 70us/step - loss: 35187.1055\n",
      "rewards:  -107.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [35187.10546875]\n",
      "Exploring\n",
      "Selected action  [4 2]\n",
      "[4 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 46us/step - loss: 30800.6641\n",
      "rewards:  -117.0 q-value:  0\n",
      "loss: [30800.6640625]\n",
      "Exploring\n",
      "Selected action  [3 2]\n",
      "[3 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 65us/step - loss: 13470.2080\n",
      "rewards:  -125.0 q-value:  0\n",
      "loss: [13470.2080078125]\n",
      "Exploring\n",
      "Selected action  [4 2]\n",
      "[4 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 48us/step - loss: 11899.6504\n",
      "rewards:  -126.0 q-value:  0\n",
      "loss: [11899.650390625]\n",
      "Exploring\n",
      "Selected action  [4 3]\n",
      "[4 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 75us/step - loss: 10797.4697\n",
      "rewards:  -123.0 q-value:  0\n",
      "loss: [10797.4697265625]\n",
      "Exploring\n",
      "Selected action  [2 3]\n",
      "[2 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 72us/step - loss: 22536.3281\n",
      "rewards:  -129.0 q-value:  0\n",
      "loss: [22536.328125]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 44us/step - loss: 21490.1582\n",
      "rewards:  -115.0 q-value:  0\n",
      "loss: [21490.158203125]\n",
      "Exploring\n",
      "Selected action  [3 0]\n",
      "[3 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 58us/step - loss: 33276.7305\n",
      "rewards:  -152.0 q-value:  0\n",
      "loss: [33276.73046875]\n",
      "Exploring\n",
      "Selected action  [3 1]\n",
      "[3 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 65us/step - loss: 28919.3555\n",
      "rewards:  -148.0 q-value:  0\n",
      "loss: [28919.35546875]\n",
      "Exploring\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 67us/step - loss: 40691.6719\n",
      "rewards:  -144.0 q-value:  0\n",
      "loss: [40691.671875]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 58us/step - loss: 21609.5430\n",
      "rewards:  -149.0 q-value:  0\n",
      "loss: [21609.54296875]\n",
      "Exploring\n",
      "Selected action  [0 2]\n",
      "[0 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 61us/step - loss: 16555.0156\n",
      "rewards:  -125.0 q-value:  0\n",
      "loss: [16555.015625]\n",
      "Exploring\n",
      "Selected action  [4 2]\n",
      "[4 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 50us/step - loss: 28660.3555\n",
      "rewards:  -125.0 q-value:  0\n",
      "loss: [28660.35546875]\n",
      "Exploring\n",
      "Selected action  [0 2]\n",
      "[0 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 64us/step - loss: 26087.2461\n",
      "rewards:  -131.0 q-value:  0\n",
      "loss: [26087.24609375]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 62us/step - loss: 14618.3848\n",
      "rewards:  -111.0 q-value:  0\n",
      "loss: [14618.384765625]\n",
      "Exploring\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 52us/step - loss: 17290.1270\n",
      "rewards:  -103.0 q-value:  0\n",
      "loss: [17290.126953125]\n",
      "Exploring\n",
      "Selected action  [3 2]\n",
      "[3 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 58us/step - loss: 38115.4609\n",
      "rewards:  -91.0 q-value:  0\n",
      "loss: [38115.4609375]\n",
      "Exploring\n",
      "Selected action  [3 1]\n",
      "[3 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 66us/step - loss: 29707.0664\n",
      "rewards:  -103.0 q-value:  0\n",
      "loss: [29707.06640625]\n",
      "Exploring\n",
      "Selected action  [3 2]\n",
      "[3 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 69us/step - loss: 12615.9287\n",
      "rewards:  -97.0 q-value:  0\n",
      "loss: [12615.9287109375]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 64us/step - loss: 21678.2500\n",
      "rewards:  -93.0 q-value:  0\n",
      "loss: [21678.25]\n",
      "Exploring\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 61us/step - loss: 18948.4961\n",
      "rewards:  -86.0 q-value:  0\n",
      "loss: [18948.49609375]\n",
      "Exploring\n",
      "Selected action  [4 2]\n",
      "[4 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 61us/step - loss: 27895.5312\n",
      "rewards:  -102.0 q-value:  0\n",
      "loss: [27895.53125]\n",
      "Exploring\n",
      "Selected action  [4 2]\n",
      "[4 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 59us/step - loss: 31515.2559\n",
      "rewards:  -103.0 q-value:  0\n",
      "loss: [31515.255859375]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 51us/step - loss: 24779.5000\n",
      "rewards:  -87.0 q-value:  0\n",
      "loss: [24779.5]\n",
      "Exploring\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 57us/step - loss: 13362.7031\n",
      "rewards:  -114.0 q-value:  0\n",
      "loss: [13362.703125]\n",
      "Exploring\n",
      "Selected action  [3 0]\n",
      "[3 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 71us/step - loss: 31479.9414\n",
      "rewards:  -106.0 q-value:  0\n",
      "loss: [31479.94140625]\n",
      "Exploring\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 52us/step - loss: 11952.1318\n",
      "rewards:  -82.0 q-value:  0\n",
      "loss: [11952.1318359375]\n",
      "Exploring\n",
      "Selected action  [3 0]\n",
      "[3 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 69us/step - loss: 19699.2188\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rewards:  -79.0 q-value:  0\n",
      "loss: [19699.21875]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 55us/step - loss: 32827.1523\n",
      "rewards:  -111.0 q-value:  0\n",
      "loss: [32827.15234375]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 59us/step - loss: 25012.3496\n",
      "rewards:  -91.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [25012.349609375]\n",
      "Exploring\n",
      "Selected action  [4 2]\n",
      "[4 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 63us/step - loss: 19543.5898\n",
      "rewards:  -93.0 q-value:  0\n",
      "loss: [19543.58984375]\n",
      "Exploring\n",
      "Selected action  [3 0]\n",
      "[3 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 51us/step - loss: 22819.5938\n",
      "rewards:  -94.0 q-value:  0\n",
      "loss: [22819.59375]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 58us/step - loss: 17454.0801\n",
      "rewards:  -99.0 q-value:  0\n",
      "loss: [17454.080078125]\n",
      "Exploring\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 54us/step - loss: 23031.0938\n",
      "rewards:  -83.0 q-value:  0\n",
      "loss: [23031.09375]\n",
      "Exploring\n",
      "Selected action  [0 2]\n",
      "[0 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 53us/step - loss: 41638.6094\n",
      "rewards:  -95.0 q-value:  0\n",
      "loss: [41638.609375]\n",
      "Exploring\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 55us/step - loss: 18022.4375\n",
      "rewards:  -112.0 q-value:  0\n",
      "loss: [18022.4375]\n",
      "Exploring\n",
      "Selected action  [3 2]\n",
      "[3 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 84us/step - loss: 28373.5117\n",
      "rewards:  -117.0 q-value:  0\n",
      "loss: [28373.51171875]\n",
      "Exploring\n",
      "Selected action  [3 1]\n",
      "[3 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 59us/step - loss: 21910.0000\n",
      "rewards:  -113.0 q-value:  0\n",
      "loss: [21910.0]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 56us/step - loss: 36710.4180\n",
      "rewards:  -153.0 q-value:  0\n",
      "loss: [36710.41796875]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 59us/step - loss: 20915.5078\n",
      "rewards:  -175.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [20915.5078125]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 70us/step - loss: 21948.7695\n",
      "rewards:  -180.0 q-value:  0\n",
      "loss: [21948.76953125]\n",
      "Exploring\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 53us/step - loss: 31050.0059\n",
      "rewards:  -152.0 q-value:  0\n",
      "loss: [31050.005859375]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 66us/step - loss: 21191.4062\n",
      "rewards:  -157.0 q-value:  0\n",
      "loss: [21191.40625]\n",
      "Exploring\n",
      "Selected action  [2 3]\n",
      "[2 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 69us/step - loss: 11261.2988\n",
      "rewards:  -170.0 q-value:  0\n",
      "loss: [11261.298828125]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 57us/step - loss: 22766.7734\n",
      "rewards:  -175.0 q-value:  0\n",
      "loss: [22766.7734375]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 50us/step - loss: 12790.7383\n",
      "rewards:  -168.0 q-value:  0\n",
      "loss: [12790.73828125]\n",
      "Exploring\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 57us/step - loss: 17318.4023\n",
      "rewards:  -156.0 q-value:  0\n",
      "loss: [17318.40234375]\n",
      "Exploring\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 59us/step - loss: 26245.2031\n",
      "rewards:  -133.0 q-value:  0\n",
      "loss: [26245.203125]\n",
      "Exploring\n",
      "Selected action  [4 2]\n",
      "[4 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 74us/step - loss: 26589.2148\n",
      "rewards:  -138.0 q-value:  0\n",
      "loss: [26589.21484375]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 54us/step - loss: 18405.9238\n",
      "rewards:  -143.0 q-value:  0\n",
      "loss: [18405.923828125]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 63us/step - loss: 11302.5430\n",
      "rewards:  -148.0 q-value:  0\n",
      "loss: [11302.54296875]\n",
      "Exploring\n",
      "Selected action  [0 2]\n",
      "[0 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 77us/step - loss: 20490.5234\n",
      "rewards:  -120.0 q-value:  0\n",
      "loss: [20490.5234375]\n",
      "Exploring\n",
      "Selected action  [3 1]\n",
      "[3 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 57us/step - loss: 30059.5273\n",
      "rewards:  -114.0 q-value:  0\n",
      "loss: [30059.52734375]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 57us/step - loss: 27561.9199\n",
      "rewards:  -118.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [27561.919921875]\n",
      "Exploring\n",
      "Selected action  [0 2]\n",
      "[0 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 53us/step - loss: 13185.3525\n",
      "rewards:  -118.0 q-value:  0\n",
      "loss: [13185.3525390625]\n",
      "Exploring\n",
      "Selected action  [3 2]\n",
      "[3 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 69us/step - loss: 35382.8789\n",
      "rewards:  -127.0 q-value:  0\n",
      "loss: [35382.87890625]\n",
      "Exploring\n",
      "Selected action  [3 2]\n",
      "[3 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 75us/step - loss: 17043.1758\n",
      "rewards:  -133.0 q-value:  0\n",
      "loss: [17043.17578125]\n",
      "Exploring\n",
      "Selected action  [2 3]\n",
      "[2 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 54us/step - loss: 35898.6875\n",
      "rewards:  -101.0 q-value:  0\n",
      "loss: [35898.6875]\n",
      "Exploring\n",
      "Selected action  [4 2]\n",
      "[4 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 60us/step - loss: 20027.6797\n",
      "rewards:  -108.0 q-value:  0\n",
      "loss: [20027.6796875]\n",
      "Exploring\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 50us/step - loss: 23872.5000\n",
      "rewards:  -110.0 q-value:  0\n",
      "loss: [23872.5]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 42us/step - loss: 27773.1934\n",
      "rewards:  -115.0 q-value:  0\n",
      "loss: [27773.193359375]\n",
      "Exploring\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 50us/step - loss: 24227.9336\n",
      "rewards:  -105.0 q-value:  0\n",
      "loss: [24227.93359375]\n",
      "Exploring\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 66us/step - loss: 25289.2695\n",
      "rewards:  -106.0 q-value:  0\n",
      "loss: [25289.26953125]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 75us/step - loss: 24696.9902\n",
      "rewards:  -85.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [24696.990234375]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 52us/step - loss: 29116.4219\n",
      "rewards:  -110.0 q-value:  0\n",
      "loss: [29116.421875]\n",
      "Exploring\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 58us/step - loss: 27754.1992\n",
      "rewards:  -126.0 q-value:  0\n",
      "loss: [27754.19921875]\n",
      "Number of actions available 3\n",
      "Episode : 5\n",
      "Exploring\n",
      "Selected action  [4 0]\n",
      "[4 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 121us/step - loss: 34848.4375\n",
      "rewards:  -6.0 q-value:  0\n",
      "loss: [34848.4375]\n",
      "Exploiting\n",
      "Selected action  [3 0]\n",
      "[3 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 55us/step - loss: 38197.5859\n",
      "rewards:  -12.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [38197.5859375]\n",
      "Exploring\n",
      "Selected action  [4 0]\n",
      "[4 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 65us/step - loss: 30554.6816\n",
      "rewards:  -15.0 q-value:  0\n",
      "loss: [30554.681640625]\n",
      "Exploring\n",
      "Selected action  [4 0]\n",
      "[4 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 67us/step - loss: 19926.8125\n",
      "rewards:  -16.0 q-value:  0\n",
      "loss: [19926.8125]\n",
      "Exploring\n",
      "Selected action  [3 0]\n",
      "[3 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 55us/step - loss: 25855.7559\n",
      "rewards:  -16.0 q-value:  0\n",
      "loss: [25855.755859375]\n",
      "Exploring\n",
      "Selected action  [4 0]\n",
      "[4 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 60us/step - loss: 25037.6875\n",
      "rewards:  -17.0 q-value:  0\n",
      "loss: [25037.6875]\n",
      "Exploring\n",
      "Selected action  [4 0]\n",
      "[4 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 110us/step - loss: 13322.7559\n",
      "rewards:  -18.0 q-value:  0\n",
      "loss: [13322.755859375]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 53us/step - loss: 17812.0391\n",
      "rewards:  -23.0 q-value:  0\n",
      "loss: [17812.0390625]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 63us/step - loss: 54678.9688\n",
      "rewards:  -28.0 q-value:  0\n",
      "loss: [54678.96875]\n",
      "Exploring\n",
      "Selected action  [4 0]\n",
      "[4 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 110us/step - loss: 21011.7520\n",
      "rewards:  -29.0 q-value:  0\n",
      "loss: [21011.751953125]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 44us/step - loss: 16790.1523\n",
      "rewards:  -34.0 q-value:  0\n",
      "loss: [16790.15234375]\n",
      "Exploring\n",
      "Selected action  [4 0]\n",
      "[4 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 61us/step - loss: 22561.4941\n",
      "rewards:  -35.0 q-value:  0\n",
      "loss: [22561.494140625]\n",
      "Exploring\n",
      "Selected action  [4 0]\n",
      "[4 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 65us/step - loss: 22826.5898\n",
      "rewards:  -43.0 q-value:  0\n",
      "loss: [22826.58984375]\n",
      "Exploring\n",
      "Selected action  [4 0]\n",
      "[4 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 61us/step - loss: 38108.0039\n",
      "rewards:  -44.0 q-value:  0\n",
      "loss: [38108.00390625]\n",
      "Exploring\n",
      "Selected action  [3 0]\n",
      "[3 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 70us/step - loss: 36340.9062\n",
      "rewards:  -54.0 q-value:  0\n",
      "loss: [36340.90625]\n",
      "Exploring\n",
      "Selected action  [3 0]\n",
      "[3 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 64us/step - loss: 19070.5508\n",
      "rewards:  -56.0 q-value:  0\n",
      "loss: [19070.55078125]\n",
      "Exploring\n",
      "Selected action  [4 0]\n",
      "[4 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 67us/step - loss: 16569.9766\n",
      "rewards:  -59.0 q-value:  0\n",
      "loss: [16569.9765625]\n",
      "Exploring\n",
      "Selected action  [3 0]\n",
      "[3 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 41us/step - loss: 32536.8555\n",
      "rewards:  -59.0 q-value:  0\n",
      "loss: [32536.85546875]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 46us/step - loss: 19184.0254\n",
      "rewards:  -64.0 q-value:  0\n",
      "loss: [19184.025390625]\n",
      "Exploring\n",
      "Selected action  [4 0]\n",
      "[4 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 47us/step - loss: 7592.8262\n",
      "rewards:  -70.0 q-value:  0\n",
      "loss: [7592.826171875]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 75us/step - loss: 10577.3848\n",
      "rewards:  -75.0 q-value:  0\n",
      "loss: [10577.384765625]\n",
      "Exploring\n",
      "Selected action  [3 0]\n",
      "[3 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 58us/step - loss: 7413.2344\n",
      "rewards:  -81.0 q-value:  0\n",
      "loss: [7413.234375]\n",
      "Exploring\n",
      "Selected action  [3 0]\n",
      "[3 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 125us/step - loss: 30045.7344\n",
      "rewards:  -84.0 q-value:  0\n",
      "loss: [30045.734375]\n",
      "Exploring\n",
      "Selected action  [4 0]\n",
      "[4 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 57us/step - loss: 9945.6025\n",
      "rewards:  -85.0 q-value:  0\n",
      "loss: [9945.6025390625]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 70us/step - loss: 26398.3477\n",
      "rewards:  -90.0 q-value:  0\n",
      "loss: [26398.34765625]\n",
      "Exploring\n",
      "Selected action  [3 0]\n",
      "[3 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 70us/step - loss: 26174.4922\n",
      "rewards:  -93.0 q-value:  0\n",
      "loss: [26174.4921875]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 78us/step - loss: 17489.6719\n",
      "rewards:  -98.0 q-value:  0\n",
      "loss: [17489.671875]\n",
      "Exploring\n",
      "Selected action  [3 0]\n",
      "[3 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 81us/step - loss: 22107.1875\n",
      "rewards:  -99.0 q-value:  0\n",
      "loss: [22107.1875]\n",
      "Exploring\n",
      "Selected action  [4 0]\n",
      "[4 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 57us/step - loss: 17641.5352\n",
      "rewards:  -100.0 q-value:  0\n",
      "loss: [17641.53515625]\n",
      "Exploring\n",
      "Selected action  [3 0]\n",
      "[3 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 74us/step - loss: 34079.0430\n",
      "rewards:  -101.0 q-value:  0\n",
      "loss: [34079.04296875]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 63us/step - loss: 9499.9365\n",
      "rewards:  -106.0 q-value:  0\n",
      "loss: [9499.9365234375]\n",
      "Exploring\n",
      "Selected action  [3 0]\n",
      "[3 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 64us/step - loss: 20737.2344\n",
      "rewards:  -107.0 q-value:  0\n",
      "loss: [20737.234375]\n",
      "Exploiting\n",
      "Selected action  [4 0]\n",
      "[4 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 60us/step - loss: 19111.8750\n",
      "rewards:  -108.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [19111.875]\n",
      "Exploring\n",
      "Selected action  [3 0]\n",
      "[3 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 83us/step - loss: 9653.2314\n",
      "rewards:  -109.0 q-value:  0\n",
      "loss: [9653.2314453125]\n",
      "Exploring\n",
      "Selected action  [3 0]\n",
      "[3 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 71us/step - loss: 33296.1562\n",
      "rewards:  -110.0 q-value:  0\n",
      "loss: [33296.15625]\n",
      "Exploring\n",
      "Selected action  [4 0]\n",
      "[4 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 55us/step - loss: 9797.3271\n",
      "rewards:  -114.0 q-value:  0\n",
      "loss: [9797.3271484375]\n",
      "Exploring\n",
      "Selected action  [4 0]\n",
      "[4 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 105us/step - loss: 21286.6367\n",
      "rewards:  -115.0 q-value:  0\n",
      "loss: [21286.63671875]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 75us/step - loss: 22695.6445\n",
      "rewards:  -120.0 q-value:  0\n",
      "loss: [22695.64453125]\n",
      "Exploring\n",
      "Selected action  [3 0]\n",
      "[3 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 59us/step - loss: 25080.7793\n",
      "rewards:  -128.0 q-value:  0\n",
      "loss: [25080.779296875]\n",
      "Exploring\n",
      "Selected action  [3 0]\n",
      "[3 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 46us/step - loss: 12318.8535\n",
      "rewards:  -136.0 q-value:  0\n",
      "loss: [12318.853515625]\n",
      "Exploring\n",
      "Selected action  [3 0]\n",
      "[3 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 48us/step - loss: 26227.3750\n",
      "rewards:  -138.0 q-value:  0\n",
      "loss: [26227.375]\n",
      "Exploring\n",
      "Selected action  [3 0]\n",
      "[3 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 78us/step - loss: 18039.8574\n",
      "rewards:  -140.0 q-value:  0\n",
      "loss: [18039.857421875]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 68us/step - loss: 21139.4512\n",
      "rewards:  -145.0 q-value:  0\n",
      "loss: [21139.451171875]\n",
      "Exploring\n",
      "Selected action  [4 0]\n",
      "[4 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 73us/step - loss: 31809.3789\n",
      "rewards:  -152.0 q-value:  0\n",
      "loss: [31809.37890625]\n",
      "Exploring\n",
      "Selected action  [3 0]\n",
      "[3 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 47us/step - loss: 24324.6191\n",
      "rewards:  -157.0 q-value:  0\n",
      "loss: [24324.619140625]\n",
      "Exploring\n",
      "Selected action  [4 0]\n",
      "[4 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 65us/step - loss: 14483.5312\n",
      "rewards:  -159.0 q-value:  0\n",
      "loss: [14483.53125]\n",
      "Exploring\n",
      "Selected action  [4 0]\n",
      "[4 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 61us/step - loss: 13786.7363\n",
      "rewards:  -161.0 q-value:  0\n",
      "loss: [13786.736328125]\n",
      "Exploring\n",
      "Selected action  [3 0]\n",
      "[3 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 67us/step - loss: 31517.6133\n",
      "rewards:  -166.0 q-value:  0\n",
      "loss: [31517.61328125]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 47us/step - loss: 21611.7012\n",
      "rewards:  -171.0 q-value:  0\n",
      "loss: [21611.701171875]\n",
      "Exploring\n",
      "Selected action  [4 0]\n",
      "[4 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 133us/step - loss: 22570.2812\n",
      "rewards:  -177.0 q-value:  0\n",
      "loss: [22570.28125]\n",
      "Exploring\n",
      "Selected action  [3 0]\n",
      "[3 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 48us/step - loss: 30110.5625\n",
      "rewards:  -184.0 q-value:  0\n",
      "loss: [30110.5625]\n",
      "Exploring\n",
      "Selected action  [3 0]\n",
      "[3 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 66us/step - loss: 11350.3701\n",
      "rewards:  -185.0 q-value:  0\n",
      "loss: [11350.3701171875]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 54us/step - loss: 23064.3516\n",
      "rewards:  -190.0 q-value:  0\n",
      "loss: [23064.3515625]\n",
      "Exploring\n",
      "Selected action  [3 0]\n",
      "[3 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 70us/step - loss: 17103.5840\n",
      "rewards:  -191.0 q-value:  0\n",
      "loss: [17103.583984375]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 61us/step - loss: 22917.0469\n",
      "rewards:  -196.0 q-value:  0\n",
      "loss: [22917.046875]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 51us/step - loss: 32401.8516\n",
      "rewards:  -201.0 q-value:  0\n",
      "loss: [32401.8515625]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 58us/step - loss: 13833.9170\n",
      "rewards:  -206.0 q-value:  0\n",
      "loss: [13833.9169921875]\n",
      "Exploring\n",
      "Selected action  [3 0]\n",
      "[3 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 55us/step - loss: 40501.8047\n",
      "rewards:  -207.0 q-value:  0\n",
      "loss: [40501.8046875]\n",
      "Exploring\n",
      "Selected action  [3 0]\n",
      "[3 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 56us/step - loss: 19119.0293\n",
      "rewards:  -208.0 q-value:  0\n",
      "loss: [19119.029296875]\n",
      "Exploring\n",
      "Selected action  [3 0]\n",
      "[3 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 61us/step - loss: 21569.5000\n",
      "rewards:  -209.0 q-value:  0\n",
      "loss: [21569.5]\n",
      "Exploring\n",
      "Selected action  [4 0]\n",
      "[4 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 79us/step - loss: 18886.6777\n",
      "rewards:  -213.0 q-value:  0\n",
      "loss: [18886.677734375]\n",
      "Exploring\n",
      "Selected action  [4 0]\n",
      "[4 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 68us/step - loss: 22622.7480\n",
      "rewards:  -217.0 q-value:  0\n",
      "loss: [22622.748046875]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 69us/step - loss: 28071.3066\n",
      "rewards:  -222.0 q-value:  0\n",
      "loss: [28071.306640625]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 66us/step - loss: 25267.4902\n",
      "rewards:  -227.0 q-value:  0\n",
      "loss: [25267.490234375]\n",
      "Exploring\n",
      "Selected action  [4 0]\n",
      "[4 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 69us/step - loss: 20203.9805\n",
      "rewards:  -230.0 q-value:  0\n",
      "loss: [20203.98046875]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 62us/step - loss: 17893.9688\n",
      "rewards:  -235.0 q-value:  0\n",
      "loss: [17893.96875]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 65us/step - loss: 17537.9082\n",
      "rewards:  -240.0 q-value:  0\n",
      "loss: [17537.908203125]\n",
      "Exploring\n",
      "Selected action  [4 0]\n",
      "[4 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 85us/step - loss: 21790.1543\n",
      "rewards:  -243.0 q-value:  0\n",
      "loss: [21790.154296875]\n",
      "Exploring\n",
      "Selected action  [4 0]\n",
      "[4 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 68us/step - loss: 18726.8633\n",
      "rewards:  -244.0 q-value:  0\n",
      "loss: [18726.86328125]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 61us/step - loss: 25239.5938\n",
      "rewards:  -249.0 q-value:  0\n",
      "loss: [25239.59375]\n",
      "Exploring\n",
      "Selected action  [4 0]\n",
      "[4 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 49us/step - loss: 29805.9375\n",
      "rewards:  -250.0 q-value:  0\n",
      "loss: [29805.9375]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 63us/step - loss: 24843.5000\n",
      "rewards:  -255.0 q-value:  0\n",
      "loss: [24843.5]\n",
      "Exploring\n",
      "Selected action  [4 0]\n",
      "[4 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 64us/step - loss: 22372.9824\n",
      "rewards:  -256.0 q-value:  0\n",
      "loss: [22372.982421875]\n",
      "Exploiting\n",
      "Selected action  [3 0]\n",
      "[3 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 79us/step - loss: 29508.6953\n",
      "rewards:  -260.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [29508.6953125]\n",
      "Exploring\n",
      "Selected action  [4 0]\n",
      "[4 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 68us/step - loss: 17429.7656\n",
      "rewards:  -260.0 q-value:  0\n",
      "loss: [17429.765625]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 51us/step - loss: 33583.2188\n",
      "rewards:  -265.0 q-value:  0\n",
      "loss: [33583.21875]\n",
      "Exploring\n",
      "Selected action  [4 0]\n",
      "[4 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 48us/step - loss: 13941.8125\n",
      "rewards:  -265.0 q-value:  0\n",
      "loss: [13941.8125]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 47us/step - loss: 27341.8438\n",
      "rewards:  -270.0 q-value:  0\n",
      "loss: [27341.84375]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 56us/step - loss: 19871.3750\n",
      "rewards:  -275.0 q-value:  0\n",
      "loss: [19871.375]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 64us/step - loss: 21085.6797\n",
      "rewards:  -280.0 q-value:  0\n",
      "loss: [21085.6796875]\n",
      "Exploring\n",
      "Selected action  [3 0]\n",
      "[3 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 83us/step - loss: 28035.0625\n",
      "rewards:  -286.0 q-value:  0\n",
      "loss: [28035.0625]\n",
      "Exploring\n",
      "Selected action  [4 0]\n",
      "[4 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 66us/step - loss: 13504.6494\n",
      "rewards:  -286.0 q-value:  0\n",
      "loss: [13504.6494140625]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 55us/step - loss: 21757.9375\n",
      "rewards:  -291.0 q-value:  0\n",
      "loss: [21757.9375]\n",
      "Exploring\n",
      "Selected action  [4 0]\n",
      "[4 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 63us/step - loss: 29487.1875\n",
      "rewards:  -291.0 q-value:  0\n",
      "loss: [29487.1875]\n",
      "Exploring\n",
      "Selected action  [4 0]\n",
      "[4 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 89us/step - loss: 23133.9688\n",
      "rewards:  -291.0 q-value:  0\n",
      "loss: [23133.96875]\n",
      "Exploring\n",
      "Selected action  [4 0]\n",
      "[4 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 55us/step - loss: 24347.6875\n",
      "rewards:  -291.0 q-value:  0\n",
      "loss: [24347.6875]\n",
      "Exploring\n",
      "Selected action  [4 0]\n",
      "[4 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 53us/step - loss: 11570.9375\n",
      "rewards:  -291.0 q-value:  0\n",
      "loss: [11570.9375]\n",
      "Exploring\n",
      "Selected action  [3 0]\n",
      "[3 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 69us/step - loss: 31173.5156\n",
      "rewards:  -295.0 q-value:  0\n",
      "loss: [31173.515625]\n",
      "Exploring\n",
      "Selected action  [4 0]\n",
      "[4 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 60us/step - loss: 19264.5938\n",
      "rewards:  -296.0 q-value:  0\n",
      "loss: [19264.59375]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 59us/step - loss: 32001.5312\n",
      "rewards:  -301.0 q-value:  0\n",
      "loss: [32001.53125]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 63us/step - loss: 21489.8242\n",
      "rewards:  -306.0 q-value:  0\n",
      "loss: [21489.82421875]\n",
      "Exploring\n",
      "Selected action  [3 0]\n",
      "[3 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 56us/step - loss: 15015.8125\n",
      "rewards:  -309.0 q-value:  0\n",
      "loss: [15015.8125]\n",
      "Exploring\n",
      "Selected action  [4 0]\n",
      "[4 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 86us/step - loss: 34521.2578\n",
      "rewards:  -310.0 q-value:  0\n",
      "loss: [34521.2578125]\n",
      "Exploring\n",
      "Selected action  [4 0]\n",
      "[4 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 59us/step - loss: 32025.5039\n",
      "rewards:  -311.0 q-value:  0\n",
      "loss: [32025.50390625]\n",
      "Exploring\n",
      "Selected action  [4 0]\n",
      "[4 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 54us/step - loss: 22862.2812\n",
      "rewards:  -312.0 q-value:  0\n",
      "loss: [22862.28125]\n",
      "Exploring\n",
      "Selected action  [4 0]\n",
      "[4 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 74us/step - loss: 23267.2188\n",
      "rewards:  -313.0 q-value:  0\n",
      "loss: [23267.21875]\n",
      "Exploring\n",
      "Selected action  [4 0]\n",
      "[4 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 56us/step - loss: 17609.0000\n",
      "rewards:  -314.0 q-value:  0\n",
      "loss: [17609.0]\n",
      "Exploring\n",
      "Selected action  [3 0]\n",
      "[3 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 49us/step - loss: 20628.0234\n",
      "rewards:  -320.0 q-value:  0\n",
      "loss: [20628.0234375]\n",
      "Exploring\n",
      "Selected action  [3 0]\n",
      "[3 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 63us/step - loss: 37853.7422\n",
      "rewards:  -323.0 q-value:  0\n",
      "loss: [37853.7421875]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 46us/step - loss: 34231.9453\n",
      "rewards:  -328.0 q-value:  0\n",
      "loss: [34231.9453125]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 52us/step - loss: 39370.5078\n",
      "rewards:  -333.0 q-value:  0\n",
      "loss: [39370.5078125]\n",
      "Exploring\n",
      "Selected action  [4 0]\n",
      "[4 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 73us/step - loss: 35461.0703\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rewards:  -334.0 q-value:  0\n",
      "loss: [35461.0703125]\n",
      "Exploring\n",
      "Selected action  [4 0]\n",
      "[4 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 57us/step - loss: 21220.5176\n",
      "rewards:  -335.0 q-value:  0\n",
      "loss: [21220.517578125]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 67us/step - loss: 16864.0430\n",
      "rewards:  -340.0 q-value:  0\n",
      "loss: [16864.04296875]\n",
      "Exploring\n",
      "Selected action  [4 0]\n",
      "[4 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 70us/step - loss: 39755.9688\n",
      "rewards:  -341.0 q-value:  0\n",
      "loss: [39755.96875]\n",
      "Exploring\n",
      "Selected action  [3 0]\n",
      "[3 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 58us/step - loss: 30542.3477\n",
      "rewards:  -341.0 q-value:  0\n",
      "loss: [30542.34765625]\n",
      "Exploring\n",
      "Selected action  [4 0]\n",
      "[4 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 71us/step - loss: 20072.7188\n",
      "rewards:  -342.0 q-value:  0\n",
      "loss: [20072.71875]\n",
      "Exploring\n",
      "Selected action  [3 0]\n",
      "[3 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 50us/step - loss: 20053.9492\n",
      "rewards:  -342.0 q-value:  0\n",
      "loss: [20053.94921875]\n",
      "Exploring\n",
      "Selected action  [3 0]\n",
      "[3 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 83us/step - loss: 15498.6680\n",
      "rewards:  -342.0 q-value:  0\n",
      "loss: [15498.66796875]\n",
      "Exploring\n",
      "Selected action  [3 0]\n",
      "[3 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 62us/step - loss: 20542.0117\n",
      "rewards:  -342.0 q-value:  0\n",
      "loss: [20542.01171875]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 55us/step - loss: 20266.4844\n",
      "rewards:  -347.0 q-value:  0\n",
      "loss: [20266.484375]\n",
      "Exploring\n",
      "Selected action  [4 0]\n",
      "[4 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 60us/step - loss: 42169.1250\n",
      "rewards:  -348.0 q-value:  0\n",
      "loss: [42169.125]\n",
      "Exploring\n",
      "Selected action  [3 0]\n",
      "[3 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 66us/step - loss: 26675.1367\n",
      "rewards:  -351.0 q-value:  0\n",
      "loss: [26675.13671875]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 57us/step - loss: 27613.9062\n",
      "rewards:  -356.0 q-value:  0\n",
      "loss: [27613.90625]\n",
      "Exploring\n",
      "Selected action  [4 0]\n",
      "[4 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 66us/step - loss: 23569.0625\n",
      "rewards:  -364.0 q-value:  0\n",
      "loss: [23569.0625]\n",
      "Exploring\n",
      "Selected action  [4 0]\n",
      "[4 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 58us/step - loss: 37178.1875\n",
      "rewards:  -365.0 q-value:  0\n",
      "loss: [37178.1875]\n",
      "Exploring\n",
      "Selected action  [4 0]\n",
      "[4 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 64us/step - loss: 33890.8242\n",
      "rewards:  -366.0 q-value:  0\n",
      "loss: [33890.82421875]\n",
      "Exploring\n",
      "Selected action  [4 0]\n",
      "[4 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 53us/step - loss: 48018.6250\n",
      "rewards:  -367.0 q-value:  0\n",
      "loss: [48018.625]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 42us/step - loss: 19416.5000\n",
      "rewards:  -372.0 q-value:  0\n",
      "loss: [19416.5]\n",
      "Exploring\n",
      "Selected action  [4 0]\n",
      "[4 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 81us/step - loss: 23878.4375\n",
      "rewards:  -373.0 q-value:  0\n",
      "loss: [23878.4375]\n",
      "Exploiting\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 58us/step - loss: 39000.3750\n",
      "rewards:  -378.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [39000.375]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 65us/step - loss: 25092.2422\n",
      "rewards:  -383.0 q-value:  0\n",
      "loss: [25092.2421875]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 67us/step - loss: 26758.0938\n",
      "rewards:  -388.0 q-value:  0\n",
      "loss: [26758.09375]\n",
      "Exploring\n",
      "Selected action  [3 0]\n",
      "[3 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 64us/step - loss: 32901.5156\n",
      "rewards:  -391.0 q-value:  0\n",
      "loss: [32901.515625]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 65us/step - loss: 26593.5625\n",
      "rewards:  -396.0 q-value:  0\n",
      "loss: [26593.5625]\n",
      "Exploring\n",
      "Selected action  [3 0]\n",
      "[3 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 46us/step - loss: 20239.1406\n",
      "rewards:  -398.0 q-value:  0\n",
      "loss: [20239.140625]\n",
      "Exploring\n",
      "Selected action  [4 0]\n",
      "[4 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 71us/step - loss: 24540.0625\n",
      "rewards:  -401.0 q-value:  0\n",
      "loss: [24540.0625]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 56us/step - loss: 25324.4355\n",
      "rewards:  -406.0 q-value:  0\n",
      "loss: [25324.435546875]\n",
      "Exploring\n",
      "Selected action  [3 0]\n",
      "[3 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 47us/step - loss: 58168.7383\n",
      "rewards:  -408.0 q-value:  0\n",
      "loss: [58168.73828125]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 41us/step - loss: 22995.5098\n",
      "rewards:  -413.0 q-value:  0\n",
      "loss: [22995.509765625]\n",
      "Exploring\n",
      "Selected action  [4 0]\n",
      "[4 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 77us/step - loss: 40515.6133\n",
      "rewards:  -419.0 q-value:  0\n",
      "loss: [40515.61328125]\n",
      "Exploring\n",
      "Selected action  [3 0]\n",
      "[3 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 65us/step - loss: 21880.1875\n",
      "rewards:  -425.0 q-value:  0\n",
      "loss: [21880.1875]\n",
      "Exploring\n",
      "Selected action  [3 0]\n",
      "[3 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 53us/step - loss: 38935.2188\n",
      "rewards:  -428.0 q-value:  0\n",
      "loss: [38935.21875]\n",
      "Exploring\n",
      "Selected action  [3 0]\n",
      "[3 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 69us/step - loss: 24158.4062\n",
      "rewards:  -431.0 q-value:  0\n",
      "loss: [24158.40625]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 51us/step - loss: 34098.9766\n",
      "rewards:  -436.0 q-value:  0\n",
      "loss: [34098.9765625]\n",
      "Exploring\n",
      "Selected action  [4 0]\n",
      "[4 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 44us/step - loss: 22367.8125\n",
      "rewards:  -437.0 q-value:  0\n",
      "loss: [22367.8125]\n",
      "Exploring\n",
      "Selected action  [4 0]\n",
      "[4 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 55us/step - loss: 36151.4688\n",
      "rewards:  -438.0 q-value:  0\n",
      "loss: [36151.46875]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 48us/step - loss: 47979.9688\n",
      "rewards:  -443.0 q-value:  0\n",
      "loss: [47979.96875]\n",
      "Exploring\n",
      "Selected action  [3 0]\n",
      "[3 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 57us/step - loss: 29381.7559\n",
      "rewards:  -444.0 q-value:  0\n",
      "loss: [29381.755859375]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 60us/step - loss: 35637.7109\n",
      "rewards:  -449.0 q-value:  0\n",
      "loss: [35637.7109375]\n",
      "Exploring\n",
      "Selected action  [4 0]\n",
      "[4 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 56us/step - loss: 30586.4375\n",
      "rewards:  -450.0 q-value:  0\n",
      "loss: [30586.4375]\n",
      "Exploring\n",
      "Selected action  [4 0]\n",
      "[4 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 60us/step - loss: 27718.3086\n",
      "rewards:  -451.0 q-value:  0\n",
      "loss: [27718.30859375]\n",
      "Exploring\n",
      "Selected action  [4 0]\n",
      "[4 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 46us/step - loss: 28902.5176\n",
      "rewards:  -455.0 q-value:  0\n",
      "loss: [28902.517578125]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 69us/step - loss: 28904.2812\n",
      "rewards:  -460.0 q-value:  0\n",
      "loss: [28904.28125]\n",
      "Exploring\n",
      "Selected action  [3 0]\n",
      "[3 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 58us/step - loss: 21619.1270\n",
      "rewards:  -461.0 q-value:  0\n",
      "loss: [21619.126953125]\n",
      "Exploiting\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 68us/step - loss: 29487.8398\n",
      "rewards:  -466.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [29487.83984375]\n",
      "Exploring\n",
      "Selected action  [3 0]\n",
      "[3 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 49us/step - loss: 43710.9961\n",
      "rewards:  -467.0 q-value:  0\n",
      "loss: [43710.99609375]\n",
      "Exploring\n",
      "Selected action  [4 0]\n",
      "[4 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 65us/step - loss: 26903.8750\n",
      "rewards:  -468.0 q-value:  0\n",
      "loss: [26903.875]\n",
      "Exploring\n",
      "Selected action  [4 0]\n",
      "[4 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 46us/step - loss: 63426.3359\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rewards:  -469.0 q-value:  0\n",
      "loss: [63426.3359375]\n",
      "Exploring\n",
      "Selected action  [4 0]\n",
      "[4 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 70us/step - loss: 37322.0273\n",
      "rewards:  -470.0 q-value:  0\n",
      "loss: [37322.02734375]\n",
      "Exploring\n",
      "Selected action  [4 0]\n",
      "[4 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 52us/step - loss: 30767.1016\n",
      "rewards:  -471.0 q-value:  0\n",
      "loss: [30767.1015625]\n",
      "Exploring\n",
      "Selected action  [4 0]\n",
      "[4 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 82us/step - loss: 31019.0312\n",
      "rewards:  -472.0 q-value:  0\n",
      "loss: [31019.03125]\n",
      "Exploiting\n",
      "Selected action  [3 0]\n",
      "[3 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 83us/step - loss: 33311.4375\n",
      "rewards:  -480.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [33311.4375]\n",
      "Exploring\n",
      "Selected action  [3 0]\n",
      "[3 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 65us/step - loss: 23077.7988\n",
      "rewards:  -482.0 q-value:  0\n",
      "loss: [23077.798828125]\n",
      "Exploiting\n",
      "Selected action  [3 0]\n",
      "[3 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 73us/step - loss: 27891.7188\n",
      "rewards:  -484.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [27891.71875]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 50us/step - loss: 31205.6367\n",
      "rewards:  -489.0 q-value:  0\n",
      "loss: [31205.63671875]\n",
      "Exploiting\n",
      "Selected action  [3 0]\n",
      "[3 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 47us/step - loss: 35615.6172\n",
      "rewards:  -491.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [35615.6171875]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 91us/step - loss: 37504.3867\n",
      "rewards:  -496.0 q-value:  0\n",
      "loss: [37504.38671875]\n",
      "Exploring\n",
      "Selected action  [4 0]\n",
      "[4 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 43us/step - loss: 45657.3008\n",
      "rewards:  -503.0 q-value:  0\n",
      "loss: [45657.30078125]\n",
      "Exploring\n",
      "Selected action  [3 0]\n",
      "[3 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 50us/step - loss: 38609.8125\n",
      "rewards:  -508.0 q-value:  0\n",
      "loss: [38609.8125]\n",
      "Exploring\n",
      "Selected action  [3 0]\n",
      "[3 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 72us/step - loss: 41452.9688\n",
      "rewards:  -514.0 q-value:  0\n",
      "loss: [41452.96875]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 60us/step - loss: 27846.8125\n",
      "rewards:  -519.0 q-value:  0\n",
      "loss: [27846.8125]\n",
      "Exploring\n",
      "Selected action  [3 0]\n",
      "[3 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 68us/step - loss: 51032.5938\n",
      "rewards:  -524.0 q-value:  0\n",
      "loss: [51032.59375]\n",
      "Exploring\n",
      "Selected action  [4 0]\n",
      "[4 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 68us/step - loss: 45818.2188\n",
      "rewards:  -530.0 q-value:  0\n",
      "loss: [45818.21875]\n",
      "Exploring\n",
      "Selected action  [4 0]\n",
      "[4 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 55us/step - loss: 31292.8438\n",
      "rewards:  -531.0 q-value:  0\n",
      "loss: [31292.84375]\n",
      "Exploring\n",
      "Selected action  [3 0]\n",
      "[3 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 48us/step - loss: 35505.1250\n",
      "rewards:  -538.0 q-value:  0\n",
      "loss: [35505.125]\n",
      "Exploring\n",
      "Selected action  [4 0]\n",
      "[4 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 62us/step - loss: 46276.2383\n",
      "rewards:  -538.0 q-value:  0\n",
      "loss: [46276.23828125]\n",
      "Exploring\n",
      "Selected action  [4 0]\n",
      "[4 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 74us/step - loss: 36295.2812\n",
      "rewards:  -538.0 q-value:  0\n",
      "loss: [36295.28125]\n",
      "Exploring\n",
      "Selected action  [4 0]\n",
      "[4 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 84us/step - loss: 46553.8438\n",
      "rewards:  -538.0 q-value:  0\n",
      "loss: [46553.84375]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 60us/step - loss: 31313.1250\n",
      "rewards:  -543.0 q-value:  0\n",
      "loss: [31313.125]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 43us/step - loss: 33994.0078\n",
      "rewards:  -548.0 q-value:  0\n",
      "loss: [33994.0078125]\n",
      "Exploring\n",
      "Selected action  [4 0]\n",
      "[4 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 64us/step - loss: 39280.3125\n",
      "rewards:  -548.0 q-value:  0\n",
      "loss: [39280.3125]\n",
      "Exploring\n",
      "Selected action  [3 0]\n",
      "[3 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 51us/step - loss: 56695.4375\n",
      "rewards:  -549.0 q-value:  0\n",
      "loss: [56695.4375]\n",
      "Exploiting\n",
      "Selected action  [3 0]\n",
      "[3 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 84us/step - loss: 16353.6250\n",
      "rewards:  -550.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [16353.625]\n",
      "Exploring\n",
      "Selected action  [4 0]\n",
      "[4 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 51us/step - loss: 37430.7266\n",
      "rewards:  -550.0 q-value:  0\n",
      "loss: [37430.7265625]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 62us/step - loss: 39192.3125\n",
      "rewards:  -555.0 q-value:  0\n",
      "loss: [39192.3125]\n",
      "Exploring\n",
      "Selected action  [4 0]\n",
      "[4 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 56us/step - loss: 44635.7461\n",
      "rewards:  -555.0 q-value:  0\n",
      "loss: [44635.74609375]\n",
      "Exploring\n",
      "Selected action  [3 0]\n",
      "[3 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 47us/step - loss: 33431.2266\n",
      "rewards:  -556.0 q-value:  0\n",
      "loss: [33431.2265625]\n",
      "Exploring\n",
      "Selected action  [4 0]\n",
      "[4 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 51us/step - loss: 48414.4375\n",
      "rewards:  -556.0 q-value:  0\n",
      "loss: [48414.4375]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 62us/step - loss: 39974.9688\n",
      "rewards:  -561.0 q-value:  0\n",
      "loss: [39974.96875]\n",
      "Exploring\n",
      "Selected action  [3 0]\n",
      "[3 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 74us/step - loss: 56755.9844\n",
      "rewards:  -562.0 q-value:  0\n",
      "loss: [56755.984375]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 85us/step - loss: 60150.0312\n",
      "rewards:  -567.0 q-value:  0\n",
      "loss: [60150.03125]\n",
      "Exploring\n",
      "Selected action  [3 0]\n",
      "[3 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 56us/step - loss: 35203.1875\n",
      "rewards:  -570.0 q-value:  0\n",
      "loss: [35203.1875]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 72us/step - loss: 31729.1562\n",
      "rewards:  -575.0 q-value:  0\n",
      "loss: [31729.15625]\n",
      "Exploring\n",
      "Selected action  [3 0]\n",
      "[3 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 82us/step - loss: 37620.9688\n",
      "rewards:  -578.0 q-value:  0\n",
      "loss: [37620.96875]\n",
      "Exploring\n",
      "Selected action  [3 0]\n",
      "[3 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 48us/step - loss: 49217.7812\n",
      "rewards:  -579.0 q-value:  0\n",
      "loss: [49217.78125]\n",
      "Exploring\n",
      "Selected action  [4 0]\n",
      "[4 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 56us/step - loss: 40050.3828\n",
      "rewards:  -582.0 q-value:  0\n",
      "loss: [40050.3828125]\n",
      "Exploring\n",
      "Selected action  [4 0]\n",
      "[4 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 55us/step - loss: 52070.6875\n",
      "rewards:  -585.0 q-value:  0\n",
      "loss: [52070.6875]\n",
      "Exploring\n",
      "Selected action  [3 0]\n",
      "[3 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 50us/step - loss: 67423.8438\n",
      "rewards:  -589.0 q-value:  0\n",
      "loss: [67423.84375]\n",
      "Exploring\n",
      "Selected action  [4 0]\n",
      "[4 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 39us/step - loss: 50359.4375\n",
      "rewards:  -590.0 q-value:  0\n",
      "loss: [50359.4375]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 59us/step - loss: 32667.1562\n",
      "rewards:  -595.0 q-value:  0\n",
      "loss: [32667.15625]\n",
      "Exploiting\n",
      "Selected action  [4 0]\n",
      "[4 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 70us/step - loss: 64173.0000\n",
      "rewards:  -595.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [64173.0]\n",
      "Exploring\n",
      "Selected action  [4 0]\n",
      "[4 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 65us/step - loss: 48688.7500\n",
      "rewards:  -595.0 q-value:  0\n",
      "loss: [48688.75]\n",
      "Exploring\n",
      "Selected action  [3 0]\n",
      "[3 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 88us/step - loss: 36181.3125\n",
      "rewards:  -601.0 q-value:  0\n",
      "loss: [36181.3125]\n",
      "Exploring\n",
      "Selected action  [3 0]\n",
      "[3 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 51us/step - loss: 72206.8438\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rewards:  -605.0 q-value:  0\n",
      "loss: [72206.84375]\n",
      "Exploring\n",
      "Selected action  [3 0]\n",
      "[3 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 44us/step - loss: 66547.1562\n",
      "rewards:  -609.0 q-value:  0\n",
      "loss: [66547.15625]\n",
      "Exploring\n",
      "Selected action  [4 0]\n",
      "[4 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 62us/step - loss: 41572.4688\n",
      "rewards:  -610.0 q-value:  0\n",
      "loss: [41572.46875]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 66us/step - loss: 68833.2812\n",
      "rewards:  -615.0 q-value:  0\n",
      "loss: [68833.28125]\n",
      "Exploring\n",
      "Selected action  [3 0]\n",
      "[3 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 56us/step - loss: 38854.2344\n",
      "rewards:  -618.0 q-value:  0\n",
      "loss: [38854.234375]\n",
      "Exploring\n",
      "Selected action  [3 0]\n",
      "[3 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 68us/step - loss: 52951.9688\n",
      "rewards:  -624.0 q-value:  0\n",
      "loss: [52951.96875]\n",
      "Exploring\n",
      "Selected action  [3 0]\n",
      "[3 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 45us/step - loss: 57327.3438\n",
      "rewards:  -627.0 q-value:  0\n",
      "loss: [57327.34375]\n",
      "Exploring\n",
      "Selected action  [4 0]\n",
      "[4 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 46us/step - loss: 35919.9531\n",
      "rewards:  -630.0 q-value:  0\n",
      "loss: [35919.953125]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 59us/step - loss: 47675.0625\n",
      "rewards:  -635.0 q-value:  0\n",
      "loss: [47675.0625]\n",
      "Exploring\n",
      "Selected action  [4 0]\n",
      "[4 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 52us/step - loss: 40834.5625\n",
      "rewards:  -636.0 q-value:  0\n",
      "loss: [40834.5625]\n",
      "Exploiting\n",
      "Selected action  [3 0]\n",
      "[3 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 47us/step - loss: 54915.5156\n",
      "rewards:  -636.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [54915.515625]\n",
      "Exploring\n",
      "Selected action  [4 0]\n",
      "[4 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 76us/step - loss: 62487.9375\n",
      "rewards:  -637.0 q-value:  0\n",
      "loss: [62487.9375]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 56us/step - loss: 77917.5312\n",
      "rewards:  -642.0 q-value:  0\n",
      "loss: [77917.53125]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 58us/step - loss: 40347.9375\n",
      "rewards:  -647.0 q-value:  0\n",
      "loss: [40347.9375]\n",
      "Exploring\n",
      "Selected action  [4 0]\n",
      "[4 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 57us/step - loss: 47016.0000\n",
      "rewards:  -648.0 q-value:  0\n",
      "loss: [47016.0]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 56us/step - loss: 47026.8125\n",
      "rewards:  -653.0 q-value:  0\n",
      "loss: [47026.8125]\n",
      "Exploring\n",
      "Selected action  [3 0]\n",
      "[3 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 64us/step - loss: 29599.4375\n",
      "rewards:  -653.0 q-value:  0\n",
      "loss: [29599.4375]\n",
      "Exploring\n",
      "Selected action  [3 0]\n",
      "[3 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 65us/step - loss: 42599.9688\n",
      "rewards:  -653.0 q-value:  0\n",
      "loss: [42599.96875]\n",
      "Exploring\n",
      "Selected action  [4 0]\n",
      "[4 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 62us/step - loss: 38315.0039\n",
      "rewards:  -654.0 q-value:  0\n",
      "loss: [38315.00390625]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 60us/step - loss: 91870.6250\n",
      "rewards:  -659.0 q-value:  0\n",
      "loss: [91870.625]\n",
      "Exploring\n",
      "Selected action  [4 0]\n",
      "[4 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 47us/step - loss: 61174.0469\n",
      "rewards:  -660.0 q-value:  0\n",
      "loss: [61174.046875]\n",
      "Exploring\n",
      "Selected action  [4 0]\n",
      "[4 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 74us/step - loss: 26189.8027\n",
      "rewards:  -661.0 q-value:  0\n",
      "loss: [26189.802734375]\n",
      "Exploiting\n",
      "Selected action  [4 0]\n",
      "[4 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 71us/step - loss: 50049.0625\n",
      "rewards:  -669.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [50049.0625]\n",
      "Exploring\n",
      "Selected action  [4 0]\n",
      "[4 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 46us/step - loss: 41137.1250\n",
      "rewards:  -670.0 q-value:  0\n",
      "loss: [41137.125]\n",
      "Number of actions available 10\n",
      "Episode : 6\n",
      "Exploring\n",
      "Selected action  [0 2]\n",
      "[0 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 61us/step - loss: 30450.0781\n",
      "rewards:  -2.0 q-value:  0\n",
      "loss: [30450.078125]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 67us/step - loss: 44630.1562\n",
      "rewards:  2.0 q-value:  0\n",
      "loss: [44630.15625]\n",
      "Exploring\n",
      "Selected action  [0 4]\n",
      "[0 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 64us/step - loss: 67983.9375\n",
      "rewards:  6.0 q-value:  0\n",
      "loss: [67983.9375]\n",
      "Exploring\n",
      "Selected action  [4 0]\n",
      "[4 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 45us/step - loss: 61028.4219\n",
      "rewards:  10.0 q-value:  0\n",
      "loss: [61028.421875]\n",
      "Exploring\n",
      "Selected action  [3 1]\n",
      "[3 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 51us/step - loss: 49305.0312\n",
      "rewards:  -5.0 q-value:  0\n",
      "loss: [49305.03125]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 71us/step - loss: 56463.8438\n",
      "rewards:  3.0 q-value:  0\n",
      "loss: [56463.84375]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 55us/step - loss: 80705.1562\n",
      "rewards:  -2.0 q-value:  0\n",
      "loss: [80705.15625]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 51us/step - loss: 25191.0352\n",
      "rewards:  -4.0 q-value:  0\n",
      "loss: [25191.03515625]\n",
      "Exploring\n",
      "Selected action  [4 0]\n",
      "[4 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 71us/step - loss: 50945.2188\n",
      "rewards:  -12.0 q-value:  0\n",
      "loss: [50945.21875]\n",
      "Exploring\n",
      "Selected action  [3 2]\n",
      "[3 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 64us/step - loss: 66476.2812\n",
      "rewards:  -19.0 q-value:  0\n",
      "loss: [66476.28125]\n",
      "Exploring\n",
      "Selected action  [0 3]\n",
      "[0 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 67us/step - loss: 58213.5391\n",
      "rewards:  -37.0 q-value:  0\n",
      "loss: [58213.5390625]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 75us/step - loss: 62064.3750\n",
      "rewards:  -42.0 q-value:  0\n",
      "loss: [62064.375]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 71us/step - loss: 30068.2812\n",
      "rewards:  -51.0 q-value:  0\n",
      "loss: [30068.28125]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 52us/step - loss: 75527.6562\n",
      "rewards:  -56.0 q-value:  0\n",
      "loss: [75527.65625]\n",
      "Exploring\n",
      "Selected action  [3 2]\n",
      "[3 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 49us/step - loss: 91677.7812\n",
      "rewards:  -44.0 q-value:  0\n",
      "loss: [91677.78125]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 63us/step - loss: 61644.3438\n",
      "rewards:  -66.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [61644.34375]\n",
      "Exploring\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 43us/step - loss: 48811.6719\n",
      "rewards:  -69.0 q-value:  0\n",
      "loss: [48811.671875]\n",
      "Exploring\n",
      "Selected action  [0 3]\n",
      "[0 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 63us/step - loss: 30274.9688\n",
      "rewards:  -60.0 q-value:  0\n",
      "loss: [30274.96875]\n",
      "Exploring\n",
      "Selected action  [0 3]\n",
      "[0 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 71us/step - loss: 70699.7656\n",
      "rewards:  -63.0 q-value:  0\n",
      "loss: [70699.765625]\n",
      "Exploring\n",
      "Selected action  [0 4]\n",
      "[0 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 70us/step - loss: 74252.1562\n",
      "rewards:  -64.0 q-value:  0\n",
      "loss: [74252.15625]\n",
      "Exploring\n",
      "Selected action  [3 2]\n",
      "[3 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 62us/step - loss: 64440.1484\n",
      "rewards:  -82.0 q-value:  0\n",
      "loss: [64440.1484375]\n",
      "Exploring\n",
      "Selected action  [0 4]\n",
      "[0 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 83us/step - loss: 80311.0625\n",
      "rewards:  -93.0 q-value:  0\n",
      "loss: [80311.0625]\n",
      "Exploring\n",
      "Selected action  [0 2]\n",
      "[0 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 61us/step - loss: 19655.0312\n",
      "rewards:  -105.0 q-value:  0\n",
      "loss: [19655.03125]\n",
      "Exploring\n",
      "Selected action  [0 2]\n",
      "[0 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 64us/step - loss: 56878.8125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rewards:  -107.0 q-value:  0\n",
      "loss: [56878.8125]\n",
      "Exploring\n",
      "Selected action  [3 1]\n",
      "[3 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 60us/step - loss: 60643.6250\n",
      "rewards:  -119.0 q-value:  0\n",
      "loss: [60643.625]\n",
      "Exploring\n",
      "Selected action  [3 1]\n",
      "[3 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 55us/step - loss: 55934.1562\n",
      "rewards:  -124.0 q-value:  0\n",
      "loss: [55934.15625]\n",
      "Exploring\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 44us/step - loss: 70526.0156\n",
      "rewards:  -127.0 q-value:  0\n",
      "loss: [70526.015625]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 50us/step - loss: 53835.1875\n",
      "rewards:  -136.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [53835.1875]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 59us/step - loss: 35134.3125\n",
      "rewards:  -112.0 q-value:  0\n",
      "loss: [35134.3125]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 76us/step - loss: 72452.3438\n",
      "rewards:  -88.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [72452.34375]\n",
      "Exploring\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 58us/step - loss: 29477.7812\n",
      "rewards:  -76.0 q-value:  0\n",
      "loss: [29477.78125]\n",
      "Exploring\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 49us/step - loss: 38282.3750\n",
      "rewards:  -79.0 q-value:  0\n",
      "loss: [38282.375]\n",
      "Exploring\n",
      "Selected action  [4 0]\n",
      "[4 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 48us/step - loss: 43803.3125\n",
      "rewards:  -86.0 q-value:  0\n",
      "loss: [43803.3125]\n",
      "Exploring\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 59us/step - loss: 50355.5938\n",
      "rewards:  -70.0 q-value:  0\n",
      "loss: [50355.59375]\n",
      "Exploring\n",
      "Selected action  [3 2]\n",
      "[3 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 46us/step - loss: 72462.0000\n",
      "rewards:  -66.0 q-value:  0\n",
      "loss: [72462.0]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 68us/step - loss: 83326.0938\n",
      "rewards:  -98.0 q-value:  0\n",
      "loss: [83326.09375]\n",
      "Exploring\n",
      "Selected action  [3 2]\n",
      "[3 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 53us/step - loss: 39957.5938\n",
      "rewards:  -109.0 q-value:  0\n",
      "loss: [39957.59375]\n",
      "Exploring\n",
      "Selected action  [0 3]\n",
      "[0 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 59us/step - loss: 48829.2812\n",
      "rewards:  -130.0 q-value:  0\n",
      "loss: [48829.28125]\n",
      "Exploring\n",
      "Selected action  [0 2]\n",
      "[0 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 59us/step - loss: 74789.3750\n",
      "rewards:  -115.0 q-value:  0\n",
      "loss: [74789.375]\n",
      "Exploring\n",
      "Selected action  [0 4]\n",
      "[0 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 64us/step - loss: 61635.4688\n",
      "rewards:  -114.0 q-value:  0\n",
      "loss: [61635.46875]\n",
      "Exploring\n",
      "Selected action  [0 4]\n",
      "[0 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 55us/step - loss: 51056.5625\n",
      "rewards:  -118.0 q-value:  0\n",
      "loss: [51056.5625]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 50us/step - loss: 36061.5547\n",
      "rewards:  -123.0 q-value:  0\n",
      "loss: [36061.5546875]\n",
      "Exploring\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 55us/step - loss: 41963.2500\n",
      "rewards:  -146.0 q-value:  0\n",
      "loss: [41963.25]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 77us/step - loss: 59940.3750\n",
      "rewards:  -151.0 q-value:  0\n",
      "loss: [59940.375]\n",
      "Exploring\n",
      "Selected action  [0 2]\n",
      "[0 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 64us/step - loss: 62943.3789\n",
      "rewards:  -123.0 q-value:  0\n",
      "loss: [62943.37890625]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 61us/step - loss: 50540.9688\n",
      "rewards:  -138.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [50540.96875]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 71us/step - loss: 27821.1250\n",
      "rewards:  -143.0 q-value:  0\n",
      "loss: [27821.125]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 62us/step - loss: 60751.2812\n",
      "rewards:  -127.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [60751.28125]\n",
      "Exploring\n",
      "Selected action  [3 2]\n",
      "[3 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 50us/step - loss: 59138.5312\n",
      "rewards:  -105.0 q-value:  0\n",
      "loss: [59138.53125]\n",
      "Exploring\n",
      "Selected action  [0 3]\n",
      "[0 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 66us/step - loss: 65073.6250\n",
      "rewards:  -116.0 q-value:  0\n",
      "loss: [65073.625]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 63us/step - loss: 61669.5234\n",
      "rewards:  -121.0 q-value:  0\n",
      "loss: [61669.5234375]\n",
      "Exploring\n",
      "Selected action  [3 2]\n",
      "[3 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 56us/step - loss: 39010.9375\n",
      "rewards:  -112.0 q-value:  0\n",
      "loss: [39010.9375]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 65us/step - loss: 63627.4062\n",
      "rewards:  -114.0 q-value:  0\n",
      "loss: [63627.40625]\n",
      "Exploring\n",
      "Selected action  [3 1]\n",
      "[3 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 53us/step - loss: 75279.5938\n",
      "rewards:  -114.0 q-value:  0\n",
      "loss: [75279.59375]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 61us/step - loss: 74250.6250\n",
      "rewards:  -119.0 q-value:  0\n",
      "loss: [74250.625]\n",
      "Exploring\n",
      "Selected action  [0 3]\n",
      "[0 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 60us/step - loss: 72315.7500\n",
      "rewards:  -119.0 q-value:  0\n",
      "loss: [72315.75]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 45us/step - loss: 47390.6797\n",
      "rewards:  -124.0 q-value:  0\n",
      "loss: [47390.6796875]\n",
      "Exploring\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 58us/step - loss: 23946.6875\n",
      "rewards:  -116.0 q-value:  0\n",
      "loss: [23946.6875]\n",
      "Exploring\n",
      "Selected action  [3 1]\n",
      "[3 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 53us/step - loss: 50008.2500\n",
      "rewards:  -116.0 q-value:  0\n",
      "loss: [50008.25]\n",
      "Exploring\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 49us/step - loss: 87961.2812\n",
      "rewards:  -116.0 q-value:  0\n",
      "loss: [87961.28125]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 48us/step - loss: 62523.2812\n",
      "rewards:  -108.0 q-value:  0\n",
      "loss: [62523.28125]\n",
      "Exploring\n",
      "Selected action  [3 2]\n",
      "[3 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 76us/step - loss: 44899.0117\n",
      "rewards:  -115.0 q-value:  0\n",
      "loss: [44899.01171875]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 52us/step - loss: 61218.1562\n",
      "rewards:  -120.0 q-value:  0\n",
      "loss: [61218.15625]\n",
      "Exploring\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 69us/step - loss: 36204.5391\n",
      "rewards:  -130.0 q-value:  0\n",
      "loss: [36204.5390625]\n",
      "Exploring\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 60us/step - loss: 48842.9219\n",
      "rewards:  -130.0 q-value:  0\n",
      "loss: [48842.921875]\n",
      "Exploring\n",
      "Selected action  [0 4]\n",
      "[0 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 75us/step - loss: 38911.4688\n",
      "rewards:  -113.0 q-value:  0\n",
      "loss: [38911.46875]\n",
      "Exploring\n",
      "Selected action  [4 0]\n",
      "[4 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 60us/step - loss: 55808.8125\n",
      "rewards:  -109.0 q-value:  0\n",
      "loss: [55808.8125]\n",
      "Exploring\n",
      "Selected action  [3 1]\n",
      "[3 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 55us/step - loss: 15240.4688\n",
      "rewards:  -139.0 q-value:  0\n",
      "loss: [15240.46875]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 62us/step - loss: 40006.8125\n",
      "rewards:  -103.0 q-value:  0\n",
      "loss: [40006.8125]\n",
      "Exploring\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 53us/step - loss: 49983.5625\n",
      "rewards:  -109.0 q-value:  0\n",
      "loss: [49983.5625]\n",
      "Exploring\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 76us/step - loss: 51586.2852\n",
      "rewards:  -110.0 q-value:  0\n",
      "loss: [51586.28515625]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 60us/step - loss: 86930.7812\n",
      "rewards:  -115.0 q-value:  0\n",
      "loss: [86930.78125]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 45us/step - loss: 62810.3438\n",
      "rewards:  -120.0 q-value:  0\n",
      "loss: [62810.34375]\n",
      "Exploring\n",
      "Selected action  [3 2]\n",
      "[3 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 55us/step - loss: 57277.0938\n",
      "rewards:  -108.0 q-value:  0\n",
      "loss: [57277.09375]\n",
      "Exploring\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 72us/step - loss: 47739.1250\n",
      "rewards:  -114.0 q-value:  0\n",
      "loss: [47739.125]\n",
      "Exploring\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 64us/step - loss: 51495.8828\n",
      "rewards:  -101.0 q-value:  0\n",
      "loss: [51495.8828125]\n",
      "Exploring\n",
      "Selected action  [0 4]\n",
      "[0 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 66us/step - loss: 52213.0586\n",
      "rewards:  -132.0 q-value:  0\n",
      "loss: [52213.05859375]\n",
      "Exploring\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 51us/step - loss: 68072.5625\n",
      "rewards:  -124.0 q-value:  0\n",
      "loss: [68072.5625]\n",
      "Exploring\n",
      "Selected action  [4 0]\n",
      "[4 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 66us/step - loss: 61844.1875\n",
      "rewards:  -150.0 q-value:  0\n",
      "loss: [61844.1875]\n",
      "Exploring\n",
      "Selected action  [0 3]\n",
      "[0 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 75us/step - loss: 47198.9688\n",
      "rewards:  -146.0 q-value:  0\n",
      "loss: [47198.96875]\n",
      "Exploring\n",
      "Selected action  [4 0]\n",
      "[4 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 68us/step - loss: 71478.0234\n",
      "rewards:  -140.0 q-value:  0\n",
      "loss: [71478.0234375]\n",
      "Exploring\n",
      "Selected action  [0 2]\n",
      "[0 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 70us/step - loss: 50913.2500\n",
      "rewards:  -132.0 q-value:  0\n",
      "loss: [50913.25]\n",
      "Exploring\n",
      "Selected action  [3 2]\n",
      "[3 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 55us/step - loss: 41499.2500\n",
      "rewards:  -135.0 q-value:  0\n",
      "loss: [41499.25]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 72us/step - loss: 81506.1250\n",
      "rewards:  -148.0 q-value:  0\n",
      "loss: [81506.125]\n",
      "Exploring\n",
      "Selected action  [3 1]\n",
      "[3 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 70us/step - loss: 33444.5469\n",
      "rewards:  -180.0 q-value:  0\n",
      "loss: [33444.546875]\n",
      "Exploring\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 61us/step - loss: 63559.4688\n",
      "rewards:  -189.0 q-value:  0\n",
      "loss: [63559.46875]\n",
      "Exploring\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 64us/step - loss: 49882.4219\n",
      "rewards:  -185.0 q-value:  0\n",
      "loss: [49882.421875]\n",
      "Exploring\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 71us/step - loss: 35805.0312\n",
      "rewards:  -171.0 q-value:  0\n",
      "loss: [35805.03125]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 63us/step - loss: 32146.5938\n",
      "rewards:  -151.0 q-value:  0\n",
      "loss: [32146.59375]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 56us/step - loss: 49105.7031\n",
      "rewards:  -156.0 q-value:  0\n",
      "loss: [49105.703125]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 84us/step - loss: 71033.9688\n",
      "rewards:  -161.0 q-value:  0\n",
      "loss: [71033.96875]\n",
      "Exploring\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 76us/step - loss: 45619.2812\n",
      "rewards:  -133.0 q-value:  0\n",
      "loss: [45619.28125]\n",
      "Exploring\n",
      "Selected action  [4 0]\n",
      "[4 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 67us/step - loss: 65049.7188\n",
      "rewards:  -133.0 q-value:  0\n",
      "loss: [65049.71875]\n",
      "Exploring\n",
      "Selected action  [0 4]\n",
      "[0 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 43us/step - loss: 53152.3750\n",
      "rewards:  -133.0 q-value:  0\n",
      "loss: [53152.375]\n",
      "Exploring\n",
      "Selected action  [0 2]\n",
      "[0 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 69us/step - loss: 49956.2812\n",
      "rewards:  -125.0 q-value:  0\n",
      "loss: [49956.28125]\n",
      "Exploring\n",
      "Selected action  [4 0]\n",
      "[4 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 73us/step - loss: 62358.1250\n",
      "rewards:  -101.0 q-value:  0\n",
      "loss: [62358.125]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 63us/step - loss: 84303.2188\n",
      "rewards:  -106.0 q-value:  0\n",
      "loss: [84303.21875]\n",
      "Exploring\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 63us/step - loss: 49465.0312\n",
      "rewards:  -78.0 q-value:  0\n",
      "loss: [49465.03125]\n",
      "Exploring\n",
      "Selected action  [4 0]\n",
      "[4 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 96us/step - loss: 53191.0234\n",
      "rewards:  -108.0 q-value:  0\n",
      "loss: [53191.0234375]\n",
      "Exploring\n",
      "Selected action  [0 3]\n",
      "[0 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 78us/step - loss: 38194.5938\n",
      "rewards:  -104.0 q-value:  0\n",
      "loss: [38194.59375]\n",
      "Exploring\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 56us/step - loss: 52255.0312\n",
      "rewards:  -107.0 q-value:  0\n",
      "loss: [52255.03125]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 52us/step - loss: 95380.1250\n",
      "rewards:  -112.0 q-value:  0\n",
      "loss: [95380.125]\n",
      "Exploring\n",
      "Selected action  [3 2]\n",
      "[3 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 69us/step - loss: 29504.7559\n",
      "rewards:  -95.0 q-value:  0\n",
      "loss: [29504.755859375]\n",
      "Exploring\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 58us/step - loss: 61950.7656\n",
      "rewards:  -87.0 q-value:  0\n",
      "loss: [61950.765625]\n",
      "Exploring\n",
      "Selected action  [0 4]\n",
      "[0 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 51us/step - loss: 43384.1250\n",
      "rewards:  -83.0 q-value:  0\n",
      "loss: [43384.125]\n",
      "Exploring\n",
      "Selected action  [0 4]\n",
      "[0 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 69us/step - loss: 28298.9688\n",
      "rewards:  -84.0 q-value:  0\n",
      "loss: [28298.96875]\n",
      "Exploring\n",
      "Selected action  [3 2]\n",
      "[3 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 58us/step - loss: 68172.3750\n",
      "rewards:  -50.0 q-value:  0\n",
      "loss: [68172.375]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 87us/step - loss: 51616.0312\n",
      "rewards:  -44.0 q-value:  0\n",
      "loss: [51616.03125]\n",
      "Exploring\n",
      "Selected action  [0 4]\n",
      "[0 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 57us/step - loss: 55157.1250\n",
      "rewards:  -40.0 q-value:  0\n",
      "loss: [55157.125]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 60us/step - loss: 46595.5312\n",
      "rewards:  -45.0 q-value:  0\n",
      "loss: [46595.53125]\n",
      "Exploring\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 74us/step - loss: 69507.5078\n",
      "rewards:  -29.0 q-value:  0\n",
      "loss: [69507.5078125]\n",
      "Exploring\n",
      "Selected action  [3 1]\n",
      "[3 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 76us/step - loss: 59268.0703\n",
      "rewards:  -33.0 q-value:  0\n",
      "loss: [59268.0703125]\n",
      "Exploring\n",
      "Selected action  [0 2]\n",
      "[0 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 59us/step - loss: 19077.9023\n",
      "rewards:  -35.0 q-value:  0\n",
      "loss: [19077.90234375]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 68us/step - loss: 61189.4062\n",
      "rewards:  -37.0 q-value:  0\n",
      "loss: [61189.40625]\n",
      "Exploring\n",
      "Selected action  [3 2]\n",
      "[3 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 87us/step - loss: 32032.4277\n",
      "rewards:  -5.0 q-value:  0\n",
      "loss: [32032.427734375]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 61us/step - loss: 41131.3438\n",
      "rewards:  -37.0 q-value:  0\n",
      "loss: [41131.34375]\n",
      "Exploring\n",
      "Selected action  [0 2]\n",
      "[0 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 45us/step - loss: 36854.2695\n",
      "rewards:  -29.0 q-value:  0\n",
      "loss: [36854.26953125]\n",
      "Exploring\n",
      "Selected action  [4 0]\n",
      "[4 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 70us/step - loss: 36529.8438\n",
      "rewards:  -30.0 q-value:  0\n",
      "loss: [36529.84375]\n",
      "Exploring\n",
      "Selected action  [0 3]\n",
      "[0 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 57us/step - loss: 56443.3242\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rewards:  10.0 q-value:  0\n",
      "loss: [56443.32421875]\n",
      "Exploring\n",
      "Selected action  [0 2]\n",
      "[0 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 101us/step - loss: 49648.6250\n",
      "rewards:  8.0 q-value:  0\n",
      "loss: [49648.625]\n",
      "Exploring\n",
      "Selected action  [3 2]\n",
      "[3 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 57us/step - loss: 41795.6250\n",
      "rewards:  -1.0 q-value:  0\n",
      "loss: [41795.625]\n",
      "Exploring\n",
      "Selected action  [0 4]\n",
      "[0 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 81us/step - loss: 38626.8750\n",
      "rewards:  -27.0 q-value:  0\n",
      "loss: [38626.875]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 72us/step - loss: 31093.0391\n",
      "rewards:  -20.0 q-value:  0\n",
      "loss: [31093.0390625]\n",
      "Exploring\n",
      "Selected action  [0 4]\n",
      "[0 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 65us/step - loss: 26669.0000\n",
      "rewards:  -16.0 q-value:  0\n",
      "loss: [26669.0]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 61us/step - loss: 53852.4531\n",
      "rewards:  -9.0 q-value:  0\n",
      "loss: [53852.453125]\n",
      "Exploring\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 65us/step - loss: 44642.5742\n",
      "rewards:  -36.0 q-value:  0\n",
      "loss: [44642.57421875]\n",
      "Number of actions available 6\n",
      "Episode : 7\n",
      "Exploring\n",
      "Selected action  [3 2]\n",
      "[3 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 57us/step - loss: 85898.3750\n",
      "rewards:  36.0 q-value:  0\n",
      "loss: [85898.375]\n",
      "Exploring\n",
      "Selected action  [3 1]\n",
      "[3 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 58us/step - loss: 46094.1562\n",
      "rewards:  -4.0 q-value:  0\n",
      "loss: [46094.15625]\n",
      "Exploring\n",
      "Selected action  [3 1]\n",
      "[3 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 83us/step - loss: 83236.1562\n",
      "rewards:  -4.0 q-value:  0\n",
      "loss: [83236.15625]\n",
      "Exploring\n",
      "Selected action  [2 1]\n",
      "[2 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 72us/step - loss: 62080.0625\n",
      "rewards:  -6.0 q-value:  0\n",
      "loss: [62080.0625]\n",
      "Exploring\n",
      "Selected action  [2 1]\n",
      "[2 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 69us/step - loss: 42186.4062\n",
      "rewards:  -8.0 q-value:  0\n",
      "loss: [42186.40625]\n",
      "Exploiting\n",
      "Selected action  [3 2]\n",
      "[3 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 70us/step - loss: 31759.6250\n",
      "rewards:  24.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [31759.625]\n",
      "Exploring\n",
      "Selected action  [2 1]\n",
      "[2 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 76us/step - loss: 37276.5000\n",
      "rewards:  44.0 q-value:  0\n",
      "loss: [37276.5]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 54us/step - loss: 53408.1562\n",
      "rewards:  39.0 q-value:  0\n",
      "loss: [53408.15625]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 51us/step - loss: 34144.4062\n",
      "rewards:  34.0 q-value:  0\n",
      "loss: [34144.40625]\n",
      "Exploring\n",
      "Selected action  [3 2]\n",
      "[3 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 64us/step - loss: 40344.8750\n",
      "rewards:  8.0 q-value:  0\n",
      "loss: [40344.875]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 63us/step - loss: 34974.7188\n",
      "rewards:  3.0 q-value:  0\n",
      "loss: [34974.71875]\n",
      "Exploring\n",
      "Selected action  [2 1]\n",
      "[2 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 53us/step - loss: 63791.1562\n",
      "rewards:  13.0 q-value:  0\n",
      "loss: [63791.15625]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 46us/step - loss: 52348.9062\n",
      "rewards:  8.0 q-value:  0\n",
      "loss: [52348.90625]\n",
      "Exploiting\n",
      "Selected action  [3 2]\n",
      "[3 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 64us/step - loss: 59698.6875\n",
      "rewards:  20.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [59698.6875]\n",
      "Exploring\n",
      "Selected action  [3 1]\n",
      "[3 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 97us/step - loss: 38880.1875\n",
      "rewards:  14.0 q-value:  0\n",
      "loss: [38880.1875]\n",
      "Exploiting\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 76us/step - loss: 62639.4062\n",
      "rewards:  42.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [62639.40625]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 71us/step - loss: 64494.3125\n",
      "rewards:  37.0 q-value:  0\n",
      "loss: [64494.3125]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 63us/step - loss: 47094.3125\n",
      "rewards:  30.0 q-value:  0\n",
      "loss: [47094.3125]\n",
      "Exploring\n",
      "Selected action  [0 3]\n",
      "[0 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 58us/step - loss: 84427.8438\n",
      "rewards:  34.0 q-value:  0\n",
      "loss: [84427.84375]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 60us/step - loss: 59602.0938\n",
      "rewards:  29.0 q-value:  0\n",
      "loss: [59602.09375]\n",
      "Exploring\n",
      "Selected action  [0 3]\n",
      "[0 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 65us/step - loss: 81293.1562\n",
      "rewards:  33.0 q-value:  0\n",
      "loss: [81293.15625]\n",
      "Exploring\n",
      "Selected action  [3 1]\n",
      "[3 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 51us/step - loss: 60091.6484\n",
      "rewards:  41.0 q-value:  0\n",
      "loss: [60091.6484375]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 53us/step - loss: 57462.9453\n",
      "rewards:  36.0 q-value:  0\n",
      "loss: [57462.9453125]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 62us/step - loss: 59252.9375\n",
      "rewards:  31.0 q-value:  0\n",
      "loss: [59252.9375]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 51us/step - loss: 37841.0312\n",
      "rewards:  28.0 q-value:  0\n",
      "loss: [37841.03125]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 71us/step - loss: 71974.2812\n",
      "rewards:  25.0 q-value:  0\n",
      "loss: [71974.28125]\n",
      "Exploring\n",
      "Selected action  [0 3]\n",
      "[0 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 57us/step - loss: 77027.0312\n",
      "rewards:  57.0 q-value:  0\n",
      "loss: [77027.03125]\n",
      "Exploring\n",
      "Selected action  [3 1]\n",
      "[3 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 65us/step - loss: 46959.4688\n",
      "rewards:  61.0 q-value:  0\n",
      "loss: [46959.46875]\n",
      "Exploring\n",
      "Selected action  [0 3]\n",
      "[0 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 49us/step - loss: 81722.0000\n",
      "rewards:  39.0 q-value:  0\n",
      "loss: [81722.0]\n",
      "Exploring\n",
      "Selected action  [3 1]\n",
      "[3 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 57us/step - loss: 53086.6562\n",
      "rewards:  43.0 q-value:  0\n",
      "loss: [53086.65625]\n",
      "Exploring\n",
      "Selected action  [0 3]\n",
      "[0 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 54us/step - loss: 57713.4062\n",
      "rewards:  21.0 q-value:  0\n",
      "loss: [57713.40625]\n",
      "Exploring\n",
      "Selected action  [2 1]\n",
      "[2 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 99us/step - loss: 39157.3125\n",
      "rewards:  29.0 q-value:  0\n",
      "loss: [39157.3125]\n",
      "Exploring\n",
      "Selected action  [2 1]\n",
      "[2 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 79us/step - loss: 52077.8125\n",
      "rewards:  22.0 q-value:  0\n",
      "loss: [52077.8125]\n",
      "Exploring\n",
      "Selected action  [3 1]\n",
      "[3 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 62us/step - loss: 58706.5625\n",
      "rewards:  19.0 q-value:  0\n",
      "loss: [58706.5625]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 76us/step - loss: 33567.3438\n",
      "rewards:  14.0 q-value:  0\n",
      "loss: [33567.34375]\n",
      "Exploiting\n",
      "Selected action  [2 1]\n",
      "[2 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 75us/step - loss: 48233.0898\n",
      "rewards:  8.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [48233.08984375]\n",
      "Exploring\n",
      "Selected action  [0 3]\n",
      "[0 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 53us/step - loss: 44951.5938\n",
      "rewards:  8.0 q-value:  0\n",
      "loss: [44951.59375]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 85us/step - loss: 51695.1250\n",
      "rewards:  3.0 q-value:  0\n",
      "loss: [51695.125]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 69us/step - loss: 62756.6875\n",
      "rewards:  -2.0 q-value:  0\n",
      "loss: [62756.6875]\n",
      "Exploring\n",
      "Selected action  [3 1]\n",
      "[3 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 74us/step - loss: 53149.8438\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rewards:  -13.0 q-value:  0\n",
      "loss: [53149.84375]\n",
      "Exploring\n",
      "Selected action  [3 2]\n",
      "[3 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 102us/step - loss: 46296.7500\n",
      "rewards:  -18.0 q-value:  0\n",
      "loss: [46296.75]\n",
      "Exploring\n",
      "Selected action  [0 3]\n",
      "[0 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 56us/step - loss: 79143.0703\n",
      "rewards:  -31.0 q-value:  0\n",
      "loss: [79143.0703125]\n",
      "Exploiting\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 55us/step - loss: 46899.3672\n",
      "rewards:  -28.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [46899.3671875]\n",
      "Exploring\n",
      "Selected action  [3 1]\n",
      "[3 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 67us/step - loss: 81395.2500\n",
      "rewards:  -43.0 q-value:  0\n",
      "loss: [81395.25]\n",
      "Exploring\n",
      "Selected action  [3 2]\n",
      "[3 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 64us/step - loss: 52178.3750\n",
      "rewards:  -46.0 q-value:  0\n",
      "loss: [52178.375]\n",
      "Exploiting\n",
      "Selected action  [2 1]\n",
      "[2 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 101us/step - loss: 51244.8672\n",
      "rewards:  -18.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [51244.8671875]\n",
      "Exploiting\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 53us/step - loss: 67194.5391\n",
      "rewards:  -23.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [67194.5390625]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 94us/step - loss: 22427.8555\n",
      "rewards:  -26.0 q-value:  0\n",
      "loss: [22427.85546875]\n",
      "Exploring\n",
      "Selected action  [3 2]\n",
      "[3 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 103us/step - loss: 37097.1562\n",
      "rewards:  -7.0 q-value:  0\n",
      "loss: [37097.15625]\n",
      "Exploring\n",
      "Selected action  [2 1]\n",
      "[2 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 62us/step - loss: 48644.9375\n",
      "rewards:  29.0 q-value:  0\n",
      "loss: [48644.9375]\n",
      "Exploring\n",
      "Selected action  [3 2]\n",
      "[3 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 65us/step - loss: 48865.4062\n",
      "rewards:  17.0 q-value:  0\n",
      "loss: [48865.40625]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 72us/step - loss: 45838.9844\n",
      "rewards:  12.0 q-value:  0\n",
      "loss: [45838.984375]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 96us/step - loss: 40831.2812\n",
      "rewards:  8.0 q-value:  0\n",
      "loss: [40831.28125]\n",
      "Exploring\n",
      "Selected action  [0 3]\n",
      "[0 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 61us/step - loss: 24627.4062\n",
      "rewards:  24.0 q-value:  0\n",
      "loss: [24627.40625]\n",
      "Exploring\n",
      "Selected action  [2 1]\n",
      "[2 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 62us/step - loss: 28038.3438\n",
      "rewards:  23.0 q-value:  0\n",
      "loss: [28038.34375]\n",
      "Exploring\n",
      "Selected action  [3 1]\n",
      "[3 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 77us/step - loss: 58972.6406\n",
      "rewards:  19.0 q-value:  0\n",
      "loss: [58972.640625]\n",
      "Exploiting\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 56us/step - loss: 60186.7812\n",
      "rewards:  43.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [60186.78125]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 71us/step - loss: 33326.2422\n",
      "rewards:  41.0 q-value:  0\n",
      "loss: [33326.2421875]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 75us/step - loss: 27631.0938\n",
      "rewards:  36.0 q-value:  0\n",
      "loss: [27631.09375]\n",
      "Exploiting\n",
      "Selected action  [2 1]\n",
      "[2 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 60us/step - loss: 58831.9375\n",
      "rewards:  29.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [58831.9375]\n",
      "Exploring\n",
      "Selected action  [2 1]\n",
      "[2 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 102us/step - loss: 30418.1562\n",
      "rewards:  27.0 q-value:  0\n",
      "loss: [30418.15625]\n",
      "Exploring\n",
      "Selected action  [3 1]\n",
      "[3 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 49us/step - loss: 50403.5352\n",
      "rewards:  27.0 q-value:  0\n",
      "loss: [50403.53515625]\n",
      "Exploring\n",
      "Selected action  [2 1]\n",
      "[2 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 59us/step - loss: 38337.4375\n",
      "rewards:  19.0 q-value:  0\n",
      "loss: [38337.4375]\n",
      "Exploring\n",
      "Selected action  [3 2]\n",
      "[3 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 108us/step - loss: 58870.7812\n",
      "rewards:  18.0 q-value:  0\n",
      "loss: [58870.78125]\n",
      "Exploring\n",
      "Selected action  [2 1]\n",
      "[2 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 53us/step - loss: 52284.7812\n",
      "rewards:  58.0 q-value:  0\n",
      "loss: [52284.78125]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 95us/step - loss: 52966.6562\n",
      "rewards:  53.0 q-value:  0\n",
      "loss: [52966.65625]\n",
      "Exploring\n",
      "Selected action  [2 1]\n",
      "[2 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 54us/step - loss: 60217.0938\n",
      "rewards:  43.0 q-value:  0\n",
      "loss: [60217.09375]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 103us/step - loss: 37830.3594\n",
      "rewards:  51.0 q-value:  0\n",
      "loss: [37830.359375]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 45us/step - loss: 57732.2188\n",
      "rewards:  46.0 q-value:  0\n",
      "loss: [57732.21875]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 63us/step - loss: 37491.4766\n",
      "rewards:  41.0 q-value:  0\n",
      "loss: [37491.4765625]\n",
      "Exploring\n",
      "Selected action  [3 2]\n",
      "[3 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 65us/step - loss: 65684.6875\n",
      "rewards:  35.0 q-value:  0\n",
      "loss: [65684.6875]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 57us/step - loss: 41392.1250\n",
      "rewards:  18.0 q-value:  0\n",
      "loss: [41392.125]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 146us/step - loss: 37389.9688\n",
      "rewards:  11.0 q-value:  0\n",
      "loss: [37389.96875]\n",
      "Exploring\n",
      "Selected action  [0 3]\n",
      "[0 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 80us/step - loss: 48698.3438\n",
      "rewards:  15.0 q-value:  0\n",
      "loss: [48698.34375]\n",
      "Exploring\n",
      "Selected action  [3 2]\n",
      "[3 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 66us/step - loss: 29341.2188\n",
      "rewards:  31.0 q-value:  0\n",
      "loss: [29341.21875]\n",
      "Exploring\n",
      "Selected action  [2 1]\n",
      "[2 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 93us/step - loss: 35631.5938\n",
      "rewards:  51.0 q-value:  0\n",
      "loss: [35631.59375]\n",
      "Exploring\n",
      "Selected action  [2 1]\n",
      "[2 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 49us/step - loss: 46169.1250\n",
      "rewards:  47.0 q-value:  0\n",
      "loss: [46169.125]\n",
      "Exploring\n",
      "Selected action  [0 3]\n",
      "[0 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 49us/step - loss: 52096.6094\n",
      "rewards:  34.0 q-value:  0\n",
      "loss: [52096.609375]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 97us/step - loss: 53836.8672\n",
      "rewards:  53.0 q-value:  0\n",
      "loss: [53836.8671875]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 63us/step - loss: 62479.9688\n",
      "rewards:  48.0 q-value:  0\n",
      "loss: [62479.96875]\n",
      "Exploring\n",
      "Selected action  [3 2]\n",
      "[3 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 66us/step - loss: 53793.8203\n",
      "rewards:  43.0 q-value:  0\n",
      "loss: [53793.8203125]\n",
      "Exploring\n",
      "Selected action  [3 2]\n",
      "[3 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 66us/step - loss: 40625.4375\n",
      "rewards:  38.0 q-value:  0\n",
      "loss: [40625.4375]\n",
      "Exploiting\n",
      "Selected action  [2 1]\n",
      "[2 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 50us/step - loss: 89001.5000\n",
      "rewards:  78.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [89001.5]\n",
      "Exploring\n",
      "Selected action  [3 1]\n",
      "[3 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 56us/step - loss: 37794.8633\n",
      "rewards:  77.0 q-value:  0\n",
      "loss: [37794.86328125]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 74us/step - loss: 41105.5859\n",
      "rewards:  85.0 q-value:  0\n",
      "loss: [41105.5859375]\n",
      "Exploring\n",
      "Selected action  [3 2]\n",
      "[3 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 69us/step - loss: 42118.6875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rewards:  74.0 q-value:  0\n",
      "loss: [42118.6875]\n",
      "Exploring\n",
      "Selected action  [2 1]\n",
      "[2 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 77us/step - loss: 70424.2188\n",
      "rewards:  102.0 q-value:  0\n",
      "loss: [70424.21875]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 65us/step - loss: 77062.6875\n",
      "rewards:  114.0 q-value:  0\n",
      "loss: [77062.6875]\n",
      "Exploiting\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 66us/step - loss: 55913.9688\n",
      "rewards:  111.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [55913.96875]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 72us/step - loss: 56357.5000\n",
      "rewards:  104.0 q-value:  0\n",
      "loss: [56357.5]\n",
      "Exploring\n",
      "Selected action  [2 1]\n",
      "[2 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 60us/step - loss: 39400.9375\n",
      "rewards:  105.0 q-value:  0\n",
      "loss: [39400.9375]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 62us/step - loss: 40099.7812\n",
      "rewards:  100.0 q-value:  0\n",
      "loss: [40099.78125]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 62us/step - loss: 54227.5000\n",
      "rewards:  95.0 q-value:  0\n",
      "loss: [54227.5]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 78us/step - loss: 46462.4062\n",
      "rewards:  90.0 q-value:  0\n",
      "loss: [46462.40625]\n",
      "Exploring\n",
      "Selected action  [2 1]\n",
      "[2 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 58us/step - loss: 57119.1875\n",
      "rewards:  78.0 q-value:  0\n",
      "loss: [57119.1875]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 50us/step - loss: 56038.9062\n",
      "rewards:  73.0 q-value:  0\n",
      "loss: [56038.90625]\n",
      "Exploring\n",
      "Selected action  [3 1]\n",
      "[3 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 52us/step - loss: 41105.2578\n",
      "rewards:  66.0 q-value:  0\n",
      "loss: [41105.2578125]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 69us/step - loss: 38918.8477\n",
      "rewards:  82.0 q-value:  0\n",
      "loss: [38918.84765625]\n",
      "Exploring\n",
      "Selected action  [0 3]\n",
      "[0 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 48us/step - loss: 29511.4062\n",
      "rewards:  106.0 q-value:  0\n",
      "loss: [29511.40625]\n",
      "Exploiting\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 69us/step - loss: 52580.2188\n",
      "rewards:  110.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [52580.21875]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 53us/step - loss: 25842.6250\n",
      "rewards:  108.0 q-value:  0\n",
      "loss: [25842.625]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 74us/step - loss: 27998.3750\n",
      "rewards:  103.0 q-value:  0\n",
      "loss: [27998.375]\n",
      "Exploring\n",
      "Selected action  [0 3]\n",
      "[0 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 62us/step - loss: 65346.9688\n",
      "rewards:  103.0 q-value:  0\n",
      "loss: [65346.96875]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 55us/step - loss: 38247.2812\n",
      "rewards:  111.0 q-value:  0\n",
      "loss: [38247.28125]\n",
      "Exploiting\n",
      "Selected action  [3 2]\n",
      "[3 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 62us/step - loss: 69551.3438\n",
      "rewards:  143.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [69551.34375]\n",
      "Exploring\n",
      "Selected action  [2 1]\n",
      "[2 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 55us/step - loss: 30170.3398\n",
      "rewards:  163.0 q-value:  0\n",
      "loss: [30170.33984375]\n",
      "Exploring\n",
      "Selected action  [0 3]\n",
      "[0 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 81us/step - loss: 74146.1250\n",
      "rewards:  193.0 q-value:  0\n",
      "loss: [74146.125]\n",
      "Exploring\n",
      "Selected action  [2 1]\n",
      "[2 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 46us/step - loss: 61746.5938\n",
      "rewards:  152.0 q-value:  0\n",
      "loss: [61746.59375]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 52us/step - loss: 51310.1406\n",
      "rewards:  147.0 q-value:  0\n",
      "loss: [51310.140625]\n",
      "Exploring\n",
      "Selected action  [3 2]\n",
      "[3 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 52us/step - loss: 61068.8125\n",
      "rewards:  173.0 q-value:  0\n",
      "loss: [61068.8125]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 73us/step - loss: 43363.6484\n",
      "rewards:  168.0 q-value:  0\n",
      "loss: [43363.6484375]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 53us/step - loss: 51294.9023\n",
      "rewards:  165.0 q-value:  0\n",
      "loss: [51294.90234375]\n",
      "Exploring\n",
      "Selected action  [2 1]\n",
      "[2 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 60us/step - loss: 45882.0312\n",
      "rewards:  159.0 q-value:  0\n",
      "loss: [45882.03125]\n",
      "Exploring\n",
      "Selected action  [3 2]\n",
      "[3 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 55us/step - loss: 48505.5312\n",
      "rewards:  169.0 q-value:  0\n",
      "loss: [48505.53125]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 75us/step - loss: 51666.5273\n",
      "rewards:  164.0 q-value:  0\n",
      "loss: [51666.52734375]\n",
      "Exploring\n",
      "Selected action  [3 2]\n",
      "[3 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 57us/step - loss: 53860.5938\n",
      "rewards:  171.0 q-value:  0\n",
      "loss: [53860.59375]\n",
      "Exploring\n",
      "Selected action  [2 1]\n",
      "[2 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 65us/step - loss: 40367.4375\n",
      "rewards:  215.0 q-value:  0\n",
      "loss: [40367.4375]\n",
      "Number of actions available 9\n",
      "Episode : 8\n",
      "Exploiting\n",
      "Selected action  [3 1]\n",
      "[3 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 58us/step - loss: 76129.5312\n",
      "rewards:  16.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [76129.53125]\n",
      "Exploring\n",
      "Selected action  [1 2]\n",
      "[1 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 64us/step - loss: 26058.1406\n",
      "rewards:  32.0 q-value:  0\n",
      "loss: [26058.140625]\n",
      "Exploring\n",
      "Selected action  [1 2]\n",
      "[1 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 69us/step - loss: 17450.3125\n",
      "rewards:  28.0 q-value:  0\n",
      "loss: [17450.3125]\n",
      "Exploring\n",
      "Selected action  [3 1]\n",
      "[3 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 63us/step - loss: 50016.0195\n",
      "rewards:  -12.0 q-value:  0\n",
      "loss: [50016.01953125]\n",
      "Exploring\n",
      "Selected action  [1 2]\n",
      "[1 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 99us/step - loss: 33847.3438\n",
      "rewards:  -4.0 q-value:  0\n",
      "loss: [33847.34375]\n",
      "Exploring\n",
      "Selected action  [1 2]\n",
      "[1 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 56us/step - loss: 27938.7500\n",
      "rewards:  -6.0 q-value:  0\n",
      "loss: [27938.75]\n",
      "Exploring\n",
      "Selected action  [3 1]\n",
      "[3 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 65us/step - loss: 50414.4062\n",
      "rewards:  -16.0 q-value:  0\n",
      "loss: [50414.40625]\n",
      "Exploring\n",
      "Selected action  [0 4]\n",
      "[0 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 83us/step - loss: 32608.8750\n",
      "rewards:  6.0 q-value:  0\n",
      "loss: [32608.875]\n",
      "Exploring\n",
      "Selected action  [3 1]\n",
      "[3 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 63us/step - loss: 54309.6172\n",
      "rewards:  16.0 q-value:  0\n",
      "loss: [54309.6171875]\n",
      "Exploring\n",
      "Selected action  [0 2]\n",
      "[0 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 64us/step - loss: 63471.6562\n",
      "rewards:  -5.0 q-value:  0\n",
      "loss: [63471.65625]\n",
      "Exploring\n",
      "Selected action  [3 1]\n",
      "[3 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 64us/step - loss: 19790.1562\n",
      "rewards:  -46.0 q-value:  0\n",
      "loss: [19790.15625]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 60us/step - loss: 52385.6562\n",
      "rewards:  -43.0 q-value:  0\n",
      "loss: [52385.65625]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 60us/step - loss: 52606.9062\n",
      "rewards:  -27.0 q-value:  0\n",
      "loss: [52606.90625]\n",
      "Exploring\n",
      "Selected action  [3 1]\n",
      "[3 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 51us/step - loss: 28907.9082\n",
      "rewards:  -23.0 q-value:  0\n",
      "loss: [28907.908203125]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 71us/step - loss: 49352.6875\n",
      "rewards:  -28.0 q-value:  0\n",
      "loss: [49352.6875]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 53us/step - loss: 54823.0312\n",
      "rewards:  -58.0 q-value:  0\n",
      "loss: [54823.03125]\n",
      "Exploiting\n",
      "Selected action  [4 0]\n",
      "[4 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 61us/step - loss: 44483.5625\n",
      "rewards:  -34.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [44483.5625]\n",
      "Exploring\n",
      "Selected action  [4 0]\n",
      "[4 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 56us/step - loss: 33630.3477\n",
      "rewards:  -35.0 q-value:  0\n",
      "loss: [33630.34765625]\n",
      "Exploring\n",
      "Selected action  [4 1]\n",
      "[4 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 52us/step - loss: 26102.4688\n",
      "rewards:  -36.0 q-value:  0\n",
      "loss: [26102.46875]\n",
      "Exploring\n",
      "Selected action  [0 4]\n",
      "[0 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 61us/step - loss: 50364.4062\n",
      "rewards:  -67.0 q-value:  0\n",
      "loss: [50364.40625]\n",
      "Exploring\n",
      "Selected action  [4 0]\n",
      "[4 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 69us/step - loss: 44696.9688\n",
      "rewards:  -63.0 q-value:  0\n",
      "loss: [44696.96875]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 51us/step - loss: 62860.7188\n",
      "rewards:  -73.0 q-value:  0\n",
      "loss: [62860.71875]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 55us/step - loss: 31846.2500\n",
      "rewards:  -74.0 q-value:  0\n",
      "loss: [31846.25]\n",
      "Exploring\n",
      "Selected action  [4 0]\n",
      "[4 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 57us/step - loss: 50381.4648\n",
      "rewards:  -70.0 q-value:  0\n",
      "loss: [50381.46484375]\n",
      "Exploring\n",
      "Selected action  [1 2]\n",
      "[1 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 55us/step - loss: 32499.6562\n",
      "rewards:  -93.0 q-value:  0\n",
      "loss: [32499.65625]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 61us/step - loss: 47561.0000\n",
      "rewards:  -136.0 q-value:  0\n",
      "loss: [47561.0]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 66us/step - loss: 43908.6016\n",
      "rewards:  -141.0 q-value:  0\n",
      "loss: [43908.6015625]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 62us/step - loss: 31446.1250\n",
      "rewards:  -146.0 q-value:  0\n",
      "loss: [31446.125]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 63us/step - loss: 38348.8750\n",
      "rewards:  -148.0 q-value:  0\n",
      "loss: [38348.875]\n",
      "Exploring\n",
      "Selected action  [3 1]\n",
      "[3 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 62us/step - loss: 57072.6211\n",
      "rewards:  -150.0 q-value:  0\n",
      "loss: [57072.62109375]\n",
      "Exploring\n",
      "Selected action  [0 4]\n",
      "[0 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 63us/step - loss: 46091.9258\n",
      "rewards:  -161.0 q-value:  0\n",
      "loss: [46091.92578125]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 42us/step - loss: 21808.2812\n",
      "rewards:  -162.0 q-value:  0\n",
      "loss: [21808.28125]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 52us/step - loss: 33792.5000\n",
      "rewards:  -170.0 q-value:  0\n",
      "loss: [33792.5]\n",
      "Exploring\n",
      "Selected action  [4 1]\n",
      "[4 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 65us/step - loss: 74200.2500\n",
      "rewards:  -157.0 q-value:  0\n",
      "loss: [74200.25]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 75us/step - loss: 63383.3438\n",
      "rewards:  -154.0 q-value:  0\n",
      "loss: [63383.34375]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 57us/step - loss: 68007.6250\n",
      "rewards:  -130.0 q-value:  0\n",
      "loss: [68007.625]\n",
      "Exploring\n",
      "Selected action  [0 2]\n",
      "[0 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 51us/step - loss: 55789.3984\n",
      "rewards:  -98.0 q-value:  0\n",
      "loss: [55789.3984375]\n",
      "Exploring\n",
      "Selected action  [3 1]\n",
      "[3 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 70us/step - loss: 88089.3750\n",
      "rewards:  -111.0 q-value:  0\n",
      "loss: [88089.375]\n",
      "Exploring\n",
      "Selected action  [4 1]\n",
      "[4 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 56us/step - loss: 45572.4531\n",
      "rewards:  -117.0 q-value:  0\n",
      "loss: [45572.453125]\n",
      "Exploring\n",
      "Selected action  [1 2]\n",
      "[1 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 64us/step - loss: 59574.6680\n",
      "rewards:  -113.0 q-value:  0\n",
      "loss: [59574.66796875]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 45us/step - loss: 23281.2812\n",
      "rewards:  -109.0 q-value:  0\n",
      "loss: [23281.28125]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 55us/step - loss: 62756.8164\n",
      "rewards:  -114.0 q-value:  0\n",
      "loss: [62756.81640625]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 88us/step - loss: 62376.3125\n",
      "rewards:  -119.0 q-value:  0\n",
      "loss: [62376.3125]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 62us/step - loss: 21783.1250\n",
      "rewards:  -123.0 q-value:  0\n",
      "loss: [21783.125]\n",
      "Exploring\n",
      "Selected action  [1 2]\n",
      "[1 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 81us/step - loss: 57804.0078\n",
      "rewards:  -101.0 q-value:  0\n",
      "loss: [57804.0078125]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 71us/step - loss: 27300.8438\n",
      "rewards:  -108.0 q-value:  0\n",
      "loss: [27300.84375]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 78us/step - loss: 39315.8438\n",
      "rewards:  -101.0 q-value:  0\n",
      "loss: [39315.84375]\n",
      "Exploring\n",
      "Selected action  [3 1]\n",
      "[3 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 51us/step - loss: 37168.3750\n",
      "rewards:  -109.0 q-value:  0\n",
      "loss: [37168.375]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 65us/step - loss: 40667.8438\n",
      "rewards:  -159.0 q-value:  0\n",
      "loss: [40667.84375]\n",
      "Exploring\n",
      "Selected action  [0 4]\n",
      "[0 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 60us/step - loss: 53865.7188\n",
      "rewards:  -162.0 q-value:  0\n",
      "loss: [53865.71875]\n",
      "Exploiting\n",
      "Selected action  [3 1]\n",
      "[3 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 62us/step - loss: 40180.5859\n",
      "rewards:  -156.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [40180.5859375]\n",
      "Exploiting\n",
      "Selected action  [0 2]\n",
      "[0 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 70us/step - loss: 55604.5000\n",
      "rewards:  -128.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [55604.5]\n",
      "Exploiting\n",
      "Selected action  [4 1]\n",
      "[4 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 66us/step - loss: 68518.6875\n",
      "rewards:  -128.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [68518.6875]\n",
      "Exploring\n",
      "Selected action  [0 4]\n",
      "[0 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 74us/step - loss: 51009.7422\n",
      "rewards:  -148.0 q-value:  0\n",
      "loss: [51009.7421875]\n",
      "Exploring\n",
      "Selected action  [4 0]\n",
      "[4 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 86us/step - loss: 49116.8672\n",
      "rewards:  -148.0 q-value:  0\n",
      "loss: [49116.8671875]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 65us/step - loss: 27802.7188\n",
      "rewards:  -152.0 q-value:  0\n",
      "loss: [27802.71875]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 60us/step - loss: 49182.0312\n",
      "rewards:  -172.0 q-value:  0\n",
      "loss: [49182.03125]\n",
      "Exploring\n",
      "Selected action  [1 2]\n",
      "[1 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 48us/step - loss: 58612.9297\n",
      "rewards:  -164.0 q-value:  0\n",
      "loss: [58612.9296875]\n",
      "Exploring\n",
      "Selected action  [0 4]\n",
      "[0 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 73us/step - loss: 41005.7812\n",
      "rewards:  -185.0 q-value:  0\n",
      "loss: [41005.78125]\n",
      "Exploring\n",
      "Selected action  [0 2]\n",
      "[0 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 61us/step - loss: 35762.0391\n",
      "rewards:  -170.0 q-value:  0\n",
      "loss: [35762.0390625]\n",
      "Exploring\n",
      "Selected action  [0 4]\n",
      "[0 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 43us/step - loss: 44677.1562\n",
      "rewards:  -201.0 q-value:  0\n",
      "loss: [44677.15625]\n",
      "Exploring\n",
      "Selected action  [1 2]\n",
      "[1 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 68us/step - loss: 46817.5312\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rewards:  -183.0 q-value:  0\n",
      "loss: [46817.53125]\n",
      "Exploiting\n",
      "Selected action  [0 2]\n",
      "[0 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 62us/step - loss: 11567.0352\n",
      "rewards:  -189.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [11567.03515625]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 75us/step - loss: 53755.5938\n",
      "rewards:  -191.0 q-value:  0\n",
      "loss: [53755.59375]\n",
      "Exploring\n",
      "Selected action  [4 0]\n",
      "[4 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 60us/step - loss: 39748.5195\n",
      "rewards:  -192.0 q-value:  0\n",
      "loss: [39748.51953125]\n",
      "Exploring\n",
      "Selected action  [4 1]\n",
      "[4 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 66us/step - loss: 42106.9688\n",
      "rewards:  -189.0 q-value:  0\n",
      "loss: [42106.96875]\n",
      "Exploring\n",
      "Selected action  [0 2]\n",
      "[0 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 73us/step - loss: 35630.1562\n",
      "rewards:  -179.0 q-value:  0\n",
      "loss: [35630.15625]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 84us/step - loss: 12460.5312\n",
      "rewards:  -196.0 q-value:  0\n",
      "loss: [12460.53125]\n",
      "Exploiting\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 84us/step - loss: 41371.2188\n",
      "rewards:  -202.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [41371.21875]\n",
      "Exploring\n",
      "Selected action  [0 2]\n",
      "[0 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 61us/step - loss: 61720.8359\n",
      "rewards:  -199.0 q-value:  0\n",
      "loss: [61720.8359375]\n",
      "Exploring\n",
      "Selected action  [1 2]\n",
      "[1 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 57us/step - loss: 33496.1914\n",
      "rewards:  -204.0 q-value:  0\n",
      "loss: [33496.19140625]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 73us/step - loss: 35670.2617\n",
      "rewards:  -218.0 q-value:  0\n",
      "loss: [35670.26171875]\n",
      "Exploiting\n",
      "Selected action  [1 2]\n",
      "[1 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 86us/step - loss: 69007.9297\n",
      "rewards:  -208.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [69007.9296875]\n",
      "Exploring\n",
      "Selected action  [4 0]\n",
      "[4 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 60us/step - loss: 33796.4062\n",
      "rewards:  -204.0 q-value:  0\n",
      "loss: [33796.40625]\n",
      "Exploiting\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 78us/step - loss: 73390.9062\n",
      "rewards:  -209.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [73390.90625]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 76us/step - loss: 28528.8438\n",
      "rewards:  -214.0 q-value:  0\n",
      "loss: [28528.84375]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 64us/step - loss: 71328.9141\n",
      "rewards:  -217.0 q-value:  0\n",
      "loss: [71328.9140625]\n",
      "Exploring\n",
      "Selected action  [0 2]\n",
      "[0 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 66us/step - loss: 46400.1875\n",
      "rewards:  -193.0 q-value:  0\n",
      "loss: [46400.1875]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 75us/step - loss: 51774.6562\n",
      "rewards:  -198.0 q-value:  0\n",
      "loss: [51774.65625]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 67us/step - loss: 54827.4688\n",
      "rewards:  -205.0 q-value:  0\n",
      "loss: [54827.46875]\n",
      "Exploring\n",
      "Selected action  [1 2]\n",
      "[1 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 63us/step - loss: 35596.1562\n",
      "rewards:  -228.0 q-value:  0\n",
      "loss: [35596.15625]\n",
      "Exploring\n",
      "Selected action  [0 4]\n",
      "[0 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 77us/step - loss: 36526.7500\n",
      "rewards:  -222.0 q-value:  0\n",
      "loss: [36526.75]\n",
      "Exploring\n",
      "Selected action  [4 0]\n",
      "[4 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 78us/step - loss: 41326.0391\n",
      "rewards:  -218.0 q-value:  0\n",
      "loss: [41326.0390625]\n",
      "Exploring\n",
      "Selected action  [4 0]\n",
      "[4 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 58us/step - loss: 49633.1172\n",
      "rewards:  -219.0 q-value:  0\n",
      "loss: [49633.1171875]\n",
      "Exploring\n",
      "Selected action  [1 2]\n",
      "[1 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 70us/step - loss: 42050.7812\n",
      "rewards:  -214.0 q-value:  0\n",
      "loss: [42050.78125]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 74us/step - loss: 82731.2812\n",
      "rewards:  -198.0 q-value:  0\n",
      "loss: [82731.28125]\n",
      "Exploring\n",
      "Selected action  [0 2]\n",
      "[0 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 59us/step - loss: 36331.6250\n",
      "rewards:  -194.0 q-value:  0\n",
      "loss: [36331.625]\n",
      "Exploring\n",
      "Selected action  [4 1]\n",
      "[4 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 61us/step - loss: 25263.6367\n",
      "rewards:  -204.0 q-value:  0\n",
      "loss: [25263.63671875]\n",
      "Exploring\n",
      "Selected action  [4 1]\n",
      "[4 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 67us/step - loss: 39445.7812\n",
      "rewards:  -204.0 q-value:  0\n",
      "loss: [39445.78125]\n",
      "Exploring\n",
      "Selected action  [4 0]\n",
      "[4 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 74us/step - loss: 29476.5625\n",
      "rewards:  -200.0 q-value:  0\n",
      "loss: [29476.5625]\n",
      "Exploiting\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 62us/step - loss: 47283.7930\n",
      "rewards:  -205.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [47283.79296875]\n",
      "Exploring\n",
      "Selected action  [1 2]\n",
      "[1 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 78us/step - loss: 48620.0625\n",
      "rewards:  -207.0 q-value:  0\n",
      "loss: [48620.0625]\n",
      "Exploring\n",
      "Selected action  [1 2]\n",
      "[1 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 87us/step - loss: 30490.7188\n",
      "rewards:  -214.0 q-value:  0\n",
      "loss: [30490.71875]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 76us/step - loss: 48065.1250\n",
      "rewards:  -219.0 q-value:  0\n",
      "loss: [48065.125]\n",
      "Exploring\n",
      "Selected action  [3 1]\n",
      "[3 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 66us/step - loss: 54050.4062\n",
      "rewards:  -237.0 q-value:  0\n",
      "loss: [54050.40625]\n",
      "Exploring\n",
      "Selected action  [0 4]\n",
      "[0 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 84us/step - loss: 57316.1172\n",
      "rewards:  -264.0 q-value:  0\n",
      "loss: [57316.1171875]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 52us/step - loss: 32159.7188\n",
      "rewards:  -265.0 q-value:  0\n",
      "loss: [32159.71875]\n",
      "Exploring\n",
      "Selected action  [0 2]\n",
      "[0 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 64us/step - loss: 45114.8125\n",
      "rewards:  -257.0 q-value:  0\n",
      "loss: [45114.8125]\n",
      "Exploring\n",
      "Selected action  [0 2]\n",
      "[0 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 54us/step - loss: 11399.4375\n",
      "rewards:  -259.0 q-value:  0\n",
      "loss: [11399.4375]\n",
      "Exploring\n",
      "Selected action  [3 1]\n",
      "[3 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 69us/step - loss: 84696.2812\n",
      "rewards:  -255.0 q-value:  0\n",
      "loss: [84696.28125]\n",
      "Exploiting\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 71us/step - loss: 32671.7031\n",
      "rewards:  -260.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [32671.703125]\n",
      "Exploring\n",
      "Selected action  [0 4]\n",
      "[0 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 66us/step - loss: 30624.9141\n",
      "rewards:  -236.0 q-value:  0\n",
      "loss: [30624.9140625]\n",
      "Exploring\n",
      "Selected action  [4 0]\n",
      "[4 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 64us/step - loss: 46637.1367\n",
      "rewards:  -232.0 q-value:  0\n",
      "loss: [46637.13671875]\n",
      "Exploring\n",
      "Selected action  [3 1]\n",
      "[3 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 70us/step - loss: 26089.9688\n",
      "rewards:  -247.0 q-value:  0\n",
      "loss: [26089.96875]\n",
      "Exploring\n",
      "Selected action  [4 1]\n",
      "[4 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 64us/step - loss: 53866.9688\n",
      "rewards:  -253.0 q-value:  0\n",
      "loss: [53866.96875]\n",
      "Exploring\n",
      "Selected action  [4 1]\n",
      "[4 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 58us/step - loss: 38706.4062\n",
      "rewards:  -255.0 q-value:  0\n",
      "loss: [38706.40625]\n",
      "Exploring\n",
      "Selected action  [4 0]\n",
      "[4 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 60us/step - loss: 50503.2500\n",
      "rewards:  -249.0 q-value:  0\n",
      "loss: [50503.25]\n",
      "Exploring\n",
      "Selected action  [0 4]\n",
      "[0 4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 51us/step - loss: 18779.3438\n",
      "rewards:  -237.0 q-value:  0\n",
      "loss: [18779.34375]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 47us/step - loss: 51633.3984\n",
      "rewards:  -209.0 q-value:  0\n",
      "loss: [51633.3984375]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 87us/step - loss: 63127.0938\n",
      "rewards:  -244.0 q-value:  0\n",
      "loss: [63127.09375]\n",
      "Exploring\n",
      "Selected action  [4 1]\n",
      "[4 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 100us/step - loss: 40038.8125\n",
      "rewards:  -240.0 q-value:  0\n",
      "loss: [40038.8125]\n",
      "Exploring\n",
      "Selected action  [0 4]\n",
      "[0 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 69us/step - loss: 51821.9375\n",
      "rewards:  -265.0 q-value:  0\n",
      "loss: [51821.9375]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 56us/step - loss: 65819.0312\n",
      "rewards:  -270.0 q-value:  0\n",
      "loss: [65819.03125]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 71us/step - loss: 20200.6875\n",
      "rewards:  -275.0 q-value:  0\n",
      "loss: [20200.6875]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 57us/step - loss: 33390.5625\n",
      "rewards:  -278.0 q-value:  0\n",
      "loss: [33390.5625]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 54us/step - loss: 41238.3750\n",
      "rewards:  -278.0 q-value:  0\n",
      "loss: [41238.375]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 57us/step - loss: 72984.5469\n",
      "rewards:  -283.0 q-value:  0\n",
      "loss: [72984.546875]\n",
      "Exploring\n",
      "Selected action  [0 2]\n",
      "[0 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 61us/step - loss: 31864.3750\n",
      "rewards:  -263.0 q-value:  0\n",
      "loss: [31864.375]\n",
      "Exploring\n",
      "Selected action  [4 1]\n",
      "[4 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 62us/step - loss: 33351.3438\n",
      "rewards:  -280.0 q-value:  0\n",
      "loss: [33351.34375]\n",
      "Exploring\n",
      "Selected action  [0 4]\n",
      "[0 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 73us/step - loss: 30308.1250\n",
      "rewards:  -306.0 q-value:  0\n",
      "loss: [30308.125]\n",
      "Exploring\n",
      "Selected action  [1 2]\n",
      "[1 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 64us/step - loss: 69336.6250\n",
      "rewards:  -288.0 q-value:  0\n",
      "loss: [69336.625]\n",
      "Exploring\n",
      "Selected action  [0 4]\n",
      "[0 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 55us/step - loss: 26654.8750\n",
      "rewards:  -306.0 q-value:  0\n",
      "loss: [26654.875]\n",
      "Exploring\n",
      "Selected action  [0 2]\n",
      "[0 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 73us/step - loss: 48384.7500\n",
      "rewards:  -299.0 q-value:  0\n",
      "loss: [48384.75]\n",
      "Exploiting\n",
      "Selected action  [4 0]\n",
      "[4 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 74us/step - loss: 47717.9062\n",
      "rewards:  -295.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [47717.90625]\n",
      "Exploiting\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 63us/step - loss: 41512.4688\n",
      "rewards:  -300.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [41512.46875]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 66us/step - loss: 29020.1250\n",
      "rewards:  -302.0 q-value:  0\n",
      "loss: [29020.125]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 72us/step - loss: 35781.1562\n",
      "rewards:  -307.0 q-value:  0\n",
      "loss: [35781.15625]\n",
      "Exploring\n",
      "Selected action  [4 1]\n",
      "[4 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 63us/step - loss: 40902.3125\n",
      "rewards:  -335.0 q-value:  0\n",
      "loss: [40902.3125]\n",
      "Exploring\n",
      "Selected action  [1 2]\n",
      "[1 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 71us/step - loss: 76948.4844\n",
      "rewards:  -303.0 q-value:  0\n",
      "loss: [76948.484375]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 56us/step - loss: 38356.1250\n",
      "rewards:  -317.0 q-value:  0\n",
      "loss: [38356.125]\n",
      "Number of actions available 8\n",
      "Episode : 9\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 64us/step - loss: 57065.6875\n",
      "rewards:  -5 q-value:  0\n",
      "loss: [57065.6875]\n",
      "Exploiting\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 60us/step - loss: 52623.4141\n",
      "rewards:  -10 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [52623.4140625]\n",
      "Exploring\n",
      "Selected action  [4 1]\n",
      "[4 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 59us/step - loss: 32294.4688\n",
      "rewards:  -7.0 q-value:  0\n",
      "loss: [32294.46875]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 56us/step - loss: 69590.9531\n",
      "rewards:  -12.0 q-value:  0\n",
      "loss: [69590.953125]\n",
      "Exploring\n",
      "Selected action  [4 2]\n",
      "[4 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 71us/step - loss: 32502.9375\n",
      "rewards:  3.0 q-value:  0\n",
      "loss: [32502.9375]\n",
      "Exploring\n",
      "Selected action  [4 2]\n",
      "[4 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 52us/step - loss: 43157.0859\n",
      "rewards:  -1.0 q-value:  0\n",
      "loss: [43157.0859375]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 59us/step - loss: 78349.4375\n",
      "rewards:  -1.0 q-value:  0\n",
      "loss: [78349.4375]\n",
      "Exploring\n",
      "Selected action  [4 2]\n",
      "[4 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 63us/step - loss: 47663.7188\n",
      "rewards:  -1.0 q-value:  0\n",
      "loss: [47663.71875]\n",
      "Exploring\n",
      "Selected action  [0 3]\n",
      "[0 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 66us/step - loss: 39612.9375\n",
      "rewards:  -16.0 q-value:  0\n",
      "loss: [39612.9375]\n",
      "Exploring\n",
      "Selected action  [0 3]\n",
      "[0 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 74us/step - loss: 39510.3047\n",
      "rewards:  -16.0 q-value:  0\n",
      "loss: [39510.3046875]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 70us/step - loss: 52255.0938\n",
      "rewards:  -8.0 q-value:  0\n",
      "loss: [52255.09375]\n",
      "Exploring\n",
      "Selected action  [0 3]\n",
      "[0 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 67us/step - loss: 45575.7930\n",
      "rewards:  -8.0 q-value:  0\n",
      "loss: [45575.79296875]\n",
      "Exploring\n",
      "Selected action  [4 1]\n",
      "[4 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 71us/step - loss: 43171.3750\n",
      "rewards:  -15.0 q-value:  0\n",
      "loss: [43171.375]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 56us/step - loss: 49682.7812\n",
      "rewards:  -7.0 q-value:  0\n",
      "loss: [49682.78125]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 69us/step - loss: 39174.5156\n",
      "rewards:  -24.0 q-value:  0\n",
      "loss: [39174.515625]\n",
      "Exploiting\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 63us/step - loss: 23567.4062\n",
      "rewards:  -39.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [23567.40625]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 77us/step - loss: 74213.2422\n",
      "rewards:  -31.0 q-value:  0\n",
      "loss: [74213.2421875]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 63us/step - loss: 53825.2812\n",
      "rewards:  -37.0 q-value:  0\n",
      "loss: [53825.28125]\n",
      "Exploiting\n",
      "Selected action  [1 2]\n",
      "[1 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 69us/step - loss: 61299.8750\n",
      "rewards:  -37.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [61299.875]\n",
      "Exploiting\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 71us/step - loss: 34972.9062\n",
      "rewards:  -51.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [34972.90625]\n",
      "Exploring\n",
      "Selected action  [4 1]\n",
      "[4 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 60us/step - loss: 32472.0000\n",
      "rewards:  -66.0 q-value:  0\n",
      "loss: [32472.0]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 73us/step - loss: 31621.4375\n",
      "rewards:  -71.0 q-value:  0\n",
      "loss: [31621.4375]\n",
      "Exploring\n",
      "Selected action  [4 2]\n",
      "[4 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 66us/step - loss: 45577.3125\n",
      "rewards:  -78.0 q-value:  0\n",
      "loss: [45577.3125]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 68us/step - loss: 35817.8750\n",
      "rewards:  -67.0 q-value:  0\n",
      "loss: [35817.875]\n",
      "Exploiting\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 73us/step - loss: 27769.1875\n",
      "rewards:  -97.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [27769.1875]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 67us/step - loss: 39431.8438\n",
      "rewards:  -109.0 q-value:  0\n",
      "loss: [39431.84375]\n",
      "Exploring\n",
      "Selected action  [4 2]\n",
      "[4 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 53us/step - loss: 72003.6875\n",
      "rewards:  -139.0 q-value:  0\n",
      "loss: [72003.6875]\n",
      "Exploring\n",
      "Selected action  [0 3]\n",
      "[0 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 60us/step - loss: 75501.6250\n",
      "rewards:  -169.0 q-value:  0\n",
      "loss: [75501.625]\n",
      "Exploring\n",
      "Selected action  [0 3]\n",
      "[0 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 54us/step - loss: 38910.1562\n",
      "rewards:  -169.0 q-value:  0\n",
      "loss: [38910.15625]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 49us/step - loss: 88188.9688\n",
      "rewards:  -166.0 q-value:  0\n",
      "loss: [88188.96875]\n",
      "Exploring\n",
      "Selected action  [4 1]\n",
      "[4 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 65us/step - loss: 53642.8750\n",
      "rewards:  -167.0 q-value:  0\n",
      "loss: [53642.875]\n",
      "Exploiting\n",
      "Selected action  [4 2]\n",
      "[4 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 61us/step - loss: 32310.5312\n",
      "rewards:  -172.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [32310.53125]\n",
      "Exploiting\n",
      "Selected action  [1 2]\n",
      "[1 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 66us/step - loss: 33337.9688\n",
      "rewards:  -178.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [33337.96875]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 89us/step - loss: 40164.5625\n",
      "rewards:  -158.0 q-value:  0\n",
      "loss: [40164.5625]\n",
      "Exploring\n",
      "Selected action  [1 2]\n",
      "[1 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 47us/step - loss: 60315.3125\n",
      "rewards:  -146.0 q-value:  0\n",
      "loss: [60315.3125]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 57us/step - loss: 43262.8438\n",
      "rewards:  -142.0 q-value:  0\n",
      "loss: [43262.84375]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 69us/step - loss: 45290.9688\n",
      "rewards:  -114.0 q-value:  0\n",
      "loss: [45290.96875]\n",
      "Exploiting\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 52us/step - loss: 32409.5039\n",
      "rewards:  -109.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [32409.50390625]\n",
      "Exploring\n",
      "Selected action  [4 1]\n",
      "[4 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 62us/step - loss: 51732.3750\n",
      "rewards:  -98.0 q-value:  0\n",
      "loss: [51732.375]\n",
      "Exploring\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 61us/step - loss: 22734.9648\n",
      "rewards:  -90.0 q-value:  0\n",
      "loss: [22734.96484375]\n",
      "Exploring\n",
      "Selected action  [1 2]\n",
      "[1 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 70us/step - loss: 45860.9375\n",
      "rewards:  -84.0 q-value:  0\n",
      "loss: [45860.9375]\n",
      "Exploring\n",
      "Selected action  [1 2]\n",
      "[1 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 62us/step - loss: 38498.8125\n",
      "rewards:  -85.0 q-value:  0\n",
      "loss: [38498.8125]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 61us/step - loss: 24377.1797\n",
      "rewards:  -90.0 q-value:  0\n",
      "loss: [24377.1796875]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 107us/step - loss: 38954.8750\n",
      "rewards:  -87.0 q-value:  0\n",
      "loss: [38954.875]\n",
      "Exploring\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 64us/step - loss: 38433.9062\n",
      "rewards:  -98.0 q-value:  0\n",
      "loss: [38433.90625]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 58us/step - loss: 38693.6562\n",
      "rewards:  -103.0 q-value:  0\n",
      "loss: [38693.65625]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 63us/step - loss: 16252.5938\n",
      "rewards:  -135.0 q-value:  0\n",
      "loss: [16252.59375]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 60us/step - loss: 32371.0938\n",
      "rewards:  -126.0 q-value:  0\n",
      "loss: [32371.09375]\n",
      "Exploring\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 60us/step - loss: 12973.8770\n",
      "rewards:  -139.0 q-value:  0\n",
      "loss: [12973.876953125]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 58us/step - loss: 59193.7734\n",
      "rewards:  -144.0 q-value:  0\n",
      "loss: [59193.7734375]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 56us/step - loss: 48183.5312\n",
      "rewards:  -151.0 q-value:  0\n",
      "loss: [48183.53125]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 74us/step - loss: 24270.1094\n",
      "rewards:  -157.0 q-value:  0\n",
      "loss: [24270.109375]\n",
      "Exploring\n",
      "Selected action  [4 1]\n",
      "[4 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 68us/step - loss: 62177.9688\n",
      "rewards:  -157.0 q-value:  0\n",
      "loss: [62177.96875]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 66us/step - loss: 46769.5312\n",
      "rewards:  -162.0 q-value:  0\n",
      "loss: [46769.53125]\n",
      "Exploring\n",
      "Selected action  [1 2]\n",
      "[1 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 51us/step - loss: 53223.5625\n",
      "rewards:  -178.0 q-value:  0\n",
      "loss: [53223.5625]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 58us/step - loss: 55309.8438\n",
      "rewards:  -174.0 q-value:  0\n",
      "loss: [55309.84375]\n",
      "Exploring\n",
      "Selected action  [4 2]\n",
      "[4 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 71us/step - loss: 35284.1875\n",
      "rewards:  -170.0 q-value:  0\n",
      "loss: [35284.1875]\n",
      "Exploring\n",
      "Selected action  [4 2]\n",
      "[4 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 95us/step - loss: 59158.0000\n",
      "rewards:  -171.0 q-value:  0\n",
      "loss: [59158.0]\n",
      "Exploring\n",
      "Selected action  [4 2]\n",
      "[4 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 67us/step - loss: 36642.1484\n",
      "rewards:  -171.0 q-value:  0\n",
      "loss: [36642.1484375]\n",
      "Exploring\n",
      "Selected action  [0 3]\n",
      "[0 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 56us/step - loss: 24699.5938\n",
      "rewards:  -184.0 q-value:  0\n",
      "loss: [24699.59375]\n",
      "Exploring\n",
      "Selected action  [0 3]\n",
      "[0 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 97us/step - loss: 36708.8750\n",
      "rewards:  -187.0 q-value:  0\n",
      "loss: [36708.875]\n",
      "Exploiting\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 69us/step - loss: 44397.0000\n",
      "rewards:  -184.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [44397.0]\n",
      "Exploring\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 55us/step - loss: 26799.1562\n",
      "rewards:  -212.0 q-value:  0\n",
      "loss: [26799.15625]\n",
      "Exploring\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 80us/step - loss: 75834.5781\n",
      "rewards:  -215.0 q-value:  0\n",
      "loss: [75834.578125]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 75us/step - loss: 36810.1875\n",
      "rewards:  -247.0 q-value:  0\n",
      "loss: [36810.1875]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 75us/step - loss: 53455.5312\n",
      "rewards:  -249.0 q-value:  0\n",
      "loss: [53455.53125]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 74us/step - loss: 39503.4609\n",
      "rewards:  -247.0 q-value:  0\n",
      "loss: [39503.4609375]\n",
      "Exploring\n",
      "Selected action  [4 2]\n",
      "[4 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 85us/step - loss: 55625.3750\n",
      "rewards:  -262.0 q-value:  0\n",
      "loss: [55625.375]\n",
      "Exploring\n",
      "Selected action  [0 3]\n",
      "[0 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 62us/step - loss: 25247.0312\n",
      "rewards:  -278.0 q-value:  0\n",
      "loss: [25247.03125]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 63us/step - loss: 49098.4375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rewards:  -283.0 q-value:  0\n",
      "loss: [49098.4375]\n",
      "Exploring\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 61us/step - loss: 44045.5000\n",
      "rewards:  -306.0 q-value:  0\n",
      "loss: [44045.5]\n",
      "Exploiting\n",
      "Selected action  [4 2]\n",
      "[4 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 71us/step - loss: 67648.1172\n",
      "rewards:  -316.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [67648.1171875]\n",
      "Exploring\n",
      "Selected action  [1 2]\n",
      "[1 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 65us/step - loss: 44596.3438\n",
      "rewards:  -325.0 q-value:  0\n",
      "loss: [44596.34375]\n",
      "Exploring\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 57us/step - loss: 14384.7861\n",
      "rewards:  -364.0 q-value:  0\n",
      "loss: [14384.7861328125]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 66us/step - loss: 66801.9375\n",
      "rewards:  -358.0 q-value:  0\n",
      "loss: [66801.9375]\n",
      "Exploring\n",
      "Selected action  [0 3]\n",
      "[0 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 78us/step - loss: 71586.2969\n",
      "rewards:  -342.0 q-value:  0\n",
      "loss: [71586.296875]\n",
      "Exploring\n",
      "Selected action  [0 3]\n",
      "[0 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 67us/step - loss: 43875.7070\n",
      "rewards:  -345.0 q-value:  0\n",
      "loss: [43875.70703125]\n",
      "Exploring\n",
      "Selected action  [1 2]\n",
      "[1 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 54us/step - loss: 56079.0000\n",
      "rewards:  -337.0 q-value:  0\n",
      "loss: [56079.0]\n",
      "Exploring\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 77us/step - loss: 22839.0645\n",
      "rewards:  -341.0 q-value:  0\n",
      "loss: [22839.064453125]\n",
      "Exploring\n",
      "Selected action  [4 1]\n",
      "[4 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 74us/step - loss: 32727.9062\n",
      "rewards:  -348.0 q-value:  0\n",
      "loss: [32727.90625]\n",
      "Exploring\n",
      "Selected action  [4 1]\n",
      "[4 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 64us/step - loss: 49411.1250\n",
      "rewards:  -351.0 q-value:  0\n",
      "loss: [49411.125]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 64us/step - loss: 67172.1875\n",
      "rewards:  -383.0 q-value:  0\n",
      "loss: [67172.1875]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 56us/step - loss: 61871.7383\n",
      "rewards:  -385.0 q-value:  0\n",
      "loss: [61871.73828125]\n",
      "Exploiting\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 51us/step - loss: 61133.8711\n",
      "rewards:  -397.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [61133.87109375]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 46us/step - loss: 80375.7500\n",
      "rewards:  -403.0 q-value:  0\n",
      "loss: [80375.75]\n",
      "Exploring\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 56us/step - loss: 57895.7422\n",
      "rewards:  -403.0 q-value:  0\n",
      "loss: [57895.7421875]\n",
      "Exploring\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 58us/step - loss: 44357.8594\n",
      "rewards:  -404.0 q-value:  0\n",
      "loss: [44357.859375]\n",
      "Exploring\n",
      "Selected action  [1 2]\n",
      "[1 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 68us/step - loss: 31694.2031\n",
      "rewards:  -369.0 q-value:  0\n",
      "loss: [31694.203125]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 77us/step - loss: 33697.8438\n",
      "rewards:  -374.0 q-value:  0\n",
      "loss: [33697.84375]\n",
      "Exploring\n",
      "Selected action  [0 3]\n",
      "[0 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 63us/step - loss: 37488.0938\n",
      "rewards:  -374.0 q-value:  0\n",
      "loss: [37488.09375]\n",
      "Exploring\n",
      "Selected action  [1 2]\n",
      "[1 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 44us/step - loss: 34080.5938\n",
      "rewards:  -359.0 q-value:  0\n",
      "loss: [34080.59375]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 74us/step - loss: 64260.3750\n",
      "rewards:  -359.0 q-value:  0\n",
      "loss: [64260.375]\n",
      "Exploiting\n",
      "Selected action  [0 3]\n",
      "[0 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 55us/step - loss: 42080.8008\n",
      "rewards:  -340.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [42080.80078125]\n",
      "Exploiting\n",
      "Selected action  [4 2]\n",
      "[4 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 59us/step - loss: 41270.4023\n",
      "rewards:  -355.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [41270.40234375]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 78us/step - loss: 28389.9062\n",
      "rewards:  -351.0 q-value:  0\n",
      "loss: [28389.90625]\n",
      "Exploiting\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 69us/step - loss: 76001.2188\n",
      "rewards:  -356.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [76001.21875]\n",
      "Exploring\n",
      "Selected action  [1 2]\n",
      "[1 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 61us/step - loss: 60585.1250\n",
      "rewards:  -379.0 q-value:  0\n",
      "loss: [60585.125]\n",
      "Exploring\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 73us/step - loss: 27908.0312\n",
      "rewards:  -386.0 q-value:  0\n",
      "loss: [27908.03125]\n",
      "Exploring\n",
      "Selected action  [4 1]\n",
      "[4 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 62us/step - loss: 35709.2148\n",
      "rewards:  -396.0 q-value:  0\n",
      "loss: [35709.21484375]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 61us/step - loss: 27180.7812\n",
      "rewards:  -384.0 q-value:  0\n",
      "loss: [27180.78125]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 57us/step - loss: 53735.8125\n",
      "rewards:  -386.0 q-value:  0\n",
      "loss: [53735.8125]\n",
      "Exploring\n",
      "Selected action  [0 3]\n",
      "[0 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 61us/step - loss: 49846.3438\n",
      "rewards:  -402.0 q-value:  0\n",
      "loss: [49846.34375]\n",
      "Exploring\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 80us/step - loss: 45307.0625\n",
      "rewards:  -407.0 q-value:  0\n",
      "loss: [45307.0625]\n",
      "Exploring\n",
      "Selected action  [1 2]\n",
      "[1 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 52us/step - loss: 39813.0000\n",
      "rewards:  -412.0 q-value:  0\n",
      "loss: [39813.0]\n",
      "Exploring\n",
      "Selected action  [0 3]\n",
      "[0 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 55us/step - loss: 48508.1250\n",
      "rewards:  -410.0 q-value:  0\n",
      "loss: [48508.125]\n",
      "Exploring\n",
      "Selected action  [4 1]\n",
      "[4 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 65us/step - loss: 59452.6562\n",
      "rewards:  -418.0 q-value:  0\n",
      "loss: [59452.65625]\n",
      "Exploring\n",
      "Selected action  [4 2]\n",
      "[4 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 73us/step - loss: 41250.3750\n",
      "rewards:  -425.0 q-value:  0\n",
      "loss: [41250.375]\n",
      "Exploiting\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 61us/step - loss: 34331.1250\n",
      "rewards:  -417.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [34331.125]\n",
      "Exploring\n",
      "Selected action  [4 1]\n",
      "[4 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 59us/step - loss: 57968.4375\n",
      "rewards:  -409.0 q-value:  0\n",
      "loss: [57968.4375]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 66us/step - loss: 69708.6250\n",
      "rewards:  -389.0 q-value:  0\n",
      "loss: [69708.625]\n",
      "Exploring\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 73us/step - loss: 39280.5312\n",
      "rewards:  -412.0 q-value:  0\n",
      "loss: [39280.53125]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 62us/step - loss: 46477.6875\n",
      "rewards:  -417.0 q-value:  0\n",
      "loss: [46477.6875]\n",
      "Exploring\n",
      "Selected action  [4 2]\n",
      "[4 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 73us/step - loss: 41258.0938\n",
      "rewards:  -413.0 q-value:  0\n",
      "loss: [41258.09375]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 60us/step - loss: 45898.8633\n",
      "rewards:  -409.0 q-value:  0\n",
      "loss: [45898.86328125]\n",
      "Exploring\n",
      "Selected action  [4 1]\n",
      "[4 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 64us/step - loss: 42761.8750\n",
      "rewards:  -409.0 q-value:  0\n",
      "loss: [42761.875]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 70us/step - loss: 48888.2188\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rewards:  -414.0 q-value:  0\n",
      "loss: [48888.21875]\n",
      "Exploring\n",
      "Selected action  [4 2]\n",
      "[4 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 68us/step - loss: 44839.8438\n",
      "rewards:  -444.0 q-value:  0\n",
      "loss: [44839.84375]\n",
      "Exploring\n",
      "Selected action  [4 1]\n",
      "[4 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 65us/step - loss: 29029.7812\n",
      "rewards:  -444.0 q-value:  0\n",
      "loss: [29029.78125]\n",
      "Exploring\n",
      "Selected action  [0 3]\n",
      "[0 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 74us/step - loss: 24881.9062\n",
      "rewards:  -442.0 q-value:  0\n",
      "loss: [24881.90625]\n",
      "Exploring\n",
      "Selected action  [0 3]\n",
      "[0 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 72us/step - loss: 56628.1094\n",
      "rewards:  -445.0 q-value:  0\n",
      "loss: [56628.109375]\n",
      "Exploring\n",
      "Selected action  [0 3]\n",
      "[0 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 52us/step - loss: 53847.8750\n",
      "rewards:  -452.0 q-value:  0\n",
      "loss: [53847.875]\n",
      "Exploring\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 64us/step - loss: 61131.5000\n",
      "rewards:  -455.0 q-value:  0\n",
      "loss: [61131.5]\n",
      "Exploring\n",
      "Selected action  [4 1]\n",
      "[4 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 69us/step - loss: 79788.8125\n",
      "rewards:  -456.0 q-value:  0\n",
      "loss: [79788.8125]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 54us/step - loss: 49225.8125\n",
      "rewards:  -453.0 q-value:  0\n",
      "loss: [49225.8125]\n",
      "Exploring\n",
      "Selected action  [4 1]\n",
      "[4 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 91us/step - loss: 31145.1250\n",
      "rewards:  -453.0 q-value:  0\n",
      "loss: [31145.125]\n",
      "Exploring\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 63us/step - loss: 55007.2305\n",
      "rewards:  -441.0 q-value:  0\n",
      "loss: [55007.23046875]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 94us/step - loss: 51469.8438\n",
      "rewards:  -446.0 q-value:  0\n",
      "loss: [51469.84375]\n",
      "Exploring\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 63us/step - loss: 33084.8438\n",
      "rewards:  -469.0 q-value:  0\n",
      "loss: [33084.84375]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 61us/step - loss: 59148.2812\n",
      "rewards:  -524.0 q-value:  0\n",
      "loss: [59148.28125]\n",
      "Exploring\n",
      "Selected action  [0 3]\n",
      "[0 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 90us/step - loss: 27704.5312\n",
      "rewards:  -513.0 q-value:  0\n",
      "loss: [27704.53125]\n",
      "Exploring\n",
      "Selected action  [4 2]\n",
      "[4 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 63us/step - loss: 89041.4688\n",
      "rewards:  -523.0 q-value:  0\n",
      "loss: [89041.46875]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 69us/step - loss: 58793.5625\n",
      "rewards:  -568.0 q-value:  0\n",
      "loss: [58793.5625]\n",
      "Exploring\n",
      "Selected action  [4 1]\n",
      "[4 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 82us/step - loss: 61530.9375\n",
      "rewards:  -569.0 q-value:  0\n",
      "loss: [61530.9375]\n",
      "Exploiting\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 71us/step - loss: 66538.9062\n",
      "rewards:  -574.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [66538.90625]\n",
      "Exploiting\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 69us/step - loss: 56413.5273\n",
      "rewards:  -579.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [56413.52734375]\n",
      "Exploring\n",
      "Selected action  [1 2]\n",
      "[1 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 89us/step - loss: 47136.1289\n",
      "rewards:  -543.0 q-value:  0\n",
      "loss: [47136.12890625]\n",
      "Exploring\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 54us/step - loss: 62201.0078\n",
      "rewards:  -545.0 q-value:  0\n",
      "loss: [62201.0078125]\n",
      "Exploiting\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 57us/step - loss: 50809.7148\n",
      "rewards:  -547.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [50809.71484375]\n",
      "Number of actions available 5\n",
      "Episode : 10\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 65us/step - loss: 25763.9688\n",
      "rewards:  -5 q-value:  0\n",
      "loss: [25763.96875]\n",
      "Exploring\n",
      "Selected action  [2 3]\n",
      "[2 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 69us/step - loss: 57642.8750\n",
      "rewards:  -4.0 q-value:  0\n",
      "loss: [57642.875]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 57us/step - loss: 67721.0625\n",
      "rewards:  -44.0 q-value:  0\n",
      "loss: [67721.0625]\n",
      "Exploring\n",
      "Selected action  [2 3]\n",
      "[2 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 59us/step - loss: 48511.2500\n",
      "rewards:  -12.0 q-value:  0\n",
      "loss: [48511.25]\n",
      "Exploiting\n",
      "Selected action  [3 0]\n",
      "[3 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 84us/step - loss: 64773.1875\n",
      "rewards:  0.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [64773.1875]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 61us/step - loss: 35967.4375\n",
      "rewards:  -5.0 q-value:  0\n",
      "loss: [35967.4375]\n",
      "Exploring\n",
      "Selected action  [2 1]\n",
      "[2 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 51us/step - loss: 41477.4648\n",
      "rewards:  2.0 q-value:  0\n",
      "loss: [41477.46484375]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 67us/step - loss: 39642.5312\n",
      "rewards:  -3.0 q-value:  0\n",
      "loss: [39642.53125]\n",
      "Exploring\n",
      "Selected action  [2 3]\n",
      "[2 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 80us/step - loss: 89214.4453\n",
      "rewards:  -25.0 q-value:  0\n",
      "loss: [89214.4453125]\n",
      "Exploiting\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 71us/step - loss: 40123.4375\n",
      "rewards:  -30.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [40123.4375]\n",
      "Exploring\n",
      "Selected action  [2 3]\n",
      "[2 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 77us/step - loss: 23378.3125\n",
      "rewards:  -52.0 q-value:  0\n",
      "loss: [23378.3125]\n",
      "Exploring\n",
      "Selected action  [2 1]\n",
      "[2 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 73us/step - loss: 27016.1797\n",
      "rewards:  -22.0 q-value:  0\n",
      "loss: [27016.1796875]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 63us/step - loss: 47974.8125\n",
      "rewards:  -47.0 q-value:  0\n",
      "loss: [47974.8125]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 82us/step - loss: 45894.1406\n",
      "rewards:  -52.0 q-value:  0\n",
      "loss: [45894.140625]\n",
      "Exploring\n",
      "Selected action  [2 1]\n",
      "[2 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 78us/step - loss: 35713.6875\n",
      "rewards:  -62.0 q-value:  0\n",
      "loss: [35713.6875]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 79us/step - loss: 42393.3359\n",
      "rewards:  -67.0 q-value:  0\n",
      "loss: [42393.3359375]\n",
      "Exploiting\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 87us/step - loss: 58051.5625\n",
      "rewards:  -72.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [58051.5625]\n",
      "Exploring\n",
      "Selected action  [2 3]\n",
      "[2 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 59us/step - loss: 59474.2812\n",
      "rewards:  -78.0 q-value:  0\n",
      "loss: [59474.28125]\n",
      "Exploring\n",
      "Selected action  [2 1]\n",
      "[2 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 62us/step - loss: 44175.6250\n",
      "rewards:  -67.0 q-value:  0\n",
      "loss: [44175.625]\n",
      "Exploring\n",
      "Selected action  [2 1]\n",
      "[2 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 71us/step - loss: 27420.5000\n",
      "rewards:  -70.0 q-value:  0\n",
      "loss: [27420.5]\n",
      "Exploring\n",
      "Selected action  [3 0]\n",
      "[3 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 75us/step - loss: 41105.5820\n",
      "rewards:  -76.0 q-value:  0\n",
      "loss: [41105.58203125]\n",
      "Exploring\n",
      "Selected action  [3 0]\n",
      "[3 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 66us/step - loss: 40119.5312\n",
      "rewards:  -77.0 q-value:  0\n",
      "loss: [40119.53125]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 78us/step - loss: 57968.2188\n",
      "rewards:  -79.0 q-value:  0\n",
      "loss: [57968.21875]\n",
      "Exploring\n",
      "Selected action  [3 0]\n",
      "[3 0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 88us/step - loss: 81668.4141\n",
      "rewards:  -52.0 q-value:  0\n",
      "loss: [81668.4140625]\n",
      "Exploring\n",
      "Selected action  [2 1]\n",
      "[2 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 64us/step - loss: 41030.5625\n",
      "rewards:  -66.0 q-value:  0\n",
      "loss: [41030.5625]\n",
      "Exploring\n",
      "Selected action  [2 1]\n",
      "[2 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 65us/step - loss: 69807.7812\n",
      "rewards:  -67.0 q-value:  0\n",
      "loss: [69807.78125]\n",
      "Exploring\n",
      "Selected action  [2 1]\n",
      "[2 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 85us/step - loss: 69214.5000\n",
      "rewards:  -68.0 q-value:  0\n",
      "loss: [69214.5]\n",
      "Exploring\n",
      "Selected action  [2 1]\n",
      "[2 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 56us/step - loss: 36031.5625\n",
      "rewards:  -69.0 q-value:  0\n",
      "loss: [36031.5625]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 71us/step - loss: 61734.7812\n",
      "rewards:  -74.0 q-value:  0\n",
      "loss: [61734.78125]\n",
      "Exploring\n",
      "Selected action  [2 3]\n",
      "[2 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 64us/step - loss: 56243.1602\n",
      "rewards:  -63.0 q-value:  0\n",
      "loss: [56243.16015625]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 79us/step - loss: 45377.9688\n",
      "rewards:  -68.0 q-value:  0\n",
      "loss: [45377.96875]\n",
      "Exploring\n",
      "Selected action  [2 3]\n",
      "[2 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 55us/step - loss: 62530.4062\n",
      "rewards:  -92.0 q-value:  0\n",
      "loss: [62530.40625]\n",
      "Exploring\n",
      "Selected action  [3 0]\n",
      "[3 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 67us/step - loss: 38200.8047\n",
      "rewards:  -84.0 q-value:  0\n",
      "loss: [38200.8046875]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 52us/step - loss: 57712.4766\n",
      "rewards:  -91.0 q-value:  0\n",
      "loss: [57712.4765625]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 54us/step - loss: 60409.7812\n",
      "rewards:  -96.0 q-value:  0\n",
      "loss: [60409.78125]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 70us/step - loss: 46284.8750\n",
      "rewards:  -103.0 q-value:  0\n",
      "loss: [46284.875]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 49us/step - loss: 28333.7500\n",
      "rewards:  -108.0 q-value:  0\n",
      "loss: [28333.75]\n",
      "Exploring\n",
      "Selected action  [3 0]\n",
      "[3 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 66us/step - loss: 37972.0000\n",
      "rewards:  -113.0 q-value:  0\n",
      "loss: [37972.0]\n",
      "Exploring\n",
      "Selected action  [3 0]\n",
      "[3 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 62us/step - loss: 33577.0312\n",
      "rewards:  -119.0 q-value:  0\n",
      "loss: [33577.03125]\n",
      "Exploring\n",
      "Selected action  [3 0]\n",
      "[3 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 61us/step - loss: 46955.6406\n",
      "rewards:  -124.0 q-value:  0\n",
      "loss: [46955.640625]\n",
      "Exploring\n",
      "Selected action  [3 0]\n",
      "[3 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 76us/step - loss: 64304.8750\n",
      "rewards:  -127.0 q-value:  0\n",
      "loss: [64304.875]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 57us/step - loss: 56398.2500\n",
      "rewards:  -132.0 q-value:  0\n",
      "loss: [56398.25]\n",
      "Exploiting\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 82us/step - loss: 24557.4062\n",
      "rewards:  -143.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [24557.40625]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 58us/step - loss: 50081.3125\n",
      "rewards:  -148.0 q-value:  0\n",
      "loss: [50081.3125]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 100us/step - loss: 63752.6875\n",
      "rewards:  -153.0 q-value:  0\n",
      "loss: [63752.6875]\n",
      "Exploiting\n",
      "Selected action  [2 1]\n",
      "[2 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 63us/step - loss: 31489.2539\n",
      "rewards:  -140.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [31489.25390625]\n",
      "Exploring\n",
      "Selected action  [2 1]\n",
      "[2 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 67us/step - loss: 44748.2812\n",
      "rewards:  -147.0 q-value:  0\n",
      "loss: [44748.28125]\n",
      "Exploring\n",
      "Selected action  [2 1]\n",
      "[2 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 63us/step - loss: 53937.7500\n",
      "rewards:  -148.0 q-value:  0\n",
      "loss: [53937.75]\n",
      "Exploring\n",
      "Selected action  [3 0]\n",
      "[3 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 73us/step - loss: 64291.6875\n",
      "rewards:  -141.0 q-value:  0\n",
      "loss: [64291.6875]\n",
      "Exploring\n",
      "Selected action  [2 1]\n",
      "[2 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 66us/step - loss: 56217.7500\n",
      "rewards:  -121.0 q-value:  0\n",
      "loss: [56217.75]\n",
      "Exploring\n",
      "Selected action  [3 0]\n",
      "[3 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 72us/step - loss: 49222.5000\n",
      "rewards:  -125.0 q-value:  0\n",
      "loss: [49222.5]\n",
      "Exploring\n",
      "Selected action  [3 0]\n",
      "[3 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 69us/step - loss: 42626.8750\n",
      "rewards:  -131.0 q-value:  0\n",
      "loss: [42626.875]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 67us/step - loss: 47159.6562\n",
      "rewards:  -151.0 q-value:  0\n",
      "loss: [47159.65625]\n",
      "Exploring\n",
      "Selected action  [2 1]\n",
      "[2 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 66us/step - loss: 63566.5938\n",
      "rewards:  -143.0 q-value:  0\n",
      "loss: [63566.59375]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 76us/step - loss: 11100.8457\n",
      "rewards:  -153.0 q-value:  0\n",
      "loss: [11100.845703125]\n",
      "Exploring\n",
      "Selected action  [2 1]\n",
      "[2 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 63us/step - loss: 59311.9688\n",
      "rewards:  -145.0 q-value:  0\n",
      "loss: [59311.96875]\n",
      "Exploring\n",
      "Selected action  [2 3]\n",
      "[2 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 74us/step - loss: 68152.4062\n",
      "rewards:  -155.0 q-value:  0\n",
      "loss: [68152.40625]\n",
      "Exploring\n",
      "Selected action  [2 1]\n",
      "[2 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 53us/step - loss: 44518.9375\n",
      "rewards:  -172.0 q-value:  0\n",
      "loss: [44518.9375]\n",
      "Exploring\n",
      "Selected action  [2 1]\n",
      "[2 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 65us/step - loss: 74473.7969\n",
      "rewards:  -176.0 q-value:  0\n",
      "loss: [74473.796875]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 71us/step - loss: 36279.9375\n",
      "rewards:  -181.0 q-value:  0\n",
      "loss: [36279.9375]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 73us/step - loss: 56911.2500\n",
      "rewards:  -186.0 q-value:  0\n",
      "loss: [56911.25]\n",
      "Exploring\n",
      "Selected action  [2 3]\n",
      "[2 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 54us/step - loss: 61740.4141\n",
      "rewards:  -192.0 q-value:  0\n",
      "loss: [61740.4140625]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 78us/step - loss: 36249.2891\n",
      "rewards:  -232.0 q-value:  0\n",
      "loss: [36249.2890625]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 101us/step - loss: 36884.0938\n",
      "rewards:  -237.0 q-value:  0\n",
      "loss: [36884.09375]\n",
      "Exploring\n",
      "Selected action  [3 0]\n",
      "[3 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 74us/step - loss: 45856.1484\n",
      "rewards:  -237.0 q-value:  0\n",
      "loss: [45856.1484375]\n",
      "Exploiting\n",
      "Selected action  [2 1]\n",
      "[2 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 98us/step - loss: 50774.7812\n",
      "rewards:  -244.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [50774.78125]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 79us/step - loss: 66315.5312\n",
      "rewards:  -276.0 q-value:  0\n",
      "loss: [66315.53125]\n",
      "Exploring\n",
      "Selected action  [2 1]\n",
      "[2 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 104us/step - loss: 61707.3438\n",
      "rewards:  -254.0 q-value:  0\n",
      "loss: [61707.34375]\n",
      "Exploring\n",
      "Selected action  [2 1]\n",
      "[2 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 79us/step - loss: 64597.3750\n",
      "rewards:  -259.0 q-value:  0\n",
      "loss: [64597.375]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 74us/step - loss: 45321.9062\n",
      "rewards:  -264.0 q-value:  0\n",
      "loss: [45321.90625]\n",
      "Exploring\n",
      "Selected action  [2 3]\n",
      "[2 3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 60us/step - loss: 34010.2500\n",
      "rewards:  -286.0 q-value:  0\n",
      "loss: [34010.25]\n",
      "Exploiting\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 62us/step - loss: 43600.9688\n",
      "rewards:  -291.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [43600.96875]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 75us/step - loss: 66026.0938\n",
      "rewards:  -296.0 q-value:  0\n",
      "loss: [66026.09375]\n",
      "Exploring\n",
      "Selected action  [3 0]\n",
      "[3 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 56us/step - loss: 46807.3438\n",
      "rewards:  -298.0 q-value:  0\n",
      "loss: [46807.34375]\n",
      "Exploring\n",
      "Selected action  [2 3]\n",
      "[2 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 71us/step - loss: 50074.4062\n",
      "rewards:  -272.0 q-value:  0\n",
      "loss: [50074.40625]\n",
      "Exploiting\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 66us/step - loss: 68422.5078\n",
      "rewards:  -287.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [68422.5078125]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 71us/step - loss: 72363.1641\n",
      "rewards:  -292.0 q-value:  0\n",
      "loss: [72363.1640625]\n",
      "Exploring\n",
      "Selected action  [3 0]\n",
      "[3 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 51us/step - loss: 65159.4062\n",
      "rewards:  -292.0 q-value:  0\n",
      "loss: [65159.40625]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 66us/step - loss: 87063.6406\n",
      "rewards:  -297.0 q-value:  0\n",
      "loss: [87063.640625]\n",
      "Exploring\n",
      "Selected action  [3 0]\n",
      "[3 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 59us/step - loss: 26996.5625\n",
      "rewards:  -297.0 q-value:  0\n",
      "loss: [26996.5625]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 72us/step - loss: 85207.6562\n",
      "rewards:  -302.0 q-value:  0\n",
      "loss: [85207.65625]\n",
      "Exploring\n",
      "Selected action  [2 1]\n",
      "[2 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 60us/step - loss: 31186.7188\n",
      "rewards:  -312.0 q-value:  0\n",
      "loss: [31186.71875]\n",
      "Exploring\n",
      "Selected action  [2 3]\n",
      "[2 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 53us/step - loss: 21469.9688\n",
      "rewards:  -318.0 q-value:  0\n",
      "loss: [21469.96875]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 58us/step - loss: 58724.4062\n",
      "rewards:  -323.0 q-value:  0\n",
      "loss: [58724.40625]\n",
      "Exploring\n",
      "Selected action  [2 1]\n",
      "[2 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 73us/step - loss: 44503.0312\n",
      "rewards:  -317.0 q-value:  0\n",
      "loss: [44503.03125]\n",
      "Exploring\n",
      "Selected action  [2 3]\n",
      "[2 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 56us/step - loss: 32526.1250\n",
      "rewards:  -356.0 q-value:  0\n",
      "loss: [32526.125]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 54us/step - loss: 32596.0645\n",
      "rewards:  -368.0 q-value:  0\n",
      "loss: [32596.064453125]\n",
      "Exploring\n",
      "Selected action  [2 1]\n",
      "[2 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 67us/step - loss: 34490.2500\n",
      "rewards:  -353.0 q-value:  0\n",
      "loss: [34490.25]\n",
      "Exploiting\n",
      "Selected action  [2 1]\n",
      "[2 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 56us/step - loss: 46552.6250\n",
      "rewards:  -357.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [46552.625]\n",
      "Exploring\n",
      "Selected action  [2 1]\n",
      "[2 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 54us/step - loss: 45426.5742\n",
      "rewards:  -361.0 q-value:  0\n",
      "loss: [45426.57421875]\n",
      "Exploring\n",
      "Selected action  [2 3]\n",
      "[2 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 54us/step - loss: 26507.4688\n",
      "rewards:  -350.0 q-value:  0\n",
      "loss: [26507.46875]\n",
      "Exploring\n",
      "Selected action  [2 3]\n",
      "[2 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 62us/step - loss: 69844.1250\n",
      "rewards:  -354.0 q-value:  0\n",
      "loss: [69844.125]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 58us/step - loss: 66190.4062\n",
      "rewards:  -359.0 q-value:  0\n",
      "loss: [66190.40625]\n",
      "Exploring\n",
      "Selected action  [3 0]\n",
      "[3 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 61us/step - loss: 45930.6875\n",
      "rewards:  -361.0 q-value:  0\n",
      "loss: [45930.6875]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 69us/step - loss: 60834.6836\n",
      "rewards:  -366.0 q-value:  0\n",
      "loss: [60834.68359375]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 74us/step - loss: 52347.9062\n",
      "rewards:  -373.0 q-value:  0\n",
      "loss: [52347.90625]\n",
      "Exploring\n",
      "Selected action  [2 1]\n",
      "[2 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 67us/step - loss: 39293.7773\n",
      "rewards:  -355.0 q-value:  0\n",
      "loss: [39293.77734375]\n",
      "Exploring\n",
      "Selected action  [2 1]\n",
      "[2 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 79us/step - loss: 39664.2812\n",
      "rewards:  -365.0 q-value:  0\n",
      "loss: [39664.28125]\n",
      "Exploiting\n",
      "Selected action  [2 3]\n",
      "[2 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 65us/step - loss: 44930.4375\n",
      "rewards:  -405.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [44930.4375]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 64us/step - loss: 51654.1016\n",
      "rewards:  -410.0 q-value:  0\n",
      "loss: [51654.1015625]\n",
      "Exploring\n",
      "Selected action  [3 0]\n",
      "[3 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 68us/step - loss: 61743.2812\n",
      "rewards:  -413.0 q-value:  0\n",
      "loss: [61743.28125]\n",
      "Exploring\n",
      "Selected action  [2 1]\n",
      "[2 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 65us/step - loss: 54467.4688\n",
      "rewards:  -406.0 q-value:  0\n",
      "loss: [54467.46875]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 85us/step - loss: 55004.6562\n",
      "rewards:  -411.0 q-value:  0\n",
      "loss: [55004.65625]\n",
      "Exploring\n",
      "Selected action  [2 3]\n",
      "[2 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 65us/step - loss: 38301.5938\n",
      "rewards:  -424.0 q-value:  0\n",
      "loss: [38301.59375]\n",
      "Exploring\n",
      "Selected action  [2 1]\n",
      "[2 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 54us/step - loss: 44178.6875\n",
      "rewards:  -411.0 q-value:  0\n",
      "loss: [44178.6875]\n",
      "Exploring\n",
      "Selected action  [2 3]\n",
      "[2 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 71us/step - loss: 43288.4688\n",
      "rewards:  -384.0 q-value:  0\n",
      "loss: [43288.46875]\n",
      "Exploring\n",
      "Selected action  [3 0]\n",
      "[3 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 74us/step - loss: 61578.0312\n",
      "rewards:  -368.0 q-value:  0\n",
      "loss: [61578.03125]\n",
      "Exploring\n",
      "Selected action  [3 0]\n",
      "[3 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 81us/step - loss: 36360.5312\n",
      "rewards:  -372.0 q-value:  0\n",
      "loss: [36360.53125]\n",
      "Exploring\n",
      "Selected action  [2 1]\n",
      "[2 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 80us/step - loss: 49438.7500\n",
      "rewards:  -363.0 q-value:  0\n",
      "loss: [49438.75]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 65us/step - loss: 79145.8125\n",
      "rewards:  -393.0 q-value:  0\n",
      "loss: [79145.8125]\n",
      "Exploring\n",
      "Selected action  [2 1]\n",
      "[2 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 77us/step - loss: 33856.7500\n",
      "rewards:  -369.0 q-value:  0\n",
      "loss: [33856.75]\n",
      "Number of actions available 3\n",
      "Episode : 11\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 77us/step - loss: 34866.6875\n",
      "rewards:  -25.0 q-value:  0\n",
      "loss: [34866.6875]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 67us/step - loss: 53820.2500\n",
      "rewards:  -30.0 q-value:  0\n",
      "loss: [53820.25]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 64us/step - loss: 74244.1094\n",
      "rewards:  -35.0 q-value:  0\n",
      "loss: [74244.109375]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 56us/step - loss: 66186.7188\n",
      "rewards:  -40.0 q-value:  0\n",
      "loss: [66186.71875]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 62us/step - loss: 30273.5938\n",
      "rewards:  -46.0 q-value:  0\n",
      "loss: [30273.59375]\n",
      "Exploiting\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 107us/step - loss: 25497.8750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rewards:  -61.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [25497.875]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 78us/step - loss: 32532.3125\n",
      "rewards:  -63.0 q-value:  0\n",
      "loss: [32532.3125]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 58us/step - loss: 38439.9688\n",
      "rewards:  -78.0 q-value:  0\n",
      "loss: [38439.96875]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 64us/step - loss: 29593.8438\n",
      "rewards:  -80.0 q-value:  0\n",
      "loss: [29593.84375]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 77us/step - loss: 57392.8945\n",
      "rewards:  -82.0 q-value:  0\n",
      "loss: [57392.89453125]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 78us/step - loss: 74793.6562\n",
      "rewards:  -99.0 q-value:  0\n",
      "loss: [74793.65625]\n",
      "Exploiting\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 67us/step - loss: 66122.2812\n",
      "rewards:  -104.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [66122.28125]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 72us/step - loss: 74551.5000\n",
      "rewards:  -106.0 q-value:  0\n",
      "loss: [74551.5]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 59us/step - loss: 42104.8750\n",
      "rewards:  -108.0 q-value:  0\n",
      "loss: [42104.875]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 57us/step - loss: 43659.5938\n",
      "rewards:  -113.0 q-value:  0\n",
      "loss: [43659.59375]\n",
      "Exploiting\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 68us/step - loss: 47442.7617\n",
      "rewards:  -118.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [47442.76171875]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 79us/step - loss: 39965.6953\n",
      "rewards:  -120.0 q-value:  0\n",
      "loss: [39965.6953125]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 70us/step - loss: 54921.4688\n",
      "rewards:  -122.0 q-value:  0\n",
      "loss: [54921.46875]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 76us/step - loss: 25812.8750\n",
      "rewards:  -131.0 q-value:  0\n",
      "loss: [25812.875]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 60us/step - loss: 73440.2188\n",
      "rewards:  -135.0 q-value:  0\n",
      "loss: [73440.21875]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 86us/step - loss: 32056.3262\n",
      "rewards:  -137.0 q-value:  0\n",
      "loss: [32056.326171875]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 64us/step - loss: 48351.1562\n",
      "rewards:  -142.0 q-value:  0\n",
      "loss: [48351.15625]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 83us/step - loss: 36747.5000\n",
      "rewards:  -147.0 q-value:  0\n",
      "loss: [36747.5]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 63us/step - loss: 67770.4609\n",
      "rewards:  -152.0 q-value:  0\n",
      "loss: [67770.4609375]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 56us/step - loss: 60510.3438\n",
      "rewards:  -182.0 q-value:  0\n",
      "loss: [60510.34375]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 62us/step - loss: 36177.5938\n",
      "rewards:  -187.0 q-value:  0\n",
      "loss: [36177.59375]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 74us/step - loss: 44370.4922\n",
      "rewards:  -192.0 q-value:  0\n",
      "loss: [44370.4921875]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 68us/step - loss: 36725.7500\n",
      "rewards:  -194.0 q-value:  0\n",
      "loss: [36725.75]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 77us/step - loss: 45775.2188\n",
      "rewards:  -224.0 q-value:  0\n",
      "loss: [45775.21875]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 74us/step - loss: 57509.2109\n",
      "rewards:  -224.0 q-value:  0\n",
      "loss: [57509.2109375]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 55us/step - loss: 72826.2500\n",
      "rewards:  -224.0 q-value:  0\n",
      "loss: [72826.25]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 97us/step - loss: 40691.3438\n",
      "rewards:  -236.0 q-value:  0\n",
      "loss: [40691.34375]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 62us/step - loss: 49415.0625\n",
      "rewards:  -266.0 q-value:  0\n",
      "loss: [49415.0625]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 67us/step - loss: 69101.0391\n",
      "rewards:  -259.0 q-value:  0\n",
      "loss: [69101.0390625]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 56us/step - loss: 48524.9688\n",
      "rewards:  -264.0 q-value:  0\n",
      "loss: [48524.96875]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 80us/step - loss: 42751.3750\n",
      "rewards:  -269.0 q-value:  0\n",
      "loss: [42751.375]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 55us/step - loss: 53987.6250\n",
      "rewards:  -272.0 q-value:  0\n",
      "loss: [53987.625]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 102us/step - loss: 28399.9375\n",
      "rewards:  -279.0 q-value:  0\n",
      "loss: [28399.9375]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 51us/step - loss: 54161.7812\n",
      "rewards:  -290.0 q-value:  0\n",
      "loss: [54161.78125]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 57us/step - loss: 41159.6562\n",
      "rewards:  -262.0 q-value:  0\n",
      "loss: [41159.65625]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 77us/step - loss: 59797.9648\n",
      "rewards:  -265.0 q-value:  0\n",
      "loss: [59797.96484375]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 78us/step - loss: 70852.8750\n",
      "rewards:  -270.0 q-value:  0\n",
      "loss: [70852.875]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 81us/step - loss: 57569.8125\n",
      "rewards:  -275.0 q-value:  0\n",
      "loss: [57569.8125]\n",
      "Exploiting\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 55us/step - loss: 36326.5000\n",
      "rewards:  -280.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [36326.5]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 64us/step - loss: 52296.0938\n",
      "rewards:  -285.0 q-value:  0\n",
      "loss: [52296.09375]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 60us/step - loss: 20429.7578\n",
      "rewards:  -290.0 q-value:  0\n",
      "loss: [20429.7578125]\n",
      "Exploiting\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 50us/step - loss: 44355.5352\n",
      "rewards:  -293.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [44355.53515625]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 75us/step - loss: 39149.4688\n",
      "rewards:  -298.0 q-value:  0\n",
      "loss: [39149.46875]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 59us/step - loss: 59970.3438\n",
      "rewards:  -301.0 q-value:  0\n",
      "loss: [59970.34375]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 66us/step - loss: 65462.2812\n",
      "rewards:  -310.0 q-value:  0\n",
      "loss: [65462.28125]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 83us/step - loss: 84505.6875\n",
      "rewards:  -316.0 q-value:  0\n",
      "loss: [84505.6875]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 62us/step - loss: 47282.1250\n",
      "rewards:  -322.0 q-value:  0\n",
      "loss: [47282.125]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 60us/step - loss: 45088.6562\n",
      "rewards:  -329.0 q-value:  0\n",
      "loss: [45088.65625]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 57us/step - loss: 20680.9688\n",
      "rewards:  -334.0 q-value:  0\n",
      "loss: [20680.96875]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 67us/step - loss: 53262.2227\n",
      "rewards:  -339.0 q-value:  0\n",
      "loss: [53262.22265625]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 78us/step - loss: 55483.7500\n",
      "rewards:  -344.0 q-value:  0\n",
      "loss: [55483.75]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 59us/step - loss: 55726.9570\n",
      "rewards:  -349.0 q-value:  0\n",
      "loss: [55726.95703125]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 69us/step - loss: 55547.1523\n",
      "rewards:  -359.0 q-value:  0\n",
      "loss: [55547.15234375]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 59us/step - loss: 41938.9062\n",
      "rewards:  -361.0 q-value:  0\n",
      "loss: [41938.90625]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 58us/step - loss: 29912.4375\n",
      "rewards:  -386.0 q-value:  0\n",
      "loss: [29912.4375]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 62us/step - loss: 40103.4688\n",
      "rewards:  -391.0 q-value:  0\n",
      "loss: [40103.46875]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 65us/step - loss: 60629.5938\n",
      "rewards:  -393.0 q-value:  0\n",
      "loss: [60629.59375]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 60us/step - loss: 81171.8750\n",
      "rewards:  -398.0 q-value:  0\n",
      "loss: [81171.875]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 70us/step - loss: 70011.5938\n",
      "rewards:  -403.0 q-value:  0\n",
      "loss: [70011.59375]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 68us/step - loss: 47682.0938\n",
      "rewards:  -408.0 q-value:  0\n",
      "loss: [47682.09375]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 59us/step - loss: 61320.1562\n",
      "rewards:  -433.0 q-value:  0\n",
      "loss: [61320.15625]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 49us/step - loss: 77573.4688\n",
      "rewards:  -438.0 q-value:  0\n",
      "loss: [77573.46875]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 64us/step - loss: 32912.0312\n",
      "rewards:  -463.0 q-value:  0\n",
      "loss: [32912.03125]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 65us/step - loss: 24682.5312\n",
      "rewards:  -463.0 q-value:  0\n",
      "loss: [24682.53125]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 81us/step - loss: 44533.8359\n",
      "rewards:  -455.0 q-value:  0\n",
      "loss: [44533.8359375]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 74us/step - loss: 59960.2188\n",
      "rewards:  -480.0 q-value:  0\n",
      "loss: [59960.21875]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 60us/step - loss: 30014.4062\n",
      "rewards:  -472.0 q-value:  0\n",
      "loss: [30014.40625]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 73us/step - loss: 54458.9062\n",
      "rewards:  -477.0 q-value:  0\n",
      "loss: [54458.90625]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 59us/step - loss: 53202.2500\n",
      "rewards:  -484.0 q-value:  0\n",
      "loss: [53202.25]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 74us/step - loss: 49097.1875\n",
      "rewards:  -489.0 q-value:  0\n",
      "loss: [49097.1875]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 77us/step - loss: 71110.4375\n",
      "rewards:  -497.0 q-value:  0\n",
      "loss: [71110.4375]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 63us/step - loss: 76371.1875\n",
      "rewards:  -502.0 q-value:  0\n",
      "loss: [76371.1875]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 64us/step - loss: 65004.0781\n",
      "rewards:  -509.0 q-value:  0\n",
      "loss: [65004.078125]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 81us/step - loss: 22790.3750\n",
      "rewards:  -514.0 q-value:  0\n",
      "loss: [22790.375]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 74us/step - loss: 68122.5625\n",
      "rewards:  -519.0 q-value:  0\n",
      "loss: [68122.5625]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 67us/step - loss: 57569.9219\n",
      "rewards:  -522.0 q-value:  0\n",
      "loss: [57569.921875]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 69us/step - loss: 44168.0000\n",
      "rewards:  -529.0 q-value:  0\n",
      "loss: [44168.0]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 65us/step - loss: 55950.7500\n",
      "rewards:  -529.0 q-value:  0\n",
      "loss: [55950.75]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 63us/step - loss: 63343.6562\n",
      "rewards:  -529.0 q-value:  0\n",
      "loss: [63343.65625]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 81us/step - loss: 49313.3750\n",
      "rewards:  -564.0 q-value:  0\n",
      "loss: [49313.375]\n",
      "Exploiting\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 77us/step - loss: 39456.4062\n",
      "rewards:  -569.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [39456.40625]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 60us/step - loss: 39001.7812\n",
      "rewards:  -604.0 q-value:  0\n",
      "loss: [39001.78125]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 71us/step - loss: 61772.9062\n",
      "rewards:  -604.0 q-value:  0\n",
      "loss: [61772.90625]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 85us/step - loss: 34165.2500\n",
      "rewards:  -609.0 q-value:  0\n",
      "loss: [34165.25]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 80us/step - loss: 37912.6328\n",
      "rewards:  -644.0 q-value:  0\n",
      "loss: [37912.6328125]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 58us/step - loss: 37255.5625\n",
      "rewards:  -644.0 q-value:  0\n",
      "loss: [37255.5625]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 72us/step - loss: 57715.3750\n",
      "rewards:  -644.0 q-value:  0\n",
      "loss: [57715.375]\n",
      "Exploiting\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 56us/step - loss: 61497.0000\n",
      "rewards:  -649.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [61497.0]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 66us/step - loss: 52081.9062\n",
      "rewards:  -649.0 q-value:  0\n",
      "loss: [52081.90625]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 60us/step - loss: 46615.4062\n",
      "rewards:  -649.0 q-value:  0\n",
      "loss: [46615.40625]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 71us/step - loss: 46169.9688\n",
      "rewards:  -654.0 q-value:  0\n",
      "loss: [46169.96875]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 89us/step - loss: 65556.6875\n",
      "rewards:  -659.0 q-value:  0\n",
      "loss: [65556.6875]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 62us/step - loss: 95519.5938\n",
      "rewards:  -659.0 q-value:  0\n",
      "loss: [95519.59375]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 53us/step - loss: 65386.9062\n",
      "rewards:  -694.0 q-value:  0\n",
      "loss: [65386.90625]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 68us/step - loss: 55453.6250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rewards:  -694.0 q-value:  0\n",
      "loss: [55453.625]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 60us/step - loss: 62535.3750\n",
      "rewards:  -694.0 q-value:  0\n",
      "loss: [62535.375]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 75us/step - loss: 48720.0938\n",
      "rewards:  -699.0 q-value:  0\n",
      "loss: [48720.09375]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 67us/step - loss: 53911.4375\n",
      "rewards:  -704.0 q-value:  0\n",
      "loss: [53911.4375]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 54us/step - loss: 61030.6250\n",
      "rewards:  -709.0 q-value:  0\n",
      "loss: [61030.625]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 64us/step - loss: 59601.7539\n",
      "rewards:  -714.0 q-value:  0\n",
      "loss: [59601.75390625]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 76us/step - loss: 47480.8750\n",
      "rewards:  -719.0 q-value:  0\n",
      "loss: [47480.875]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 59us/step - loss: 43411.6562\n",
      "rewards:  -724.0 q-value:  0\n",
      "loss: [43411.65625]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 104us/step - loss: 67497.1250\n",
      "rewards:  -724.0 q-value:  0\n",
      "loss: [67497.125]\n",
      "Exploiting\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 69us/step - loss: 82038.0000\n",
      "rewards:  -759.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [82038.0]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 70us/step - loss: 71730.5938\n",
      "rewards:  -764.0 q-value:  0\n",
      "loss: [71730.59375]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 62us/step - loss: 56850.1875\n",
      "rewards:  -764.0 q-value:  0\n",
      "loss: [56850.1875]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 58us/step - loss: 72502.4062\n",
      "rewards:  -799.0 q-value:  0\n",
      "loss: [72502.40625]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 66us/step - loss: 49021.9688\n",
      "rewards:  -804.0 q-value:  0\n",
      "loss: [49021.96875]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 71us/step - loss: 43869.1875\n",
      "rewards:  -804.0 q-value:  0\n",
      "loss: [43869.1875]\n",
      "Exploiting\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 73us/step - loss: 46851.4688\n",
      "rewards:  -809.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [46851.46875]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 55us/step - loss: 25433.1094\n",
      "rewards:  -809.0 q-value:  0\n",
      "loss: [25433.109375]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 67us/step - loss: 70789.7188\n",
      "rewards:  -814.0 q-value:  0\n",
      "loss: [70789.71875]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 55us/step - loss: 79308.8828\n",
      "rewards:  -849.0 q-value:  0\n",
      "loss: [79308.8828125]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 62us/step - loss: 80452.1562\n",
      "rewards:  -854.0 q-value:  0\n",
      "loss: [80452.15625]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 67us/step - loss: 53399.2500\n",
      "rewards:  -854.0 q-value:  0\n",
      "loss: [53399.25]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 86us/step - loss: 58743.8438\n",
      "rewards:  -859.0 q-value:  0\n",
      "loss: [58743.84375]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 75us/step - loss: 44082.3906\n",
      "rewards:  -859.0 q-value:  0\n",
      "loss: [44082.390625]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 58us/step - loss: 80891.5625\n",
      "rewards:  -859.0 q-value:  0\n",
      "loss: [80891.5625]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 60us/step - loss: 109597.3750\n",
      "rewards:  -859.0 q-value:  0\n",
      "loss: [109597.375]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 56us/step - loss: 79595.9375\n",
      "rewards:  -894.0 q-value:  0\n",
      "loss: [79595.9375]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 73us/step - loss: 110519.9375\n",
      "rewards:  -894.0 q-value:  0\n",
      "loss: [110519.9375]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 73us/step - loss: 88568.7188\n",
      "rewards:  -899.0 q-value:  0\n",
      "loss: [88568.71875]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 78us/step - loss: 40992.1562\n",
      "rewards:  -934.0 q-value:  0\n",
      "loss: [40992.15625]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 72us/step - loss: 103232.0938\n",
      "rewards:  -939.0 q-value:  0\n",
      "loss: [103232.09375]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 76us/step - loss: 35093.5625\n",
      "rewards:  -974.0 q-value:  0\n",
      "loss: [35093.5625]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 60us/step - loss: 141999.3438\n",
      "rewards:  -974.0 q-value:  0\n",
      "loss: [141999.34375]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 65us/step - loss: 55335.9375\n",
      "rewards:  -974.0 q-value:  0\n",
      "loss: [55335.9375]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 71us/step - loss: 48566.9375\n",
      "rewards:  -974.0 q-value:  0\n",
      "loss: [48566.9375]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 67us/step - loss: 48285.8438\n",
      "rewards:  -979.0 q-value:  0\n",
      "loss: [48285.84375]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 55us/step - loss: 87389.8438\n",
      "rewards:  -979.0 q-value:  0\n",
      "loss: [87389.84375]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 64us/step - loss: 51648.6250\n",
      "rewards:  -984.0 q-value:  0\n",
      "loss: [51648.625]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 67us/step - loss: 89628.3438\n",
      "rewards:  -984.0 q-value:  0\n",
      "loss: [89628.34375]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 77us/step - loss: 75370.3125\n",
      "rewards:  -989.0 q-value:  0\n",
      "loss: [75370.3125]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 59us/step - loss: 77912.5312\n",
      "rewards:  -989.0 q-value:  0\n",
      "loss: [77912.53125]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 70us/step - loss: 69805.1250\n",
      "rewards:  -994.0 q-value:  0\n",
      "loss: [69805.125]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 68us/step - loss: 76398.8750\n",
      "rewards:  -994.0 q-value:  0\n",
      "loss: [76398.875]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 61us/step - loss: 94633.3438\n",
      "rewards:  -1029.0 q-value:  0\n",
      "loss: [94633.34375]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 78us/step - loss: 77225.2812\n",
      "rewards:  -1029.0 q-value:  0\n",
      "loss: [77225.28125]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 83us/step - loss: 43905.6875\n",
      "rewards:  -1029.0 q-value:  0\n",
      "loss: [43905.6875]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 66us/step - loss: 90629.1250\n",
      "rewards:  -1029.0 q-value:  0\n",
      "loss: [90629.125]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 60us/step - loss: 89946.4688\n",
      "rewards:  -1034.0 q-value:  0\n",
      "loss: [89946.46875]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 88us/step - loss: 96805.9375\n",
      "rewards:  -1034.0 q-value:  0\n",
      "loss: [96805.9375]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 57us/step - loss: 75209.4375\n",
      "rewards:  -1039.0 q-value:  0\n",
      "loss: [75209.4375]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 55us/step - loss: 87794.1250\n",
      "rewards:  -1044.0 q-value:  0\n",
      "loss: [87794.125]\n",
      "Exploiting\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 65us/step - loss: 43995.3750\n",
      "rewards:  -1049.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [43995.375]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 57us/step - loss: 92659.7500\n",
      "rewards:  -1054.0 q-value:  0\n",
      "loss: [92659.75]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 53us/step - loss: 60227.0312\n",
      "rewards:  -1059.0 q-value:  0\n",
      "loss: [60227.03125]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 71us/step - loss: 72383.1250\n",
      "rewards:  -1064.0 q-value:  0\n",
      "loss: [72383.125]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 69us/step - loss: 63232.1250\n",
      "rewards:  -1069.0 q-value:  0\n",
      "loss: [63232.125]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 79us/step - loss: 49516.8750\n",
      "rewards:  -1074.0 q-value:  0\n",
      "loss: [49516.875]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 70us/step - loss: 71294.9062\n",
      "rewards:  -1109.0 q-value:  0\n",
      "loss: [71294.90625]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 80us/step - loss: 92937.7500\n",
      "rewards:  -1109.0 q-value:  0\n",
      "loss: [92937.75]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 59us/step - loss: 108229.7812\n",
      "rewards:  -1109.0 q-value:  0\n",
      "loss: [108229.78125]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 74us/step - loss: 99259.2812\n",
      "rewards:  -1114.0 q-value:  0\n",
      "loss: [99259.28125]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 68us/step - loss: 89036.3125\n",
      "rewards:  -1149.0 q-value:  0\n",
      "loss: [89036.3125]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 69us/step - loss: 107986.4375\n",
      "rewards:  -1154.0 q-value:  0\n",
      "loss: [107986.4375]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 70us/step - loss: 127584.6250\n",
      "rewards:  -1159.0 q-value:  0\n",
      "loss: [127584.625]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 54us/step - loss: 71730.6250\n",
      "rewards:  -1159.0 q-value:  0\n",
      "loss: [71730.625]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 54us/step - loss: 101606.0625\n",
      "rewards:  -1164.0 q-value:  0\n",
      "loss: [101606.0625]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 57us/step - loss: 56432.5312\n",
      "rewards:  -1169.0 q-value:  0\n",
      "loss: [56432.53125]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 60us/step - loss: 130119.5625\n",
      "rewards:  -1169.0 q-value:  0\n",
      "loss: [130119.5625]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 64us/step - loss: 190498.3125\n",
      "rewards:  -1174.0 q-value:  0\n",
      "loss: [190498.3125]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 74us/step - loss: 31530.8750\n",
      "rewards:  -1179.0 q-value:  0\n",
      "loss: [31530.875]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 67us/step - loss: 75364.5312\n",
      "rewards:  -1179.0 q-value:  0\n",
      "loss: [75364.53125]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 77us/step - loss: 79128.5000\n",
      "rewards:  -1179.0 q-value:  0\n",
      "loss: [79128.5]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 60us/step - loss: 55223.8438\n",
      "rewards:  -1184.0 q-value:  0\n",
      "loss: [55223.84375]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 106us/step - loss: 76794.4375\n",
      "rewards:  -1219.0 q-value:  0\n",
      "loss: [76794.4375]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 69us/step - loss: 103502.8125\n",
      "rewards:  -1219.0 q-value:  0\n",
      "loss: [103502.8125]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 67us/step - loss: 80781.3047\n",
      "rewards:  -1224.0 q-value:  0\n",
      "loss: [80781.3046875]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 84us/step - loss: 88224.3438\n",
      "rewards:  -1224.0 q-value:  0\n",
      "loss: [88224.34375]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 65us/step - loss: 61720.3438\n",
      "rewards:  -1229.0 q-value:  0\n",
      "loss: [61720.34375]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 69us/step - loss: 84915.2812\n",
      "rewards:  -1264.0 q-value:  0\n",
      "loss: [84915.28125]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 79us/step - loss: 73899.0938\n",
      "rewards:  -1269.0 q-value:  0\n",
      "loss: [73899.09375]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 47us/step - loss: 127809.7500\n",
      "rewards:  -1274.0 q-value:  0\n",
      "loss: [127809.75]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 60us/step - loss: 83808.2188\n",
      "rewards:  -1279.0 q-value:  0\n",
      "loss: [83808.21875]\n",
      "Exploiting\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 69us/step - loss: 113684.1250\n",
      "rewards:  -1284.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [113684.125]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 60us/step - loss: 50318.5625\n",
      "rewards:  -1284.0 q-value:  0\n",
      "loss: [50318.5625]\n",
      "Exploiting\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 78us/step - loss: 121198.9062\n",
      "rewards:  -1289.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [121198.90625]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 93us/step - loss: 65645.1875\n",
      "rewards:  -1324.0 q-value:  0\n",
      "loss: [65645.1875]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 80us/step - loss: 50389.0938\n",
      "rewards:  -1324.0 q-value:  0\n",
      "loss: [50389.09375]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 53us/step - loss: 86464.4688\n",
      "rewards:  -1324.0 q-value:  0\n",
      "loss: [86464.46875]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 85us/step - loss: 19616.4062\n",
      "rewards:  -1329.0 q-value:  0\n",
      "loss: [19616.40625]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 66us/step - loss: 144471.4375\n",
      "rewards:  -1329.0 q-value:  0\n",
      "loss: [144471.4375]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 62us/step - loss: 248953.9375\n",
      "rewards:  -1334.0 q-value:  0\n",
      "loss: [248953.9375]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 62us/step - loss: 188844.9062\n",
      "rewards:  -1339.0 q-value:  0\n",
      "loss: [188844.90625]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 61us/step - loss: 50910.1875\n",
      "rewards:  -1374.0 q-value:  0\n",
      "loss: [50910.1875]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 67us/step - loss: 119053.2188\n",
      "rewards:  -1374.0 q-value:  0\n",
      "loss: [119053.21875]\n",
      "Exploiting\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 69us/step - loss: 50949.5625\n",
      "rewards:  -1374.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [50949.5625]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 62us/step - loss: 66229.6562\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rewards:  -1379.0 q-value:  0\n",
      "loss: [66229.65625]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 78us/step - loss: 205025.6250\n",
      "rewards:  -1384.0 q-value:  0\n",
      "loss: [205025.625]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 56us/step - loss: 51955.3125\n",
      "rewards:  -1419.0 q-value:  0\n",
      "loss: [51955.3125]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 55us/step - loss: 85323.7188\n",
      "rewards:  -1419.0 q-value:  0\n",
      "loss: [85323.71875]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 68us/step - loss: 82852.3438\n",
      "rewards:  -1424.0 q-value:  0\n",
      "loss: [82852.34375]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 86us/step - loss: 215929.1875\n",
      "rewards:  -1459.0 q-value:  0\n",
      "loss: [215929.1875]\n",
      "Exploiting\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 65us/step - loss: 230533.2188\n",
      "rewards:  -1464.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [230533.21875]\n",
      "Exploiting\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 53us/step - loss: 108541.3438\n",
      "rewards:  -1499.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [108541.34375]\n",
      "Exploiting\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 72us/step - loss: 110024.4531\n",
      "rewards:  -1499.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [110024.453125]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 58us/step - loss: 294739.3750\n",
      "rewards:  -1504.0 q-value:  0\n",
      "loss: [294739.375]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 63us/step - loss: 170763.6250\n",
      "rewards:  -1509.0 q-value:  0\n",
      "loss: [170763.625]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 68us/step - loss: 74784.6562\n",
      "rewards:  -1509.0 q-value:  0\n",
      "loss: [74784.65625]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 52us/step - loss: 180050.0625\n",
      "rewards:  -1509.0 q-value:  0\n",
      "loss: [180050.0625]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 70us/step - loss: 71220.6875\n",
      "rewards:  -1509.0 q-value:  0\n",
      "loss: [71220.6875]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 55us/step - loss: 137464.0625\n",
      "rewards:  -1509.0 q-value:  0\n",
      "loss: [137464.0625]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 60us/step - loss: 94274.1250\n",
      "rewards:  -1509.0 q-value:  0\n",
      "loss: [94274.125]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 67us/step - loss: 111999.8438\n",
      "rewards:  -1509.0 q-value:  0\n",
      "loss: [111999.84375]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 88us/step - loss: 172989.9375\n",
      "rewards:  -1514.0 q-value:  0\n",
      "loss: [172989.9375]\n",
      "Exploiting\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 79us/step - loss: 177857.8750\n",
      "rewards:  -1514.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [177857.875]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 61us/step - loss: 278235.4375\n",
      "rewards:  -1519.0 q-value:  0\n",
      "loss: [278235.4375]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 65us/step - loss: 51258.8125\n",
      "rewards:  -1554.0 q-value:  0\n",
      "loss: [51258.8125]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 68us/step - loss: 126778.9375\n",
      "rewards:  -1559.0 q-value:  0\n",
      "loss: [126778.9375]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 63us/step - loss: 99282.0625\n",
      "rewards:  -1559.0 q-value:  0\n",
      "loss: [99282.0625]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 69us/step - loss: 195101.9375\n",
      "rewards:  -1564.0 q-value:  0\n",
      "loss: [195101.9375]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 83us/step - loss: 131194.8750\n",
      "rewards:  -1564.0 q-value:  0\n",
      "loss: [131194.875]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 55us/step - loss: 195532.5312\n",
      "rewards:  -1569.0 q-value:  0\n",
      "loss: [195532.53125]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 64us/step - loss: 121592.9922\n",
      "rewards:  -1574.0 q-value:  0\n",
      "loss: [121592.9921875]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 62us/step - loss: 146960.3438\n",
      "rewards:  -1579.0 q-value:  0\n",
      "loss: [146960.34375]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 62us/step - loss: 104286.3125\n",
      "rewards:  -1614.0 q-value:  0\n",
      "loss: [104286.3125]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 66us/step - loss: 51000.0938\n",
      "rewards:  -1619.0 q-value:  0\n",
      "loss: [51000.09375]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 67us/step - loss: 221662.5625\n",
      "rewards:  -1654.0 q-value:  0\n",
      "loss: [221662.5625]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 89us/step - loss: 85347.5938\n",
      "rewards:  -1654.0 q-value:  0\n",
      "loss: [85347.59375]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 72us/step - loss: 132326.0312\n",
      "rewards:  -1659.0 q-value:  0\n",
      "loss: [132326.03125]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 60us/step - loss: 204167.8125\n",
      "rewards:  -1659.0 q-value:  0\n",
      "loss: [204167.8125]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 82us/step - loss: 283163.6250\n",
      "rewards:  -1694.0 q-value:  0\n",
      "loss: [283163.625]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 77us/step - loss: 193003.6562\n",
      "rewards:  -1694.0 q-value:  0\n",
      "loss: [193003.65625]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 82us/step - loss: 103932.4062\n",
      "rewards:  -1699.0 q-value:  0\n",
      "loss: [103932.40625]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 67us/step - loss: 220612.6562\n",
      "rewards:  -1734.0 q-value:  0\n",
      "loss: [220612.65625]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 61us/step - loss: 144826.5000\n",
      "rewards:  -1739.0 q-value:  0\n",
      "loss: [144826.5]\n",
      "Exploiting\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 77us/step - loss: 54194.7188\n",
      "rewards:  -1739.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [54194.71875]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 71us/step - loss: 73303.2188\n",
      "rewards:  -1739.0 q-value:  0\n",
      "loss: [73303.21875]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 80us/step - loss: 172034.7812\n",
      "rewards:  -1744.0 q-value:  0\n",
      "loss: [172034.78125]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 76us/step - loss: 366409.7812\n",
      "rewards:  -1749.0 q-value:  0\n",
      "loss: [366409.78125]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 79us/step - loss: 106658.6875\n",
      "rewards:  -1784.0 q-value:  0\n",
      "loss: [106658.6875]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 57us/step - loss: 67905.5312\n",
      "rewards:  -1784.0 q-value:  0\n",
      "loss: [67905.53125]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 88us/step - loss: 180054.4062\n",
      "rewards:  -1784.0 q-value:  0\n",
      "loss: [180054.40625]\n",
      "Exploiting\n",
      "Selected action  [2 4]\n",
      "[2 4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 68us/step - loss: 106245.4062\n",
      "rewards:  -1784.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [106245.40625]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 66us/step - loss: 209324.2500\n",
      "rewards:  -1789.0 q-value:  0\n",
      "loss: [209324.25]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 71us/step - loss: 142651.9062\n",
      "rewards:  -1824.0 q-value:  0\n",
      "loss: [142651.90625]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 54us/step - loss: 117095.9375\n",
      "rewards:  -1824.0 q-value:  0\n",
      "loss: [117095.9375]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 53us/step - loss: 215726.3438\n",
      "rewards:  -1829.0 q-value:  0\n",
      "loss: [215726.34375]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 80us/step - loss: 242831.6250\n",
      "rewards:  -1829.0 q-value:  0\n",
      "loss: [242831.625]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 67us/step - loss: 143197.4688\n",
      "rewards:  -1864.0 q-value:  0\n",
      "loss: [143197.46875]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 53us/step - loss: 117675.4062\n",
      "rewards:  -1869.0 q-value:  0\n",
      "loss: [117675.40625]\n",
      "Exploiting\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 64us/step - loss: 275790.9375\n",
      "rewards:  -1874.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [275790.9375]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 63us/step - loss: 238016.7812\n",
      "rewards:  -1909.0 q-value:  0\n",
      "loss: [238016.78125]\n",
      "Exploiting\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 58us/step - loss: 304175.0312\n",
      "rewards:  -1909.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [304175.03125]\n",
      "Exploiting\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 71us/step - loss: 207873.2812\n",
      "rewards:  -1914.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [207873.28125]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 107us/step - loss: 135089.4375\n",
      "rewards:  -1919.0 q-value:  0\n",
      "loss: [135089.4375]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 64us/step - loss: 352994.8438\n",
      "rewards:  -1954.0 q-value:  0\n",
      "loss: [352994.84375]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 89us/step - loss: 70614.2812\n",
      "rewards:  -1959.0 q-value:  0\n",
      "loss: [70614.28125]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 82us/step - loss: 23334.3750\n",
      "rewards:  -1994.0 q-value:  0\n",
      "loss: [23334.375]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 60us/step - loss: 387607.3438\n",
      "rewards:  -1999.0 q-value:  0\n",
      "loss: [387607.34375]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 83us/step - loss: 255302.4688\n",
      "rewards:  -2034.0 q-value:  0\n",
      "loss: [255302.46875]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 60us/step - loss: 422260.0625\n",
      "rewards:  -2039.0 q-value:  0\n",
      "loss: [422260.0625]\n",
      "Exploiting\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 57us/step - loss: 159682.3281\n",
      "rewards:  -2044.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [159682.328125]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 68us/step - loss: 67167.5000\n",
      "rewards:  -2079.0 q-value:  0\n",
      "loss: [67167.5]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 61us/step - loss: 62974.9844\n",
      "rewards:  -2084.0 q-value:  0\n",
      "loss: [62974.984375]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 56us/step - loss: 95592.5625\n",
      "rewards:  -2119.0 q-value:  0\n",
      "loss: [95592.5625]\n",
      "Exploiting\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 61us/step - loss: 303676.2500\n",
      "rewards:  -2119.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [303676.25]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 63us/step - loss: 102001.9375\n",
      "rewards:  -2124.0 q-value:  0\n",
      "loss: [102001.9375]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 67us/step - loss: 321400.8125\n",
      "rewards:  -2159.0 q-value:  0\n",
      "loss: [321400.8125]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 63us/step - loss: 339429.6250\n",
      "rewards:  -2159.0 q-value:  0\n",
      "loss: [339429.625]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 68us/step - loss: 95561.0938\n",
      "rewards:  -2164.0 q-value:  0\n",
      "loss: [95561.09375]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 59us/step - loss: 114011.6875\n",
      "rewards:  -2169.0 q-value:  0\n",
      "loss: [114011.6875]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 92us/step - loss: 406436.1562\n",
      "rewards:  -2174.0 q-value:  0\n",
      "loss: [406436.15625]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 79us/step - loss: 449932.1250\n",
      "rewards:  -2209.0 q-value:  0\n",
      "loss: [449932.125]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 63us/step - loss: 68496.9062\n",
      "rewards:  -2214.0 q-value:  0\n",
      "loss: [68496.90625]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 70us/step - loss: 177144.6250\n",
      "rewards:  -2219.0 q-value:  0\n",
      "loss: [177144.625]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 70us/step - loss: 157469.0938\n",
      "rewards:  -2254.0 q-value:  0\n",
      "loss: [157469.09375]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 74us/step - loss: 199018.2188\n",
      "rewards:  -2259.0 q-value:  0\n",
      "loss: [199018.21875]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 64us/step - loss: 150530.5625\n",
      "rewards:  -2294.0 q-value:  0\n",
      "loss: [150530.5625]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 70us/step - loss: 57778.6562\n",
      "rewards:  -2299.0 q-value:  0\n",
      "loss: [57778.65625]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 73us/step - loss: 251425.2188\n",
      "rewards:  -2299.0 q-value:  0\n",
      "loss: [251425.21875]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 74us/step - loss: 148760.8750\n",
      "rewards:  -2334.0 q-value:  0\n",
      "loss: [148760.875]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 89us/step - loss: 498728.2812\n",
      "rewards:  -2339.0 q-value:  0\n",
      "loss: [498728.28125]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 72us/step - loss: 479720.1250\n",
      "rewards:  -2344.0 q-value:  0\n",
      "loss: [479720.125]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 91us/step - loss: 358644.8750\n",
      "rewards:  -2379.0 q-value:  0\n",
      "loss: [358644.875]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 66us/step - loss: 383371.6562\n",
      "rewards:  -2384.0 q-value:  0\n",
      "loss: [383371.65625]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 62us/step - loss: 344760.6875\n",
      "rewards:  -2384.0 q-value:  0\n",
      "loss: [344760.6875]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 87us/step - loss: 132707.3125\n",
      "rewards:  -2384.0 q-value:  0\n",
      "loss: [132707.3125]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 53us/step - loss: 188162.8750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rewards:  -2384.0 q-value:  0\n",
      "loss: [188162.875]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 59us/step - loss: 168766.7812\n",
      "rewards:  -2384.0 q-value:  0\n",
      "loss: [168766.78125]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 88us/step - loss: 219730.3750\n",
      "rewards:  -2419.0 q-value:  0\n",
      "loss: [219730.375]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 64us/step - loss: 248479.5938\n",
      "rewards:  -2424.0 q-value:  0\n",
      "loss: [248479.59375]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 75us/step - loss: 259086.1562\n",
      "rewards:  -2424.0 q-value:  0\n",
      "loss: [259086.15625]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 58us/step - loss: 420352.4062\n",
      "rewards:  -2429.0 q-value:  0\n",
      "loss: [420352.40625]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 64us/step - loss: 249557.0312\n",
      "rewards:  -2434.0 q-value:  0\n",
      "loss: [249557.03125]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 77us/step - loss: 290806.7188\n",
      "rewards:  -2434.0 q-value:  0\n",
      "loss: [290806.71875]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 63us/step - loss: 163249.3750\n",
      "rewards:  -2469.0 q-value:  0\n",
      "loss: [163249.375]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 79us/step - loss: 414828.2188\n",
      "rewards:  -2469.0 q-value:  0\n",
      "loss: [414828.21875]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 91us/step - loss: 324297.7188\n",
      "rewards:  -2474.0 q-value:  0\n",
      "loss: [324297.71875]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 87us/step - loss: 95862.3438\n",
      "rewards:  -2474.0 q-value:  0\n",
      "loss: [95862.34375]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 58us/step - loss: 101684.6250\n",
      "rewards:  -2509.0 q-value:  0\n",
      "loss: [101684.625]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 77us/step - loss: 507715.7188\n",
      "rewards:  -2514.0 q-value:  0\n",
      "loss: [507715.71875]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 72us/step - loss: 148961.9844\n",
      "rewards:  -2514.0 q-value:  0\n",
      "loss: [148961.984375]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 74us/step - loss: 243760.3750\n",
      "rewards:  -2519.0 q-value:  0\n",
      "loss: [243760.375]\n",
      "Exploiting\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 60us/step - loss: 333540.3750\n",
      "rewards:  -2519.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [333540.375]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 54us/step - loss: 111951.3125\n",
      "rewards:  -2524.0 q-value:  0\n",
      "loss: [111951.3125]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 67us/step - loss: 227220.0938\n",
      "rewards:  -2559.0 q-value:  0\n",
      "loss: [227220.09375]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 82us/step - loss: 472744.7188\n",
      "rewards:  -2559.0 q-value:  0\n",
      "loss: [472744.71875]\n",
      "Exploiting\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 55us/step - loss: 737013.1875\n",
      "rewards:  -2559.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [737013.1875]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 62us/step - loss: 647498.6250\n",
      "rewards:  -2559.0 q-value:  0\n",
      "loss: [647498.625]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 65us/step - loss: 55006.2812\n",
      "rewards:  -2564.0 q-value:  0\n",
      "loss: [55006.28125]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 61us/step - loss: 129234.0625\n",
      "rewards:  -2569.0 q-value:  0\n",
      "loss: [129234.0625]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 60us/step - loss: 263431.0625\n",
      "rewards:  -2569.0 q-value:  0\n",
      "loss: [263431.0625]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 54us/step - loss: 692604.2500\n",
      "rewards:  -2604.0 q-value:  0\n",
      "loss: [692604.25]\n",
      "Number of actions available 9\n",
      "Episode : 12\n",
      "Exploring\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 76us/step - loss: 449169.3750\n",
      "rewards:  -6.0 q-value:  0\n",
      "loss: [449169.375]\n",
      "Exploring\n",
      "Selected action  [4 1]\n",
      "[4 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 62us/step - loss: 888189.0000\n",
      "rewards:  -13.0 q-value:  0\n",
      "loss: [888189.0]\n",
      "Exploring\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 70us/step - loss: 207366.7500\n",
      "rewards:  -15.0 q-value:  0\n",
      "loss: [207366.75]\n",
      "Exploring\n",
      "Selected action  [3 0]\n",
      "[3 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 71us/step - loss: 139922.5000\n",
      "rewards:  -3.0 q-value:  0\n",
      "loss: [139922.5]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 64us/step - loss: 509276.9688\n",
      "rewards:  5.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [509276.96875]\n",
      "Exploring\n",
      "Selected action  [3 0]\n",
      "[3 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 85us/step - loss: 416548.8125\n",
      "rewards:  17.0 q-value:  0\n",
      "loss: [416548.8125]\n",
      "Exploring\n",
      "Selected action  [0 2]\n",
      "[0 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 70us/step - loss: 76526.5625\n",
      "rewards:  25.0 q-value:  0\n",
      "loss: [76526.5625]\n",
      "Exploring\n",
      "Selected action  [1 4]\n",
      "[1 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 61us/step - loss: 362758.9062\n",
      "rewards:  16.0 q-value:  0\n",
      "loss: [362758.90625]\n",
      "Exploring\n",
      "Selected action  [4 2]\n",
      "[4 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 79us/step - loss: 386241.5625\n",
      "rewards:  40.0 q-value:  0\n",
      "loss: [386241.5625]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 73us/step - loss: 334189.2812\n",
      "rewards:  35.0 q-value:  0\n",
      "loss: [334189.28125]\n",
      "Exploring\n",
      "Selected action  [0 2]\n",
      "[0 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 75us/step - loss: 432791.9375\n",
      "rewards:  43.0 q-value:  0\n",
      "loss: [432791.9375]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 50us/step - loss: 676644.0000\n",
      "rewards:  38.0 q-value:  0\n",
      "loss: [676644.0]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 87us/step - loss: 400862.0938\n",
      "rewards:  54.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [400862.09375]\n",
      "Exploring\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 59us/step - loss: 456817.8438\n",
      "rewards:  53.0 q-value:  0\n",
      "loss: [456817.84375]\n",
      "Exploring\n",
      "Selected action  [4 3]\n",
      "[4 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 66us/step - loss: 457286.6250\n",
      "rewards:  68.0 q-value:  0\n",
      "loss: [457286.625]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 81us/step - loss: 222877.1250\n",
      "rewards:  63.0 q-value:  0\n",
      "loss: [222877.125]\n",
      "Exploring\n",
      "Selected action  [4 2]\n",
      "[4 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 63us/step - loss: 240894.4375\n",
      "rewards:  78.0 q-value:  0\n",
      "loss: [240894.4375]\n",
      "Exploring\n",
      "Selected action  [0 2]\n",
      "[0 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 51us/step - loss: 263300.0938\n",
      "rewards:  75.0 q-value:  0\n",
      "loss: [263300.09375]\n",
      "Exploring\n",
      "Selected action  [4 1]\n",
      "[4 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 70us/step - loss: 399940.6562\n",
      "rewards:  70.0 q-value:  0\n",
      "loss: [399940.65625]\n",
      "Exploring\n",
      "Selected action  [3 0]\n",
      "[3 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 56us/step - loss: 296407.9062\n",
      "rewards:  64.0 q-value:  0\n",
      "loss: [296407.90625]\n",
      "Exploring\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 65us/step - loss: 299809.8750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rewards:  92.0 q-value:  0\n",
      "loss: [299809.875]\n",
      "Exploring\n",
      "Selected action  [4 2]\n",
      "[4 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 66us/step - loss: 295687.7500\n",
      "rewards:  100.0 q-value:  0\n",
      "loss: [295687.75]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 72us/step - loss: 170170.4062\n",
      "rewards:  95.0 q-value:  0\n",
      "loss: [170170.40625]\n",
      "Exploring\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 58us/step - loss: 172289.7500\n",
      "rewards:  90.0 q-value:  0\n",
      "loss: [172289.75]\n",
      "Exploring\n",
      "Selected action  [0 2]\n",
      "[0 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 69us/step - loss: 381799.4375\n",
      "rewards:  114.0 q-value:  0\n",
      "loss: [381799.4375]\n",
      "Exploring\n",
      "Selected action  [0 2]\n",
      "[0 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 66us/step - loss: 95137.8438\n",
      "rewards:  113.0 q-value:  0\n",
      "loss: [95137.84375]\n",
      "Exploring\n",
      "Selected action  [1 4]\n",
      "[1 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 77us/step - loss: 278931.5938\n",
      "rewards:  108.0 q-value:  0\n",
      "loss: [278931.59375]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 78us/step - loss: 651533.1250\n",
      "rewards:  103.0 q-value:  0\n",
      "loss: [651533.125]\n",
      "Exploring\n",
      "Selected action  [0 2]\n",
      "[0 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 78us/step - loss: 247117.0625\n",
      "rewards:  107.0 q-value:  0\n",
      "loss: [247117.0625]\n",
      "Exploring\n",
      "Selected action  [3 0]\n",
      "[3 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 59us/step - loss: 157228.6250\n",
      "rewards:  95.0 q-value:  0\n",
      "loss: [157228.625]\n",
      "Exploring\n",
      "Selected action  [4 1]\n",
      "[4 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 53us/step - loss: 425182.3125\n",
      "rewards:  90.0 q-value:  0\n",
      "loss: [425182.3125]\n",
      "Exploring\n",
      "Selected action  [1 4]\n",
      "[1 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 57us/step - loss: 193099.5625\n",
      "rewards:  90.0 q-value:  0\n",
      "loss: [193099.5625]\n",
      "Exploring\n",
      "Selected action  [4 3]\n",
      "[4 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 57us/step - loss: 192866.0625\n",
      "rewards:  114.0 q-value:  0\n",
      "loss: [192866.0625]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 86us/step - loss: 76728.1875\n",
      "rewards:  109.0 q-value:  0\n",
      "loss: [76728.1875]\n",
      "Exploring\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 78us/step - loss: 135772.2812\n",
      "rewards:  101.0 q-value:  0\n",
      "loss: [135772.28125]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 89us/step - loss: 316940.2500\n",
      "rewards:  129.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [316940.25]\n",
      "Exploring\n",
      "Selected action  [0 2]\n",
      "[0 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 67us/step - loss: 382396.5312\n",
      "rewards:  117.0 q-value:  0\n",
      "loss: [382396.53125]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 72us/step - loss: 563037.6875\n",
      "rewards:  112.0 q-value:  0\n",
      "loss: [563037.6875]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 61us/step - loss: 356323.5312\n",
      "rewards:  128.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [356323.53125]\n",
      "Exploring\n",
      "Selected action  [0 2]\n",
      "[0 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 68us/step - loss: 247482.9062\n",
      "rewards:  138.0 q-value:  0\n",
      "loss: [247482.90625]\n",
      "Exploring\n",
      "Selected action  [1 4]\n",
      "[1 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 92us/step - loss: 355231.6875\n",
      "rewards:  115.0 q-value:  0\n",
      "loss: [355231.6875]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 84us/step - loss: 532113.2500\n",
      "rewards:  138.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [532113.25]\n",
      "Exploring\n",
      "Selected action  [1 4]\n",
      "[1 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 75us/step - loss: 468877.9375\n",
      "rewards:  162.0 q-value:  0\n",
      "loss: [468877.9375]\n",
      "Exploring\n",
      "Selected action  [4 1]\n",
      "[4 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 58us/step - loss: 511255.1562\n",
      "rewards:  170.0 q-value:  0\n",
      "loss: [511255.15625]\n",
      "Exploring\n",
      "Selected action  [1 4]\n",
      "[1 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 64us/step - loss: 172552.6875\n",
      "rewards:  170.0 q-value:  0\n",
      "loss: [172552.6875]\n",
      "Exploring\n",
      "Selected action  [4 1]\n",
      "[4 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 58us/step - loss: 567550.4375\n",
      "rewards:  170.0 q-value:  0\n",
      "loss: [567550.4375]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 68us/step - loss: 309710.4062\n",
      "rewards:  163.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [309710.40625]\n",
      "Exploring\n",
      "Selected action  [4 1]\n",
      "[4 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 67us/step - loss: 274476.1875\n",
      "rewards:  162.0 q-value:  0\n",
      "loss: [274476.1875]\n",
      "Exploring\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 58us/step - loss: 342033.0312\n",
      "rewards:  162.0 q-value:  0\n",
      "loss: [342033.03125]\n",
      "Exploring\n",
      "Selected action  [4 2]\n",
      "[4 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 89us/step - loss: 248117.6562\n",
      "rewards:  157.0 q-value:  0\n",
      "loss: [248117.65625]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 76us/step - loss: 325797.5000\n",
      "rewards:  122.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [325797.5]\n",
      "Exploring\n",
      "Selected action  [4 3]\n",
      "[4 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 60us/step - loss: 245505.2500\n",
      "rewards:  125.0 q-value:  0\n",
      "loss: [245505.25]\n",
      "Exploring\n",
      "Selected action  [4 2]\n",
      "[4 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 59us/step - loss: 296709.6875\n",
      "rewards:  115.0 q-value:  0\n",
      "loss: [296709.6875]\n",
      "Exploring\n",
      "Selected action  [0 2]\n",
      "[0 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 98us/step - loss: 546231.5625\n",
      "rewards:  108.0 q-value:  0\n",
      "loss: [546231.5625]\n",
      "Exploring\n",
      "Selected action  [4 2]\n",
      "[4 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 71us/step - loss: 266185.0000\n",
      "rewards:  100.0 q-value:  0\n",
      "loss: [266185.0]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 57us/step - loss: 348796.2188\n",
      "rewards:  91.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [348796.21875]\n",
      "Exploring\n",
      "Selected action  [1 4]\n",
      "[1 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 75us/step - loss: 1008630.7500\n",
      "rewards:  99.0 q-value:  0\n",
      "loss: [1008630.75]\n",
      "Exploring\n",
      "Selected action  [4 1]\n",
      "[4 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 60us/step - loss: 232892.3438\n",
      "rewards:  107.0 q-value:  0\n",
      "loss: [232892.34375]\n",
      "Exploring\n",
      "Selected action  [3 0]\n",
      "[3 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 85us/step - loss: 158643.8750\n",
      "rewards:  111.0 q-value:  0\n",
      "loss: [158643.875]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 59us/step - loss: 35710.1016\n",
      "rewards:  135.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [35710.1015625]\n",
      "Exploring\n",
      "Selected action  [4 3]\n",
      "[4 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 80us/step - loss: 167060.2969\n",
      "rewards:  137.0 q-value:  0\n",
      "loss: [167060.296875]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 75us/step - loss: 414607.4062\n",
      "rewards:  130.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [414607.40625]\n",
      "Exploring\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 66us/step - loss: 303117.0000\n",
      "rewards:  110.0 q-value:  0\n",
      "loss: [303117.0]\n",
      "Exploring\n",
      "Selected action  [4 1]\n",
      "[4 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 67us/step - loss: 291304.0312\n",
      "rewards:  121.0 q-value:  0\n",
      "loss: [291304.03125]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 68us/step - loss: 122318.5000\n",
      "rewards:  119.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [122318.5]\n",
      "Exploring\n",
      "Selected action  [3 0]\n",
      "[3 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 74us/step - loss: 328219.2188\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rewards:  126.0 q-value:  0\n",
      "loss: [328219.21875]\n",
      "Exploring\n",
      "Selected action  [0 2]\n",
      "[0 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 57us/step - loss: 288060.2500\n",
      "rewards:  150.0 q-value:  0\n",
      "loss: [288060.25]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 89us/step - loss: 282586.0000\n",
      "rewards:  145.0 q-value:  0\n",
      "loss: [282586.0]\n",
      "Exploring\n",
      "Selected action  [3 0]\n",
      "[3 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 66us/step - loss: 624822.1875\n",
      "rewards:  143.0 q-value:  0\n",
      "loss: [624822.1875]\n",
      "Exploring\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 64us/step - loss: 289221.1250\n",
      "rewards:  137.0 q-value:  0\n",
      "loss: [289221.125]\n",
      "Exploring\n",
      "Selected action  [3 0]\n",
      "[3 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 67us/step - loss: 278056.3125\n",
      "rewards:  131.0 q-value:  0\n",
      "loss: [278056.3125]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 61us/step - loss: 352980.7188\n",
      "rewards:  126.0 q-value:  0\n",
      "loss: [352980.71875]\n",
      "Exploring\n",
      "Selected action  [4 3]\n",
      "[4 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 65us/step - loss: 226850.3438\n",
      "rewards:  149.0 q-value:  0\n",
      "loss: [226850.34375]\n",
      "Exploring\n",
      "Selected action  [4 2]\n",
      "[4 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 62us/step - loss: 172242.0625\n",
      "rewards:  123.0 q-value:  0\n",
      "loss: [172242.0625]\n",
      "Exploring\n",
      "Selected action  [4 1]\n",
      "[4 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 66us/step - loss: 211861.9688\n",
      "rewards:  118.0 q-value:  0\n",
      "loss: [211861.96875]\n",
      "Exploring\n",
      "Selected action  [0 2]\n",
      "[0 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 65us/step - loss: 505898.4688\n",
      "rewards:  95.0 q-value:  0\n",
      "loss: [505898.46875]\n",
      "Exploring\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 74us/step - loss: 615045.8125\n",
      "rewards:  107.0 q-value:  0\n",
      "loss: [615045.8125]\n",
      "Exploring\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 63us/step - loss: 182471.0000\n",
      "rewards:  105.0 q-value:  0\n",
      "loss: [182471.0]\n",
      "Exploring\n",
      "Selected action  [4 1]\n",
      "[4 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 84us/step - loss: 348738.6562\n",
      "rewards:  85.0 q-value:  0\n",
      "loss: [348738.65625]\n",
      "Exploring\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 54us/step - loss: 324525.1250\n",
      "rewards:  82.0 q-value:  0\n",
      "loss: [324525.125]\n",
      "Exploring\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 75us/step - loss: 274486.6875\n",
      "rewards:  79.0 q-value:  0\n",
      "loss: [274486.6875]\n",
      "Exploring\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 70us/step - loss: 111422.8438\n",
      "rewards:  76.0 q-value:  0\n",
      "loss: [111422.84375]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 57us/step - loss: 663441.6250\n",
      "rewards:  67.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [663441.625]\n",
      "Exploring\n",
      "Selected action  [4 2]\n",
      "[4 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 62us/step - loss: 166202.4062\n",
      "rewards:  75.0 q-value:  0\n",
      "loss: [166202.40625]\n",
      "Exploring\n",
      "Selected action  [0 2]\n",
      "[0 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 74us/step - loss: 693620.7500\n",
      "rewards:  67.0 q-value:  0\n",
      "loss: [693620.75]\n",
      "Exploring\n",
      "Selected action  [4 1]\n",
      "[4 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 58us/step - loss: 284154.5938\n",
      "rewards:  65.0 q-value:  0\n",
      "loss: [284154.59375]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 80us/step - loss: 152214.0312\n",
      "rewards:  60.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [152214.03125]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 61us/step - loss: 152701.3438\n",
      "rewards:  53.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [152701.34375]\n",
      "Exploring\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 63us/step - loss: 142803.8438\n",
      "rewards:  49.0 q-value:  0\n",
      "loss: [142803.84375]\n",
      "Exploring\n",
      "Selected action  [4 3]\n",
      "[4 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 66us/step - loss: 202111.7500\n",
      "rewards:  73.0 q-value:  0\n",
      "loss: [202111.75]\n",
      "Exploring\n",
      "Selected action  [4 2]\n",
      "[4 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 93us/step - loss: 295651.1562\n",
      "rewards:  62.0 q-value:  0\n",
      "loss: [295651.15625]\n",
      "Exploring\n",
      "Selected action  [3 0]\n",
      "[3 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 54us/step - loss: 252288.1250\n",
      "rewards:  60.0 q-value:  0\n",
      "loss: [252288.125]\n",
      "Exploring\n",
      "Selected action  [0 2]\n",
      "[0 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 70us/step - loss: 511099.1875\n",
      "rewards:  80.0 q-value:  0\n",
      "loss: [511099.1875]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 67us/step - loss: 399784.5312\n",
      "rewards:  75.0 q-value:  0\n",
      "loss: [399784.53125]\n",
      "Exploring\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 60us/step - loss: 34327.0000\n",
      "rewards:  72.0 q-value:  0\n",
      "loss: [34327.0]\n",
      "Exploring\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 80us/step - loss: 461686.8125\n",
      "rewards:  68.0 q-value:  0\n",
      "loss: [461686.8125]\n",
      "Exploring\n",
      "Selected action  [3 0]\n",
      "[3 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 67us/step - loss: 511252.6562\n",
      "rewards:  67.0 q-value:  0\n",
      "loss: [511252.65625]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 75us/step - loss: 298551.6875\n",
      "rewards:  95.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [298551.6875]\n",
      "Exploring\n",
      "Selected action  [4 1]\n",
      "[4 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 62us/step - loss: 249912.0312\n",
      "rewards:  90.0 q-value:  0\n",
      "loss: [249912.03125]\n",
      "Exploring\n",
      "Selected action  [0 2]\n",
      "[0 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 73us/step - loss: 772180.5000\n",
      "rewards:  93.0 q-value:  0\n",
      "loss: [772180.5]\n",
      "Exploring\n",
      "Selected action  [4 2]\n",
      "[4 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 59us/step - loss: 486463.9688\n",
      "rewards:  93.0 q-value:  0\n",
      "loss: [486463.96875]\n",
      "Exploring\n",
      "Selected action  [0 2]\n",
      "[0 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 72us/step - loss: 399179.0312\n",
      "rewards:  88.0 q-value:  0\n",
      "loss: [399179.03125]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 61us/step - loss: 232532.0312\n",
      "rewards:  83.0 q-value:  0\n",
      "loss: [232532.03125]\n",
      "Exploring\n",
      "Selected action  [4 2]\n",
      "[4 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 53us/step - loss: 446005.6875\n",
      "rewards:  78.0 q-value:  0\n",
      "loss: [446005.6875]\n",
      "Exploring\n",
      "Selected action  [3 0]\n",
      "[3 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 71us/step - loss: 173821.9375\n",
      "rewards:  65.0 q-value:  0\n",
      "loss: [173821.9375]\n",
      "Exploring\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 73us/step - loss: 107388.0000\n",
      "rewards:  58.0 q-value:  0\n",
      "loss: [107388.0]\n",
      "Exploring\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 79us/step - loss: 297601.6875\n",
      "rewards:  52.0 q-value:  0\n",
      "loss: [297601.6875]\n",
      "Exploring\n",
      "Selected action  [4 1]\n",
      "[4 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 87us/step - loss: 135560.3750\n",
      "rewards:  55.0 q-value:  0\n",
      "loss: [135560.375]\n",
      "Exploring\n",
      "Selected action  [4 2]\n",
      "[4 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 55us/step - loss: 69181.9375\n",
      "rewards:  45.0 q-value:  0\n",
      "loss: [69181.9375]\n",
      "Exploring\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 76us/step - loss: 507294.3438\n",
      "rewards:  38.0 q-value:  0\n",
      "loss: [507294.34375]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 58us/step - loss: 486677.0312\n",
      "rewards:  36.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [486677.03125]\n",
      "Exploring\n",
      "Selected action  [3 0]\n",
      "[3 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 77us/step - loss: 597069.2500\n",
      "rewards:  48.0 q-value:  0\n",
      "loss: [597069.25]\n",
      "Exploring\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 77us/step - loss: 256776.2031\n",
      "rewards:  56.0 q-value:  0\n",
      "loss: [256776.203125]\n",
      "Exploring\n",
      "Selected action  [4 2]\n",
      "[4 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 71us/step - loss: 121585.8438\n",
      "rewards:  40.0 q-value:  0\n",
      "loss: [121585.84375]\n",
      "Exploring\n",
      "Selected action  [1 4]\n",
      "[1 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 73us/step - loss: 428057.5000\n",
      "rewards:  31.0 q-value:  0\n",
      "loss: [428057.5]\n",
      "Exploring\n",
      "Selected action  [1 4]\n",
      "[1 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 89us/step - loss: 301984.8750\n",
      "rewards:  28.0 q-value:  0\n",
      "loss: [301984.875]\n",
      "Exploring\n",
      "Selected action  [4 1]\n",
      "[4 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 98us/step - loss: 490694.0000\n",
      "rewards:  40.0 q-value:  0\n",
      "loss: [490694.0]\n",
      "Exploring\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 56us/step - loss: 383761.5000\n",
      "rewards:  43.0 q-value:  0\n",
      "loss: [383761.5]\n",
      "Exploring\n",
      "Selected action  [0 2]\n",
      "[0 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 57us/step - loss: 339658.9688\n",
      "rewards:  51.0 q-value:  0\n",
      "loss: [339658.96875]\n",
      "Exploring\n",
      "Selected action  [4 3]\n",
      "[4 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 70us/step - loss: 178802.2500\n",
      "rewards:  77.0 q-value:  0\n",
      "loss: [178802.25]\n",
      "Exploring\n",
      "Selected action  [1 4]\n",
      "[1 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 72us/step - loss: 199434.5625\n",
      "rewards:  51.0 q-value:  0\n",
      "loss: [199434.5625]\n",
      "Exploring\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 60us/step - loss: 248860.5000\n",
      "rewards:  75.0 q-value:  0\n",
      "loss: [248860.5]\n",
      "Exploring\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 70us/step - loss: 235752.9375\n",
      "rewards:  103.0 q-value:  0\n",
      "loss: [235752.9375]\n",
      "Exploring\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 80us/step - loss: 482029.9375\n",
      "rewards:  100.0 q-value:  0\n",
      "loss: [482029.9375]\n",
      "Exploring\n",
      "Selected action  [4 1]\n",
      "[4 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 64us/step - loss: 390251.3438\n",
      "rewards:  80.0 q-value:  0\n",
      "loss: [390251.34375]\n",
      "Number of actions available 5\n",
      "Episode : 13\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 51us/step - loss: 404486.5938\n",
      "rewards:  -25.0 q-value:  0\n",
      "loss: [404486.59375]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 70us/step - loss: 212779.5938\n",
      "rewards:  -29.0 q-value:  0\n",
      "loss: [212779.59375]\n",
      "Exploring\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 70us/step - loss: 519419.5312\n",
      "rewards:  -17.0 q-value:  0\n",
      "loss: [519419.53125]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 69us/step - loss: 439205.5938\n",
      "rewards:  -22.0 q-value:  0\n",
      "loss: [439205.59375]\n",
      "Exploiting\n",
      "Selected action  [3 4]\n",
      "[3 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 57us/step - loss: 79776.2188\n",
      "rewards:  -10.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [79776.21875]\n",
      "Exploiting\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 57us/step - loss: 171581.2812\n",
      "rewards:  0.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [171581.28125]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 74us/step - loss: 602213.6250\n",
      "rewards:  -17.0 q-value:  0\n",
      "loss: [602213.625]\n",
      "Exploring\n",
      "Selected action  [3 4]\n",
      "[3 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 68us/step - loss: 298496.8750\n",
      "rewards:  -19.0 q-value:  0\n",
      "loss: [298496.875]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 64us/step - loss: 200422.1875\n",
      "rewards:  -24.0 q-value:  0\n",
      "loss: [200422.1875]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 64us/step - loss: 245137.6562\n",
      "rewards:  -29.0 q-value:  0\n",
      "loss: [245137.65625]\n",
      "Exploring\n",
      "Selected action  [3 4]\n",
      "[3 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 73us/step - loss: 255970.5625\n",
      "rewards:  -71.0 q-value:  0\n",
      "loss: [255970.5625]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 87us/step - loss: 326359.0938\n",
      "rewards:  -76.0 q-value:  0\n",
      "loss: [326359.09375]\n",
      "Exploring\n",
      "Selected action  [4 2]\n",
      "[4 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 61us/step - loss: 211913.3750\n",
      "rewards:  -77.0 q-value:  0\n",
      "loss: [211913.375]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 77us/step - loss: 352718.9375\n",
      "rewards:  -53.0 q-value:  0\n",
      "loss: [352718.9375]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 81us/step - loss: 456524.6875\n",
      "rewards:  -55.0 q-value:  0\n",
      "loss: [456524.6875]\n",
      "Exploring\n",
      "Selected action  [4 2]\n",
      "[4 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 57us/step - loss: 267739.8125\n",
      "rewards:  -47.0 q-value:  0\n",
      "loss: [267739.8125]\n",
      "Exploring\n",
      "Selected action  [3 4]\n",
      "[3 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 59us/step - loss: 215301.8125\n",
      "rewards:  -56.0 q-value:  0\n",
      "loss: [215301.8125]\n",
      "Exploring\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 59us/step - loss: 168911.4375\n",
      "rewards:  -32.0 q-value:  0\n",
      "loss: [168911.4375]\n",
      "Exploring\n",
      "Selected action  [4 2]\n",
      "[4 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 86us/step - loss: 786896.3750\n",
      "rewards:  -17.0 q-value:  0\n",
      "loss: [786896.375]\n",
      "Exploring\n",
      "Selected action  [3 4]\n",
      "[3 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 66us/step - loss: 206637.5156\n",
      "rewards:  -8.0 q-value:  0\n",
      "loss: [206637.515625]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 74us/step - loss: 798998.6250\n",
      "rewards:  -10.0 q-value:  0\n",
      "loss: [798998.625]\n",
      "Exploring\n",
      "Selected action  [4 2]\n",
      "[4 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 71us/step - loss: 193277.4688\n",
      "rewards:  -2.0 q-value:  0\n",
      "loss: [193277.46875]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 94us/step - loss: 212237.2500\n",
      "rewards:  6.0 q-value:  0\n",
      "loss: [212237.25]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 61us/step - loss: 73170.8750\n",
      "rewards:  1.0 q-value:  0\n",
      "loss: [73170.875]\n",
      "Exploring\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 63us/step - loss: 496660.0625\n",
      "rewards:  -4.0 q-value:  0\n",
      "loss: [496660.0625]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 61us/step - loss: 165713.1875\n",
      "rewards:  -9.0 q-value:  0\n",
      "loss: [165713.1875]\n",
      "Exploring\n",
      "Selected action  [3 4]\n",
      "[3 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 53us/step - loss: 72025.9375\n",
      "rewards:  -45.0 q-value:  0\n",
      "loss: [72025.9375]\n",
      "Exploiting\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 72us/step - loss: 410768.6250\n",
      "rewards:  -41.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [410768.625]\n",
      "Exploring\n",
      "Selected action  [3 4]\n",
      "[3 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 95us/step - loss: 170954.6875\n",
      "rewards:  -27.0 q-value:  0\n",
      "loss: [170954.6875]\n",
      "Exploiting\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 75us/step - loss: 326520.2812\n",
      "rewards:  -32.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [326520.28125]\n",
      "Exploring\n",
      "Selected action  [3 4]\n",
      "[3 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 56us/step - loss: 336193.8125\n",
      "rewards:  -26.0 q-value:  0\n",
      "loss: [336193.8125]\n",
      "Exploring\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 92us/step - loss: 215168.0938\n",
      "rewards:  -4.0 q-value:  0\n",
      "loss: [215168.09375]\n",
      "Exploring\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 79us/step - loss: 45010.5625\n",
      "rewards:  -10.0 q-value:  0\n",
      "loss: [45010.5625]\n",
      "Exploring\n",
      "Selected action  [3 4]\n",
      "[3 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 69us/step - loss: 451158.3125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rewards:  -11.0 q-value:  0\n",
      "loss: [451158.3125]\n",
      "Exploring\n",
      "Selected action  [4 2]\n",
      "[4 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 78us/step - loss: 345006.0312\n",
      "rewards:  -11.0 q-value:  0\n",
      "loss: [345006.03125]\n",
      "Exploring\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 56us/step - loss: 703533.8750\n",
      "rewards:  9.0 q-value:  0\n",
      "loss: [703533.875]\n",
      "Exploring\n",
      "Selected action  [4 2]\n",
      "[4 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 73us/step - loss: 177103.2812\n",
      "rewards:  -21.0 q-value:  0\n",
      "loss: [177103.28125]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 74us/step - loss: 736420.3750\n",
      "rewards:  -21.0 q-value:  0\n",
      "loss: [736420.375]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 67us/step - loss: 159043.8125\n",
      "rewards:  -21.0 q-value:  0\n",
      "loss: [159043.8125]\n",
      "Exploring\n",
      "Selected action  [4 2]\n",
      "[4 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 58us/step - loss: 401187.4375\n",
      "rewards:  -21.0 q-value:  0\n",
      "loss: [401187.4375]\n",
      "Exploring\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 62us/step - loss: 245372.3438\n",
      "rewards:  -1.0 q-value:  0\n",
      "loss: [245372.34375]\n",
      "Exploring\n",
      "Selected action  [3 4]\n",
      "[3 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 75us/step - loss: 280963.3125\n",
      "rewards:  -24.0 q-value:  0\n",
      "loss: [280963.3125]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 58us/step - loss: 762540.5000\n",
      "rewards:  -29.0 q-value:  0\n",
      "loss: [762540.5]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 59us/step - loss: 392163.2500\n",
      "rewards:  -22.0 q-value:  0\n",
      "loss: [392163.25]\n",
      "Exploring\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 61us/step - loss: 237508.3906\n",
      "rewards:  -20.0 q-value:  0\n",
      "loss: [237508.390625]\n",
      "Exploring\n",
      "Selected action  [3 4]\n",
      "[3 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 63us/step - loss: 136710.2500\n",
      "rewards:  -9.0 q-value:  0\n",
      "loss: [136710.25]\n",
      "Exploring\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 74us/step - loss: 172049.5625\n",
      "rewards:  7.0 q-value:  0\n",
      "loss: [172049.5625]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 62us/step - loss: 345724.1562\n",
      "rewards:  -28.0 q-value:  0\n",
      "loss: [345724.15625]\n",
      "Exploring\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 76us/step - loss: 435724.5000\n",
      "rewards:  0.0 q-value:  0\n",
      "loss: [435724.5]\n",
      "Exploiting\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 80us/step - loss: 319812.0625\n",
      "rewards:  -5.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [319812.0625]\n",
      "Exploring\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 68us/step - loss: 542144.2500\n",
      "rewards:  -12.0 q-value:  0\n",
      "loss: [542144.25]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 89us/step - loss: 357928.9688\n",
      "rewards:  -32.0 q-value:  0\n",
      "loss: [357928.96875]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 70us/step - loss: 356873.1875\n",
      "rewards:  -37.0 q-value:  0\n",
      "loss: [356873.1875]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 79us/step - loss: 323057.2812\n",
      "rewards:  -42.0 q-value:  0\n",
      "loss: [323057.28125]\n",
      "Exploring\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 76us/step - loss: 200595.4062\n",
      "rewards:  -46.0 q-value:  0\n",
      "loss: [200595.40625]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 63us/step - loss: 318330.2500\n",
      "rewards:  -71.0 q-value:  0\n",
      "loss: [318330.25]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 66us/step - loss: 702711.8750\n",
      "rewards:  -76.0 q-value:  0\n",
      "loss: [702711.875]\n",
      "Exploring\n",
      "Selected action  [3 4]\n",
      "[3 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 64us/step - loss: 414731.1562\n",
      "rewards:  -67.0 q-value:  0\n",
      "loss: [414731.15625]\n",
      "Exploring\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 64us/step - loss: 147037.0312\n",
      "rewards:  -64.0 q-value:  0\n",
      "loss: [147037.03125]\n",
      "Exploring\n",
      "Selected action  [4 2]\n",
      "[4 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 96us/step - loss: 265378.1875\n",
      "rewards:  -63.0 q-value:  0\n",
      "loss: [265378.1875]\n",
      "Exploiting\n",
      "Selected action  [3 4]\n",
      "[3 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 71us/step - loss: 261125.4219\n",
      "rewards:  -91.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [261125.421875]\n",
      "Exploiting\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 94us/step - loss: 383402.7500\n",
      "rewards:  -79.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [383402.75]\n",
      "Exploring\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 68us/step - loss: 456913.1875\n",
      "rewards:  -84.0 q-value:  0\n",
      "loss: [456913.1875]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 68us/step - loss: 320254.8750\n",
      "rewards:  -90.0 q-value:  0\n",
      "loss: [320254.875]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 120us/step - loss: 338654.7812\n",
      "rewards:  -95.0 q-value:  0\n",
      "loss: [338654.78125]\n",
      "Exploring\n",
      "Selected action  [4 2]\n",
      "[4 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 79us/step - loss: 278991.2500\n",
      "rewards:  -96.0 q-value:  0\n",
      "loss: [278991.25]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 70us/step - loss: 302033.4062\n",
      "rewards:  -101.0 q-value:  0\n",
      "loss: [302033.40625]\n",
      "Exploring\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 58us/step - loss: 219068.9688\n",
      "rewards:  -103.0 q-value:  0\n",
      "loss: [219068.96875]\n",
      "Exploiting\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 72us/step - loss: 361909.9062\n",
      "rewards:  -108.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [361909.90625]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 64us/step - loss: 456108.9688\n",
      "rewards:  -114.0 q-value:  0\n",
      "loss: [456108.96875]\n",
      "Exploring\n",
      "Selected action  [3 4]\n",
      "[3 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 72us/step - loss: 242323.9375\n",
      "rewards:  -116.0 q-value:  0\n",
      "loss: [242323.9375]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 53us/step - loss: 275592.0938\n",
      "rewards:  -122.0 q-value:  0\n",
      "loss: [275592.09375]\n",
      "Exploring\n",
      "Selected action  [4 2]\n",
      "[4 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 59us/step - loss: 589406.2500\n",
      "rewards:  -114.0 q-value:  0\n",
      "loss: [589406.25]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 55us/step - loss: 846607.0000\n",
      "rewards:  -119.0 q-value:  0\n",
      "loss: [846607.0]\n",
      "Exploring\n",
      "Selected action  [4 2]\n",
      "[4 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 53us/step - loss: 78532.3125\n",
      "rewards:  -126.0 q-value:  0\n",
      "loss: [78532.3125]\n",
      "Exploring\n",
      "Selected action  [3 4]\n",
      "[3 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 87us/step - loss: 416504.9375\n",
      "rewards:  -135.0 q-value:  0\n",
      "loss: [416504.9375]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 63us/step - loss: 473516.4062\n",
      "rewards:  -140.0 q-value:  0\n",
      "loss: [473516.40625]\n",
      "Exploring\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 80us/step - loss: 556948.0625\n",
      "rewards:  -146.0 q-value:  0\n",
      "loss: [556948.0625]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 62us/step - loss: 558318.5625\n",
      "rewards:  -151.0 q-value:  0\n",
      "loss: [558318.5625]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 63us/step - loss: 632161.7500\n",
      "rewards:  -156.0 q-value:  0\n",
      "loss: [632161.75]\n",
      "Exploring\n",
      "Selected action  [4 2]\n",
      "[4 2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 66us/step - loss: 463489.9688\n",
      "rewards:  -141.0 q-value:  0\n",
      "loss: [463489.96875]\n",
      "Exploring\n",
      "Selected action  [4 2]\n",
      "[4 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 74us/step - loss: 442560.0938\n",
      "rewards:  -142.0 q-value:  0\n",
      "loss: [442560.09375]\n",
      "Exploring\n",
      "Selected action  [4 2]\n",
      "[4 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 75us/step - loss: 163875.7812\n",
      "rewards:  -143.0 q-value:  0\n",
      "loss: [163875.78125]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 54us/step - loss: 256105.6875\n",
      "rewards:  -148.0 q-value:  0\n",
      "loss: [256105.6875]\n",
      "Exploiting\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 66us/step - loss: 426664.6562\n",
      "rewards:  -153.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [426664.65625]\n",
      "Exploring\n",
      "Selected action  [3 4]\n",
      "[3 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 70us/step - loss: 45223.0000\n",
      "rewards:  -134.0 q-value:  0\n",
      "loss: [45223.0]\n",
      "Exploring\n",
      "Selected action  [4 2]\n",
      "[4 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 73us/step - loss: 385891.8125\n",
      "rewards:  -126.0 q-value:  0\n",
      "loss: [385891.8125]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 71us/step - loss: 528403.8125\n",
      "rewards:  -131.0 q-value:  0\n",
      "loss: [528403.8125]\n",
      "Exploring\n",
      "Selected action  [4 2]\n",
      "[4 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 59us/step - loss: 387204.2500\n",
      "rewards:  -143.0 q-value:  0\n",
      "loss: [387204.25]\n",
      "Exploring\n",
      "Selected action  [3 4]\n",
      "[3 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 71us/step - loss: 401644.5625\n",
      "rewards:  -154.0 q-value:  0\n",
      "loss: [401644.5625]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 80us/step - loss: 169685.7500\n",
      "rewards:  -155.0 q-value:  0\n",
      "loss: [169685.75]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 65us/step - loss: 627871.3125\n",
      "rewards:  -160.0 q-value:  0\n",
      "loss: [627871.3125]\n",
      "Exploring\n",
      "Selected action  [3 4]\n",
      "[3 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 57us/step - loss: 193012.6875\n",
      "rewards:  -196.0 q-value:  0\n",
      "loss: [193012.6875]\n",
      "Exploiting\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 69us/step - loss: 133354.6875\n",
      "rewards:  -201.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [133354.6875]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 72us/step - loss: 539876.0000\n",
      "rewards:  -206.0 q-value:  0\n",
      "loss: [539876.0]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 76us/step - loss: 110152.0000\n",
      "rewards:  -227.0 q-value:  0\n",
      "loss: [110152.0]\n",
      "Exploring\n",
      "Selected action  [3 4]\n",
      "[3 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 91us/step - loss: 696188.8750\n",
      "rewards:  -228.0 q-value:  0\n",
      "loss: [696188.875]\n",
      "Exploiting\n",
      "Selected action  [3 4]\n",
      "[3 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 61us/step - loss: 329565.6250\n",
      "rewards:  -234.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [329565.625]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 136us/step - loss: 470773.0625\n",
      "rewards:  -239.0 q-value:  0\n",
      "loss: [470773.0625]\n",
      "Exploring\n",
      "Selected action  [3 4]\n",
      "[3 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 59us/step - loss: 666401.8750\n",
      "rewards:  -225.0 q-value:  0\n",
      "loss: [666401.875]\n",
      "Exploring\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 76us/step - loss: 302603.8750\n",
      "rewards:  -203.0 q-value:  0\n",
      "loss: [302603.875]\n",
      "Exploring\n",
      "Selected action  [3 4]\n",
      "[3 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 73us/step - loss: 332335.1875\n",
      "rewards:  -220.0 q-value:  0\n",
      "loss: [332335.1875]\n",
      "Exploring\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 56us/step - loss: 94376.7500\n",
      "rewards:  -218.0 q-value:  0\n",
      "loss: [94376.75]\n",
      "Exploring\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 59us/step - loss: 239779.7812\n",
      "rewards:  -224.0 q-value:  0\n",
      "loss: [239779.78125]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 62us/step - loss: 788552.1250\n",
      "rewards:  -230.0 q-value:  0\n",
      "loss: [788552.125]\n",
      "Exploiting\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 76us/step - loss: 338135.6562\n",
      "rewards:  -227.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [338135.65625]\n",
      "Exploring\n",
      "Selected action  [3 4]\n",
      "[3 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 66us/step - loss: 327623.2188\n",
      "rewards:  -228.0 q-value:  0\n",
      "loss: [327623.21875]\n",
      "Exploring\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 69us/step - loss: 357076.4062\n",
      "rewards:  -208.0 q-value:  0\n",
      "loss: [357076.40625]\n",
      "Exploring\n",
      "Selected action  [4 2]\n",
      "[4 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 75us/step - loss: 358403.5312\n",
      "rewards:  -209.0 q-value:  0\n",
      "loss: [358403.53125]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 78us/step - loss: 109939.1250\n",
      "rewards:  -214.0 q-value:  0\n",
      "loss: [109939.125]\n",
      "Exploring\n",
      "Selected action  [4 2]\n",
      "[4 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 59us/step - loss: 447155.4688\n",
      "rewards:  -215.0 q-value:  0\n",
      "loss: [447155.46875]\n",
      "Exploring\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 69us/step - loss: 110340.1562\n",
      "rewards:  -203.0 q-value:  0\n",
      "loss: [110340.15625]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 63us/step - loss: 260412.0000\n",
      "rewards:  -208.0 q-value:  0\n",
      "loss: [260412.0]\n",
      "Exploring\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 67us/step - loss: 305138.0938\n",
      "rewards:  -213.0 q-value:  0\n",
      "loss: [305138.09375]\n",
      "Exploiting\n",
      "Selected action  [4 2]\n",
      "[4 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 61us/step - loss: 214664.1562\n",
      "rewards:  -225.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [214664.15625]\n",
      "Exploring\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 82us/step - loss: 656525.3750\n",
      "rewards:  -213.0 q-value:  0\n",
      "loss: [656525.375]\n",
      "Exploring\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 70us/step - loss: 589822.6250\n",
      "rewards:  -217.0 q-value:  0\n",
      "loss: [589822.625]\n",
      "Exploring\n",
      "Selected action  [3 4]\n",
      "[3 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 95us/step - loss: 597914.8750\n",
      "rewards:  -206.0 q-value:  0\n",
      "loss: [597914.875]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 68us/step - loss: 511446.0000\n",
      "rewards:  -211.0 q-value:  0\n",
      "loss: [511446.0]\n",
      "Exploring\n",
      "Selected action  [3 4]\n",
      "[3 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 56us/step - loss: 778690.2500\n",
      "rewards:  -223.0 q-value:  0\n",
      "loss: [778690.25]\n",
      "Exploiting\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 96us/step - loss: 495062.1562\n",
      "rewards:  -228.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [495062.15625]\n",
      "Exploring\n",
      "Selected action  [3 4]\n",
      "[3 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 80us/step - loss: 318531.7812\n",
      "rewards:  -240.0 q-value:  0\n",
      "loss: [318531.78125]\n",
      "Exploring\n",
      "Selected action  [4 2]\n",
      "[4 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 63us/step - loss: 100062.7812\n",
      "rewards:  -208.0 q-value:  0\n",
      "loss: [100062.78125]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 78us/step - loss: 175563.1562\n",
      "rewards:  -213.0 q-value:  0\n",
      "loss: [175563.15625]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 92us/step - loss: 316198.2188\n",
      "rewards:  -233.0 q-value:  0\n",
      "loss: [316198.21875]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 75us/step - loss: 378699.9375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rewards:  -238.0 q-value:  0\n",
      "loss: [378699.9375]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 71us/step - loss: 342867.2812\n",
      "rewards:  -243.0 q-value:  0\n",
      "loss: [342867.28125]\n",
      "Exploiting\n",
      "Selected action  [3 4]\n",
      "[3 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 78us/step - loss: 909041.1875\n",
      "rewards:  -239.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [909041.1875]\n",
      "Exploring\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 68us/step - loss: 381199.3125\n",
      "rewards:  -219.0 q-value:  0\n",
      "loss: [381199.3125]\n",
      "Exploring\n",
      "Selected action  [4 2]\n",
      "[4 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 65us/step - loss: 221592.3438\n",
      "rewards:  -204.0 q-value:  0\n",
      "loss: [221592.34375]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 67us/step - loss: 153361.3438\n",
      "rewards:  -188.0 q-value:  0\n",
      "loss: [153361.34375]\n",
      "Exploring\n",
      "Selected action  [3 4]\n",
      "[3 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 64us/step - loss: 287268.0625\n",
      "rewards:  -195.0 q-value:  0\n",
      "loss: [287268.0625]\n",
      "Exploring\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 66us/step - loss: 381560.4375\n",
      "rewards:  -183.0 q-value:  0\n",
      "loss: [381560.4375]\n",
      "Exploring\n",
      "Selected action  [3 4]\n",
      "[3 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 60us/step - loss: 397959.8125\n",
      "rewards:  -186.0 q-value:  0\n",
      "loss: [397959.8125]\n",
      "Exploring\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 97us/step - loss: 301413.8438\n",
      "rewards:  -176.0 q-value:  0\n",
      "loss: [301413.84375]\n",
      "Exploring\n",
      "Selected action  [3 4]\n",
      "[3 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 66us/step - loss: 117209.8438\n",
      "rewards:  -218.0 q-value:  0\n",
      "loss: [117209.84375]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 71us/step - loss: 321939.5625\n",
      "rewards:  -223.0 q-value:  0\n",
      "loss: [321939.5625]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 58us/step - loss: 408227.7812\n",
      "rewards:  -228.0 q-value:  0\n",
      "loss: [408227.78125]\n",
      "Exploring\n",
      "Selected action  [3 4]\n",
      "[3 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 69us/step - loss: 181291.7812\n",
      "rewards:  -215.0 q-value:  0\n",
      "loss: [181291.78125]\n",
      "Exploring\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 51us/step - loss: 523430.5000\n",
      "rewards:  -217.0 q-value:  0\n",
      "loss: [523430.5]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 56us/step - loss: 357315.5312\n",
      "rewards:  -222.0 q-value:  0\n",
      "loss: [357315.53125]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 72us/step - loss: 320311.6875\n",
      "rewards:  -224.0 q-value:  0\n",
      "loss: [320311.6875]\n",
      "Exploring\n",
      "Selected action  [4 2]\n",
      "[4 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 72us/step - loss: 340008.5938\n",
      "rewards:  -216.0 q-value:  0\n",
      "loss: [340008.59375]\n",
      "Exploring\n",
      "Selected action  [4 2]\n",
      "[4 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 64us/step - loss: 248193.4688\n",
      "rewards:  -216.0 q-value:  0\n",
      "loss: [248193.46875]\n",
      "Exploring\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 58us/step - loss: 443607.9688\n",
      "rewards:  -192.0 q-value:  0\n",
      "loss: [443607.96875]\n",
      "Number of actions available 11\n",
      "Episode : 14\n",
      "Exploring\n",
      "Selected action  [3 0]\n",
      "[3 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 58us/step - loss: 272531.7500\n",
      "rewards:  24.0 q-value:  0\n",
      "loss: [272531.75]\n",
      "Exploring\n",
      "Selected action  [2 3]\n",
      "[2 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 61us/step - loss: 821438.1250\n",
      "rewards:  18.0 q-value:  0\n",
      "loss: [821438.125]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 81us/step - loss: 71555.9609\n",
      "rewards:  26.0 q-value:  0\n",
      "loss: [71555.9609375]\n",
      "Exploring\n",
      "Selected action  [3 4]\n",
      "[3 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 66us/step - loss: 383335.0000\n",
      "rewards:  38.0 q-value:  0\n",
      "loss: [383335.0]\n",
      "Exploiting\n",
      "Selected action  [3 0]\n",
      "[3 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 74us/step - loss: 260432.9062\n",
      "rewards:  35.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [260432.90625]\n",
      "Exploring\n",
      "Selected action  [3 4]\n",
      "[3 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 71us/step - loss: 272832.9688\n",
      "rewards:  32.0 q-value:  0\n",
      "loss: [272832.96875]\n",
      "Exploring\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 79us/step - loss: 430346.6250\n",
      "rewards:  32.0 q-value:  0\n",
      "loss: [430346.625]\n",
      "Exploring\n",
      "Selected action  [0 3]\n",
      "[0 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 69us/step - loss: 377055.5000\n",
      "rewards:  29.0 q-value:  0\n",
      "loss: [377055.5]\n",
      "Exploring\n",
      "Selected action  [0 2]\n",
      "[0 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 102us/step - loss: 336390.2500\n",
      "rewards:  38.0 q-value:  0\n",
      "loss: [336390.25]\n",
      "Exploring\n",
      "Selected action  [0 3]\n",
      "[0 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 77us/step - loss: 398199.5938\n",
      "rewards:  36.0 q-value:  0\n",
      "loss: [398199.59375]\n",
      "Exploring\n",
      "Selected action  [4 0]\n",
      "[4 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 68us/step - loss: 324155.2500\n",
      "rewards:  35.0 q-value:  0\n",
      "loss: [324155.25]\n",
      "Exploiting\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 56us/step - loss: 312682.6562\n",
      "rewards:  30.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [312682.65625]\n",
      "Exploiting\n",
      "Selected action  [3 0]\n",
      "[3 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 82us/step - loss: 67649.3125\n",
      "rewards:  24.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [67649.3125]\n",
      "Exploring\n",
      "Selected action  [0 2]\n",
      "[0 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 82us/step - loss: 635687.3750\n",
      "rewards:  48.0 q-value:  0\n",
      "loss: [635687.375]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 68us/step - loss: 334182.9062\n",
      "rewards:  61.0 q-value:  0\n",
      "loss: [334182.90625]\n",
      "Exploring\n",
      "Selected action  [3 0]\n",
      "[3 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 68us/step - loss: 791150.9375\n",
      "rewards:  60.0 q-value:  0\n",
      "loss: [791150.9375]\n",
      "Exploring\n",
      "Selected action  [2 1]\n",
      "[2 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 81us/step - loss: 275182.4062\n",
      "rewards:  94.0 q-value:  0\n",
      "loss: [275182.40625]\n",
      "Exploring\n",
      "Selected action  [2 1]\n",
      "[2 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 68us/step - loss: 353604.8125\n",
      "rewards:  90.0 q-value:  0\n",
      "loss: [353604.8125]\n",
      "Exploring\n",
      "Selected action  [3 0]\n",
      "[3 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 74us/step - loss: 717318.9375\n",
      "rewards:  112.0 q-value:  0\n",
      "loss: [717318.9375]\n",
      "Exploring\n",
      "Selected action  [4 0]\n",
      "[4 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 64us/step - loss: 232803.3750\n",
      "rewards:  105.0 q-value:  0\n",
      "loss: [232803.375]\n",
      "Exploring\n",
      "Selected action  [0 2]\n",
      "[0 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 65us/step - loss: 159328.7500\n",
      "rewards:  117.0 q-value:  0\n",
      "loss: [159328.75]\n",
      "Exploring\n",
      "Selected action  [2 3]\n",
      "[2 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 90us/step - loss: 99124.5938\n",
      "rewards:  137.0 q-value:  0\n",
      "loss: [99124.59375]\n",
      "Exploring\n",
      "Selected action  [3 4]\n",
      "[3 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 82us/step - loss: 224277.0938\n",
      "rewards:  149.0 q-value:  0\n",
      "loss: [224277.09375]\n",
      "Exploring\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 73us/step - loss: 366632.6875\n",
      "rewards:  165.0 q-value:  0\n",
      "loss: [366632.6875]\n",
      "Exploring\n",
      "Selected action  [2 1]\n",
      "[2 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 53us/step - loss: 746078.1250\n",
      "rewards:  139.0 q-value:  0\n",
      "loss: [746078.125]\n",
      "Exploring\n",
      "Selected action  [4 0]\n",
      "[4 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 74us/step - loss: 249417.5625\n",
      "rewards:  163.0 q-value:  0\n",
      "loss: [249417.5625]\n",
      "Exploring\n",
      "Selected action  [0 2]\n",
      "[0 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 79us/step - loss: 348363.3750\n",
      "rewards:  175.0 q-value:  0\n",
      "loss: [348363.375]\n",
      "Exploring\n",
      "Selected action  [3 4]\n",
      "[3 4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 73us/step - loss: 551671.3750\n",
      "rewards:  157.0 q-value:  0\n",
      "loss: [551671.375]\n",
      "Exploiting\n",
      "Selected action  [0 2]\n",
      "[0 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 75us/step - loss: 264945.1250\n",
      "rewards:  177.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [264945.125]\n",
      "Exploring\n",
      "Selected action  [4 0]\n",
      "[4 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 51us/step - loss: 104828.3125\n",
      "rewards:  137.0 q-value:  0\n",
      "loss: [104828.3125]\n",
      "Exploring\n",
      "Selected action  [4 0]\n",
      "[4 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 69us/step - loss: 364171.0000\n",
      "rewards:  137.0 q-value:  0\n",
      "loss: [364171.0]\n",
      "Exploiting\n",
      "Selected action  [2 1]\n",
      "[2 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 63us/step - loss: 144066.5312\n",
      "rewards:  140.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [144066.53125]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 58us/step - loss: 608248.8750\n",
      "rewards:  135.0 q-value:  0\n",
      "loss: [608248.875]\n",
      "Exploring\n",
      "Selected action  [2 1]\n",
      "[2 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 80us/step - loss: 91310.0625\n",
      "rewards:  155.0 q-value:  0\n",
      "loss: [91310.0625]\n",
      "Exploiting\n",
      "Selected action  [2 1]\n",
      "[2 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 68us/step - loss: 481299.2500\n",
      "rewards:  146.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [481299.25]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 69us/step - loss: 983663.6250\n",
      "rewards:  141.0 q-value:  0\n",
      "loss: [983663.625]\n",
      "Exploring\n",
      "Selected action  [3 0]\n",
      "[3 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 55us/step - loss: 378094.9375\n",
      "rewards:  137.0 q-value:  0\n",
      "loss: [378094.9375]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 73us/step - loss: 500785.0938\n",
      "rewards:  133.0 q-value:  0\n",
      "loss: [500785.09375]\n",
      "Exploring\n",
      "Selected action  [3 0]\n",
      "[3 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 62us/step - loss: 44250.0938\n",
      "rewards:  130.0 q-value:  0\n",
      "loss: [44250.09375]\n",
      "Exploring\n",
      "Selected action  [2 1]\n",
      "[2 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 81us/step - loss: 269722.9688\n",
      "rewards:  123.0 q-value:  0\n",
      "loss: [269722.96875]\n",
      "Exploring\n",
      "Selected action  [0 2]\n",
      "[0 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 65us/step - loss: 533154.3750\n",
      "rewards:  117.0 q-value:  0\n",
      "loss: [533154.375]\n",
      "Exploring\n",
      "Selected action  [2 3]\n",
      "[2 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 84us/step - loss: 375797.0000\n",
      "rewards:  149.0 q-value:  0\n",
      "loss: [375797.0]\n",
      "Exploring\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 76us/step - loss: 221259.4688\n",
      "rewards:  149.0 q-value:  0\n",
      "loss: [221259.46875]\n",
      "Exploring\n",
      "Selected action  [3 4]\n",
      "[3 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 63us/step - loss: 477880.2188\n",
      "rewards:  161.0 q-value:  0\n",
      "loss: [477880.21875]\n",
      "Exploring\n",
      "Selected action  [2 1]\n",
      "[2 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 65us/step - loss: 185604.0312\n",
      "rewards:  176.0 q-value:  0\n",
      "loss: [185604.03125]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 61us/step - loss: 413045.8750\n",
      "rewards:  171.0 q-value:  0\n",
      "loss: [413045.875]\n",
      "Exploiting\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 98us/step - loss: 708798.8125\n",
      "rewards:  166.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [708798.8125]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 71us/step - loss: 266766.7500\n",
      "rewards:  164.0 q-value:  0\n",
      "loss: [266766.75]\n",
      "Exploring\n",
      "Selected action  [2 1]\n",
      "[2 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 78us/step - loss: 186354.3438\n",
      "rewards:  174.0 q-value:  0\n",
      "loss: [186354.34375]\n",
      "Exploring\n",
      "Selected action  [4 2]\n",
      "[4 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 66us/step - loss: 356687.5938\n",
      "rewards:  182.0 q-value:  0\n",
      "loss: [356687.59375]\n",
      "Exploring\n",
      "Selected action  [2 3]\n",
      "[2 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 64us/step - loss: 263446.1875\n",
      "rewards:  194.0 q-value:  0\n",
      "loss: [263446.1875]\n",
      "Exploiting\n",
      "Selected action  [0 2]\n",
      "[0 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 72us/step - loss: 480884.2500\n",
      "rewards:  218.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [480884.25]\n",
      "Exploring\n",
      "Selected action  [2 3]\n",
      "[2 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 68us/step - loss: 142509.0312\n",
      "rewards:  242.0 q-value:  0\n",
      "loss: [142509.03125]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 66us/step - loss: 249913.5312\n",
      "rewards:  237.0 q-value:  0\n",
      "loss: [249913.53125]\n",
      "Exploring\n",
      "Selected action  [0 2]\n",
      "[0 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 67us/step - loss: 38621.6562\n",
      "rewards:  261.0 q-value:  0\n",
      "loss: [38621.65625]\n",
      "Exploring\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 58us/step - loss: 170862.7500\n",
      "rewards:  254.0 q-value:  0\n",
      "loss: [170862.75]\n",
      "Exploring\n",
      "Selected action  [0 3]\n",
      "[0 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 61us/step - loss: 400236.7812\n",
      "rewards:  253.0 q-value:  0\n",
      "loss: [400236.78125]\n",
      "Exploring\n",
      "Selected action  [2 3]\n",
      "[2 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 91us/step - loss: 395763.8750\n",
      "rewards:  249.0 q-value:  0\n",
      "loss: [395763.875]\n",
      "Exploring\n",
      "Selected action  [2 1]\n",
      "[2 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 73us/step - loss: 282714.6562\n",
      "rewards:  273.0 q-value:  0\n",
      "loss: [282714.65625]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 71us/step - loss: 69117.5625\n",
      "rewards:  268.0 q-value:  0\n",
      "loss: [69117.5625]\n",
      "Exploring\n",
      "Selected action  [0 3]\n",
      "[0 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 71us/step - loss: 566217.0000\n",
      "rewards:  300.0 q-value:  0\n",
      "loss: [566217.0]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 73us/step - loss: 148805.7500\n",
      "rewards:  319.0 q-value:  0\n",
      "loss: [148805.75]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 83us/step - loss: 184713.0781\n",
      "rewards:  314.0 q-value:  0\n",
      "loss: [184713.078125]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 65us/step - loss: 519004.0312\n",
      "rewards:  309.0 q-value:  0\n",
      "loss: [519004.03125]\n",
      "Exploiting\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 86us/step - loss: 429031.0938\n",
      "rewards:  304.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [429031.09375]\n",
      "Exploring\n",
      "Selected action  [0 2]\n",
      "[0 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 80us/step - loss: 271628.0312\n",
      "rewards:  328.0 q-value:  0\n",
      "loss: [271628.03125]\n",
      "Exploring\n",
      "Selected action  [3 4]\n",
      "[3 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 59us/step - loss: 623995.1250\n",
      "rewards:  322.0 q-value:  0\n",
      "loss: [623995.125]\n",
      "Exploring\n",
      "Selected action  [0 3]\n",
      "[0 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 70us/step - loss: 254015.3438\n",
      "rewards:  304.0 q-value:  0\n",
      "loss: [254015.34375]\n",
      "Exploring\n",
      "Selected action  [3 4]\n",
      "[3 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 84us/step - loss: 305803.5625\n",
      "rewards:  316.0 q-value:  0\n",
      "loss: [305803.5625]\n",
      "Exploring\n",
      "Selected action  [4 0]\n",
      "[4 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 69us/step - loss: 188509.3750\n",
      "rewards:  320.0 q-value:  0\n",
      "loss: [188509.375]\n",
      "Exploring\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 69us/step - loss: 483136.1875\n",
      "rewards:  305.0 q-value:  0\n",
      "loss: [483136.1875]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 68us/step - loss: 229272.1875\n",
      "rewards:  322.0 q-value:  0\n",
      "loss: [229272.1875]\n",
      "Exploring\n",
      "Selected action  [4 2]\n",
      "[4 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 64us/step - loss: 586883.5625\n",
      "rewards:  307.0 q-value:  0\n",
      "loss: [586883.5625]\n",
      "Exploring\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 91us/step - loss: 258514.2500\n",
      "rewards:  269.0 q-value:  0\n",
      "loss: [258514.25]\n",
      "Exploring\n",
      "Selected action  [3 0]\n",
      "[3 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 86us/step - loss: 324616.3125\n",
      "rewards:  273.0 q-value:  0\n",
      "loss: [324616.3125]\n",
      "Exploring\n",
      "Selected action  [3 4]\n",
      "[3 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 115us/step - loss: 168479.1875\n",
      "rewards:  284.0 q-value:  0\n",
      "loss: [168479.1875]\n",
      "Exploring\n",
      "Selected action  [0 3]\n",
      "[0 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 82us/step - loss: 115702.6406\n",
      "rewards:  295.0 q-value:  0\n",
      "loss: [115702.640625]\n",
      "Exploring\n",
      "Selected action  [3 0]\n",
      "[3 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 80us/step - loss: 493207.4375\n",
      "rewards:  319.0 q-value:  0\n",
      "loss: [493207.4375]\n",
      "Exploiting\n",
      "Selected action  [3 4]\n",
      "[3 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 64us/step - loss: 515517.1250\n",
      "rewards:  323.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [515517.125]\n",
      "Exploring\n",
      "Selected action  [0 3]\n",
      "[0 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 89us/step - loss: 583093.0000\n",
      "rewards:  330.0 q-value:  0\n",
      "loss: [583093.0]\n",
      "Exploring\n",
      "Selected action  [2 1]\n",
      "[2 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 64us/step - loss: 322819.0312\n",
      "rewards:  329.0 q-value:  0\n",
      "loss: [322819.03125]\n",
      "Exploring\n",
      "Selected action  [2 1]\n",
      "[2 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 80us/step - loss: 251008.1094\n",
      "rewards:  322.0 q-value:  0\n",
      "loss: [251008.109375]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 73us/step - loss: 242575.8125\n",
      "rewards:  346.0 q-value:  0\n",
      "loss: [242575.8125]\n",
      "Exploring\n",
      "Selected action  [2 1]\n",
      "[2 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 79us/step - loss: 456035.1875\n",
      "rewards:  339.0 q-value:  0\n",
      "loss: [456035.1875]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 78us/step - loss: 359230.6250\n",
      "rewards:  334.0 q-value:  0\n",
      "loss: [359230.625]\n",
      "Exploring\n",
      "Selected action  [0 2]\n",
      "[0 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 80us/step - loss: 203959.9688\n",
      "rewards:  354.0 q-value:  0\n",
      "loss: [203959.96875]\n",
      "Exploring\n",
      "Selected action  [2 3]\n",
      "[2 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 57us/step - loss: 161252.1875\n",
      "rewards:  362.0 q-value:  0\n",
      "loss: [161252.1875]\n",
      "Exploiting\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 67us/step - loss: 366053.1250\n",
      "rewards:  357.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [366053.125]\n",
      "Exploring\n",
      "Selected action  [3 4]\n",
      "[3 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 68us/step - loss: 599538.5625\n",
      "rewards:  385.0 q-value:  0\n",
      "loss: [599538.5625]\n",
      "Exploring\n",
      "Selected action  [2 1]\n",
      "[2 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 75us/step - loss: 584774.1250\n",
      "rewards:  379.0 q-value:  0\n",
      "loss: [584774.125]\n",
      "Exploring\n",
      "Selected action  [2 1]\n",
      "[2 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 76us/step - loss: 212555.4688\n",
      "rewards:  378.0 q-value:  0\n",
      "loss: [212555.46875]\n",
      "Exploring\n",
      "Selected action  [0 3]\n",
      "[0 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 65us/step - loss: 653861.1250\n",
      "rewards:  366.0 q-value:  0\n",
      "loss: [653861.125]\n",
      "Exploring\n",
      "Selected action  [3 4]\n",
      "[3 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 75us/step - loss: 498739.3438\n",
      "rewards:  402.0 q-value:  0\n",
      "loss: [498739.34375]\n",
      "Exploring\n",
      "Selected action  [0 3]\n",
      "[0 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 57us/step - loss: 146461.5938\n",
      "rewards:  421.0 q-value:  0\n",
      "loss: [146461.59375]\n",
      "Exploiting\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 144us/step - loss: 228494.0938\n",
      "rewards:  416.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [228494.09375]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 96us/step - loss: 91213.5938\n",
      "rewards:  409.0 q-value:  0\n",
      "loss: [91213.59375]\n",
      "Exploring\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 62us/step - loss: 537453.4375\n",
      "rewards:  382.0 q-value:  0\n",
      "loss: [537453.4375]\n",
      "Exploiting\n",
      "Selected action  [2 1]\n",
      "[2 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 77us/step - loss: 148068.3750\n",
      "rewards:  379.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [148068.375]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 77us/step - loss: 159989.9375\n",
      "rewards:  374.0 q-value:  0\n",
      "loss: [159989.9375]\n",
      "Exploring\n",
      "Selected action  [0 3]\n",
      "[0 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 72us/step - loss: 313080.1562\n",
      "rewards:  378.0 q-value:  0\n",
      "loss: [313080.15625]\n",
      "Exploring\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 66us/step - loss: 221705.5312\n",
      "rewards:  376.0 q-value:  0\n",
      "loss: [221705.53125]\n",
      "Exploring\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 95us/step - loss: 715186.6250\n",
      "rewards:  374.0 q-value:  0\n",
      "loss: [715186.625]\n",
      "Exploiting\n",
      "Selected action  [0 3]\n",
      "[0 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 66us/step - loss: 428728.3125\n",
      "rewards:  366.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [428728.3125]\n",
      "Exploring\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 72us/step - loss: 142674.6875\n",
      "rewards:  364.0 q-value:  0\n",
      "loss: [142674.6875]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 111us/step - loss: 650194.2500\n",
      "rewards:  359.0 q-value:  0\n",
      "loss: [650194.25]\n",
      "Exploring\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 74us/step - loss: 293749.5000\n",
      "rewards:  322.0 q-value:  0\n",
      "loss: [293749.5]\n",
      "Exploring\n",
      "Selected action  [0 3]\n",
      "[0 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 80us/step - loss: 242545.2812\n",
      "rewards:  320.0 q-value:  0\n",
      "loss: [242545.28125]\n",
      "Number of actions available 10\n",
      "Episode : 15\n",
      "Exploring\n",
      "Selected action  [1 4]\n",
      "[1 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 72us/step - loss: 508905.6562\n",
      "rewards:  -12.0 q-value:  0\n",
      "loss: [508905.65625]\n",
      "Exploring\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 86us/step - loss: 676038.2500\n",
      "rewards:  7.0 q-value:  0\n",
      "loss: [676038.25]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 134us/step - loss: 591392.6250\n",
      "rewards:  2.0 q-value:  0\n",
      "loss: [591392.625]\n",
      "Exploring\n",
      "Selected action  [3 0]\n",
      "[3 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 119us/step - loss: 212241.1562\n",
      "rewards:  -1.0 q-value:  0\n",
      "loss: [212241.15625]\n",
      "Exploring\n",
      "Selected action  [3 1]\n",
      "[3 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 55us/step - loss: 632585.0000\n",
      "rewards:  -1.0 q-value:  0\n",
      "loss: [632585.0]\n",
      "Exploring\n",
      "Selected action  [3 1]\n",
      "[3 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 71us/step - loss: 563890.7500\n",
      "rewards:  -1.0 q-value:  0\n",
      "loss: [563890.75]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 57us/step - loss: 247628.8438\n",
      "rewards:  -3.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [247628.84375]\n",
      "Exploring\n",
      "Selected action  [2 3]\n",
      "[2 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 124us/step - loss: 506896.7500\n",
      "rewards:  19.0 q-value:  0\n",
      "loss: [506896.75]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 58us/step - loss: 316674.6562\n",
      "rewards:  -7.0 q-value:  0\n",
      "loss: [316674.65625]\n",
      "Exploring\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 67us/step - loss: 111118.8750\n",
      "rewards:  -7.0 q-value:  0\n",
      "loss: [111118.875]\n",
      "Exploring\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 77us/step - loss: 481369.5312\n",
      "rewards:  14.0 q-value:  0\n",
      "loss: [481369.53125]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 76us/step - loss: 152721.4375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rewards:  10.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [152721.4375]\n",
      "Exploring\n",
      "Selected action  [1 4]\n",
      "[1 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 229us/step - loss: 375540.2188\n",
      "rewards:  26.0 q-value:  0\n",
      "loss: [375540.21875]\n",
      "Exploring\n",
      "Selected action  [3 1]\n",
      "[3 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 68us/step - loss: 258063.8125\n",
      "rewards:  5.0 q-value:  0\n",
      "loss: [258063.8125]\n",
      "Exploring\n",
      "Selected action  [0 2]\n",
      "[0 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 82us/step - loss: 287282.8438\n",
      "rewards:  14.0 q-value:  0\n",
      "loss: [287282.84375]\n",
      "Exploring\n",
      "Selected action  [0 2]\n",
      "[0 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 50us/step - loss: 105021.5938\n",
      "rewards:  8.0 q-value:  0\n",
      "loss: [105021.59375]\n",
      "Exploring\n",
      "Selected action  [2 3]\n",
      "[2 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 57us/step - loss: 288764.1250\n",
      "rewards:  20.0 q-value:  0\n",
      "loss: [288764.125]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 58us/step - loss: 275901.6562\n",
      "rewards:  9.0 q-value:  0\n",
      "loss: [275901.65625]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 65us/step - loss: 150758.5000\n",
      "rewards:  32.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [150758.5]\n",
      "Exploring\n",
      "Selected action  [3 0]\n",
      "[3 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 82us/step - loss: 493457.5312\n",
      "rewards:  26.0 q-value:  0\n",
      "loss: [493457.53125]\n",
      "Exploring\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 73us/step - loss: 259647.0156\n",
      "rewards:  31.0 q-value:  0\n",
      "loss: [259647.015625]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 101us/step - loss: 645141.7500\n",
      "rewards:  3.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [645141.75]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 80us/step - loss: 864482.1250\n",
      "rewards:  -1.0 q-value:  0\n",
      "loss: [864482.125]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 67us/step - loss: 323525.1250\n",
      "rewards:  18.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [323525.125]\n",
      "Exploring\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 56us/step - loss: 474698.5938\n",
      "rewards:  12.0 q-value:  0\n",
      "loss: [474698.59375]\n",
      "Exploring\n",
      "Selected action  [1 4]\n",
      "[1 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 64us/step - loss: 229603.4062\n",
      "rewards:  20.0 q-value:  0\n",
      "loss: [229603.40625]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 60us/step - loss: 426912.5625\n",
      "rewards:  15.0 q-value:  0\n",
      "loss: [426912.5625]\n",
      "Exploring\n",
      "Selected action  [1 4]\n",
      "[1 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 56us/step - loss: 300785.1562\n",
      "rewards:  -2.0 q-value:  0\n",
      "loss: [300785.15625]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 74us/step - loss: 317892.1875\n",
      "rewards:  -7.0 q-value:  0\n",
      "loss: [317892.1875]\n",
      "Exploring\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 65us/step - loss: 68825.0000\n",
      "rewards:  -20.0 q-value:  0\n",
      "loss: [68825.0]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 61us/step - loss: 342743.5625\n",
      "rewards:  -25.0 q-value:  0\n",
      "loss: [342743.5625]\n",
      "Exploring\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 67us/step - loss: 222096.5938\n",
      "rewards:  3.0 q-value:  0\n",
      "loss: [222096.59375]\n",
      "Exploring\n",
      "Selected action  [3 1]\n",
      "[3 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 66us/step - loss: 362792.2500\n",
      "rewards:  -1.0 q-value:  0\n",
      "loss: [362792.25]\n",
      "Exploring\n",
      "Selected action  [3 0]\n",
      "[3 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 62us/step - loss: 366881.9688\n",
      "rewards:  6.0 q-value:  0\n",
      "loss: [366881.96875]\n",
      "Exploring\n",
      "Selected action  [4 1]\n",
      "[4 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 74us/step - loss: 83058.7812\n",
      "rewards:  -24.0 q-value:  0\n",
      "loss: [83058.78125]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 52us/step - loss: 449733.8750\n",
      "rewards:  -26.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [449733.875]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 53us/step - loss: 343414.8438\n",
      "rewards:  -66.0 q-value:  0\n",
      "loss: [343414.84375]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 78us/step - loss: 309225.0312\n",
      "rewards:  -88.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [309225.03125]\n",
      "Exploring\n",
      "Selected action  [4 1]\n",
      "[4 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 62us/step - loss: 429033.3438\n",
      "rewards:  -91.0 q-value:  0\n",
      "loss: [429033.34375]\n",
      "Exploring\n",
      "Selected action  [2 3]\n",
      "[2 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 83us/step - loss: 689838.5625\n",
      "rewards:  -102.0 q-value:  0\n",
      "loss: [689838.5625]\n",
      "Exploring\n",
      "Selected action  [3 1]\n",
      "[3 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 74us/step - loss: 505541.7188\n",
      "rewards:  -90.0 q-value:  0\n",
      "loss: [505541.71875]\n",
      "Exploring\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 69us/step - loss: 318422.8750\n",
      "rewards:  -93.0 q-value:  0\n",
      "loss: [318422.875]\n",
      "Exploring\n",
      "Selected action  [4 1]\n",
      "[4 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 81us/step - loss: 285248.1250\n",
      "rewards:  -95.0 q-value:  0\n",
      "loss: [285248.125]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 61us/step - loss: 78270.5312\n",
      "rewards:  -145.0 q-value:  0\n",
      "loss: [78270.53125]\n",
      "Exploring\n",
      "Selected action  [4 1]\n",
      "[4 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 69us/step - loss: 232085.5938\n",
      "rewards:  -145.0 q-value:  0\n",
      "loss: [232085.59375]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 109us/step - loss: 185503.1562\n",
      "rewards:  -152.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [185503.15625]\n",
      "Exploring\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 56us/step - loss: 208981.7500\n",
      "rewards:  -136.0 q-value:  0\n",
      "loss: [208981.75]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 59us/step - loss: 116515.3750\n",
      "rewards:  -156.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [116515.375]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 76us/step - loss: 409834.7500\n",
      "rewards:  -156.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [409834.75]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 55us/step - loss: 300091.1875\n",
      "rewards:  -201.0 q-value:  0\n",
      "loss: [300091.1875]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 69us/step - loss: 443317.7812\n",
      "rewards:  -206.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [443317.78125]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 66us/step - loss: 397482.8125\n",
      "rewards:  -211.0 q-value:  0\n",
      "loss: [397482.8125]\n",
      "Exploring\n",
      "Selected action  [2 3]\n",
      "[2 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 59us/step - loss: 371835.3750\n",
      "rewards:  -202.0 q-value:  0\n",
      "loss: [371835.375]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 71us/step - loss: 386610.3125\n",
      "rewards:  -206.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [386610.3125]\n",
      "Exploring\n",
      "Selected action  [3 0]\n",
      "[3 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 86us/step - loss: 246414.5000\n",
      "rewards:  -204.0 q-value:  0\n",
      "loss: [246414.5]\n",
      "Exploring\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 56us/step - loss: 442860.6875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rewards:  -188.0 q-value:  0\n",
      "loss: [442860.6875]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 62us/step - loss: 119726.9688\n",
      "rewards:  -194.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [119726.96875]\n",
      "Exploring\n",
      "Selected action  [4 1]\n",
      "[4 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 86us/step - loss: 308662.8438\n",
      "rewards:  -201.0 q-value:  0\n",
      "loss: [308662.84375]\n",
      "Exploring\n",
      "Selected action  [1 4]\n",
      "[1 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 75us/step - loss: 572725.0000\n",
      "rewards:  -193.0 q-value:  0\n",
      "loss: [572725.0]\n",
      "Exploring\n",
      "Selected action  [3 0]\n",
      "[3 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 60us/step - loss: 159818.7188\n",
      "rewards:  -196.0 q-value:  0\n",
      "loss: [159818.71875]\n",
      "Exploring\n",
      "Selected action  [0 2]\n",
      "[0 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 63us/step - loss: 467715.4062\n",
      "rewards:  -176.0 q-value:  0\n",
      "loss: [467715.40625]\n",
      "Exploring\n",
      "Selected action  [3 1]\n",
      "[3 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 80us/step - loss: 309943.0000\n",
      "rewards:  -186.0 q-value:  0\n",
      "loss: [309943.0]\n",
      "Exploring\n",
      "Selected action  [3 0]\n",
      "[3 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 56us/step - loss: 221450.0938\n",
      "rewards:  -179.0 q-value:  0\n",
      "loss: [221450.09375]\n",
      "Exploring\n",
      "Selected action  [0 2]\n",
      "[0 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 74us/step - loss: 380063.6562\n",
      "rewards:  -155.0 q-value:  0\n",
      "loss: [380063.65625]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 73us/step - loss: 73851.5000\n",
      "rewards:  -149.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [73851.5]\n",
      "Exploring\n",
      "Selected action  [3 1]\n",
      "[3 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 67us/step - loss: 259033.8438\n",
      "rewards:  -150.0 q-value:  0\n",
      "loss: [259033.84375]\n",
      "Exploring\n",
      "Selected action  [3 0]\n",
      "[3 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 60us/step - loss: 69886.6875\n",
      "rewards:  -155.0 q-value:  0\n",
      "loss: [69886.6875]\n",
      "Exploring\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 53us/step - loss: 561646.3750\n",
      "rewards:  -161.0 q-value:  0\n",
      "loss: [561646.375]\n",
      "Exploring\n",
      "Selected action  [3 0]\n",
      "[3 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 59us/step - loss: 152141.5312\n",
      "rewards:  -161.0 q-value:  0\n",
      "loss: [152141.53125]\n",
      "Exploring\n",
      "Selected action  [2 3]\n",
      "[2 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 66us/step - loss: 396177.5000\n",
      "rewards:  -179.0 q-value:  0\n",
      "loss: [396177.5]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 71us/step - loss: 88677.9375\n",
      "rewards:  -197.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [88677.9375]\n",
      "Exploring\n",
      "Selected action  [0 2]\n",
      "[0 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 55us/step - loss: 314100.7500\n",
      "rewards:  -188.0 q-value:  0\n",
      "loss: [314100.75]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 73us/step - loss: 734729.0000\n",
      "rewards:  -193.0 q-value:  0\n",
      "loss: [734729.0]\n",
      "Exploring\n",
      "Selected action  [2 3]\n",
      "[2 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 74us/step - loss: 134699.8750\n",
      "rewards:  -203.0 q-value:  0\n",
      "loss: [134699.875]\n",
      "Exploring\n",
      "Selected action  [0 2]\n",
      "[0 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 60us/step - loss: 393841.9375\n",
      "rewards:  -196.0 q-value:  0\n",
      "loss: [393841.9375]\n",
      "Exploring\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 80us/step - loss: 303443.6875\n",
      "rewards:  -194.0 q-value:  0\n",
      "loss: [303443.6875]\n",
      "Exploring\n",
      "Selected action  [3 1]\n",
      "[3 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 65us/step - loss: 75180.8750\n",
      "rewards:  -196.0 q-value:  0\n",
      "loss: [75180.875]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 78us/step - loss: 45932.0312\n",
      "rewards:  -243.0 q-value:  0\n",
      "loss: [45932.03125]\n",
      "Exploring\n",
      "Selected action  [3 0]\n",
      "[3 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 66us/step - loss: 102037.7969\n",
      "rewards:  -216.0 q-value:  0\n",
      "loss: [102037.796875]\n",
      "Exploring\n",
      "Selected action  [3 0]\n",
      "[3 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 74us/step - loss: 510483.3438\n",
      "rewards:  -224.0 q-value:  0\n",
      "loss: [510483.34375]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 52us/step - loss: 66350.1562\n",
      "rewards:  -229.0 q-value:  0\n",
      "loss: [66350.15625]\n",
      "Exploring\n",
      "Selected action  [0 2]\n",
      "[0 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 68us/step - loss: 240724.1250\n",
      "rewards:  -225.0 q-value:  0\n",
      "loss: [240724.125]\n",
      "Exploring\n",
      "Selected action  [2 3]\n",
      "[2 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 58us/step - loss: 250090.1250\n",
      "rewards:  -209.0 q-value:  0\n",
      "loss: [250090.125]\n",
      "Exploring\n",
      "Selected action  [3 1]\n",
      "[3 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 74us/step - loss: 168235.4688\n",
      "rewards:  -205.0 q-value:  0\n",
      "loss: [168235.46875]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 67us/step - loss: 262967.9375\n",
      "rewards:  -210.0 q-value:  0\n",
      "loss: [262967.9375]\n",
      "Exploring\n",
      "Selected action  [3 0]\n",
      "[3 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 63us/step - loss: 316794.6875\n",
      "rewards:  -212.0 q-value:  0\n",
      "loss: [316794.6875]\n",
      "Exploring\n",
      "Selected action  [3 0]\n",
      "[3 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 84us/step - loss: 467156.7812\n",
      "rewards:  -217.0 q-value:  0\n",
      "loss: [467156.78125]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 59us/step - loss: 568765.3750\n",
      "rewards:  -227.0 q-value:  0\n",
      "loss: [568765.375]\n",
      "Exploring\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 75us/step - loss: 448488.2188\n",
      "rewards:  -209.0 q-value:  0\n",
      "loss: [448488.21875]\n",
      "Exploring\n",
      "Selected action  [3 0]\n",
      "[3 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 73us/step - loss: 332935.4375\n",
      "rewards:  -202.0 q-value:  0\n",
      "loss: [332935.4375]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 79us/step - loss: 68576.4375\n",
      "rewards:  -194.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [68576.4375]\n",
      "Exploring\n",
      "Selected action  [3 0]\n",
      "[3 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 62us/step - loss: 420901.1875\n",
      "rewards:  -187.0 q-value:  0\n",
      "loss: [420901.1875]\n",
      "Exploring\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 82us/step - loss: 146861.5000\n",
      "rewards:  -202.0 q-value:  0\n",
      "loss: [146861.5]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 57us/step - loss: 57727.8125\n",
      "rewards:  -185.0 q-value:  0\n",
      "loss: [57727.8125]\n",
      "Exploring\n",
      "Selected action  [4 1]\n",
      "[4 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 63us/step - loss: 261891.3125\n",
      "rewards:  -177.0 q-value:  0\n",
      "loss: [261891.3125]\n",
      "Exploring\n",
      "Selected action  [0 2]\n",
      "[0 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 78us/step - loss: 481283.2812\n",
      "rewards:  -180.0 q-value:  0\n",
      "loss: [481283.28125]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 60us/step - loss: 61988.5000\n",
      "rewards:  -172.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [61988.5]\n",
      "Exploring\n",
      "Selected action  [0 2]\n",
      "[0 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 66us/step - loss: 264326.5938\n",
      "rewards:  -144.0 q-value:  0\n",
      "loss: [264326.59375]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 70us/step - loss: 463632.8438\n",
      "rewards:  -149.0 q-value:  0\n",
      "loss: [463632.84375]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 67us/step - loss: 471086.6562\n",
      "rewards:  -154.0 q-value:  0\n",
      "loss: [471086.65625]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 70us/step - loss: 633696.1250\n",
      "rewards:  -159.0 q-value:  0\n",
      "loss: [633696.125]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 80us/step - loss: 503023.6875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rewards:  -162.0 q-value:  0\n",
      "loss: [503023.6875]\n",
      "Exploring\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 71us/step - loss: 467356.3750\n",
      "rewards:  -151.0 q-value:  0\n",
      "loss: [467356.375]\n",
      "Exploring\n",
      "Selected action  [3 0]\n",
      "[3 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 86us/step - loss: 266649.6875\n",
      "rewards:  -149.0 q-value:  0\n",
      "loss: [266649.6875]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 69us/step - loss: 455392.8125\n",
      "rewards:  -154.0 q-value:  0\n",
      "loss: [455392.8125]\n",
      "Exploring\n",
      "Selected action  [3 1]\n",
      "[3 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 76us/step - loss: 519272.6875\n",
      "rewards:  -168.0 q-value:  0\n",
      "loss: [519272.6875]\n",
      "Exploring\n",
      "Selected action  [1 4]\n",
      "[1 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 61us/step - loss: 126852.8125\n",
      "rewards:  -160.0 q-value:  0\n",
      "loss: [126852.8125]\n",
      "Exploring\n",
      "Selected action  [2 3]\n",
      "[2 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 59us/step - loss: 209551.2500\n",
      "rewards:  -156.0 q-value:  0\n",
      "loss: [209551.25]\n",
      "Exploring\n",
      "Selected action  [2 3]\n",
      "[2 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 99us/step - loss: 371025.7812\n",
      "rewards:  -164.0 q-value:  0\n",
      "loss: [371025.78125]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 59us/step - loss: 564761.9375\n",
      "rewards:  -171.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [564761.9375]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 73us/step - loss: 176305.9062\n",
      "rewards:  -173.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [176305.90625]\n",
      "Exploring\n",
      "Selected action  [3 1]\n",
      "[3 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 87us/step - loss: 397568.8125\n",
      "rewards:  -178.0 q-value:  0\n",
      "loss: [397568.8125]\n",
      "Exploring\n",
      "Selected action  [4 1]\n",
      "[4 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 95us/step - loss: 187080.7188\n",
      "rewards:  -181.0 q-value:  0\n",
      "loss: [187080.71875]\n",
      "Exploring\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 82us/step - loss: 207703.1562\n",
      "rewards:  -177.0 q-value:  0\n",
      "loss: [207703.15625]\n",
      "Exploring\n",
      "Selected action  [0 2]\n",
      "[0 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 70us/step - loss: 299969.2500\n",
      "rewards:  -168.0 q-value:  0\n",
      "loss: [299969.25]\n",
      "Number of actions available 11\n",
      "Episode : 16\n",
      "Exploring\n",
      "Selected action  [2 3]\n",
      "[2 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 82us/step - loss: 391018.8438\n",
      "rewards:  -9.0 q-value:  0\n",
      "loss: [391018.84375]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 61us/step - loss: 219838.8438\n",
      "rewards:  -1.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [219838.84375]\n",
      "Exploring\n",
      "Selected action  [0 4]\n",
      "[0 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 97us/step - loss: 364102.0625\n",
      "rewards:  -7.0 q-value:  0\n",
      "loss: [364102.0625]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 57us/step - loss: 231854.3438\n",
      "rewards:  -4.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [231854.34375]\n",
      "Exploring\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 116us/step - loss: 244293.8438\n",
      "rewards:  -2.0 q-value:  0\n",
      "loss: [244293.84375]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 49us/step - loss: 202031.1875\n",
      "rewards:  6.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [202031.1875]\n",
      "Exploring\n",
      "Selected action  [1 2]\n",
      "[1 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 42us/step - loss: 129528.9688\n",
      "rewards:  38.0 q-value:  0\n",
      "loss: [129528.96875]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 60us/step - loss: 440383.1562\n",
      "rewards:  44.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [440383.15625]\n",
      "Exploring\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 69us/step - loss: 355881.0000\n",
      "rewards:  47.0 q-value:  0\n",
      "loss: [355881.0]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 71us/step - loss: 109877.7188\n",
      "rewards:  45.0 q-value:  0\n",
      "loss: [109877.71875]\n",
      "Exploring\n",
      "Selected action  [4 3]\n",
      "[4 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 78us/step - loss: 629608.0000\n",
      "rewards:  65.0 q-value:  0\n",
      "loss: [629608.0]\n",
      "Exploring\n",
      "Selected action  [2 3]\n",
      "[2 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 97us/step - loss: 434058.6250\n",
      "rewards:  59.0 q-value:  0\n",
      "loss: [434058.625]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 93us/step - loss: 140493.6250\n",
      "rewards:  72.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [140493.625]\n",
      "Exploring\n",
      "Selected action  [4 3]\n",
      "[4 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 95us/step - loss: 482074.4062\n",
      "rewards:  96.0 q-value:  0\n",
      "loss: [482074.40625]\n",
      "Exploring\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 58us/step - loss: 508250.5938\n",
      "rewards:  94.0 q-value:  0\n",
      "loss: [508250.59375]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 57us/step - loss: 465766.7188\n",
      "rewards:  101.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [465766.71875]\n",
      "Exploring\n",
      "Selected action  [2 3]\n",
      "[2 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 77us/step - loss: 173647.8750\n",
      "rewards:  88.0 q-value:  0\n",
      "loss: [173647.875]\n",
      "Exploring\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 77us/step - loss: 637889.7500\n",
      "rewards:  83.0 q-value:  0\n",
      "loss: [637889.75]\n",
      "Exploring\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 127us/step - loss: 37907.6250\n",
      "rewards:  81.0 q-value:  0\n",
      "loss: [37907.625]\n",
      "Exploring\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 72us/step - loss: 379492.7500\n",
      "rewards:  90.0 q-value:  0\n",
      "loss: [379492.75]\n",
      "Exploring\n",
      "Selected action  [2 3]\n",
      "[2 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 62us/step - loss: 186997.9688\n",
      "rewards:  101.0 q-value:  0\n",
      "loss: [186997.96875]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 60us/step - loss: 187959.4688\n",
      "rewards:  96.0 q-value:  0\n",
      "loss: [187959.46875]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 64us/step - loss: 309869.7500\n",
      "rewards:  120.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [309869.75]\n",
      "Exploring\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 57us/step - loss: 339579.0312\n",
      "rewards:  115.0 q-value:  0\n",
      "loss: [339579.03125]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 61us/step - loss: 112521.6562\n",
      "rewards:  85.0 q-value:  0\n",
      "loss: [112521.65625]\n",
      "Exploring\n",
      "Selected action  [2 3]\n",
      "[2 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 72us/step - loss: 496044.5312\n",
      "rewards:  104.0 q-value:  0\n",
      "loss: [496044.53125]\n",
      "Exploring\n",
      "Selected action  [2 3]\n",
      "[2 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 55us/step - loss: 95163.1875\n",
      "rewards:  104.0 q-value:  0\n",
      "loss: [95163.1875]\n",
      "Exploring\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 98us/step - loss: 201813.2812\n",
      "rewards:  103.0 q-value:  0\n",
      "loss: [201813.28125]\n",
      "Exploring\n",
      "Selected action  [1 2]\n",
      "[1 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 76us/step - loss: 638096.7500\n",
      "rewards:  130.0 q-value:  0\n",
      "loss: [638096.75]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 71us/step - loss: 80368.6250\n",
      "rewards:  125.0 q-value:  0\n",
      "loss: [80368.625]\n",
      "Exploring\n",
      "Selected action  [0 4]\n",
      "[0 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 74us/step - loss: 469947.3750\n",
      "rewards:  129.0 q-value:  0\n",
      "loss: [469947.375]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 83us/step - loss: 540754.5000\n",
      "rewards:  124.0 q-value:  0\n",
      "loss: [540754.5]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 72us/step - loss: 477729.7812\n",
      "rewards:  113.0 q-value:  0\n",
      "loss: [477729.78125]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 78us/step - loss: 188015.0000\n",
      "rewards:  112.0 q-value:  0\n",
      "loss: [188015.0]\n",
      "Exploring\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 76us/step - loss: 433620.5312\n",
      "rewards:  94.0 q-value:  0\n",
      "loss: [433620.53125]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 66us/step - loss: 230869.0000\n",
      "rewards:  89.0 q-value:  0\n",
      "loss: [230869.0]\n",
      "Exploring\n",
      "Selected action  [4 3]\n",
      "[4 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 60us/step - loss: 113345.2812\n",
      "rewards:  109.0 q-value:  0\n",
      "loss: [113345.28125]\n",
      "Exploring\n",
      "Selected action  [2 3]\n",
      "[2 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 88us/step - loss: 240818.7500\n",
      "rewards:  101.0 q-value:  0\n",
      "loss: [240818.75]\n",
      "Exploring\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 61us/step - loss: 234169.4062\n",
      "rewards:  98.0 q-value:  0\n",
      "loss: [234169.40625]\n",
      "Exploring\n",
      "Selected action  [4 3]\n",
      "[4 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 89us/step - loss: 360888.7812\n",
      "rewards:  96.0 q-value:  0\n",
      "loss: [360888.78125]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 64us/step - loss: 251867.0312\n",
      "rewards:  76.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [251867.03125]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 80us/step - loss: 250427.8125\n",
      "rewards:  71.0 q-value:  0\n",
      "loss: [250427.8125]\n",
      "Exploring\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 70us/step - loss: 484362.8438\n",
      "rewards:  87.0 q-value:  0\n",
      "loss: [484362.84375]\n",
      "Exploring\n",
      "Selected action  [0 4]\n",
      "[0 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 89us/step - loss: 534869.8750\n",
      "rewards:  57.0 q-value:  0\n",
      "loss: [534869.875]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 67us/step - loss: 268634.5938\n",
      "rewards:  52.0 q-value:  0\n",
      "loss: [268634.59375]\n",
      "Exploring\n",
      "Selected action  [0 4]\n",
      "[0 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 97us/step - loss: 272126.4062\n",
      "rewards:  52.0 q-value:  0\n",
      "loss: [272126.40625]\n",
      "Exploring\n",
      "Selected action  [1 2]\n",
      "[1 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 47us/step - loss: 250823.8438\n",
      "rewards:  71.0 q-value:  0\n",
      "loss: [250823.84375]\n",
      "Exploring\n",
      "Selected action  [1 2]\n",
      "[1 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 76us/step - loss: 399749.5000\n",
      "rewards:  65.0 q-value:  0\n",
      "loss: [399749.5]\n",
      "Exploring\n",
      "Selected action  [1 2]\n",
      "[1 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 68us/step - loss: 268084.9688\n",
      "rewards:  58.0 q-value:  0\n",
      "loss: [268084.96875]\n",
      "Exploring\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 103us/step - loss: 553022.3750\n",
      "rewards:  82.0 q-value:  0\n",
      "loss: [553022.375]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 91us/step - loss: 232666.1250\n",
      "rewards:  77.0 q-value:  0\n",
      "loss: [232666.125]\n",
      "Exploring\n",
      "Selected action  [2 3]\n",
      "[2 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 80us/step - loss: 278935.9375\n",
      "rewards:  94.0 q-value:  0\n",
      "loss: [278935.9375]\n",
      "Exploring\n",
      "Selected action  [4 3]\n",
      "[4 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 86us/step - loss: 94688.4375\n",
      "rewards:  91.0 q-value:  0\n",
      "loss: [94688.4375]\n",
      "Exploring\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 69us/step - loss: 398500.7188\n",
      "rewards:  69.0 q-value:  0\n",
      "loss: [398500.71875]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 76us/step - loss: 335544.0312\n",
      "rewards:  77.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [335544.03125]\n",
      "Exploring\n",
      "Selected action  [0 4]\n",
      "[0 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 64us/step - loss: 347087.1875\n",
      "rewards:  71.0 q-value:  0\n",
      "loss: [347087.1875]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 75us/step - loss: 259248.0000\n",
      "rewards:  70.0 q-value:  0\n",
      "loss: [259248.0]\n",
      "Exploring\n",
      "Selected action  [4 3]\n",
      "[4 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 56us/step - loss: 176667.0625\n",
      "rewards:  98.0 q-value:  0\n",
      "loss: [176667.0625]\n",
      "Exploring\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 89us/step - loss: 230892.3750\n",
      "rewards:  61.0 q-value:  0\n",
      "loss: [230892.375]\n",
      "Exploring\n",
      "Selected action  [2 3]\n",
      "[2 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 80us/step - loss: 81936.5000\n",
      "rewards:  87.0 q-value:  0\n",
      "loss: [81936.5]\n",
      "Exploring\n",
      "Selected action  [2 3]\n",
      "[2 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 71us/step - loss: 477229.2188\n",
      "rewards:  81.0 q-value:  0\n",
      "loss: [477229.21875]\n",
      "Exploring\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 58us/step - loss: 343420.5625\n",
      "rewards:  94.0 q-value:  0\n",
      "loss: [343420.5625]\n",
      "Exploring\n",
      "Selected action  [0 2]\n",
      "[0 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 76us/step - loss: 289153.9375\n",
      "rewards:  71.0 q-value:  0\n",
      "loss: [289153.9375]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 84us/step - loss: 205822.5938\n",
      "rewards:  66.0 q-value:  0\n",
      "loss: [205822.59375]\n",
      "Exploring\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 82us/step - loss: 574548.1875\n",
      "rewards:  94.0 q-value:  0\n",
      "loss: [574548.1875]\n",
      "Exploring\n",
      "Selected action  [0 2]\n",
      "[0 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 67us/step - loss: 232036.4688\n",
      "rewards:  87.0 q-value:  0\n",
      "loss: [232036.46875]\n",
      "Exploring\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 77us/step - loss: 411890.1250\n",
      "rewards:  107.0 q-value:  0\n",
      "loss: [411890.125]\n",
      "Exploring\n",
      "Selected action  [4 2]\n",
      "[4 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 65us/step - loss: 266483.2188\n",
      "rewards:  108.0 q-value:  0\n",
      "loss: [266483.21875]\n",
      "Exploring\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 85us/step - loss: 366610.0000\n",
      "rewards:  96.0 q-value:  0\n",
      "loss: [366610.0]\n",
      "Exploring\n",
      "Selected action  [4 3]\n",
      "[4 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 63us/step - loss: 314747.5312\n",
      "rewards:  90.0 q-value:  0\n",
      "loss: [314747.53125]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 70us/step - loss: 46634.5469\n",
      "rewards:  78.0 q-value:  0\n",
      "loss: [46634.546875]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 51us/step - loss: 152767.7344\n",
      "rewards:  67.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [152767.734375]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 72us/step - loss: 321728.6562\n",
      "rewards:  62.0 q-value:  0\n",
      "loss: [321728.65625]\n",
      "Exploring\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 85us/step - loss: 504520.7188\n",
      "rewards:  82.0 q-value:  0\n",
      "loss: [504520.71875]\n",
      "Exploring\n",
      "Selected action  [4 2]\n",
      "[4 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 62us/step - loss: 95766.8125\n",
      "rewards:  72.0 q-value:  0\n",
      "loss: [95766.8125]\n",
      "Exploring\n",
      "Selected action  [0 4]\n",
      "[0 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 95us/step - loss: 480741.9062\n",
      "rewards:  62.0 q-value:  0\n",
      "loss: [480741.90625]\n",
      "Exploring\n",
      "Selected action  [0 4]\n",
      "[0 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 65us/step - loss: 383929.6875\n",
      "rewards:  62.0 q-value:  0\n",
      "loss: [383929.6875]\n",
      "Exploring\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 64us/step - loss: 358863.9688\n",
      "rewards:  65.0 q-value:  0\n",
      "loss: [358863.96875]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 65us/step - loss: 84399.0000\n",
      "rewards:  60.0 q-value:  0\n",
      "loss: [84399.0]\n",
      "Exploring\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 97us/step - loss: 51443.1875\n",
      "rewards:  58.0 q-value:  0\n",
      "loss: [51443.1875]\n",
      "Exploring\n",
      "Selected action  [4 3]\n",
      "[4 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 61us/step - loss: 761884.0000\n",
      "rewards:  82.0 q-value:  0\n",
      "loss: [761884.0]\n",
      "Exploring\n",
      "Selected action  [4 2]\n",
      "[4 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 67us/step - loss: 639023.5000\n",
      "rewards:  52.0 q-value:  0\n",
      "loss: [639023.5]\n",
      "Exploring\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 82us/step - loss: 322969.2500\n",
      "rewards:  16.0 q-value:  0\n",
      "loss: [322969.25]\n",
      "Exploring\n",
      "Selected action  [1 2]\n",
      "[1 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 86us/step - loss: 805193.2500\n",
      "rewards:  43.0 q-value:  0\n",
      "loss: [805193.25]\n",
      "Exploring\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 57us/step - loss: 519788.0625\n",
      "rewards:  50.0 q-value:  0\n",
      "loss: [519788.0625]\n",
      "Exploring\n",
      "Selected action  [4 3]\n",
      "[4 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 79us/step - loss: 377015.0625\n",
      "rewards:  60.0 q-value:  0\n",
      "loss: [377015.0625]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 80us/step - loss: 244436.6250\n",
      "rewards:  83.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [244436.625]\n",
      "Exploring\n",
      "Selected action  [1 2]\n",
      "[1 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 62us/step - loss: 780129.7500\n",
      "rewards:  119.0 q-value:  0\n",
      "loss: [780129.75]\n",
      "Exploring\n",
      "Selected action  [4 3]\n",
      "[4 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 66us/step - loss: 517197.1250\n",
      "rewards:  143.0 q-value:  0\n",
      "loss: [517197.125]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 91us/step - loss: 641656.4375\n",
      "rewards:  118.0 q-value:  0\n",
      "loss: [641656.4375]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 81us/step - loss: 391629.5000\n",
      "rewards:  129.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [391629.5]\n",
      "Exploring\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 71us/step - loss: 132603.9375\n",
      "rewards:  137.0 q-value:  0\n",
      "loss: [132603.9375]\n",
      "Exploring\n",
      "Selected action  [4 3]\n",
      "[4 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 64us/step - loss: 288354.5625\n",
      "rewards:  135.0 q-value:  0\n",
      "loss: [288354.5625]\n",
      "Exploring\n",
      "Selected action  [4 3]\n",
      "[4 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 99us/step - loss: 332660.7812\n",
      "rewards:  133.0 q-value:  0\n",
      "loss: [332660.78125]\n",
      "Exploring\n",
      "Selected action  [4 3]\n",
      "[4 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 78us/step - loss: 509865.2812\n",
      "rewards:  131.0 q-value:  0\n",
      "loss: [509865.28125]\n",
      "Exploring\n",
      "Selected action  [2 3]\n",
      "[2 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 100us/step - loss: 77774.8438\n",
      "rewards:  125.0 q-value:  0\n",
      "loss: [77774.84375]\n",
      "Exploring\n",
      "Selected action  [0 4]\n",
      "[0 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 83us/step - loss: 510443.7500\n",
      "rewards:  129.0 q-value:  0\n",
      "loss: [510443.75]\n",
      "Exploring\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 64us/step - loss: 517704.3750\n",
      "rewards:  119.0 q-value:  0\n",
      "loss: [517704.375]\n",
      "Exploring\n",
      "Selected action  [0 4]\n",
      "[0 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 90us/step - loss: 370562.9688\n",
      "rewards:  123.0 q-value:  0\n",
      "loss: [370562.96875]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 89us/step - loss: 376168.4688\n",
      "rewards:  126.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [376168.46875]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 67us/step - loss: 436141.3438\n",
      "rewards:  116.0 q-value:  0\n",
      "loss: [436141.34375]\n",
      "Exploring\n",
      "Selected action  [0 4]\n",
      "[0 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 78us/step - loss: 230945.9062\n",
      "rewards:  115.0 q-value:  0\n",
      "loss: [230945.90625]\n",
      "Exploring\n",
      "Selected action  [1 2]\n",
      "[1 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 75us/step - loss: 90122.2812\n",
      "rewards:  113.0 q-value:  0\n",
      "loss: [90122.28125]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 76us/step - loss: 678818.8750\n",
      "rewards:  108.0 q-value:  0\n",
      "loss: [678818.875]\n",
      "Exploring\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 76us/step - loss: 172503.0312\n",
      "rewards:  98.0 q-value:  0\n",
      "loss: [172503.03125]\n",
      "Exploring\n",
      "Selected action  [0 4]\n",
      "[0 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 71us/step - loss: 353775.4375\n",
      "rewards:  115.0 q-value:  0\n",
      "loss: [353775.4375]\n",
      "Exploring\n",
      "Selected action  [1 2]\n",
      "[1 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 78us/step - loss: 124768.7500\n",
      "rewards:  115.0 q-value:  0\n",
      "loss: [124768.75]\n",
      "Exploring\n",
      "Selected action  [0 2]\n",
      "[0 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 61us/step - loss: 150388.3750\n",
      "rewards:  109.0 q-value:  0\n",
      "loss: [150388.375]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 81us/step - loss: 169020.5000\n",
      "rewards:  117.0 q-value:  0\n",
      "loss: [169020.5]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 68us/step - loss: 614241.1875\n",
      "rewards:  112.0 q-value:  0\n",
      "loss: [614241.1875]\n",
      "Exploring\n",
      "Selected action  [1 2]\n",
      "[1 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 76us/step - loss: 292168.2812\n",
      "rewards:  96.0 q-value:  0\n",
      "loss: [292168.28125]\n",
      "Exploring\n",
      "Selected action  [2 3]\n",
      "[2 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 77us/step - loss: 495106.9688\n",
      "rewards:  132.0 q-value:  0\n",
      "loss: [495106.96875]\n",
      "Exploring\n",
      "Selected action  [1 2]\n",
      "[1 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 73us/step - loss: 294343.2188\n",
      "rewards:  126.0 q-value:  0\n",
      "loss: [294343.21875]\n",
      "Exploring\n",
      "Selected action  [2 3]\n",
      "[2 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 85us/step - loss: 90587.7812\n",
      "rewards:  146.0 q-value:  0\n",
      "loss: [90587.78125]\n",
      "Exploring\n",
      "Selected action  [4 2]\n",
      "[4 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 79us/step - loss: 68492.5312\n",
      "rewards:  120.0 q-value:  0\n",
      "loss: [68492.53125]\n",
      "Exploring\n",
      "Selected action  [1 2]\n",
      "[1 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 67us/step - loss: 349698.5000\n",
      "rewards:  117.0 q-value:  0\n",
      "loss: [349698.5]\n",
      "Exploring\n",
      "Selected action  [4 2]\n",
      "[4 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 73us/step - loss: 479229.3438\n",
      "rewards:  116.0 q-value:  0\n",
      "loss: [479229.34375]\n",
      "Exploring\n",
      "Selected action  [4 2]\n",
      "[4 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 58us/step - loss: 438862.7812\n",
      "rewards:  114.0 q-value:  0\n",
      "loss: [438862.78125]\n",
      "Exploring\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 67us/step - loss: 287490.1250\n",
      "rewards:  116.0 q-value:  0\n",
      "loss: [287490.125]\n",
      "Exploring\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 70us/step - loss: 115885.7500\n",
      "rewards:  69.0 q-value:  0\n",
      "loss: [115885.75]\n",
      "Number of actions available 4\n",
      "Episode : 17\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 86us/step - loss: 586895.5000\n",
      "rewards:  -25.0 q-value:  0\n",
      "loss: [586895.5]\n",
      "Exploring\n",
      "Selected action  [0 2]\n",
      "[0 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 75us/step - loss: 354299.7188\n",
      "rewards:  -16.0 q-value:  0\n",
      "loss: [354299.71875]\n",
      "Exploring\n",
      "Selected action  [0 2]\n",
      "[0 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 56us/step - loss: 199197.1562\n",
      "rewards:  -19.0 q-value:  0\n",
      "loss: [199197.15625]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 63us/step - loss: 512705.9375\n",
      "rewards:  -24.0 q-value:  0\n",
      "loss: [512705.9375]\n",
      "Exploiting\n",
      "Selected action  [0 2]\n",
      "[0 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 75us/step - loss: 522343.1250\n",
      "rewards:  -12.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [522343.125]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 67us/step - loss: 296445.5625\n",
      "rewards:  -17.0 q-value:  0\n",
      "loss: [296445.5625]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 69us/step - loss: 359314.1562\n",
      "rewards:  -22.0 q-value:  0\n",
      "loss: [359314.15625]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 68us/step - loss: 307224.4375\n",
      "rewards:  -27.0 q-value:  0\n",
      "loss: [307224.4375]\n",
      "Exploring\n",
      "Selected action  [0 2]\n",
      "[0 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 66us/step - loss: 291146.1562\n",
      "rewards:  -7.0 q-value:  0\n",
      "loss: [291146.15625]\n",
      "Exploring\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 87us/step - loss: 335435.8750\n",
      "rewards:  -12.0 q-value:  0\n",
      "loss: [335435.875]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 63us/step - loss: 350339.8438\n",
      "rewards:  2.0 q-value:  0\n",
      "loss: [350339.84375]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 72us/step - loss: 364076.5312\n",
      "rewards:  0.0 q-value:  0\n",
      "loss: [364076.53125]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 63us/step - loss: 587727.7500\n",
      "rewards:  -2.0 q-value:  0\n",
      "loss: [587727.75]\n",
      "Exploring\n",
      "Selected action  [0 2]\n",
      "[0 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 92us/step - loss: 569546.8125\n",
      "rewards:  -9.0 q-value:  0\n",
      "loss: [569546.8125]\n",
      "Exploring\n",
      "Selected action  [0 2]\n",
      "[0 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 79us/step - loss: 175097.0625\n",
      "rewards:  -15.0 q-value:  0\n",
      "loss: [175097.0625]\n",
      "Exploiting\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 65us/step - loss: 426316.9062\n",
      "rewards:  -20.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [426316.90625]\n",
      "Exploring\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 72us/step - loss: 283616.3750\n",
      "rewards:  -11.0 q-value:  0\n",
      "loss: [283616.375]\n",
      "Exploring\n",
      "Selected action  [0 2]\n",
      "[0 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 84us/step - loss: 289396.7188\n",
      "rewards:  -2.0 q-value:  0\n",
      "loss: [289396.71875]\n",
      "Exploring\n",
      "Selected action  [0 2]\n",
      "[0 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 68us/step - loss: 171534.2188\n",
      "rewards:  -5.0 q-value:  0\n",
      "loss: [171534.21875]\n",
      "Exploiting\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 79us/step - loss: 353240.8125\n",
      "rewards:  -12.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [353240.8125]\n",
      "Exploring\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 70us/step - loss: 636159.6250\n",
      "rewards:  -14.0 q-value:  0\n",
      "loss: [636159.625]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 65us/step - loss: 282296.7812\n",
      "rewards:  -19.0 q-value:  0\n",
      "loss: [282296.78125]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 75us/step - loss: 506522.0625\n",
      "rewards:  -21.0 q-value:  0\n",
      "loss: [506522.0625]\n",
      "Exploring\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 93us/step - loss: 89362.5625\n",
      "rewards:  -13.0 q-value:  0\n",
      "loss: [89362.5625]\n",
      "Exploring\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 68us/step - loss: 286153.3125\n",
      "rewards:  -15.0 q-value:  0\n",
      "loss: [286153.3125]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 66us/step - loss: 128309.6562\n",
      "rewards:  -26.0 q-value:  0\n",
      "loss: [128309.65625]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 83us/step - loss: 545581.8125\n",
      "rewards:  -31.0 q-value:  0\n",
      "loss: [545581.8125]\n",
      "Exploring\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 64us/step - loss: 414188.6875\n",
      "rewards:  -26.0 q-value:  0\n",
      "loss: [414188.6875]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 64us/step - loss: 155963.7500\n",
      "rewards:  -25.0 q-value:  0\n",
      "loss: [155963.75]\n",
      "Exploring\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 95us/step - loss: 227529.7812\n",
      "rewards:  -52.0 q-value:  0\n",
      "loss: [227529.78125]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 74us/step - loss: 263228.9688\n",
      "rewards:  -64.0 q-value:  0\n",
      "loss: [263228.96875]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 74us/step - loss: 157279.5938\n",
      "rewards:  -66.0 q-value:  0\n",
      "loss: [157279.59375]\n",
      "Exploring\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 87us/step - loss: 340583.4062\n",
      "rewards:  -62.0 q-value:  0\n",
      "loss: [340583.40625]\n",
      "Exploiting\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 86us/step - loss: 399375.1562\n",
      "rewards:  -67.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [399375.15625]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 74us/step - loss: 298454.7812\n",
      "rewards:  -72.0 q-value:  0\n",
      "loss: [298454.78125]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 92us/step - loss: 199010.1562\n",
      "rewards:  -77.0 q-value:  0\n",
      "loss: [199010.15625]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 67us/step - loss: 338717.9062\n",
      "rewards:  -82.0 q-value:  0\n",
      "loss: [338717.90625]\n",
      "Exploring\n",
      "Selected action  [0 2]\n",
      "[0 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 162us/step - loss: 363870.1875\n",
      "rewards:  -50.0 q-value:  0\n",
      "loss: [363870.1875]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 90us/step - loss: 133234.3125\n",
      "rewards:  -42.0 q-value:  0\n",
      "loss: [133234.3125]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 73us/step - loss: 220754.0625\n",
      "rewards:  -44.0 q-value:  0\n",
      "loss: [220754.0625]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 69us/step - loss: 226408.8750\n",
      "rewards:  -49.0 q-value:  0\n",
      "loss: [226408.875]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 98us/step - loss: 235155.7500\n",
      "rewards:  -59.0 q-value:  0\n",
      "loss: [235155.75]\n",
      "Exploring\n",
      "Selected action  [0 2]\n",
      "[0 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 82us/step - loss: 156938.3750\n",
      "rewards:  -45.0 q-value:  0\n",
      "loss: [156938.375]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 65us/step - loss: 100329.5625\n",
      "rewards:  -41.0 q-value:  0\n",
      "loss: [100329.5625]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 72us/step - loss: 215900.6562\n",
      "rewards:  -41.0 q-value:  0\n",
      "loss: [215900.65625]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 68us/step - loss: 498184.1875\n",
      "rewards:  -41.0 q-value:  0\n",
      "loss: [498184.1875]\n",
      "Exploiting\n",
      "Selected action  [0 2]\n",
      "[0 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 61us/step - loss: 213893.8438\n",
      "rewards:  -51.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [213893.84375]\n",
      "Exploiting\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 56us/step - loss: 320903.8438\n",
      "rewards:  -51.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [320903.84375]\n",
      "Exploring\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 77us/step - loss: 501357.8750\n",
      "rewards:  -47.0 q-value:  0\n",
      "loss: [501357.875]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 82us/step - loss: 145095.5000\n",
      "rewards:  -73.0 q-value:  0\n",
      "loss: [145095.5]\n",
      "Exploiting\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 62us/step - loss: 655451.6250\n",
      "rewards:  -74.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [655451.625]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 68us/step - loss: 549578.1250\n",
      "rewards:  -75.0 q-value:  0\n",
      "loss: [549578.125]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 63us/step - loss: 80646.2500\n",
      "rewards:  -80.0 q-value:  0\n",
      "loss: [80646.25]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 112us/step - loss: 259639.4531\n",
      "rewards:  -85.0 q-value:  0\n",
      "loss: [259639.453125]\n",
      "Exploiting\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 83us/step - loss: 224202.4375\n",
      "rewards:  -90.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [224202.4375]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 88us/step - loss: 416201.3125\n",
      "rewards:  -101.0 q-value:  0\n",
      "loss: [416201.3125]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 81us/step - loss: 53751.3750\n",
      "rewards:  -102.0 q-value:  0\n",
      "loss: [53751.375]\n",
      "Exploring\n",
      "Selected action  [0 2]\n",
      "[0 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 80us/step - loss: 903192.5000\n",
      "rewards:  -95.0 q-value:  0\n",
      "loss: [903192.5]\n",
      "Exploring\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 257us/step - loss: 162318.1875\n",
      "rewards:  -118.0 q-value:  0\n",
      "loss: [162318.1875]\n",
      "Exploiting\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 71us/step - loss: 444163.1250\n",
      "rewards:  -123.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [444163.125]\n",
      "Exploiting\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 122us/step - loss: 359573.9375\n",
      "rewards:  -128.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [359573.9375]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 167us/step - loss: 73539.8438\n",
      "rewards:  -133.0 q-value:  0\n",
      "loss: [73539.84375]\n",
      "Exploring\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 59us/step - loss: 427488.0000\n",
      "rewards:  -161.0 q-value:  0\n",
      "loss: [427488.0]\n",
      "Exploiting\n",
      "Selected action  [0 2]\n",
      "[0 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 97us/step - loss: 115646.3125\n",
      "rewards:  -164.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [115646.3125]\n",
      "Exploring\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 83us/step - loss: 503325.0312\n",
      "rewards:  -165.0 q-value:  0\n",
      "loss: [503325.03125]\n",
      "Exploring\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 69us/step - loss: 138025.5625\n",
      "rewards:  -168.0 q-value:  0\n",
      "loss: [138025.5625]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 84us/step - loss: 160951.5000\n",
      "rewards:  -198.0 q-value:  0\n",
      "loss: [160951.5]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 80us/step - loss: 209403.2500\n",
      "rewards:  -203.0 q-value:  0\n",
      "loss: [209403.25]\n",
      "Exploring\n",
      "Selected action  [0 2]\n",
      "[0 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 86us/step - loss: 675888.6250\n",
      "rewards:  -187.0 q-value:  0\n",
      "loss: [675888.625]\n",
      "Exploring\n",
      "Selected action  [0 2]\n",
      "[0 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 75us/step - loss: 443406.6250\n",
      "rewards:  -194.0 q-value:  0\n",
      "loss: [443406.625]\n",
      "Exploring\n",
      "Selected action  [0 2]\n",
      "[0 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 70us/step - loss: 486725.7812\n",
      "rewards:  -201.0 q-value:  0\n",
      "loss: [486725.78125]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 74us/step - loss: 438756.7500\n",
      "rewards:  -206.0 q-value:  0\n",
      "loss: [438756.75]\n",
      "Exploring\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 77us/step - loss: 235121.4688\n",
      "rewards:  -218.0 q-value:  0\n",
      "loss: [235121.46875]\n",
      "Exploring\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 89us/step - loss: 819196.0625\n",
      "rewards:  -220.0 q-value:  0\n",
      "loss: [819196.0625]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 61us/step - loss: 344428.6875\n",
      "rewards:  -245.0 q-value:  0\n",
      "loss: [344428.6875]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 64us/step - loss: 545909.8750\n",
      "rewards:  -250.0 q-value:  0\n",
      "loss: [545909.875]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 75us/step - loss: 352533.1250\n",
      "rewards:  -275.0 q-value:  0\n",
      "loss: [352533.125]\n",
      "Exploiting\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 64us/step - loss: 263296.0625\n",
      "rewards:  -280.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [263296.0625]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 75us/step - loss: 272345.1250\n",
      "rewards:  -305.0 q-value:  0\n",
      "loss: [272345.125]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 85us/step - loss: 166302.7500\n",
      "rewards:  -305.0 q-value:  0\n",
      "loss: [166302.75]\n",
      "Exploring\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 71us/step - loss: 565708.3750\n",
      "rewards:  -307.0 q-value:  0\n",
      "loss: [565708.375]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 67us/step - loss: 178166.6250\n",
      "rewards:  -332.0 q-value:  0\n",
      "loss: [178166.625]\n",
      "Exploring\n",
      "Selected action  [0 2]\n",
      "[0 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 78us/step - loss: 377621.0625\n",
      "rewards:  -317.0 q-value:  0\n",
      "loss: [377621.0625]\n",
      "Exploring\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 65us/step - loss: 641586.5000\n",
      "rewards:  -336.0 q-value:  0\n",
      "loss: [641586.5]\n",
      "Exploring\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 116us/step - loss: 317212.9375\n",
      "rewards:  -340.0 q-value:  0\n",
      "loss: [317212.9375]\n",
      "Exploring\n",
      "Selected action  [0 2]\n",
      "[0 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 87us/step - loss: 773227.1250\n",
      "rewards:  -331.0 q-value:  0\n",
      "loss: [773227.125]\n",
      "Exploring\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 63us/step - loss: 693404.3750\n",
      "rewards:  -341.0 q-value:  0\n",
      "loss: [693404.375]\n",
      "Exploring\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 61us/step - loss: 120606.6562\n",
      "rewards:  -341.0 q-value:  0\n",
      "loss: [120606.65625]\n",
      "Exploring\n",
      "Selected action  [0 2]\n",
      "[0 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 66us/step - loss: 96890.1562\n",
      "rewards:  -329.0 q-value:  0\n",
      "loss: [96890.15625]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 67us/step - loss: 128207.0938\n",
      "rewards:  -321.0 q-value:  0\n",
      "loss: [128207.09375]\n",
      "Exploiting\n",
      "Selected action  [0 2]\n",
      "[0 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 58us/step - loss: 287337.9375\n",
      "rewards:  -341.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [287337.9375]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 75us/step - loss: 239136.7500\n",
      "rewards:  -346.0 q-value:  0\n",
      "loss: [239136.75]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 67us/step - loss: 296960.9688\n",
      "rewards:  -352.0 q-value:  0\n",
      "loss: [296960.96875]\n",
      "Exploring\n",
      "Selected action  [0 2]\n",
      "[0 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 68us/step - loss: 235602.4375\n",
      "rewards:  -349.0 q-value:  0\n",
      "loss: [235602.4375]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 69us/step - loss: 347154.4062\n",
      "rewards:  -345.0 q-value:  0\n",
      "loss: [347154.40625]\n",
      "Exploiting\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 98us/step - loss: 274331.4062\n",
      "rewards:  -356.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [274331.40625]\n",
      "Exploring\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 63us/step - loss: 506386.9375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rewards:  -357.0 q-value:  0\n",
      "loss: [506386.9375]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 65us/step - loss: 86857.7812\n",
      "rewards:  -343.0 q-value:  0\n",
      "loss: [86857.78125]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 85us/step - loss: 347915.5625\n",
      "rewards:  -345.0 q-value:  0\n",
      "loss: [347915.5625]\n",
      "Exploring\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 73us/step - loss: 221990.5000\n",
      "rewards:  -341.0 q-value:  0\n",
      "loss: [221990.5]\n",
      "Exploiting\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 74us/step - loss: 76115.4062\n",
      "rewards:  -342.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [76115.40625]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 69us/step - loss: 340427.7188\n",
      "rewards:  -357.0 q-value:  0\n",
      "loss: [340427.71875]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 63us/step - loss: 363726.2188\n",
      "rewards:  -362.0 q-value:  0\n",
      "loss: [363726.21875]\n",
      "Exploring\n",
      "Selected action  [0 2]\n",
      "[0 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 75us/step - loss: 375776.8125\n",
      "rewards:  -338.0 q-value:  0\n",
      "loss: [375776.8125]\n",
      "Exploring\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 58us/step - loss: 70822.9062\n",
      "rewards:  -344.0 q-value:  0\n",
      "loss: [70822.90625]\n",
      "Exploring\n",
      "Selected action  [0 2]\n",
      "[0 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 70us/step - loss: 521113.8438\n",
      "rewards:  -335.0 q-value:  0\n",
      "loss: [521113.84375]\n",
      "Exploring\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 83us/step - loss: 515947.0312\n",
      "rewards:  -342.0 q-value:  0\n",
      "loss: [515947.03125]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 63us/step - loss: 488231.9062\n",
      "rewards:  -353.0 q-value:  0\n",
      "loss: [488231.90625]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 54us/step - loss: 592751.6875\n",
      "rewards:  -358.0 q-value:  0\n",
      "loss: [592751.6875]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 60us/step - loss: 674418.3750\n",
      "rewards:  -369.0 q-value:  0\n",
      "loss: [674418.375]\n",
      "Exploring\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 83us/step - loss: 56846.7812\n",
      "rewards:  -361.0 q-value:  0\n",
      "loss: [56846.78125]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 66us/step - loss: 223388.7500\n",
      "rewards:  -366.0 q-value:  0\n",
      "loss: [223388.75]\n",
      "Exploiting\n",
      "Selected action  [0 2]\n",
      "[0 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 89us/step - loss: 534529.1875\n",
      "rewards:  -358.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [534529.1875]\n",
      "Exploring\n",
      "Selected action  [0 2]\n",
      "[0 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 69us/step - loss: 615088.0000\n",
      "rewards:  -360.0 q-value:  0\n",
      "loss: [615088.0]\n",
      "Exploiting\n",
      "Selected action  [0 2]\n",
      "[0 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 59us/step - loss: 418448.0000\n",
      "rewards:  -362.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [418448.0]\n",
      "Exploring\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 72us/step - loss: 191570.0000\n",
      "rewards:  -367.0 q-value:  0\n",
      "loss: [191570.0]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 82us/step - loss: 410356.6250\n",
      "rewards:  -372.0 q-value:  0\n",
      "loss: [410356.625]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 68us/step - loss: 661165.1250\n",
      "rewards:  -377.0 q-value:  0\n",
      "loss: [661165.125]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 64us/step - loss: 245124.9062\n",
      "rewards:  -398.0 q-value:  0\n",
      "loss: [245124.90625]\n",
      "Exploring\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 69us/step - loss: 449415.7500\n",
      "rewards:  -425.0 q-value:  0\n",
      "loss: [449415.75]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 81us/step - loss: 540000.2500\n",
      "rewards:  -424.0 q-value:  0\n",
      "loss: [540000.25]\n",
      "Exploiting\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 87us/step - loss: 441295.4375\n",
      "rewards:  -429.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [441295.4375]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 71us/step - loss: 275227.5312\n",
      "rewards:  -426.0 q-value:  0\n",
      "loss: [275227.53125]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 65us/step - loss: 325596.0000\n",
      "rewards:  -431.0 q-value:  0\n",
      "loss: [325596.0]\n",
      "Exploring\n",
      "Selected action  [0 2]\n",
      "[0 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 63us/step - loss: 455953.6875\n",
      "rewards:  -427.0 q-value:  0\n",
      "loss: [455953.6875]\n",
      "Exploiting\n",
      "Selected action  [0 2]\n",
      "[0 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 78us/step - loss: 423373.2812\n",
      "rewards:  -428.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [423373.28125]\n",
      "Exploring\n",
      "Selected action  [0 2]\n",
      "[0 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 70us/step - loss: 304469.1875\n",
      "rewards:  -429.0 q-value:  0\n",
      "loss: [304469.1875]\n",
      "Exploiting\n",
      "Selected action  [0 2]\n",
      "[0 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 61us/step - loss: 285048.6562\n",
      "rewards:  -430.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [285048.65625]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 66us/step - loss: 406783.0000\n",
      "rewards:  -422.0 q-value:  0\n",
      "loss: [406783.0]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 75us/step - loss: 340486.1250\n",
      "rewards:  -424.0 q-value:  0\n",
      "loss: [340486.125]\n",
      "Exploring\n",
      "Selected action  [0 2]\n",
      "[0 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 67us/step - loss: 158433.0000\n",
      "rewards:  -427.0 q-value:  0\n",
      "loss: [158433.0]\n",
      "Exploiting\n",
      "Selected action  [0 2]\n",
      "[0 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 88us/step - loss: 330759.3750\n",
      "rewards:  -433.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [330759.375]\n",
      "Exploring\n",
      "Selected action  [0 2]\n",
      "[0 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 80us/step - loss: 632491.4375\n",
      "rewards:  -435.0 q-value:  0\n",
      "loss: [632491.4375]\n",
      "Exploring\n",
      "Selected action  [0 2]\n",
      "[0 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 59us/step - loss: 482818.7188\n",
      "rewards:  -437.0 q-value:  0\n",
      "loss: [482818.71875]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 69us/step - loss: 395294.7500\n",
      "rewards:  -433.0 q-value:  0\n",
      "loss: [395294.75]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 73us/step - loss: 884442.7500\n",
      "rewards:  -438.0 q-value:  0\n",
      "loss: [884442.75]\n",
      "Exploring\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 78us/step - loss: 553200.6250\n",
      "rewards:  -442.0 q-value:  0\n",
      "loss: [553200.625]\n",
      "Exploiting\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 77us/step - loss: 465591.2812\n",
      "rewards:  -443.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [465591.28125]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 60us/step - loss: 378541.5938\n",
      "rewards:  -448.0 q-value:  0\n",
      "loss: [378541.59375]\n",
      "Exploiting\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 77us/step - loss: 486121.0312\n",
      "rewards:  -453.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [486121.03125]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 91us/step - loss: 257059.0625\n",
      "rewards:  -458.0 q-value:  0\n",
      "loss: [257059.0625]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 75us/step - loss: 276486.6875\n",
      "rewards:  -463.0 q-value:  0\n",
      "loss: [276486.6875]\n",
      "Exploring\n",
      "Selected action  [0 2]\n",
      "[0 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 64us/step - loss: 201724.2812\n",
      "rewards:  -443.0 q-value:  0\n",
      "loss: [201724.28125]\n",
      "Exploring\n",
      "Selected action  [0 2]\n",
      "[0 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 74us/step - loss: 510676.9375\n",
      "rewards:  -446.0 q-value:  0\n",
      "loss: [510676.9375]\n",
      "Exploiting\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 57us/step - loss: 188129.5938\n",
      "rewards:  -451.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [188129.59375]\n",
      "Exploiting\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 80us/step - loss: 273080.8125\n",
      "rewards:  -456.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [273080.8125]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 86us/step - loss: 690347.3750\n",
      "rewards:  -461.0 q-value:  0\n",
      "loss: [690347.375]\n",
      "Exploiting\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 62us/step - loss: 266351.8750\n",
      "rewards:  -489.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [266351.875]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 73us/step - loss: 288971.4062\n",
      "rewards:  -472.0 q-value:  0\n",
      "loss: [288971.40625]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 64us/step - loss: 203828.7500\n",
      "rewards:  -474.0 q-value:  0\n",
      "loss: [203828.75]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 69us/step - loss: 281596.6250\n",
      "rewards:  -474.0 q-value:  0\n",
      "loss: [281596.625]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 71us/step - loss: 765781.5000\n",
      "rewards:  -479.0 q-value:  0\n",
      "loss: [765781.5]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 62us/step - loss: 353723.3125\n",
      "rewards:  -484.0 q-value:  0\n",
      "loss: [353723.3125]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 76us/step - loss: 540328.8750\n",
      "rewards:  -489.0 q-value:  0\n",
      "loss: [540328.875]\n",
      "Exploring\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 65us/step - loss: 540578.9375\n",
      "rewards:  -512.0 q-value:  0\n",
      "loss: [540578.9375]\n",
      "Exploring\n",
      "Selected action  [0 2]\n",
      "[0 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 77us/step - loss: 307308.7500\n",
      "rewards:  -501.0 q-value:  0\n",
      "loss: [307308.75]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 70us/step - loss: 253601.6562\n",
      "rewards:  -506.0 q-value:  0\n",
      "loss: [253601.65625]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 63us/step - loss: 274025.8750\n",
      "rewards:  -541.0 q-value:  0\n",
      "loss: [274025.875]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 59us/step - loss: 110508.3125\n",
      "rewards:  -546.0 q-value:  0\n",
      "loss: [110508.3125]\n",
      "Exploring\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 63us/step - loss: 422156.6250\n",
      "rewards:  -530.0 q-value:  0\n",
      "loss: [422156.625]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 89us/step - loss: 337577.0000\n",
      "rewards:  -535.0 q-value:  0\n",
      "loss: [337577.0]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 66us/step - loss: 101340.4688\n",
      "rewards:  -540.0 q-value:  0\n",
      "loss: [101340.46875]\n",
      "Exploiting\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 73us/step - loss: 144745.6875\n",
      "rewards:  -543.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [144745.6875]\n",
      "Number of actions available 7\n",
      "Episode : 18\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 63us/step - loss: 381115.8750\n",
      "rewards:  -5 q-value:  0\n",
      "loss: [381115.875]\n",
      "Exploring\n",
      "Selected action  [3 4]\n",
      "[3 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 61us/step - loss: 88163.3125\n",
      "rewards:  -27.0 q-value:  0\n",
      "loss: [88163.3125]\n",
      "Exploring\n",
      "Selected action  [0 4]\n",
      "[0 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 61us/step - loss: 150175.9062\n",
      "rewards:  -28.0 q-value:  0\n",
      "loss: [150175.90625]\n",
      "Exploring\n",
      "Selected action  [0 4]\n",
      "[0 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 97us/step - loss: 526109.5000\n",
      "rewards:  -31.0 q-value:  0\n",
      "loss: [526109.5]\n",
      "Exploring\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 65us/step - loss: 296238.1562\n",
      "rewards:  -27.0 q-value:  0\n",
      "loss: [296238.15625]\n",
      "Exploring\n",
      "Selected action  [3 4]\n",
      "[3 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 70us/step - loss: 417244.0000\n",
      "rewards:  -15.0 q-value:  0\n",
      "loss: [417244.0]\n",
      "Exploiting\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 68us/step - loss: 489803.2188\n",
      "rewards:  -20.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [489803.21875]\n",
      "Exploring\n",
      "Selected action  [3 0]\n",
      "[3 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 60us/step - loss: 281670.2812\n",
      "rewards:  -23.0 q-value:  0\n",
      "loss: [281670.28125]\n",
      "Exploring\n",
      "Selected action  [4 2]\n",
      "[4 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 71us/step - loss: 219839.6250\n",
      "rewards:  -55.0 q-value:  0\n",
      "loss: [219839.625]\n",
      "Exploiting\n",
      "Selected action  [4 3]\n",
      "[4 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 56us/step - loss: 190760.1875\n",
      "rewards:  -53.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [190760.1875]\n",
      "Exploiting\n",
      "Selected action  [4 2]\n",
      "[4 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 64us/step - loss: 463156.2500\n",
      "rewards:  -59.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [463156.25]\n",
      "Exploring\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 63us/step - loss: 550715.0625\n",
      "rewards:  -51.0 q-value:  0\n",
      "loss: [550715.0625]\n",
      "Exploring\n",
      "Selected action  [3 0]\n",
      "[3 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 62us/step - loss: 242202.9688\n",
      "rewards:  -61.0 q-value:  0\n",
      "loss: [242202.96875]\n",
      "Exploring\n",
      "Selected action  [3 0]\n",
      "[3 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 61us/step - loss: 242270.4062\n",
      "rewards:  -63.0 q-value:  0\n",
      "loss: [242270.40625]\n",
      "Exploring\n",
      "Selected action  [4 2]\n",
      "[4 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 65us/step - loss: 72715.9062\n",
      "rewards:  -70.0 q-value:  0\n",
      "loss: [72715.90625]\n",
      "Exploring\n",
      "Selected action  [4 3]\n",
      "[4 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 84us/step - loss: 155207.7812\n",
      "rewards:  -50.0 q-value:  0\n",
      "loss: [155207.78125]\n",
      "Exploring\n",
      "Selected action  [0 4]\n",
      "[0 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 67us/step - loss: 737394.2500\n",
      "rewards:  -76.0 q-value:  0\n",
      "loss: [737394.25]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 75us/step - loss: 853675.7500\n",
      "rewards:  -81.0 q-value:  0\n",
      "loss: [853675.75]\n",
      "Exploring\n",
      "Selected action  [3 0]\n",
      "[3 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 81us/step - loss: 659622.5625\n",
      "rewards:  -87.0 q-value:  0\n",
      "loss: [659622.5625]\n",
      "Exploiting\n",
      "Selected action  [3 4]\n",
      "[3 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 64us/step - loss: 95099.2812\n",
      "rewards:  -74.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [95099.28125]\n",
      "Exploring\n",
      "Selected action  [0 4]\n",
      "[0 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 77us/step - loss: 611917.5625\n",
      "rewards:  -75.0 q-value:  0\n",
      "loss: [611917.5625]\n",
      "Exploring\n",
      "Selected action  [3 4]\n",
      "[3 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 69us/step - loss: 473136.0938\n",
      "rewards:  -81.0 q-value:  0\n",
      "loss: [473136.09375]\n",
      "Exploring\n",
      "Selected action  [4 2]\n",
      "[4 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 73us/step - loss: 77116.7812\n",
      "rewards:  -73.0 q-value:  0\n",
      "loss: [77116.78125]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 68us/step - loss: 224716.9375\n",
      "rewards:  -78.0 q-value:  0\n",
      "loss: [224716.9375]\n",
      "Exploring\n",
      "Selected action  [3 0]\n",
      "[3 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 78us/step - loss: 477114.8750\n",
      "rewards:  -79.0 q-value:  0\n",
      "loss: [477114.875]\n",
      "Exploring\n",
      "Selected action  [3 4]\n",
      "[3 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 60us/step - loss: 476992.1875\n",
      "rewards:  -115.0 q-value:  0\n",
      "loss: [476992.1875]\n",
      "Exploring\n",
      "Selected action  [4 2]\n",
      "[4 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 79us/step - loss: 543831.8750\n",
      "rewards:  -111.0 q-value:  0\n",
      "loss: [543831.875]\n",
      "Exploring\n",
      "Selected action  [4 2]\n",
      "[4 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 70us/step - loss: 467499.8125\n",
      "rewards:  -112.0 q-value:  0\n",
      "loss: [467499.8125]\n",
      "Exploring\n",
      "Selected action  [0 4]\n",
      "[0 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 65us/step - loss: 750400.5000\n",
      "rewards:  -133.0 q-value:  0\n",
      "loss: [750400.5]\n",
      "Exploring\n",
      "Selected action  [4 3]\n",
      "[4 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 63us/step - loss: 883017.1250\n",
      "rewards:  -129.0 q-value:  0\n",
      "loss: [883017.125]\n",
      "Exploring\n",
      "Selected action  [3 4]\n",
      "[3 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 68us/step - loss: 422200.5938\n",
      "rewards:  -125.0 q-value:  0\n",
      "loss: [422200.59375]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 75us/step - loss: 222550.4375\n",
      "rewards:  -130.0 q-value:  0\n",
      "loss: [222550.4375]\n",
      "Exploiting\n",
      "Selected action  [4 3]\n",
      "[4 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 65us/step - loss: 420020.9062\n",
      "rewards:  -121.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [420020.90625]\n",
      "Exploring\n",
      "Selected action  [3 0]\n",
      "[3 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 72us/step - loss: 334658.2188\n",
      "rewards:  -113.0 q-value:  0\n",
      "loss: [334658.21875]\n",
      "Exploring\n",
      "Selected action  [4 2]\n",
      "[4 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 91us/step - loss: 464538.4062\n",
      "rewards:  -110.0 q-value:  0\n",
      "loss: [464538.40625]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 62us/step - loss: 184423.2500\n",
      "rewards:  -115.0 q-value:  0\n",
      "loss: [184423.25]\n",
      "Exploring\n",
      "Selected action  [4 3]\n",
      "[4 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 76us/step - loss: 330406.3125\n",
      "rewards:  -96.0 q-value:  0\n",
      "loss: [330406.3125]\n",
      "Exploring\n",
      "Selected action  [0 4]\n",
      "[0 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 73us/step - loss: 216411.8906\n",
      "rewards:  -78.0 q-value:  0\n",
      "loss: [216411.890625]\n",
      "Exploring\n",
      "Selected action  [0 4]\n",
      "[0 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 78us/step - loss: 170749.0312\n",
      "rewards:  -78.0 q-value:  0\n",
      "loss: [170749.03125]\n",
      "Exploring\n",
      "Selected action  [4 3]\n",
      "[4 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 72us/step - loss: 250836.6562\n",
      "rewards:  -70.0 q-value:  0\n",
      "loss: [250836.65625]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 86us/step - loss: 295162.9062\n",
      "rewards:  -75.0 q-value:  0\n",
      "loss: [295162.90625]\n",
      "Exploiting\n",
      "Selected action  [3 0]\n",
      "[3 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 77us/step - loss: 299755.1875\n",
      "rewards:  -81.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [299755.1875]\n",
      "Exploring\n",
      "Selected action  [3 4]\n",
      "[3 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 97us/step - loss: 144046.0625\n",
      "rewards:  -82.0 q-value:  0\n",
      "loss: [144046.0625]\n",
      "Exploiting\n",
      "Selected action  [3 4]\n",
      "[3 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 70us/step - loss: 225726.5000\n",
      "rewards:  -88.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [225726.5]\n",
      "Exploring\n",
      "Selected action  [3 4]\n",
      "[3 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 67us/step - loss: 883529.2500\n",
      "rewards:  -91.0 q-value:  0\n",
      "loss: [883529.25]\n",
      "Exploring\n",
      "Selected action  [4 2]\n",
      "[4 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 76us/step - loss: 217544.0938\n",
      "rewards:  -87.0 q-value:  0\n",
      "loss: [217544.09375]\n",
      "Exploiting\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 63us/step - loss: 300908.5625\n",
      "rewards:  -75.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [300908.5625]\n",
      "Exploring\n",
      "Selected action  [0 4]\n",
      "[0 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 60us/step - loss: 370057.7812\n",
      "rewards:  -75.0 q-value:  0\n",
      "loss: [370057.78125]\n",
      "Exploiting\n",
      "Selected action  [4 3]\n",
      "[4 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 62us/step - loss: 448145.6250\n",
      "rewards:  -55.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [448145.625]\n",
      "Exploring\n",
      "Selected action  [4 3]\n",
      "[4 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 85us/step - loss: 634420.6250\n",
      "rewards:  -60.0 q-value:  0\n",
      "loss: [634420.625]\n",
      "Exploiting\n",
      "Selected action  [3 0]\n",
      "[3 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 79us/step - loss: 185082.0938\n",
      "rewards:  -56.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [185082.09375]\n",
      "Exploring\n",
      "Selected action  [0 4]\n",
      "[0 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 74us/step - loss: 434189.1562\n",
      "rewards:  -44.0 q-value:  0\n",
      "loss: [434189.15625]\n",
      "Exploring\n",
      "Selected action  [3 0]\n",
      "[3 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 80us/step - loss: 754993.3750\n",
      "rewards:  -60.0 q-value:  0\n",
      "loss: [754993.375]\n",
      "Exploring\n",
      "Selected action  [4 2]\n",
      "[4 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 72us/step - loss: 168345.8438\n",
      "rewards:  -75.0 q-value:  0\n",
      "loss: [168345.84375]\n",
      "Exploring\n",
      "Selected action  [3 0]\n",
      "[3 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 78us/step - loss: 229480.6875\n",
      "rewards:  -101.0 q-value:  0\n",
      "loss: [229480.6875]\n",
      "Exploring\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 74us/step - loss: 634537.0000\n",
      "rewards:  -108.0 q-value:  0\n",
      "loss: [634537.0]\n",
      "Exploring\n",
      "Selected action  [3 4]\n",
      "[3 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 64us/step - loss: 464174.3125\n",
      "rewards:  -122.0 q-value:  0\n",
      "loss: [464174.3125]\n",
      "Exploiting\n",
      "Selected action  [3 4]\n",
      "[3 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 73us/step - loss: 130256.2812\n",
      "rewards:  -126.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [130256.28125]\n",
      "Exploring\n",
      "Selected action  [4 2]\n",
      "[4 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 88us/step - loss: 556144.5625\n",
      "rewards:  -126.0 q-value:  0\n",
      "loss: [556144.5625]\n",
      "Exploring\n",
      "Selected action  [0 4]\n",
      "[0 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 72us/step - loss: 213669.6562\n",
      "rewards:  -146.0 q-value:  0\n",
      "loss: [213669.65625]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 49us/step - loss: 266975.5000\n",
      "rewards:  -151.0 q-value:  0\n",
      "loss: [266975.5]\n",
      "Exploring\n",
      "Selected action  [3 0]\n",
      "[3 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 101us/step - loss: 96454.6875\n",
      "rewards:  -155.0 q-value:  0\n",
      "loss: [96454.6875]\n",
      "Exploiting\n",
      "Selected action  [4 2]\n",
      "[4 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 75us/step - loss: 277165.1562\n",
      "rewards:  -160.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [277165.15625]\n",
      "Exploiting\n",
      "Selected action  [4 3]\n",
      "[4 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 70us/step - loss: 385144.6250\n",
      "rewards:  -136.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [385144.625]\n",
      "Exploring\n",
      "Selected action  [4 2]\n",
      "[4 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 65us/step - loss: 402473.5938\n",
      "rewards:  -126.0 q-value:  0\n",
      "loss: [402473.59375]\n",
      "Exploring\n",
      "Selected action  [4 3]\n",
      "[4 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 60us/step - loss: 586939.7500\n",
      "rewards:  -118.0 q-value:  0\n",
      "loss: [586939.75]\n",
      "Exploring\n",
      "Selected action  [0 4]\n",
      "[0 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 71us/step - loss: 285812.5938\n",
      "rewards:  -114.0 q-value:  0\n",
      "loss: [285812.59375]\n",
      "Exploiting\n",
      "Selected action  [4 3]\n",
      "[4 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 49us/step - loss: 254186.6875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rewards:  -102.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [254186.6875]\n",
      "Exploring\n",
      "Selected action  [4 3]\n",
      "[4 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 73us/step - loss: 585065.2500\n",
      "rewards:  -105.0 q-value:  0\n",
      "loss: [585065.25]\n",
      "Exploring\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 90us/step - loss: 328666.4688\n",
      "rewards:  -95.0 q-value:  0\n",
      "loss: [328666.46875]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 65us/step - loss: 213515.4688\n",
      "rewards:  -100.0 q-value:  0\n",
      "loss: [213515.46875]\n",
      "Exploring\n",
      "Selected action  [4 2]\n",
      "[4 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 82us/step - loss: 388117.5625\n",
      "rewards:  -101.0 q-value:  0\n",
      "loss: [388117.5625]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 61us/step - loss: 636649.3750\n",
      "rewards:  -106.0 q-value:  0\n",
      "loss: [636649.375]\n",
      "Exploring\n",
      "Selected action  [0 4]\n",
      "[0 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 67us/step - loss: 445254.6250\n",
      "rewards:  -102.0 q-value:  0\n",
      "loss: [445254.625]\n",
      "Exploring\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 67us/step - loss: 482435.3750\n",
      "rewards:  -99.0 q-value:  0\n",
      "loss: [482435.375]\n",
      "Exploring\n",
      "Selected action  [3 4]\n",
      "[3 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 77us/step - loss: 320714.2812\n",
      "rewards:  -141.0 q-value:  0\n",
      "loss: [320714.28125]\n",
      "Exploring\n",
      "Selected action  [3 4]\n",
      "[3 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 92us/step - loss: 402820.2812\n",
      "rewards:  -148.0 q-value:  0\n",
      "loss: [402820.28125]\n",
      "Exploiting\n",
      "Selected action  [0 4]\n",
      "[0 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 51us/step - loss: 812383.8750\n",
      "rewards:  -151.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [812383.875]\n",
      "Exploring\n",
      "Selected action  [3 4]\n",
      "[3 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 57us/step - loss: 640828.7500\n",
      "rewards:  -160.0 q-value:  0\n",
      "loss: [640828.75]\n",
      "Exploring\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 83us/step - loss: 272012.7812\n",
      "rewards:  -136.0 q-value:  0\n",
      "loss: [272012.78125]\n",
      "Exploring\n",
      "Selected action  [4 2]\n",
      "[4 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 66us/step - loss: 489417.6562\n",
      "rewards:  -121.0 q-value:  0\n",
      "loss: [489417.65625]\n",
      "Exploring\n",
      "Selected action  [4 3]\n",
      "[4 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 77us/step - loss: 335238.7500\n",
      "rewards:  -102.0 q-value:  0\n",
      "loss: [335238.75]\n",
      "Exploring\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 84us/step - loss: 285014.6875\n",
      "rewards:  -114.0 q-value:  0\n",
      "loss: [285014.6875]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 73us/step - loss: 351883.3438\n",
      "rewards:  -119.0 q-value:  0\n",
      "loss: [351883.34375]\n",
      "Exploring\n",
      "Selected action  [0 4]\n",
      "[0 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 57us/step - loss: 224219.9062\n",
      "rewards:  -103.0 q-value:  0\n",
      "loss: [224219.90625]\n",
      "Exploiting\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 61us/step - loss: 557798.5000\n",
      "rewards:  -108.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [557798.5]\n",
      "Exploring\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 65us/step - loss: 258518.6562\n",
      "rewards:  -113.0 q-value:  0\n",
      "loss: [258518.65625]\n",
      "Exploiting\n",
      "Selected action  [3 0]\n",
      "[3 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 80us/step - loss: 307701.8750\n",
      "rewards:  -121.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [307701.875]\n",
      "Exploring\n",
      "Selected action  [0 4]\n",
      "[0 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 56us/step - loss: 536486.5000\n",
      "rewards:  -117.0 q-value:  0\n",
      "loss: [536486.5]\n",
      "Exploring\n",
      "Selected action  [3 0]\n",
      "[3 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 64us/step - loss: 208780.6562\n",
      "rewards:  -139.0 q-value:  0\n",
      "loss: [208780.65625]\n",
      "Exploiting\n",
      "Selected action  [4 2]\n",
      "[4 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 64us/step - loss: 355796.4375\n",
      "rewards:  -136.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [355796.4375]\n",
      "Exploring\n",
      "Selected action  [4 3]\n",
      "[4 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 70us/step - loss: 616461.0000\n",
      "rewards:  -130.0 q-value:  0\n",
      "loss: [616461.0]\n",
      "Exploring\n",
      "Selected action  [3 4]\n",
      "[3 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 60us/step - loss: 325705.5938\n",
      "rewards:  -114.0 q-value:  0\n",
      "loss: [325705.59375]\n",
      "Exploring\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 77us/step - loss: 476153.0625\n",
      "rewards:  -112.0 q-value:  0\n",
      "loss: [476153.0625]\n",
      "Exploring\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 73us/step - loss: 435090.1875\n",
      "rewards:  -118.0 q-value:  0\n",
      "loss: [435090.1875]\n",
      "Exploring\n",
      "Selected action  [4 3]\n",
      "[4 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 79us/step - loss: 785658.7500\n",
      "rewards:  -94.0 q-value:  0\n",
      "loss: [785658.75]\n",
      "Exploring\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 62us/step - loss: 223076.1562\n",
      "rewards:  -74.0 q-value:  0\n",
      "loss: [223076.15625]\n",
      "Exploring\n",
      "Selected action  [4 3]\n",
      "[4 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 75us/step - loss: 344053.5000\n",
      "rewards:  -80.0 q-value:  0\n",
      "loss: [344053.5]\n",
      "Exploring\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 59us/step - loss: 361395.4375\n",
      "rewards:  -98.0 q-value:  0\n",
      "loss: [361395.4375]\n",
      "Exploring\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 70us/step - loss: 320656.8750\n",
      "rewards:  -103.0 q-value:  0\n",
      "loss: [320656.875]\n",
      "Exploring\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 63us/step - loss: 264252.1562\n",
      "rewards:  -106.0 q-value:  0\n",
      "loss: [264252.15625]\n",
      "Exploring\n",
      "Selected action  [3 4]\n",
      "[3 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 57us/step - loss: 439057.9688\n",
      "rewards:  -101.0 q-value:  0\n",
      "loss: [439057.96875]\n",
      "Exploring\n",
      "Selected action  [4 3]\n",
      "[4 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 74us/step - loss: 345010.3125\n",
      "rewards:  -85.0 q-value:  0\n",
      "loss: [345010.3125]\n",
      "Exploring\n",
      "Selected action  [4 2]\n",
      "[4 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 89us/step - loss: 509976.5625\n",
      "rewards:  -95.0 q-value:  0\n",
      "loss: [509976.5625]\n",
      "Exploiting\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 67us/step - loss: 484676.2188\n",
      "rewards:  -67.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [484676.21875]\n",
      "Exploring\n",
      "Selected action  [3 0]\n",
      "[3 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 78us/step - loss: 665279.6875\n",
      "rewards:  -73.0 q-value:  0\n",
      "loss: [665279.6875]\n",
      "Exploring\n",
      "Selected action  [3 0]\n",
      "[3 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 65us/step - loss: 296809.2500\n",
      "rewards:  -77.0 q-value:  0\n",
      "loss: [296809.25]\n",
      "Exploring\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 77us/step - loss: 544266.4375\n",
      "rewards:  -82.0 q-value:  0\n",
      "loss: [544266.4375]\n",
      "Exploring\n",
      "Selected action  [4 2]\n",
      "[4 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 81us/step - loss: 105140.0938\n",
      "rewards:  -87.0 q-value:  0\n",
      "loss: [105140.09375]\n",
      "Exploring\n",
      "Selected action  [3 0]\n",
      "[3 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 57us/step - loss: 355476.6875\n",
      "rewards:  -100.0 q-value:  0\n",
      "loss: [355476.6875]\n",
      "Exploring\n",
      "Selected action  [3 0]\n",
      "[3 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 64us/step - loss: 281191.3750\n",
      "rewards:  -106.0 q-value:  0\n",
      "loss: [281191.375]\n",
      "Exploring\n",
      "Selected action  [4 2]\n",
      "[4 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 67us/step - loss: 42687.8125\n",
      "rewards:  -105.0 q-value:  0\n",
      "loss: [42687.8125]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 78us/step - loss: 288528.5938\n",
      "rewards:  -110.0 q-value:  0\n",
      "loss: [288528.59375]\n",
      "Exploring\n",
      "Selected action  [2 0]\n",
      "[2 0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 76us/step - loss: 603585.0625\n",
      "rewards:  -113.0 q-value:  0\n",
      "loss: [603585.0625]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 67us/step - loss: 650516.7500\n",
      "rewards:  -118.0 q-value:  0\n",
      "loss: [650516.75]\n",
      "Exploring\n",
      "Selected action  [3 0]\n",
      "[3 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 102us/step - loss: 140039.7500\n",
      "rewards:  -118.0 q-value:  0\n",
      "loss: [140039.75]\n",
      "Exploring\n",
      "Selected action  [4 3]\n",
      "[4 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 65us/step - loss: 282307.5312\n",
      "rewards:  -111.0 q-value:  0\n",
      "loss: [282307.53125]\n",
      "Exploring\n",
      "Selected action  [3 4]\n",
      "[3 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 73us/step - loss: 361012.9688\n",
      "rewards:  -99.0 q-value:  0\n",
      "loss: [361012.96875]\n",
      "Exploiting\n",
      "Selected action  [0 4]\n",
      "[0 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 60us/step - loss: 639937.8750\n",
      "rewards:  -107.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [639937.875]\n",
      "Exploiting\n",
      "Selected action  [4 3]\n",
      "[4 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 81us/step - loss: 381331.5000\n",
      "rewards:  -99.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [381331.5]\n",
      "Exploiting\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 64us/step - loss: 518864.5938\n",
      "rewards:  -104.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [518864.59375]\n",
      "Exploring\n",
      "Selected action  [4 2]\n",
      "[4 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 63us/step - loss: 422284.9062\n",
      "rewards:  -85.0 q-value:  0\n",
      "loss: [422284.90625]\n",
      "Exploiting\n",
      "Selected action  [4 3]\n",
      "[4 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 66us/step - loss: 469294.1250\n",
      "rewards:  -59.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [469294.125]\n",
      "Exploring\n",
      "Selected action  [3 4]\n",
      "[3 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 98us/step - loss: 323164.5938\n",
      "rewards:  -39.0 q-value:  0\n",
      "loss: [323164.59375]\n",
      "Number of actions available 7\n",
      "Episode : 19\n",
      "Exploring\n",
      "Selected action  [0 4]\n",
      "[0 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 53us/step - loss: 320535.2812\n",
      "rewards:  -26.0 q-value:  0\n",
      "loss: [320535.28125]\n",
      "Exploring\n",
      "Selected action  [0 4]\n",
      "[0 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 67us/step - loss: 494686.4375\n",
      "rewards:  -27.0 q-value:  0\n",
      "loss: [494686.4375]\n",
      "Exploring\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 64us/step - loss: 136020.5312\n",
      "rewards:  -21.0 q-value:  0\n",
      "loss: [136020.53125]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 63us/step - loss: 162514.6250\n",
      "rewards:  -26.0 q-value:  0\n",
      "loss: [162514.625]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 61us/step - loss: 543731.7500\n",
      "rewards:  -2.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [543731.75]\n",
      "Exploring\n",
      "Selected action  [0 4]\n",
      "[0 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 67us/step - loss: 867766.6250\n",
      "rewards:  -8.0 q-value:  0\n",
      "loss: [867766.625]\n",
      "Exploring\n",
      "Selected action  [0 4]\n",
      "[0 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 59us/step - loss: 208454.4688\n",
      "rewards:  -9.0 q-value:  0\n",
      "loss: [208454.46875]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 76us/step - loss: 441585.6562\n",
      "rewards:  -6.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [441585.65625]\n",
      "Exploring\n",
      "Selected action  [3 1]\n",
      "[3 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 73us/step - loss: 88633.4688\n",
      "rewards:  -6.0 q-value:  0\n",
      "loss: [88633.46875]\n",
      "Exploring\n",
      "Selected action  [4 3]\n",
      "[4 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 63us/step - loss: 449796.0625\n",
      "rewards:  -9.0 q-value:  0\n",
      "loss: [449796.0625]\n",
      "Exploring\n",
      "Selected action  [3 1]\n",
      "[3 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 63us/step - loss: 493279.3750\n",
      "rewards:  -9.0 q-value:  0\n",
      "loss: [493279.375]\n",
      "Exploring\n",
      "Selected action  [3 0]\n",
      "[3 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 74us/step - loss: 118142.1250\n",
      "rewards:  3.0 q-value:  0\n",
      "loss: [118142.125]\n",
      "Exploring\n",
      "Selected action  [3 1]\n",
      "[3 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 82us/step - loss: 179648.5312\n",
      "rewards:  -27.0 q-value:  0\n",
      "loss: [179648.53125]\n",
      "Exploring\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 70us/step - loss: 281287.0312\n",
      "rewards:  -36.0 q-value:  0\n",
      "loss: [281287.03125]\n",
      "Exploring\n",
      "Selected action  [3 1]\n",
      "[3 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 74us/step - loss: 959725.8750\n",
      "rewards:  -37.0 q-value:  0\n",
      "loss: [959725.875]\n",
      "Exploring\n",
      "Selected action  [3 1]\n",
      "[3 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 101us/step - loss: 781695.8125\n",
      "rewards:  -38.0 q-value:  0\n",
      "loss: [781695.8125]\n",
      "Exploring\n",
      "Selected action  [0 4]\n",
      "[0 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 75us/step - loss: 131035.9375\n",
      "rewards:  -46.0 q-value:  0\n",
      "loss: [131035.9375]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 68us/step - loss: 256612.0000\n",
      "rewards:  -68.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [256612.0]\n",
      "Exploring\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 74us/step - loss: 439569.2500\n",
      "rewards:  -70.0 q-value:  0\n",
      "loss: [439569.25]\n",
      "Exploring\n",
      "Selected action  [3 0]\n",
      "[3 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 80us/step - loss: 262471.4688\n",
      "rewards:  -76.0 q-value:  0\n",
      "loss: [262471.46875]\n",
      "Exploring\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 62us/step - loss: 106947.7500\n",
      "rewards:  -48.0 q-value:  0\n",
      "loss: [106947.75]\n",
      "Exploring\n",
      "Selected action  [3 0]\n",
      "[3 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 58us/step - loss: 555346.2500\n",
      "rewards:  -54.0 q-value:  0\n",
      "loss: [555346.25]\n",
      "Exploring\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 56us/step - loss: 301138.1562\n",
      "rewards:  -81.0 q-value:  0\n",
      "loss: [301138.15625]\n",
      "Exploring\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 92us/step - loss: 62396.2812\n",
      "rewards:  -58.0 q-value:  0\n",
      "loss: [62396.28125]\n",
      "Exploring\n",
      "Selected action  [3 1]\n",
      "[3 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 63us/step - loss: 309826.7188\n",
      "rewards:  -60.0 q-value:  0\n",
      "loss: [309826.71875]\n",
      "Exploring\n",
      "Selected action  [4 3]\n",
      "[4 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 78us/step - loss: 204507.8750\n",
      "rewards:  -76.0 q-value:  0\n",
      "loss: [204507.875]\n",
      "Exploring\n",
      "Selected action  [3 1]\n",
      "[3 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 93us/step - loss: 110246.9375\n",
      "rewards:  -56.0 q-value:  0\n",
      "loss: [110246.9375]\n",
      "Exploring\n",
      "Selected action  [4 3]\n",
      "[4 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 59us/step - loss: 185073.5312\n",
      "rewards:  -67.0 q-value:  0\n",
      "loss: [185073.53125]\n",
      "Exploring\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 79us/step - loss: 120815.4688\n",
      "rewards:  -53.0 q-value:  0\n",
      "loss: [120815.46875]\n",
      "Exploring\n",
      "Selected action  [3 0]\n",
      "[3 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 84us/step - loss: 143769.4375\n",
      "rewards:  -50.0 q-value:  0\n",
      "loss: [143769.4375]\n",
      "Exploring\n",
      "Selected action  [3 0]\n",
      "[3 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 64us/step - loss: 274427.6250\n",
      "rewards:  -52.0 q-value:  0\n",
      "loss: [274427.625]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 72us/step - loss: 646760.6250\n",
      "rewards:  -28.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [646760.625]\n",
      "Exploring\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 61us/step - loss: 407053.2500\n",
      "rewards:  -33.0 q-value:  0\n",
      "loss: [407053.25]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 80us/step - loss: 177533.2812\n",
      "rewards:  -38.0 q-value:  0\n",
      "loss: [177533.28125]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 69us/step - loss: 288627.8750\n",
      "rewards:  -10.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [288627.875]\n",
      "Exploring\n",
      "Selected action  [0 4]\n",
      "[0 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 79us/step - loss: 169265.2500\n",
      "rewards:  -30.0 q-value:  0\n",
      "loss: [169265.25]\n",
      "Exploring\n",
      "Selected action  [4 3]\n",
      "[4 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 56us/step - loss: 248961.9375\n",
      "rewards:  -6.0 q-value:  0\n",
      "loss: [248961.9375]\n",
      "Exploring\n",
      "Selected action  [0 4]\n",
      "[0 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 63us/step - loss: 269715.9062\n",
      "rewards:  3.0 q-value:  0\n",
      "loss: [269715.90625]\n",
      "Exploring\n",
      "Selected action  [0 4]\n",
      "[0 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 72us/step - loss: 406067.4375\n",
      "rewards:  2.0 q-value:  0\n",
      "loss: [406067.4375]\n",
      "Exploring\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 70us/step - loss: 278123.9688\n",
      "rewards:  -16.0 q-value:  0\n",
      "loss: [278123.96875]\n",
      "Exploring\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 90us/step - loss: 368274.0938\n",
      "rewards:  -19.0 q-value:  0\n",
      "loss: [368274.09375]\n",
      "Exploring\n",
      "Selected action  [0 4]\n",
      "[0 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 62us/step - loss: 419599.9062\n",
      "rewards:  -18.0 q-value:  0\n",
      "loss: [419599.90625]\n",
      "Exploring\n",
      "Selected action  [3 1]\n",
      "[3 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 63us/step - loss: 389904.2812\n",
      "rewards:  -39.0 q-value:  0\n",
      "loss: [389904.28125]\n",
      "Exploring\n",
      "Selected action  [0 4]\n",
      "[0 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 65us/step - loss: 473414.4375\n",
      "rewards:  -38.0 q-value:  0\n",
      "loss: [473414.4375]\n",
      "Exploring\n",
      "Selected action  [0 4]\n",
      "[0 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 65us/step - loss: 288594.3125\n",
      "rewards:  -41.0 q-value:  0\n",
      "loss: [288594.3125]\n",
      "Exploring\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 56us/step - loss: 219482.4375\n",
      "rewards:  -46.0 q-value:  0\n",
      "loss: [219482.4375]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 77us/step - loss: 291251.3750\n",
      "rewards:  -46.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [291251.375]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 62us/step - loss: 345326.7812\n",
      "rewards:  -46.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [345326.78125]\n",
      "Exploring\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 61us/step - loss: 502881.6562\n",
      "rewards:  -30.0 q-value:  0\n",
      "loss: [502881.65625]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 62us/step - loss: 115127.1562\n",
      "rewards:  -50.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [115127.15625]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 64us/step - loss: 149511.6875\n",
      "rewards:  -55.0 q-value:  0\n",
      "loss: [149511.6875]\n",
      "Exploring\n",
      "Selected action  [3 1]\n",
      "[3 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 87us/step - loss: 342408.5625\n",
      "rewards:  -59.0 q-value:  0\n",
      "loss: [342408.5625]\n",
      "Exploring\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 72us/step - loss: 343536.7500\n",
      "rewards:  -64.0 q-value:  0\n",
      "loss: [343536.75]\n",
      "Exploring\n",
      "Selected action  [3 1]\n",
      "[3 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 77us/step - loss: 577293.7500\n",
      "rewards:  -66.0 q-value:  0\n",
      "loss: [577293.75]\n",
      "Exploring\n",
      "Selected action  [0 4]\n",
      "[0 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 65us/step - loss: 419918.6562\n",
      "rewards:  -86.0 q-value:  0\n",
      "loss: [419918.65625]\n",
      "Exploring\n",
      "Selected action  [4 3]\n",
      "[4 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 92us/step - loss: 382903.1875\n",
      "rewards:  -62.0 q-value:  0\n",
      "loss: [382903.1875]\n",
      "Exploring\n",
      "Selected action  [4 3]\n",
      "[4 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 62us/step - loss: 224754.5938\n",
      "rewards:  -68.0 q-value:  0\n",
      "loss: [224754.59375]\n",
      "Exploring\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 72us/step - loss: 176025.9688\n",
      "rewards:  -74.0 q-value:  0\n",
      "loss: [176025.96875]\n",
      "Exploring\n",
      "Selected action  [4 3]\n",
      "[4 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 86us/step - loss: 294809.1562\n",
      "rewards:  -81.0 q-value:  0\n",
      "loss: [294809.15625]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 73us/step - loss: 397553.5312\n",
      "rewards:  -86.0 q-value:  0\n",
      "loss: [397553.53125]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 75us/step - loss: 389535.2500\n",
      "rewards:  -91.0 q-value:  0\n",
      "loss: [389535.25]\n",
      "Exploring\n",
      "Selected action  [4 3]\n",
      "[4 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 86us/step - loss: 343905.0938\n",
      "rewards:  -84.0 q-value:  0\n",
      "loss: [343905.09375]\n",
      "Exploring\n",
      "Selected action  [3 1]\n",
      "[3 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 89us/step - loss: 98739.8438\n",
      "rewards:  -84.0 q-value:  0\n",
      "loss: [98739.84375]\n",
      "Exploring\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 81us/step - loss: 397236.1250\n",
      "rewards:  -86.0 q-value:  0\n",
      "loss: [397236.125]\n",
      "Exploring\n",
      "Selected action  [3 1]\n",
      "[3 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 80us/step - loss: 196641.2188\n",
      "rewards:  -86.0 q-value:  0\n",
      "loss: [196641.21875]\n",
      "Exploring\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 73us/step - loss: 797638.8750\n",
      "rewards:  -88.0 q-value:  0\n",
      "loss: [797638.875]\n",
      "Exploring\n",
      "Selected action  [0 4]\n",
      "[0 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 61us/step - loss: 575349.3125\n",
      "rewards:  -66.0 q-value:  0\n",
      "loss: [575349.3125]\n",
      "Exploring\n",
      "Selected action  [3 1]\n",
      "[3 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 79us/step - loss: 141000.0625\n",
      "rewards:  -97.0 q-value:  0\n",
      "loss: [141000.0625]\n",
      "Exploring\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 64us/step - loss: 577550.0000\n",
      "rewards:  -106.0 q-value:  0\n",
      "loss: [577550.0]\n",
      "Exploring\n",
      "Selected action  [3 0]\n",
      "[3 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 60us/step - loss: 664614.5000\n",
      "rewards:  -103.0 q-value:  0\n",
      "loss: [664614.5]\n",
      "Exploring\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 64us/step - loss: 76089.6250\n",
      "rewards:  -95.0 q-value:  0\n",
      "loss: [76089.625]\n",
      "Exploring\n",
      "Selected action  [4 3]\n",
      "[4 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 63us/step - loss: 558616.5000\n",
      "rewards:  -95.0 q-value:  0\n",
      "loss: [558616.5]\n",
      "Exploring\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 49us/step - loss: 271867.5000\n",
      "rewards:  -113.0 q-value:  0\n",
      "loss: [271867.5]\n",
      "Exploring\n",
      "Selected action  [0 4]\n",
      "[0 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 80us/step - loss: 208274.0312\n",
      "rewards:  -124.0 q-value:  0\n",
      "loss: [208274.03125]\n",
      "Exploring\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 64us/step - loss: 322888.8125\n",
      "rewards:  -126.0 q-value:  0\n",
      "loss: [322888.8125]\n",
      "Exploring\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 80us/step - loss: 550029.2500\n",
      "rewards:  -113.0 q-value:  0\n",
      "loss: [550029.25]\n",
      "Exploring\n",
      "Selected action  [0 4]\n",
      "[0 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 70us/step - loss: 151615.0312\n",
      "rewards:  -144.0 q-value:  0\n",
      "loss: [151615.03125]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 70us/step - loss: 312531.5938\n",
      "rewards:  -121.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [312531.59375]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 83us/step - loss: 325433.8438\n",
      "rewards:  -126.0 q-value:  0\n",
      "loss: [325433.84375]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 79us/step - loss: 486542.4688\n",
      "rewards:  -131.0 q-value:  0\n",
      "loss: [486542.46875]\n",
      "Exploring\n",
      "Selected action  [4 3]\n",
      "[4 3]\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 74us/step - loss: 600289.3750\n",
      "rewards:  -143.0 q-value:  0\n",
      "loss: [600289.375]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 61us/step - loss: 475299.3750\n",
      "rewards:  -171.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [475299.375]\n",
      "Exploring\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 79us/step - loss: 195873.3438\n",
      "rewards:  -151.0 q-value:  0\n",
      "loss: [195873.34375]\n",
      "Exploring\n",
      "Selected action  [3 1]\n",
      "[3 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 73us/step - loss: 178093.4062\n",
      "rewards:  -143.0 q-value:  0\n",
      "loss: [178093.40625]\n",
      "Exploring\n",
      "Selected action  [4 3]\n",
      "[4 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 58us/step - loss: 892919.3750\n",
      "rewards:  -154.0 q-value:  0\n",
      "loss: [892919.375]\n",
      "Exploring\n",
      "Selected action  [3 0]\n",
      "[3 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 65us/step - loss: 205866.4375\n",
      "rewards:  -146.0 q-value:  0\n",
      "loss: [205866.4375]\n",
      "Exploring\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 73us/step - loss: 314031.7500\n",
      "rewards:  -122.0 q-value:  0\n",
      "loss: [314031.75]\n",
      "Exploring\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 59us/step - loss: 593645.8125\n",
      "rewards:  -110.0 q-value:  0\n",
      "loss: [593645.8125]\n",
      "Exploring\n",
      "Selected action  [0 4]\n",
      "[0 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 65us/step - loss: 526157.3750\n",
      "rewards:  -135.0 q-value:  0\n",
      "loss: [526157.375]\n",
      "Exploring\n",
      "Selected action  [4 3]\n",
      "[4 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 66us/step - loss: 215461.8125\n",
      "rewards:  -127.0 q-value:  0\n",
      "loss: [215461.8125]\n",
      "Exploring\n",
      "Selected action  [4 3]\n",
      "[4 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 76us/step - loss: 488145.0625\n",
      "rewards:  -130.0 q-value:  0\n",
      "loss: [488145.0625]\n",
      "Exploring\n",
      "Selected action  [3 0]\n",
      "[3 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 72us/step - loss: 355874.0625\n",
      "rewards:  -106.0 q-value:  0\n",
      "loss: [355874.0625]\n",
      "Exploring\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 72us/step - loss: 280300.1250\n",
      "rewards:  -90.0 q-value:  0\n",
      "loss: [280300.125]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 57us/step - loss: 405111.4375\n",
      "rewards:  -92.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [405111.4375]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 63us/step - loss: 212016.1875\n",
      "rewards:  -94.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [212016.1875]\n",
      "Exploring\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 61us/step - loss: 505148.5938\n",
      "rewards:  -90.0 q-value:  0\n",
      "loss: [505148.59375]\n",
      "Exploring\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 54us/step - loss: 436588.6875\n",
      "rewards:  -95.0 q-value:  0\n",
      "loss: [436588.6875]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 87us/step - loss: 268822.3750\n",
      "rewards:  -102.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [268822.375]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 62us/step - loss: 351434.0625\n",
      "rewards:  -105.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [351434.0625]\n",
      "Exploring\n",
      "Selected action  [4 3]\n",
      "[4 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 69us/step - loss: 208197.7188\n",
      "rewards:  -95.0 q-value:  0\n",
      "loss: [208197.71875]\n",
      "Exploring\n",
      "Selected action  [3 0]\n",
      "[3 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 66us/step - loss: 118360.5938\n",
      "rewards:  -91.0 q-value:  0\n",
      "loss: [118360.59375]\n",
      "Exploring\n",
      "Selected action  [0 4]\n",
      "[0 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 74us/step - loss: 588553.0000\n",
      "rewards:  -79.0 q-value:  0\n",
      "loss: [588553.0]\n",
      "Exploring\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 59us/step - loss: 254541.0625\n",
      "rewards:  -68.0 q-value:  0\n",
      "loss: [254541.0625]\n",
      "Exploring\n",
      "Selected action  [3 1]\n",
      "[3 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 98us/step - loss: 956171.0000\n",
      "rewards:  -52.0 q-value:  0\n",
      "loss: [956171.0]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 76us/step - loss: 361679.6875\n",
      "rewards:  -57.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [361679.6875]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 72us/step - loss: 231903.7812\n",
      "rewards:  -61.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [231903.78125]\n",
      "Exploring\n",
      "Selected action  [4 3]\n",
      "[4 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 70us/step - loss: 203986.1875\n",
      "rewards:  -37.0 q-value:  0\n",
      "loss: [203986.1875]\n",
      "Exploring\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 69us/step - loss: 497410.3438\n",
      "rewards:  -36.0 q-value:  0\n",
      "loss: [497410.34375]\n",
      "Exploring\n",
      "Selected action  [4 3]\n",
      "[4 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 70us/step - loss: 373789.2812\n",
      "rewards:  -38.0 q-value:  0\n",
      "loss: [373789.28125]\n",
      "Exploring\n",
      "Selected action  [0 4]\n",
      "[0 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 79us/step - loss: 130275.1875\n",
      "rewards:  -64.0 q-value:  0\n",
      "loss: [130275.1875]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 166us/step - loss: 204109.0156\n",
      "rewards:  -55.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [204109.015625]\n",
      "Exploring\n",
      "Selected action  [0 4]\n",
      "[0 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 71us/step - loss: 380020.9062\n",
      "rewards:  -61.0 q-value:  0\n",
      "loss: [380020.90625]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 66us/step - loss: 413584.7188\n",
      "rewards:  -58.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [413584.71875]\n",
      "Exploring\n",
      "Selected action  [3 0]\n",
      "[3 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 80us/step - loss: 323370.0938\n",
      "rewards:  -58.0 q-value:  0\n",
      "loss: [323370.09375]\n",
      "Exploring\n",
      "Selected action  [0 4]\n",
      "[0 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 117us/step - loss: 120173.2188\n",
      "rewards:  -54.0 q-value:  0\n",
      "loss: [120173.21875]\n",
      "Exploring\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 67us/step - loss: 397557.3750\n",
      "rewards:  -51.0 q-value:  0\n",
      "loss: [397557.375]\n",
      "Exploring\n",
      "Selected action  [4 3]\n",
      "[4 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 72us/step - loss: 213527.7500\n",
      "rewards:  -54.0 q-value:  0\n",
      "loss: [213527.75]\n",
      "Exploring\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 74us/step - loss: 508425.5000\n",
      "rewards:  -54.0 q-value:  0\n",
      "loss: [508425.5]\n",
      "Exploring\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 90us/step - loss: 494525.8125\n",
      "rewards:  -61.0 q-value:  0\n",
      "loss: [494525.8125]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 68us/step - loss: 517430.3125\n",
      "rewards:  -63.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [517430.3125]\n",
      "Exploring\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 62us/step - loss: 174473.4688\n",
      "rewards:  -43.0 q-value:  0\n",
      "loss: [174473.46875]\n",
      "Exploring\n",
      "Selected action  [4 3]\n",
      "[4 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 89us/step - loss: 200749.1562\n",
      "rewards:  -50.0 q-value:  0\n",
      "loss: [200749.15625]\n",
      "Exploring\n",
      "Selected action  [3 1]\n",
      "[3 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 80us/step - loss: 476011.5625\n",
      "rewards:  -46.0 q-value:  0\n",
      "loss: [476011.5625]\n",
      "Exploring\n",
      "Selected action  [3 0]\n",
      "[3 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 65us/step - loss: 513780.9375\n",
      "rewards:  -43.0 q-value:  0\n",
      "loss: [513780.9375]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 87us/step - loss: 304148.3125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rewards:  -48.0 q-value:  0\n",
      "loss: [304148.3125]\n",
      "Exploring\n",
      "Selected action  [3 0]\n",
      "[3 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 83us/step - loss: 292882.5938\n",
      "rewards:  -50.0 q-value:  0\n",
      "loss: [292882.59375]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 84us/step - loss: 224143.3438\n",
      "rewards:  -42.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [224143.34375]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 58us/step - loss: 274860.0312\n",
      "rewards:  -44.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [274860.03125]\n",
      "Exploring\n",
      "Selected action  [4 3]\n",
      "[4 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 60us/step - loss: 455193.9062\n",
      "rewards:  -44.0 q-value:  0\n",
      "loss: [455193.90625]\n",
      "Exploring\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 69us/step - loss: 504957.1562\n",
      "rewards:  -50.0 q-value:  0\n",
      "loss: [504957.15625]\n",
      "Exploring\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 68us/step - loss: 261885.6562\n",
      "rewards:  -52.0 q-value:  0\n",
      "loss: [261885.65625]\n",
      "Number of actions available 8\n",
      "Episode : 20\n",
      "Exploring\n",
      "Selected action  [4 3]\n",
      "[4 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 83us/step - loss: 557732.3750\n",
      "rewards:  -2.0 q-value:  0\n",
      "loss: [557732.375]\n",
      "Exploring\n",
      "Selected action  [1 2]\n",
      "[1 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 68us/step - loss: 521947.9375\n",
      "rewards:  6.0 q-value:  0\n",
      "loss: [521947.9375]\n",
      "Exploring\n",
      "Selected action  [1 4]\n",
      "[1 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 65us/step - loss: 117179.9688\n",
      "rewards:  4.0 q-value:  0\n",
      "loss: [117179.96875]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 89us/step - loss: 488653.8438\n",
      "rewards:  2.0 q-value:  0\n",
      "loss: [488653.84375]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 71us/step - loss: 696158.5625\n",
      "rewards:  0.0 q-value:  0\n",
      "loss: [696158.5625]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 67us/step - loss: 210944.3750\n",
      "rewards:  -5.0 q-value:  0\n",
      "loss: [210944.375]\n",
      "Exploiting\n",
      "Selected action  [4 3]\n",
      "[4 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 70us/step - loss: 304817.2812\n",
      "rewards:  -33.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [304817.28125]\n",
      "Exploring\n",
      "Selected action  [1 4]\n",
      "[1 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 71us/step - loss: 138490.2188\n",
      "rewards:  -21.0 q-value:  0\n",
      "loss: [138490.21875]\n",
      "Exploiting\n",
      "Selected action  [3 0]\n",
      "[3 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 73us/step - loss: 651710.8750\n",
      "rewards:  9.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [651710.875]\n",
      "Exploring\n",
      "Selected action  [3 0]\n",
      "[3 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 66us/step - loss: 25133.4902\n",
      "rewards:  6.0 q-value:  0\n",
      "loss: [25133.490234375]\n",
      "Exploring\n",
      "Selected action  [4 2]\n",
      "[4 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 88us/step - loss: 184386.2500\n",
      "rewards:  -1.0 q-value:  0\n",
      "loss: [184386.25]\n",
      "Exploiting\n",
      "Selected action  [4 3]\n",
      "[4 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 63us/step - loss: 392997.9375\n",
      "rewards:  25.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [392997.9375]\n",
      "Exploring\n",
      "Selected action  [3 0]\n",
      "[3 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 64us/step - loss: 247380.0312\n",
      "rewards:  49.0 q-value:  0\n",
      "loss: [247380.03125]\n",
      "Exploring\n",
      "Selected action  [4 2]\n",
      "[4 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 74us/step - loss: 311716.5312\n",
      "rewards:  64.0 q-value:  0\n",
      "loss: [311716.53125]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 80us/step - loss: 281700.8125\n",
      "rewards:  47.0 q-value:  0\n",
      "loss: [281700.8125]\n",
      "Exploring\n",
      "Selected action  [4 3]\n",
      "[4 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 59us/step - loss: 376114.8750\n",
      "rewards:  35.0 q-value:  0\n",
      "loss: [376114.875]\n",
      "Exploiting\n",
      "Selected action  [4 3]\n",
      "[4 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 74us/step - loss: 276516.5312\n",
      "rewards:  33.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [276516.53125]\n",
      "Exploiting\n",
      "Selected action  [3 0]\n",
      "[3 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 75us/step - loss: 215659.9375\n",
      "rewards:  37.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [215659.9375]\n",
      "Exploring\n",
      "Selected action  [1 2]\n",
      "[1 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 108us/step - loss: 125993.6250\n",
      "rewards:  66.0 q-value:  0\n",
      "loss: [125993.625]\n",
      "Exploring\n",
      "Selected action  [3 0]\n",
      "[3 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 87us/step - loss: 200062.0312\n",
      "rewards:  83.0 q-value:  0\n",
      "loss: [200062.03125]\n",
      "Exploring\n",
      "Selected action  [4 3]\n",
      "[4 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 77us/step - loss: 692627.0625\n",
      "rewards:  64.0 q-value:  0\n",
      "loss: [692627.0625]\n",
      "Exploiting\n",
      "Selected action  [3 0]\n",
      "[3 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 69us/step - loss: 576275.6250\n",
      "rewards:  72.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [576275.625]\n",
      "Exploiting\n",
      "Selected action  [0 2]\n",
      "[0 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 64us/step - loss: 438017.1875\n",
      "rewards:  84.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [438017.1875]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 55us/step - loss: 494601.7500\n",
      "rewards:  69.0 q-value:  0\n",
      "loss: [494601.75]\n",
      "Exploring\n",
      "Selected action  [3 0]\n",
      "[3 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 64us/step - loss: 407991.8125\n",
      "rewards:  63.0 q-value:  0\n",
      "loss: [407991.8125]\n",
      "Exploring\n",
      "Selected action  [3 0]\n",
      "[3 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 70us/step - loss: 885535.5000\n",
      "rewards:  58.0 q-value:  0\n",
      "loss: [885535.5]\n",
      "Exploiting\n",
      "Selected action  [4 3]\n",
      "[4 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 85us/step - loss: 161840.4062\n",
      "rewards:  52.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [161840.40625]\n",
      "Exploring\n",
      "Selected action  [1 4]\n",
      "[1 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 89us/step - loss: 336190.5938\n",
      "rewards:  39.0 q-value:  0\n",
      "loss: [336190.59375]\n",
      "Exploring\n",
      "Selected action  [1 2]\n",
      "[1 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 61us/step - loss: 186493.4688\n",
      "rewards:  52.0 q-value:  0\n",
      "loss: [186493.46875]\n",
      "Exploring\n",
      "Selected action  [0 2]\n",
      "[0 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 67us/step - loss: 421022.4062\n",
      "rewards:  47.0 q-value:  0\n",
      "loss: [421022.40625]\n",
      "Exploiting\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 72us/step - loss: 112212.4062\n",
      "rewards:  54.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [112212.40625]\n",
      "Exploring\n",
      "Selected action  [3 0]\n",
      "[3 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 62us/step - loss: 215177.6875\n",
      "rewards:  53.0 q-value:  0\n",
      "loss: [215177.6875]\n",
      "Exploiting\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 69us/step - loss: 289808.9375\n",
      "rewards:  46.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [289808.9375]\n",
      "Exploring\n",
      "Selected action  [3 0]\n",
      "[3 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 79us/step - loss: 270124.7188\n",
      "rewards:  42.0 q-value:  0\n",
      "loss: [270124.71875]\n",
      "Exploring\n",
      "Selected action  [4 3]\n",
      "[4 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 100us/step - loss: 542283.2500\n",
      "rewards:  58.0 q-value:  0\n",
      "loss: [542283.25]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 75us/step - loss: 256351.2188\n",
      "rewards:  53.0 q-value:  0\n",
      "loss: [256351.21875]\n",
      "Exploiting\n",
      "Selected action  [4 2]\n",
      "[4 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 80us/step - loss: 195532.8750\n",
      "rewards:  85.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [195532.875]\n",
      "Exploring\n",
      "Selected action  [3 0]\n",
      "[3 0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 72us/step - loss: 252608.0938\n",
      "rewards:  72.0 q-value:  0\n",
      "loss: [252608.09375]\n",
      "Exploring\n",
      "Selected action  [4 3]\n",
      "[4 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 58us/step - loss: 528472.5000\n",
      "rewards:  91.0 q-value:  0\n",
      "loss: [528472.5]\n",
      "Exploring\n",
      "Selected action  [1 2]\n",
      "[1 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 68us/step - loss: 30938.2812\n",
      "rewards:  99.0 q-value:  0\n",
      "loss: [30938.28125]\n",
      "Exploiting\n",
      "Selected action  [0 2]\n",
      "[0 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 74us/step - loss: 273910.9375\n",
      "rewards:  93.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [273910.9375]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 75us/step - loss: 208637.0938\n",
      "rewards:  91.0 q-value:  0\n",
      "loss: [208637.09375]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 98us/step - loss: 73984.4688\n",
      "rewards:  86.0 q-value:  0\n",
      "loss: [73984.46875]\n",
      "Exploring\n",
      "Selected action  [4 3]\n",
      "[4 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 50us/step - loss: 485937.5000\n",
      "rewards:  58.0 q-value:  0\n",
      "loss: [485937.5]\n",
      "Exploiting\n",
      "Selected action  [4 3]\n",
      "[4 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 55us/step - loss: 677895.8750\n",
      "rewards:  55.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [677895.875]\n",
      "Exploring\n",
      "Selected action  [0 2]\n",
      "[0 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 94us/step - loss: 231007.9062\n",
      "rewards:  13.0 q-value:  0\n",
      "loss: [231007.90625]\n",
      "Exploring\n",
      "Selected action  [1 2]\n",
      "[1 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 84us/step - loss: 466569.7188\n",
      "rewards:  8.0 q-value:  0\n",
      "loss: [466569.71875]\n",
      "Exploring\n",
      "Selected action  [0 2]\n",
      "[0 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 77us/step - loss: 826542.4375\n",
      "rewards:  2.0 q-value:  0\n",
      "loss: [826542.4375]\n",
      "Exploring\n",
      "Selected action  [3 0]\n",
      "[3 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 75us/step - loss: 212417.2500\n",
      "rewards:  -35.0 q-value:  0\n",
      "loss: [212417.25]\n",
      "Exploring\n",
      "Selected action  [1 2]\n",
      "[1 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 69us/step - loss: 187061.2812\n",
      "rewards:  -51.0 q-value:  0\n",
      "loss: [187061.28125]\n",
      "Exploring\n",
      "Selected action  [1 2]\n",
      "[1 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 61us/step - loss: 576768.8125\n",
      "rewards:  -52.0 q-value:  0\n",
      "loss: [576768.8125]\n",
      "Exploring\n",
      "Selected action  [1 2]\n",
      "[1 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 66us/step - loss: 245021.5938\n",
      "rewards:  -57.0 q-value:  0\n",
      "loss: [245021.59375]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 61us/step - loss: 224160.3750\n",
      "rewards:  -62.0 q-value:  0\n",
      "loss: [224160.375]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 62us/step - loss: 375847.3125\n",
      "rewards:  -67.0 q-value:  0\n",
      "loss: [375847.3125]\n",
      "Exploring\n",
      "Selected action  [1 2]\n",
      "[1 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 70us/step - loss: 422339.5938\n",
      "rewards:  -57.0 q-value:  0\n",
      "loss: [422339.59375]\n",
      "Exploring\n",
      "Selected action  [3 0]\n",
      "[3 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 61us/step - loss: 354078.6250\n",
      "rewards:  -63.0 q-value:  0\n",
      "loss: [354078.625]\n",
      "Exploring\n",
      "Selected action  [1 2]\n",
      "[1 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 60us/step - loss: 845249.6250\n",
      "rewards:  -62.0 q-value:  0\n",
      "loss: [845249.625]\n",
      "Exploring\n",
      "Selected action  [1 4]\n",
      "[1 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 80us/step - loss: 80002.4062\n",
      "rewards:  -117.0 q-value:  0\n",
      "loss: [80002.40625]\n",
      "Exploring\n",
      "Selected action  [1 2]\n",
      "[1 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 75us/step - loss: 277317.4062\n",
      "rewards:  -73.0 q-value:  0\n",
      "loss: [277317.40625]\n",
      "Exploring\n",
      "Selected action  [1 2]\n",
      "[1 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 79us/step - loss: 165884.0625\n",
      "rewards:  -77.0 q-value:  0\n",
      "loss: [165884.0625]\n",
      "Exploiting\n",
      "Selected action  [1 2]\n",
      "[1 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 71us/step - loss: 450504.7188\n",
      "rewards:  -81.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [450504.71875]\n",
      "Exploiting\n",
      "Selected action  [1 4]\n",
      "[1 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 63us/step - loss: 228616.9688\n",
      "rewards:  -86.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [228616.96875]\n",
      "Exploiting\n",
      "Selected action  [3 0]\n",
      "[3 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 55us/step - loss: 437490.1875\n",
      "rewards:  -108.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [437490.1875]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 82us/step - loss: 487270.1562\n",
      "rewards:  -113.0 q-value:  0\n",
      "loss: [487270.15625]\n",
      "Exploring\n",
      "Selected action  [4 3]\n",
      "[4 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 94us/step - loss: 339182.2500\n",
      "rewards:  -94.0 q-value:  0\n",
      "loss: [339182.25]\n",
      "Exploiting\n",
      "Selected action  [4 3]\n",
      "[4 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 68us/step - loss: 221663.9062\n",
      "rewards:  -98.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [221663.90625]\n",
      "Exploring\n",
      "Selected action  [1 4]\n",
      "[1 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 59us/step - loss: 494695.8750\n",
      "rewards:  -105.0 q-value:  0\n",
      "loss: [494695.875]\n",
      "Exploring\n",
      "Selected action  [3 0]\n",
      "[3 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 74us/step - loss: 572415.8750\n",
      "rewards:  -95.0 q-value:  0\n",
      "loss: [572415.875]\n",
      "Exploring\n",
      "Selected action  [3 0]\n",
      "[3 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 81us/step - loss: 483345.5312\n",
      "rewards:  -101.0 q-value:  0\n",
      "loss: [483345.53125]\n",
      "Exploring\n",
      "Selected action  [0 2]\n",
      "[0 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 82us/step - loss: 652736.6250\n",
      "rewards:  -93.0 q-value:  0\n",
      "loss: [652736.625]\n",
      "Exploiting\n",
      "Selected action  [4 2]\n",
      "[4 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 84us/step - loss: 106210.4062\n",
      "rewards:  -94.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [106210.40625]\n",
      "Exploiting\n",
      "Selected action  [0 2]\n",
      "[0 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 68us/step - loss: 451250.7500\n",
      "rewards:  -99.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [451250.75]\n",
      "Exploring\n",
      "Selected action  [4 3]\n",
      "[4 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 91us/step - loss: 313196.0000\n",
      "rewards:  -75.0 q-value:  0\n",
      "loss: [313196.0]\n",
      "Exploring\n",
      "Selected action  [3 0]\n",
      "[3 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 83us/step - loss: 33068.5000\n",
      "rewards:  -47.0 q-value:  0\n",
      "loss: [33068.5]\n",
      "Exploiting\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 89us/step - loss: 322412.8750\n",
      "rewards:  -52.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [322412.875]\n",
      "Exploring\n",
      "Selected action  [4 3]\n",
      "[4 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 95us/step - loss: 444323.6562\n",
      "rewards:  -52.0 q-value:  0\n",
      "loss: [444323.65625]\n",
      "Exploring\n",
      "Selected action  [0 2]\n",
      "[0 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 61us/step - loss: 164682.8438\n",
      "rewards:  -55.0 q-value:  0\n",
      "loss: [164682.84375]\n",
      "Exploring\n",
      "Selected action  [1 4]\n",
      "[1 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 87us/step - loss: 454763.8750\n",
      "rewards:  -105.0 q-value:  0\n",
      "loss: [454763.875]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 77us/step - loss: 364319.1875\n",
      "rewards:  -110.0 q-value:  0\n",
      "loss: [364319.1875]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 71us/step - loss: 690274.5000\n",
      "rewards:  -117.0 q-value:  0\n",
      "loss: [690274.5]\n",
      "Exploiting\n",
      "Selected action  [3 0]\n",
      "[3 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 74us/step - loss: 408764.9062\n",
      "rewards:  -121.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [408764.90625]\n",
      "Exploring\n",
      "Selected action  [4 2]\n",
      "[4 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 71us/step - loss: 46575.1562\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rewards:  -89.0 q-value:  0\n",
      "loss: [46575.15625]\n",
      "Exploring\n",
      "Selected action  [1 2]\n",
      "[1 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 81us/step - loss: 91457.5938\n",
      "rewards:  -91.0 q-value:  0\n",
      "loss: [91457.59375]\n",
      "Exploring\n",
      "Selected action  [0 2]\n",
      "[0 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 71us/step - loss: 310039.1875\n",
      "rewards:  -95.0 q-value:  0\n",
      "loss: [310039.1875]\n",
      "Exploiting\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 78us/step - loss: 264337.9688\n",
      "rewards:  -109.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [264337.96875]\n",
      "Exploring\n",
      "Selected action  [4 3]\n",
      "[4 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 89us/step - loss: 414549.9062\n",
      "rewards:  -106.0 q-value:  0\n",
      "loss: [414549.90625]\n",
      "Exploring\n",
      "Selected action  [1 2]\n",
      "[1 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 72us/step - loss: 198846.1562\n",
      "rewards:  -98.0 q-value:  0\n",
      "loss: [198846.15625]\n",
      "Exploring\n",
      "Selected action  [4 2]\n",
      "[4 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 70us/step - loss: 570582.2500\n",
      "rewards:  -102.0 q-value:  0\n",
      "loss: [570582.25]\n",
      "Exploring\n",
      "Selected action  [1 4]\n",
      "[1 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 69us/step - loss: 73119.0000\n",
      "rewards:  -104.0 q-value:  0\n",
      "loss: [73119.0]\n",
      "Exploring\n",
      "Selected action  [0 2]\n",
      "[0 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 77us/step - loss: 169640.3125\n",
      "rewards:  -97.0 q-value:  0\n",
      "loss: [169640.3125]\n",
      "Exploring\n",
      "Selected action  [1 4]\n",
      "[1 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 78us/step - loss: 65252.9375\n",
      "rewards:  -125.0 q-value:  0\n",
      "loss: [65252.9375]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 101us/step - loss: 437317.9062\n",
      "rewards:  -132.0 q-value:  0\n",
      "loss: [437317.90625]\n",
      "Exploring\n",
      "Selected action  [1 2]\n",
      "[1 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 69us/step - loss: 541076.5000\n",
      "rewards:  -122.0 q-value:  0\n",
      "loss: [541076.5]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 88us/step - loss: 314045.5625\n",
      "rewards:  -139.0 q-value:  0\n",
      "loss: [314045.5625]\n",
      "Exploring\n",
      "Selected action  [1 2]\n",
      "[1 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 64us/step - loss: 574763.6875\n",
      "rewards:  -144.0 q-value:  0\n",
      "loss: [574763.6875]\n",
      "Exploring\n",
      "Selected action  [1 4]\n",
      "[1 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 69us/step - loss: 414373.7812\n",
      "rewards:  -149.0 q-value:  0\n",
      "loss: [414373.78125]\n",
      "Exploring\n",
      "Selected action  [4 3]\n",
      "[4 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 76us/step - loss: 83421.5469\n",
      "rewards:  -113.0 q-value:  0\n",
      "loss: [83421.546875]\n",
      "Exploiting\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 73us/step - loss: 229539.4375\n",
      "rewards:  -131.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [229539.4375]\n",
      "Number of actions available 9\n",
      "Episode : 21\n",
      "Exploring\n",
      "Selected action  [4 0]\n",
      "[4 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 77us/step - loss: 470432.5625\n",
      "rewards:  -6.0 q-value:  0\n",
      "loss: [470432.5625]\n",
      "Exploiting\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 76us/step - loss: 130694.4375\n",
      "rewards:  -12.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [130694.4375]\n",
      "Exploiting\n",
      "Selected action  [4 2]\n",
      "[4 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 79us/step - loss: 120580.2812\n",
      "rewards:  -11.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [120580.28125]\n",
      "Exploiting\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 59us/step - loss: 137782.9375\n",
      "rewards:  -21.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [137782.9375]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 94us/step - loss: 386626.2500\n",
      "rewards:  -13.0 q-value:  0\n",
      "loss: [386626.25]\n",
      "Exploiting\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 55us/step - loss: 97012.6250\n",
      "rewards:  -18.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [97012.625]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 75us/step - loss: 37461.8438\n",
      "rewards:  -23.0 q-value:  0\n",
      "loss: [37461.84375]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 72us/step - loss: 492834.9062\n",
      "rewards:  -25.0 q-value:  0\n",
      "loss: [492834.90625]\n",
      "Exploiting\n",
      "Selected action  [4 2]\n",
      "[4 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 82us/step - loss: 132310.5000\n",
      "rewards:  -57.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [132310.5]\n",
      "Exploring\n",
      "Selected action  [0 4]\n",
      "[0 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 89us/step - loss: 17211.5938\n",
      "rewards:  -50.0 q-value:  0\n",
      "loss: [17211.59375]\n",
      "Exploring\n",
      "Selected action  [3 2]\n",
      "[3 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 82us/step - loss: 166361.3125\n",
      "rewards:  -36.0 q-value:  0\n",
      "loss: [166361.3125]\n",
      "Exploiting\n",
      "Selected action  [4 1]\n",
      "[4 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 74us/step - loss: 512736.6875\n",
      "rewards:  -54.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [512736.6875]\n",
      "Exploring\n",
      "Selected action  [3 1]\n",
      "[3 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 92us/step - loss: 143096.0938\n",
      "rewards:  -55.0 q-value:  0\n",
      "loss: [143096.09375]\n",
      "Exploring\n",
      "Selected action  [4 1]\n",
      "[4 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 83us/step - loss: 442967.5625\n",
      "rewards:  -55.0 q-value:  0\n",
      "loss: [442967.5625]\n",
      "Exploring\n",
      "Selected action  [4 1]\n",
      "[4 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 73us/step - loss: 598281.0000\n",
      "rewards:  -55.0 q-value:  0\n",
      "loss: [598281.0]\n",
      "Exploring\n",
      "Selected action  [4 1]\n",
      "[4 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 70us/step - loss: 477837.9062\n",
      "rewards:  -55.0 q-value:  0\n",
      "loss: [477837.90625]\n",
      "Exploring\n",
      "Selected action  [3 1]\n",
      "[3 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 71us/step - loss: 115174.6250\n",
      "rewards:  -56.0 q-value:  0\n",
      "loss: [115174.625]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 76us/step - loss: 463285.4375\n",
      "rewards:  -61.0 q-value:  0\n",
      "loss: [463285.4375]\n",
      "Exploring\n",
      "Selected action  [3 1]\n",
      "[3 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 93us/step - loss: 272665.5000\n",
      "rewards:  -67.0 q-value:  0\n",
      "loss: [272665.5]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 94us/step - loss: 537110.9375\n",
      "rewards:  -72.0 q-value:  0\n",
      "loss: [537110.9375]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 76us/step - loss: 183376.4375\n",
      "rewards:  -77.0 q-value:  0\n",
      "loss: [183376.4375]\n",
      "Exploring\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 58us/step - loss: 453528.1562\n",
      "rewards:  -93.0 q-value:  0\n",
      "loss: [453528.15625]\n",
      "Exploring\n",
      "Selected action  [4 2]\n",
      "[4 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 72us/step - loss: 259968.6562\n",
      "rewards:  -130.0 q-value:  0\n",
      "loss: [259968.65625]\n",
      "Exploring\n",
      "Selected action  [3 1]\n",
      "[3 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 80us/step - loss: 234284.5312\n",
      "rewards:  -141.0 q-value:  0\n",
      "loss: [234284.53125]\n",
      "Exploiting\n",
      "Selected action  [4 2]\n",
      "[4 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 97us/step - loss: 138368.2500\n",
      "rewards:  -161.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [138368.25]\n",
      "Exploiting\n",
      "Selected action  [4 0]\n",
      "[4 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 60us/step - loss: 508937.9688\n",
      "rewards:  -137.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [508937.96875]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 93us/step - loss: 410352.0938\n",
      "rewards:  -140.0 q-value:  0\n",
      "loss: [410352.09375]\n",
      "Exploring\n",
      "Selected action  [4 2]\n",
      "[4 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 73us/step - loss: 115115.0938\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rewards:  -145.0 q-value:  0\n",
      "loss: [115115.09375]\n",
      "Exploring\n",
      "Selected action  [4 0]\n",
      "[4 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 85us/step - loss: 34316.4688\n",
      "rewards:  -141.0 q-value:  0\n",
      "loss: [34316.46875]\n",
      "Exploiting\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 104us/step - loss: 242220.0625\n",
      "rewards:  -148.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [242220.0625]\n",
      "Exploiting\n",
      "Selected action  [3 1]\n",
      "[3 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 73us/step - loss: 268272.7188\n",
      "rewards:  -145.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [268272.71875]\n",
      "Exploring\n",
      "Selected action  [4 1]\n",
      "[4 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 97us/step - loss: 340020.1250\n",
      "rewards:  -145.0 q-value:  0\n",
      "loss: [340020.125]\n",
      "Exploring\n",
      "Selected action  [3 1]\n",
      "[3 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 59us/step - loss: 253023.7500\n",
      "rewards:  -147.0 q-value:  0\n",
      "loss: [253023.75]\n",
      "Exploiting\n",
      "Selected action  [3 1]\n",
      "[3 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 85us/step - loss: 364038.0938\n",
      "rewards:  -149.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [364038.09375]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 64us/step - loss: 44656.4688\n",
      "rewards:  -137.0 q-value:  0\n",
      "loss: [44656.46875]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 92us/step - loss: 391710.1562\n",
      "rewards:  -140.0 q-value:  0\n",
      "loss: [391710.15625]\n",
      "Exploring\n",
      "Selected action  [3 2]\n",
      "[3 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 69us/step - loss: 525410.7500\n",
      "rewards:  -168.0 q-value:  0\n",
      "loss: [525410.75]\n",
      "Exploring\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 88us/step - loss: 344726.7188\n",
      "rewards:  -173.0 q-value:  0\n",
      "loss: [344726.71875]\n",
      "Exploring\n",
      "Selected action  [3 1]\n",
      "[3 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 106us/step - loss: 363348.9688\n",
      "rewards:  -165.0 q-value:  0\n",
      "loss: [363348.96875]\n",
      "Exploiting\n",
      "Selected action  [0 4]\n",
      "[0 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 71us/step - loss: 275805.5938\n",
      "rewards:  -198.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [275805.59375]\n",
      "Exploring\n",
      "Selected action  [0 4]\n",
      "[0 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 83us/step - loss: 279058.3125\n",
      "rewards:  -199.0 q-value:  0\n",
      "loss: [279058.3125]\n",
      "Exploiting\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 62us/step - loss: 127801.4375\n",
      "rewards:  -195.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [127801.4375]\n",
      "Exploring\n",
      "Selected action  [4 0]\n",
      "[4 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 67us/step - loss: 29251.5625\n",
      "rewards:  -221.0 q-value:  0\n",
      "loss: [29251.5625]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 65us/step - loss: 554282.6250\n",
      "rewards:  -227.0 q-value:  0\n",
      "loss: [554282.625]\n",
      "Exploring\n",
      "Selected action  [4 0]\n",
      "[4 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 77us/step - loss: 360659.0000\n",
      "rewards:  -234.0 q-value:  0\n",
      "loss: [360659.0]\n",
      "Exploring\n",
      "Selected action  [4 1]\n",
      "[4 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 89us/step - loss: 58745.9375\n",
      "rewards:  -220.0 q-value:  0\n",
      "loss: [58745.9375]\n",
      "Exploring\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 70us/step - loss: 643190.5625\n",
      "rewards:  -204.0 q-value:  0\n",
      "loss: [643190.5625]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 82us/step - loss: 113421.1875\n",
      "rewards:  -209.0 q-value:  0\n",
      "loss: [113421.1875]\n",
      "Exploring\n",
      "Selected action  [3 1]\n",
      "[3 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 63us/step - loss: 369509.4062\n",
      "rewards:  -218.0 q-value:  0\n",
      "loss: [369509.40625]\n",
      "Exploring\n",
      "Selected action  [0 4]\n",
      "[0 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 85us/step - loss: 279599.4688\n",
      "rewards:  -204.0 q-value:  0\n",
      "loss: [279599.46875]\n",
      "Exploring\n",
      "Selected action  [4 2]\n",
      "[4 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 61us/step - loss: 444107.6875\n",
      "rewards:  -200.0 q-value:  0\n",
      "loss: [444107.6875]\n",
      "Exploiting\n",
      "Selected action  [4 0]\n",
      "[4 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 81us/step - loss: 172799.4062\n",
      "rewards:  -201.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [172799.40625]\n",
      "Exploring\n",
      "Selected action  [4 1]\n",
      "[4 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 70us/step - loss: 257617.3750\n",
      "rewards:  -194.0 q-value:  0\n",
      "loss: [257617.375]\n",
      "Exploring\n",
      "Selected action  [0 4]\n",
      "[0 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 75us/step - loss: 511665.7812\n",
      "rewards:  -234.0 q-value:  0\n",
      "loss: [511665.78125]\n",
      "Exploiting\n",
      "Selected action  [0 4]\n",
      "[0 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 64us/step - loss: 306460.0625\n",
      "rewards:  -234.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [306460.0625]\n",
      "Exploring\n",
      "Selected action  [4 0]\n",
      "[4 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 70us/step - loss: 404422.3438\n",
      "rewards:  -234.0 q-value:  0\n",
      "loss: [404422.34375]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 83us/step - loss: 416137.1250\n",
      "rewards:  -242.0 q-value:  0\n",
      "loss: [416137.125]\n",
      "Exploring\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 60us/step - loss: 469893.0000\n",
      "rewards:  -253.0 q-value:  0\n",
      "loss: [469893.0]\n",
      "Exploring\n",
      "Selected action  [4 0]\n",
      "[4 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 66us/step - loss: 427333.7188\n",
      "rewards:  -262.0 q-value:  0\n",
      "loss: [427333.71875]\n",
      "Exploring\n",
      "Selected action  [3 1]\n",
      "[3 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 75us/step - loss: 294276.5000\n",
      "rewards:  -255.0 q-value:  0\n",
      "loss: [294276.5]\n",
      "Exploring\n",
      "Selected action  [4 1]\n",
      "[4 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 81us/step - loss: 121913.4375\n",
      "rewards:  -255.0 q-value:  0\n",
      "loss: [121913.4375]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 72us/step - loss: 115876.1562\n",
      "rewards:  -227.0 q-value:  0\n",
      "loss: [115876.15625]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 63us/step - loss: 261373.6562\n",
      "rewards:  -232.0 q-value:  0\n",
      "loss: [261373.65625]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 73us/step - loss: 509857.0312\n",
      "rewards:  -237.0 q-value:  0\n",
      "loss: [509857.03125]\n",
      "Exploring\n",
      "Selected action  [4 1]\n",
      "[4 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 64us/step - loss: 706630.4375\n",
      "rewards:  -237.0 q-value:  0\n",
      "loss: [706630.4375]\n",
      "Exploring\n",
      "Selected action  [3 1]\n",
      "[3 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 76us/step - loss: 750476.1875\n",
      "rewards:  -239.0 q-value:  0\n",
      "loss: [750476.1875]\n",
      "Exploring\n",
      "Selected action  [0 4]\n",
      "[0 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 83us/step - loss: 498227.3438\n",
      "rewards:  -255.0 q-value:  0\n",
      "loss: [498227.34375]\n",
      "Exploiting\n",
      "Selected action  [3 2]\n",
      "[3 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 75us/step - loss: 260170.0000\n",
      "rewards:  -265.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [260170.0]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 65us/step - loss: 627903.2500\n",
      "rewards:  -276.0 q-value:  0\n",
      "loss: [627903.25]\n",
      "Exploring\n",
      "Selected action  [4 0]\n",
      "[4 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 77us/step - loss: 128760.0469\n",
      "rewards:  -279.0 q-value:  0\n",
      "loss: [128760.046875]\n",
      "Exploring\n",
      "Selected action  [3 2]\n",
      "[3 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 73us/step - loss: 189952.7812\n",
      "rewards:  -270.0 q-value:  0\n",
      "loss: [189952.78125]\n",
      "Exploiting\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 78us/step - loss: 386782.6250\n",
      "rewards:  -280.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [386782.625]\n",
      "Exploring\n",
      "Selected action  [0 4]\n",
      "[0 4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 53us/step - loss: 149765.0312\n",
      "rewards:  -276.0 q-value:  0\n",
      "loss: [149765.03125]\n",
      "Exploring\n",
      "Selected action  [4 0]\n",
      "[4 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 80us/step - loss: 29308.8438\n",
      "rewards:  -272.0 q-value:  0\n",
      "loss: [29308.84375]\n",
      "Exploring\n",
      "Selected action  [4 2]\n",
      "[4 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 83us/step - loss: 406269.1562\n",
      "rewards:  -277.0 q-value:  0\n",
      "loss: [406269.15625]\n",
      "Exploring\n",
      "Selected action  [4 0]\n",
      "[4 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 70us/step - loss: 557761.8750\n",
      "rewards:  -273.0 q-value:  0\n",
      "loss: [557761.875]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 71us/step - loss: 211518.0625\n",
      "rewards:  -275.0 q-value:  0\n",
      "loss: [211518.0625]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 85us/step - loss: 361712.7812\n",
      "rewards:  -277.0 q-value:  0\n",
      "loss: [361712.78125]\n",
      "Exploiting\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 75us/step - loss: 525224.5000\n",
      "rewards:  -287.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [525224.5]\n",
      "Exploring\n",
      "Selected action  [4 0]\n",
      "[4 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 72us/step - loss: 183002.9062\n",
      "rewards:  -270.0 q-value:  0\n",
      "loss: [183002.90625]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 77us/step - loss: 315901.9375\n",
      "rewards:  -275.0 q-value:  0\n",
      "loss: [315901.9375]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 67us/step - loss: 285876.7812\n",
      "rewards:  -280.0 q-value:  0\n",
      "loss: [285876.78125]\n",
      "Exploring\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 67us/step - loss: 375060.8750\n",
      "rewards:  -321.0 q-value:  0\n",
      "loss: [375060.875]\n",
      "Exploring\n",
      "Selected action  [4 2]\n",
      "[4 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 72us/step - loss: 527561.8750\n",
      "rewards:  -332.0 q-value:  0\n",
      "loss: [527561.875]\n",
      "Exploring\n",
      "Selected action  [0 4]\n",
      "[0 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 70us/step - loss: 37343.2812\n",
      "rewards:  -330.0 q-value:  0\n",
      "loss: [37343.28125]\n",
      "Exploring\n",
      "Selected action  [0 4]\n",
      "[0 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 77us/step - loss: 278128.2812\n",
      "rewards:  -333.0 q-value:  0\n",
      "loss: [278128.28125]\n",
      "Exploring\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 73us/step - loss: 125623.1250\n",
      "rewards:  -349.0 q-value:  0\n",
      "loss: [125623.125]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 85us/step - loss: 643199.2500\n",
      "rewards:  -346.0 q-value:  0\n",
      "loss: [643199.25]\n",
      "Exploring\n",
      "Selected action  [3 1]\n",
      "[3 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 84us/step - loss: 876852.5000\n",
      "rewards:  -342.0 q-value:  0\n",
      "loss: [876852.5]\n",
      "Exploring\n",
      "Selected action  [3 1]\n",
      "[3 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 61us/step - loss: 258689.9375\n",
      "rewards:  -343.0 q-value:  0\n",
      "loss: [258689.9375]\n",
      "Exploiting\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 60us/step - loss: 84642.6875\n",
      "rewards:  -319.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [84642.6875]\n",
      "Exploring\n",
      "Selected action  [4 0]\n",
      "[4 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 66us/step - loss: 83223.2812\n",
      "rewards:  -350.0 q-value:  0\n",
      "loss: [83223.28125]\n",
      "Exploiting\n",
      "Selected action  [3 2]\n",
      "[3 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 159us/step - loss: 437787.1562\n",
      "rewards:  -345.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [437787.15625]\n",
      "Exploring\n",
      "Selected action  [3 2]\n",
      "[3 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 98us/step - loss: 305278.8750\n",
      "rewards:  -348.0 q-value:  0\n",
      "loss: [305278.875]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 76us/step - loss: 220382.6250\n",
      "rewards:  -335.0 q-value:  0\n",
      "loss: [220382.625]\n",
      "Exploring\n",
      "Selected action  [0 4]\n",
      "[0 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 73us/step - loss: 372611.5938\n",
      "rewards:  -319.0 q-value:  0\n",
      "loss: [372611.59375]\n",
      "Exploiting\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 67us/step - loss: 317637.5312\n",
      "rewards:  -324.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [317637.53125]\n",
      "Exploring\n",
      "Selected action  [0 4]\n",
      "[0 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 113us/step - loss: 129363.0312\n",
      "rewards:  -320.0 q-value:  0\n",
      "loss: [129363.03125]\n",
      "Exploring\n",
      "Selected action  [4 1]\n",
      "[4 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 71us/step - loss: 294279.0625\n",
      "rewards:  -304.0 q-value:  0\n",
      "loss: [294279.0625]\n",
      "Exploring\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 118us/step - loss: 90770.4062\n",
      "rewards:  -296.0 q-value:  0\n",
      "loss: [90770.40625]\n",
      "Exploiting\n",
      "Selected action  [4 2]\n",
      "[4 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 66us/step - loss: 112147.5625\n",
      "rewards:  -310.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [112147.5625]\n",
      "Exploring\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 110us/step - loss: 317826.2188\n",
      "rewards:  -311.0 q-value:  0\n",
      "loss: [317826.21875]\n",
      "Exploring\n",
      "Selected action  [3 2]\n",
      "[3 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 87us/step - loss: 383502.6875\n",
      "rewards:  -295.0 q-value:  0\n",
      "loss: [383502.6875]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 71us/step - loss: 119677.7812\n",
      "rewards:  -300.0 q-value:  0\n",
      "loss: [119677.78125]\n",
      "Exploring\n",
      "Selected action  [4 2]\n",
      "[4 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 59us/step - loss: 544504.7500\n",
      "rewards:  -327.0 q-value:  0\n",
      "loss: [544504.75]\n",
      "Exploring\n",
      "Selected action  [3 2]\n",
      "[3 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 79us/step - loss: 416812.1250\n",
      "rewards:  -331.0 q-value:  0\n",
      "loss: [416812.125]\n",
      "Exploring\n",
      "Selected action  [4 0]\n",
      "[4 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 74us/step - loss: 700003.2500\n",
      "rewards:  -341.0 q-value:  0\n",
      "loss: [700003.25]\n",
      "Exploiting\n",
      "Selected action  [4 1]\n",
      "[4 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 69us/step - loss: 259506.2188\n",
      "rewards:  -333.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [259506.21875]\n",
      "Exploiting\n",
      "Selected action  [4 1]\n",
      "[4 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 73us/step - loss: 211852.5938\n",
      "rewards:  -335.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [211852.59375]\n",
      "Exploring\n",
      "Selected action  [3 2]\n",
      "[3 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 73us/step - loss: 310235.6250\n",
      "rewards:  -330.0 q-value:  0\n",
      "loss: [310235.625]\n",
      "Exploiting\n",
      "Selected action  [4 1]\n",
      "[4 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 66us/step - loss: 460105.3438\n",
      "rewards:  -331.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [460105.34375]\n",
      "Exploiting\n",
      "Selected action  [3 1]\n",
      "[3 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 69us/step - loss: 318468.9688\n",
      "rewards:  -335.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [318468.96875]\n",
      "Exploiting\n",
      "Selected action  [4 2]\n",
      "[4 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 87us/step - loss: 230084.1562\n",
      "rewards:  -335.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [230084.15625]\n",
      "Exploring\n",
      "Selected action  [3 1]\n",
      "[3 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 67us/step - loss: 375197.1875\n",
      "rewards:  -331.0 q-value:  0\n",
      "loss: [375197.1875]\n",
      "Exploring\n",
      "Selected action  [4 0]\n",
      "[4 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 64us/step - loss: 734153.8750\n",
      "rewards:  -307.0 q-value:  0\n",
      "loss: [734153.875]\n",
      "Exploring\n",
      "Selected action  [3 2]\n",
      "[3 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 64us/step - loss: 511432.8750\n",
      "rewards:  -318.0 q-value:  0\n",
      "loss: [511432.875]\n",
      "Exploring\n",
      "Selected action  [1 3]\n",
      "[1 3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 79us/step - loss: 588624.1250\n",
      "rewards:  -341.0 q-value:  0\n",
      "loss: [588624.125]\n",
      "Exploring\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 67us/step - loss: 193841.7812\n",
      "rewards:  -344.0 q-value:  0\n",
      "loss: [193841.78125]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 85us/step - loss: 306885.7812\n",
      "rewards:  -349.0 q-value:  0\n",
      "loss: [306885.78125]\n",
      "Exploring\n",
      "Selected action  [0 4]\n",
      "[0 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 63us/step - loss: 188863.3750\n",
      "rewards:  -333.0 q-value:  0\n",
      "loss: [188863.375]\n",
      "Exploring\n",
      "Selected action  [4 1]\n",
      "[4 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 55us/step - loss: 140740.3438\n",
      "rewards:  -333.0 q-value:  0\n",
      "loss: [140740.34375]\n",
      "Exploring\n",
      "Selected action  [4 0]\n",
      "[4 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 85us/step - loss: 475948.0000\n",
      "rewards:  -321.0 q-value:  0\n",
      "loss: [475948.0]\n",
      "Exploring\n",
      "Selected action  [3 1]\n",
      "[3 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 63us/step - loss: 52811.0938\n",
      "rewards:  -314.0 q-value:  0\n",
      "loss: [52811.09375]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 72us/step - loss: 281340.0938\n",
      "rewards:  -314.0 q-value:  0\n",
      "loss: [281340.09375]\n",
      "Exploiting\n",
      "Selected action  [3 1]\n",
      "[3 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 70us/step - loss: 50997.5625\n",
      "rewards:  -318.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [50997.5625]\n",
      "Exploiting\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 81us/step - loss: 126691.1875\n",
      "rewards:  -323.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [126691.1875]\n",
      "Exploring\n",
      "Selected action  [3 1]\n",
      "[3 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 97us/step - loss: 167784.2500\n",
      "rewards:  -327.0 q-value:  0\n",
      "loss: [167784.25]\n",
      "Exploring\n",
      "Selected action  [4 1]\n",
      "[4 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 75us/step - loss: 221754.6250\n",
      "rewards:  -332.0 q-value:  0\n",
      "loss: [221754.625]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 67us/step - loss: 251389.0938\n",
      "rewards:  -316.0 q-value:  0\n",
      "loss: [251389.09375]\n",
      "Exploring\n",
      "Selected action  [4 2]\n",
      "[4 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 77us/step - loss: 161595.2812\n",
      "rewards:  -316.0 q-value:  0\n",
      "loss: [161595.28125]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 57us/step - loss: 118605.7500\n",
      "rewards:  -321.0 q-value:  0\n",
      "loss: [118605.75]\n",
      "Exploring\n",
      "Selected action  [4 2]\n",
      "[4 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 88us/step - loss: 391580.6562\n",
      "rewards:  -321.0 q-value:  0\n",
      "loss: [391580.65625]\n",
      "Exploring\n",
      "Selected action  [0 4]\n",
      "[0 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 82us/step - loss: 395107.6562\n",
      "rewards:  -341.0 q-value:  0\n",
      "loss: [395107.65625]\n",
      "Exploiting\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 70us/step - loss: 404060.1562\n",
      "rewards:  -346.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [404060.15625]\n",
      "Exploring\n",
      "Selected action  [4 1]\n",
      "[4 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 61us/step - loss: 180293.0938\n",
      "rewards:  -346.0 q-value:  0\n",
      "loss: [180293.09375]\n",
      "Exploring\n",
      "Selected action  [4 0]\n",
      "[4 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 63us/step - loss: 259477.6875\n",
      "rewards:  -346.0 q-value:  0\n",
      "loss: [259477.6875]\n",
      "Exploring\n",
      "Selected action  [4 1]\n",
      "[4 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 66us/step - loss: 160534.7188\n",
      "rewards:  -346.0 q-value:  0\n",
      "loss: [160534.71875]\n",
      "Exploring\n",
      "Selected action  [4 1]\n",
      "[4 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 83us/step - loss: 260241.3750\n",
      "rewards:  -346.0 q-value:  0\n",
      "loss: [260241.375]\n",
      "Exploring\n",
      "Selected action  [3 1]\n",
      "[3 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 76us/step - loss: 727661.2500\n",
      "rewards:  -348.0 q-value:  0\n",
      "loss: [727661.25]\n",
      "Exploring\n",
      "Selected action  [4 2]\n",
      "[4 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 67us/step - loss: 412319.9688\n",
      "rewards:  -358.0 q-value:  0\n",
      "loss: [412319.96875]\n",
      "Exploring\n",
      "Selected action  [4 0]\n",
      "[4 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 104us/step - loss: 177059.9688\n",
      "rewards:  -354.0 q-value:  0\n",
      "loss: [177059.96875]\n",
      "Exploring\n",
      "Selected action  [3 2]\n",
      "[3 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 77us/step - loss: 259168.5938\n",
      "rewards:  -349.0 q-value:  0\n",
      "loss: [259168.59375]\n",
      "Exploring\n",
      "Selected action  [4 0]\n",
      "[4 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 86us/step - loss: 270170.6875\n",
      "rewards:  -370.0 q-value:  0\n",
      "loss: [270170.6875]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 69us/step - loss: 391670.4375\n",
      "rewards:  -376.0 q-value:  0\n",
      "loss: [391670.4375]\n",
      "Exploring\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 64us/step - loss: 424006.3438\n",
      "rewards:  -390.0 q-value:  0\n",
      "loss: [424006.34375]\n",
      "Exploring\n",
      "Selected action  [3 1]\n",
      "[3 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 66us/step - loss: 64737.0195\n",
      "rewards:  -390.0 q-value:  0\n",
      "loss: [64737.01953125]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 68us/step - loss: 470523.3750\n",
      "rewards:  -395.0 q-value:  0\n",
      "loss: [470523.375]\n",
      "Exploring\n",
      "Selected action  [4 2]\n",
      "[4 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 78us/step - loss: 420342.5938\n",
      "rewards:  -400.0 q-value:  0\n",
      "loss: [420342.59375]\n",
      "Exploring\n",
      "Selected action  [4 1]\n",
      "[4 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 72us/step - loss: 175157.5625\n",
      "rewards:  -392.0 q-value:  0\n",
      "loss: [175157.5625]\n",
      "Exploiting\n",
      "Selected action  [0 4]\n",
      "[0 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 57us/step - loss: 478111.4062\n",
      "rewards:  -398.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [478111.40625]\n",
      "Number of actions available 3\n",
      "Episode : 22\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 69us/step - loss: 473662.4375\n",
      "rewards:  -25.0 q-value:  0\n",
      "loss: [473662.4375]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 107us/step - loss: 512935.6875\n",
      "rewards:  -30.0 q-value:  0\n",
      "loss: [512935.6875]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 78us/step - loss: 171839.0938\n",
      "rewards:  -35.0 q-value:  0\n",
      "loss: [171839.09375]\n",
      "Exploring\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 90us/step - loss: 590054.3750\n",
      "rewards:  -41.0 q-value:  0\n",
      "loss: [590054.375]\n",
      "Exploiting\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 83us/step - loss: 320660.4062\n",
      "rewards:  -56.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [320660.40625]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 72us/step - loss: 154045.8125\n",
      "rewards:  -56.0 q-value:  0\n",
      "loss: [154045.8125]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 70us/step - loss: 340473.3750\n",
      "rewards:  -56.0 q-value:  0\n",
      "loss: [340473.375]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 81us/step - loss: 439636.3438\n",
      "rewards:  -56.0 q-value:  0\n",
      "loss: [439636.34375]\n",
      "Exploiting\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 68us/step - loss: 554412.7500\n",
      "rewards:  -61.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [554412.75]\n",
      "Exploring\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 107us/step - loss: 334113.8750\n",
      "rewards:  -64.0 q-value:  0\n",
      "loss: [334113.875]\n",
      "Exploring\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 80us/step - loss: 441329.3438\n",
      "rewards:  -67.0 q-value:  0\n",
      "loss: [441329.34375]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 62us/step - loss: 314021.9062\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rewards:  -72.0 q-value:  0\n",
      "loss: [314021.90625]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 67us/step - loss: 260297.1875\n",
      "rewards:  -77.0 q-value:  0\n",
      "loss: [260297.1875]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 72us/step - loss: 141216.2812\n",
      "rewards:  -94.0 q-value:  0\n",
      "loss: [141216.28125]\n",
      "Exploiting\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 64us/step - loss: 307571.2188\n",
      "rewards:  -99.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [307571.21875]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 77us/step - loss: 191026.1562\n",
      "rewards:  -116.0 q-value:  0\n",
      "loss: [191026.15625]\n",
      "Exploring\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 68us/step - loss: 105136.5938\n",
      "rewards:  -113.0 q-value:  0\n",
      "loss: [105136.59375]\n",
      "Exploring\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 74us/step - loss: 415345.2812\n",
      "rewards:  -115.0 q-value:  0\n",
      "loss: [415345.28125]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 63us/step - loss: 391822.9688\n",
      "rewards:  -120.0 q-value:  0\n",
      "loss: [391822.96875]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 98us/step - loss: 319358.4688\n",
      "rewards:  -126.0 q-value:  0\n",
      "loss: [319358.46875]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 70us/step - loss: 402120.2500\n",
      "rewards:  -127.0 q-value:  0\n",
      "loss: [402120.25]\n",
      "Exploiting\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 75us/step - loss: 447263.2188\n",
      "rewards:  -133.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [447263.21875]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 108us/step - loss: 132482.1562\n",
      "rewards:  -135.0 q-value:  0\n",
      "loss: [132482.15625]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 70us/step - loss: 349852.5000\n",
      "rewards:  -137.0 q-value:  0\n",
      "loss: [349852.5]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 73us/step - loss: 230925.6250\n",
      "rewards:  -142.0 q-value:  0\n",
      "loss: [230925.625]\n",
      "Exploiting\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 88us/step - loss: 263463.3125\n",
      "rewards:  -144.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [263463.3125]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 63us/step - loss: 444610.7812\n",
      "rewards:  -149.0 q-value:  0\n",
      "loss: [444610.78125]\n",
      "Exploring\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 81us/step - loss: 233199.4062\n",
      "rewards:  -155.0 q-value:  0\n",
      "loss: [233199.40625]\n",
      "Exploring\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 65us/step - loss: 76431.1250\n",
      "rewards:  -161.0 q-value:  0\n",
      "loss: [76431.125]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 78us/step - loss: 237908.5625\n",
      "rewards:  -166.0 q-value:  0\n",
      "loss: [237908.5625]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 96us/step - loss: 145893.2500\n",
      "rewards:  -171.0 q-value:  0\n",
      "loss: [145893.25]\n",
      "Exploring\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 109us/step - loss: 542465.8750\n",
      "rewards:  -177.0 q-value:  0\n",
      "loss: [542465.875]\n",
      "Exploring\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 72us/step - loss: 506063.8125\n",
      "rewards:  -180.0 q-value:  0\n",
      "loss: [506063.8125]\n",
      "Exploring\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 66us/step - loss: 512626.2812\n",
      "rewards:  -183.0 q-value:  0\n",
      "loss: [512626.28125]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 106us/step - loss: 838426.1875\n",
      "rewards:  -185.0 q-value:  0\n",
      "loss: [838426.1875]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 84us/step - loss: 243435.0625\n",
      "rewards:  -190.0 q-value:  0\n",
      "loss: [243435.0625]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 90us/step - loss: 70756.0000\n",
      "rewards:  -192.0 q-value:  0\n",
      "loss: [70756.0]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 66us/step - loss: 85059.7500\n",
      "rewards:  -197.0 q-value:  0\n",
      "loss: [85059.75]\n",
      "Exploiting\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 76us/step - loss: 197153.2812\n",
      "rewards:  -199.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [197153.28125]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 84us/step - loss: 261113.4062\n",
      "rewards:  -204.0 q-value:  0\n",
      "loss: [261113.40625]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 77us/step - loss: 649137.1250\n",
      "rewards:  -209.0 q-value:  0\n",
      "loss: [649137.125]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 66us/step - loss: 190785.4688\n",
      "rewards:  -230.0 q-value:  0\n",
      "loss: [190785.46875]\n",
      "Exploring\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 71us/step - loss: 173109.7812\n",
      "rewards:  -215.0 q-value:  0\n",
      "loss: [173109.78125]\n",
      "Exploring\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 78us/step - loss: 600659.2500\n",
      "rewards:  -221.0 q-value:  0\n",
      "loss: [600659.25]\n",
      "Exploring\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 65us/step - loss: 40030.6250\n",
      "rewards:  -222.0 q-value:  0\n",
      "loss: [40030.625]\n",
      "Exploiting\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 62us/step - loss: 54967.6250\n",
      "rewards:  -219.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [54967.625]\n",
      "Exploiting\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 80us/step - loss: 439719.1562\n",
      "rewards:  -225.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [439719.15625]\n",
      "Exploring\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 92us/step - loss: 750842.2500\n",
      "rewards:  -226.0 q-value:  0\n",
      "loss: [750842.25]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 111us/step - loss: 468190.5312\n",
      "rewards:  -231.0 q-value:  0\n",
      "loss: [468190.53125]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 85us/step - loss: 403297.4062\n",
      "rewards:  -236.0 q-value:  0\n",
      "loss: [403297.40625]\n",
      "Exploiting\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 75us/step - loss: 483570.6875\n",
      "rewards:  -237.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [483570.6875]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 79us/step - loss: 60425.7500\n",
      "rewards:  -242.0 q-value:  0\n",
      "loss: [60425.75]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 79us/step - loss: 142487.4375\n",
      "rewards:  -274.0 q-value:  0\n",
      "loss: [142487.4375]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 71us/step - loss: 520044.0625\n",
      "rewards:  -279.0 q-value:  0\n",
      "loss: [520044.0625]\n",
      "Exploring\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 59us/step - loss: 116064.7812\n",
      "rewards:  -287.0 q-value:  0\n",
      "loss: [116064.78125]\n",
      "Exploring\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 74us/step - loss: 626572.6875\n",
      "rewards:  -290.0 q-value:  0\n",
      "loss: [626572.6875]\n",
      "Exploiting\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 87us/step - loss: 350250.1875\n",
      "rewards:  -295.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [350250.1875]\n",
      "Exploring\n",
      "Selected action  [2 0]\n",
      "[2 0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 81us/step - loss: 403066.5000\n",
      "rewards:  -301.0 q-value:  0\n",
      "loss: [403066.5]\n",
      "Exploiting\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 87us/step - loss: 392286.7188\n",
      "rewards:  -306.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [392286.71875]\n",
      "Exploring\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 73us/step - loss: 86657.8438\n",
      "rewards:  -308.0 q-value:  0\n",
      "loss: [86657.84375]\n",
      "Exploiting\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 61us/step - loss: 155917.2500\n",
      "rewards:  -313.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [155917.25]\n",
      "Exploring\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 75us/step - loss: 452162.5625\n",
      "rewards:  -315.0 q-value:  0\n",
      "loss: [452162.5625]\n",
      "Exploring\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 102us/step - loss: 610498.6250\n",
      "rewards:  -317.0 q-value:  0\n",
      "loss: [610498.625]\n",
      "Exploiting\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 83us/step - loss: 301357.7188\n",
      "rewards:  -322.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [301357.71875]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 94us/step - loss: 548507.1250\n",
      "rewards:  -327.0 q-value:  0\n",
      "loss: [548507.125]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 97us/step - loss: 422053.6250\n",
      "rewards:  -332.0 q-value:  0\n",
      "loss: [422053.625]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 63us/step - loss: 173101.9375\n",
      "rewards:  -337.0 q-value:  0\n",
      "loss: [173101.9375]\n",
      "Exploiting\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 79us/step - loss: 377983.0625\n",
      "rewards:  -340.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [377983.0625]\n",
      "Exploiting\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 64us/step - loss: 494528.7188\n",
      "rewards:  -345.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [494528.71875]\n",
      "Exploiting\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 63us/step - loss: 250178.9375\n",
      "rewards:  -350.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [250178.9375]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 74us/step - loss: 563826.7500\n",
      "rewards:  -355.0 q-value:  0\n",
      "loss: [563826.75]\n",
      "Exploring\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 115us/step - loss: 453055.7188\n",
      "rewards:  -358.0 q-value:  0\n",
      "loss: [453055.71875]\n",
      "Exploiting\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 77us/step - loss: 416989.0938\n",
      "rewards:  -363.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [416989.09375]\n",
      "Exploiting\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 66us/step - loss: 388027.9375\n",
      "rewards:  -368.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [388027.9375]\n",
      "Exploiting\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 77us/step - loss: 224753.4688\n",
      "rewards:  -373.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [224753.46875]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 92us/step - loss: 113409.2812\n",
      "rewards:  -366.0 q-value:  0\n",
      "loss: [113409.28125]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 88us/step - loss: 107322.0312\n",
      "rewards:  -371.0 q-value:  0\n",
      "loss: [107322.03125]\n",
      "Exploring\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 105us/step - loss: 318970.8125\n",
      "rewards:  -375.0 q-value:  0\n",
      "loss: [318970.8125]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 80us/step - loss: 692965.8125\n",
      "rewards:  -380.0 q-value:  0\n",
      "loss: [692965.8125]\n",
      "Exploring\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 60us/step - loss: 267886.6250\n",
      "rewards:  -384.0 q-value:  0\n",
      "loss: [267886.625]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 67us/step - loss: 190476.7188\n",
      "rewards:  -419.0 q-value:  0\n",
      "loss: [190476.71875]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 85us/step - loss: 283857.6562\n",
      "rewards:  -419.0 q-value:  0\n",
      "loss: [283857.65625]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 87us/step - loss: 443719.5938\n",
      "rewards:  -424.0 q-value:  0\n",
      "loss: [443719.59375]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 76us/step - loss: 89559.9062\n",
      "rewards:  -459.0 q-value:  0\n",
      "loss: [89559.90625]\n",
      "Exploring\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 73us/step - loss: 404611.1250\n",
      "rewards:  -431.0 q-value:  0\n",
      "loss: [404611.125]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 82us/step - loss: 211019.0625\n",
      "rewards:  -434.0 q-value:  0\n",
      "loss: [211019.0625]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 60us/step - loss: 157905.7500\n",
      "rewards:  -434.0 q-value:  0\n",
      "loss: [157905.75]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 88us/step - loss: 730689.1250\n",
      "rewards:  -439.0 q-value:  0\n",
      "loss: [730689.125]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 75us/step - loss: 333519.4688\n",
      "rewards:  -444.0 q-value:  0\n",
      "loss: [333519.46875]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 71us/step - loss: 736808.7500\n",
      "rewards:  -449.0 q-value:  0\n",
      "loss: [736808.75]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 83us/step - loss: 276081.7500\n",
      "rewards:  -454.0 q-value:  0\n",
      "loss: [276081.75]\n",
      "Exploring\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 101us/step - loss: 265503.0000\n",
      "rewards:  -459.0 q-value:  0\n",
      "loss: [265503.0]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 67us/step - loss: 61642.4062\n",
      "rewards:  -484.0 q-value:  0\n",
      "loss: [61642.40625]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 101us/step - loss: 294386.6250\n",
      "rewards:  -484.0 q-value:  0\n",
      "loss: [294386.625]\n",
      "Exploring\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 96us/step - loss: 452434.1875\n",
      "rewards:  -464.0 q-value:  0\n",
      "loss: [452434.1875]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 64us/step - loss: 72011.7812\n",
      "rewards:  -479.0 q-value:  0\n",
      "loss: [72011.78125]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 82us/step - loss: 665339.2500\n",
      "rewards:  -484.0 q-value:  0\n",
      "loss: [665339.25]\n",
      "Exploring\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 77us/step - loss: 244842.0312\n",
      "rewards:  -490.0 q-value:  0\n",
      "loss: [244842.03125]\n",
      "Exploring\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 74us/step - loss: 199220.6250\n",
      "rewards:  -493.0 q-value:  0\n",
      "loss: [199220.625]\n",
      "Exploring\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 64us/step - loss: 190317.9688\n",
      "rewards:  -498.0 q-value:  0\n",
      "loss: [190317.96875]\n",
      "Exploiting\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 72us/step - loss: 328006.1250\n",
      "rewards:  -503.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [328006.125]\n",
      "Exploring\n",
      "Selected action  [2 4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 74us/step - loss: 62802.4062\n",
      "rewards:  -520.0 q-value:  0\n",
      "loss: [62802.40625]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 95us/step - loss: 313489.1562\n",
      "rewards:  -521.0 q-value:  0\n",
      "loss: [313489.15625]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 81us/step - loss: 423562.4375\n",
      "rewards:  -522.0 q-value:  0\n",
      "loss: [423562.4375]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 85us/step - loss: 559947.3750\n",
      "rewards:  -523.0 q-value:  0\n",
      "loss: [559947.375]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 86us/step - loss: 244114.5938\n",
      "rewards:  -524.0 q-value:  0\n",
      "loss: [244114.59375]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 70us/step - loss: 268894.5938\n",
      "rewards:  -525.0 q-value:  0\n",
      "loss: [268894.59375]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 85us/step - loss: 255560.9688\n",
      "rewards:  -531.0 q-value:  0\n",
      "loss: [255560.96875]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 58us/step - loss: 631059.8750\n",
      "rewards:  -533.0 q-value:  0\n",
      "loss: [631059.875]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 67us/step - loss: 454565.0312\n",
      "rewards:  -535.0 q-value:  0\n",
      "loss: [454565.03125]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 76us/step - loss: 196120.3750\n",
      "rewards:  -537.0 q-value:  0\n",
      "loss: [196120.375]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 75us/step - loss: 174333.7188\n",
      "rewards:  -537.0 q-value:  0\n",
      "loss: [174333.71875]\n",
      "Exploring\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 72us/step - loss: 175432.7188\n",
      "rewards:  -513.0 q-value:  0\n",
      "loss: [175432.71875]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 73us/step - loss: 435281.4375\n",
      "rewards:  -543.0 q-value:  0\n",
      "loss: [435281.4375]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 76us/step - loss: 221883.2188\n",
      "rewards:  -548.0 q-value:  0\n",
      "loss: [221883.21875]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 68us/step - loss: 242378.1875\n",
      "rewards:  -553.0 q-value:  0\n",
      "loss: [242378.1875]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 94us/step - loss: 369591.9062\n",
      "rewards:  -558.0 q-value:  0\n",
      "loss: [369591.90625]\n",
      "Exploiting\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 72us/step - loss: 197186.1562\n",
      "rewards:  -588.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [197186.15625]\n",
      "Exploring\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 63us/step - loss: 450625.7812\n",
      "rewards:  -564.0 q-value:  0\n",
      "loss: [450625.78125]\n",
      "Exploring\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 65us/step - loss: 459193.6250\n",
      "rewards:  -570.0 q-value:  0\n",
      "loss: [459193.625]\n",
      "Exploiting\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 101us/step - loss: 419634.0625\n",
      "rewards:  -581.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [419634.0625]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 80us/step - loss: 389503.0625\n",
      "rewards:  -586.0 q-value:  0\n",
      "loss: [389503.0625]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 76us/step - loss: 275464.0938\n",
      "rewards:  -597.0 q-value:  0\n",
      "loss: [275464.09375]\n",
      "Exploiting\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 77us/step - loss: 230822.7812\n",
      "rewards:  -598.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [230822.78125]\n",
      "Exploiting\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 69us/step - loss: 538683.7500\n",
      "rewards:  -599.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [538683.75]\n",
      "Exploring\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 77us/step - loss: 375313.7500\n",
      "rewards:  -592.0 q-value:  0\n",
      "loss: [375313.75]\n",
      "Exploiting\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 79us/step - loss: 534770.3750\n",
      "rewards:  -597.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [534770.375]\n",
      "Exploring\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 61us/step - loss: 356516.3750\n",
      "rewards:  -599.0 q-value:  0\n",
      "loss: [356516.375]\n",
      "Exploiting\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 61us/step - loss: 616440.8125\n",
      "rewards:  -604.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [616440.8125]\n",
      "Exploiting\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 81us/step - loss: 40051.5938\n",
      "rewards:  -606.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [40051.59375]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 64us/step - loss: 287954.5312\n",
      "rewards:  -611.0 q-value:  0\n",
      "loss: [287954.53125]\n",
      "Exploring\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 71us/step - loss: 290103.0938\n",
      "rewards:  -613.0 q-value:  0\n",
      "loss: [290103.09375]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 106us/step - loss: 518575.5312\n",
      "rewards:  -618.0 q-value:  0\n",
      "loss: [518575.53125]\n",
      "Exploring\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 79us/step - loss: 295892.5938\n",
      "rewards:  -623.0 q-value:  0\n",
      "loss: [295892.59375]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 82us/step - loss: 357436.7188\n",
      "rewards:  -628.0 q-value:  0\n",
      "loss: [357436.71875]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 87us/step - loss: 450922.9375\n",
      "rewards:  -642.0 q-value:  0\n",
      "loss: [450922.9375]\n",
      "Exploring\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 66us/step - loss: 220230.8438\n",
      "rewards:  -638.0 q-value:  0\n",
      "loss: [220230.84375]\n",
      "Exploiting\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 71us/step - loss: 234820.5000\n",
      "rewards:  -643.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [234820.5]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 58us/step - loss: 376623.5625\n",
      "rewards:  -648.0 q-value:  0\n",
      "loss: [376623.5625]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 86us/step - loss: 310646.2500\n",
      "rewards:  -653.0 q-value:  0\n",
      "loss: [310646.25]\n",
      "Exploiting\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 77us/step - loss: 191081.2500\n",
      "rewards:  -654.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [191081.25]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 82us/step - loss: 423874.3125\n",
      "rewards:  -659.0 q-value:  0\n",
      "loss: [423874.3125]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 84us/step - loss: 233299.6875\n",
      "rewards:  -664.0 q-value:  0\n",
      "loss: [233299.6875]\n",
      "Exploiting\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 108us/step - loss: 836708.1250\n",
      "rewards:  -669.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [836708.125]\n",
      "Exploiting\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 82us/step - loss: 254483.7188\n",
      "rewards:  -674.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [254483.71875]\n",
      "Exploring\n",
      "Selected action  [2 0]\n",
      "[2 0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 71us/step - loss: 290663.7812\n",
      "rewards:  -675.0 q-value:  0\n",
      "loss: [290663.78125]\n",
      "Exploiting\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 92us/step - loss: 554398.2500\n",
      "rewards:  -683.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [554398.25]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 69us/step - loss: 414220.5312\n",
      "rewards:  -688.0 q-value:  0\n",
      "loss: [414220.53125]\n",
      "Exploring\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 84us/step - loss: 395922.0625\n",
      "rewards:  -691.0 q-value:  0\n",
      "loss: [395922.0625]\n",
      "Exploring\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 70us/step - loss: 541050.5000\n",
      "rewards:  -694.0 q-value:  0\n",
      "loss: [541050.5]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 76us/step - loss: 184553.4688\n",
      "rewards:  -699.0 q-value:  0\n",
      "loss: [184553.46875]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 69us/step - loss: 622893.5000\n",
      "rewards:  -709.0 q-value:  0\n",
      "loss: [622893.5]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 80us/step - loss: 601146.8125\n",
      "rewards:  -714.0 q-value:  0\n",
      "loss: [601146.8125]\n",
      "Exploring\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 90us/step - loss: 166650.7812\n",
      "rewards:  -716.0 q-value:  0\n",
      "loss: [166650.78125]\n",
      "Exploiting\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 97us/step - loss: 177463.0000\n",
      "rewards:  -718.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [177463.0]\n",
      "Exploring\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 94us/step - loss: 376185.4375\n",
      "rewards:  -720.0 q-value:  0\n",
      "loss: [376185.4375]\n",
      "Exploiting\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 59us/step - loss: 470892.8125\n",
      "rewards:  -725.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [470892.8125]\n",
      "Exploiting\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 86us/step - loss: 661268.1875\n",
      "rewards:  -730.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [661268.1875]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 75us/step - loss: 98854.9688\n",
      "rewards:  -735.0 q-value:  0\n",
      "loss: [98854.96875]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 60us/step - loss: 218654.1250\n",
      "rewards:  -746.0 q-value:  0\n",
      "loss: [218654.125]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 104us/step - loss: 207099.4688\n",
      "rewards:  -747.0 q-value:  0\n",
      "loss: [207099.46875]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 73us/step - loss: 255708.6875\n",
      "rewards:  -748.0 q-value:  0\n",
      "loss: [255708.6875]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 115us/step - loss: 352674.9062\n",
      "rewards:  -753.0 q-value:  0\n",
      "loss: [352674.90625]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 52us/step - loss: 697098.8750\n",
      "rewards:  -764.0 q-value:  0\n",
      "loss: [697098.875]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 67us/step - loss: 79357.9688\n",
      "rewards:  -765.0 q-value:  0\n",
      "loss: [79357.96875]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 87us/step - loss: 226489.0938\n",
      "rewards:  -770.0 q-value:  0\n",
      "loss: [226489.09375]\n",
      "Exploring\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 66us/step - loss: 458206.4062\n",
      "rewards:  -773.0 q-value:  0\n",
      "loss: [458206.40625]\n",
      "Exploring\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 67us/step - loss: 344807.3125\n",
      "rewards:  -778.0 q-value:  0\n",
      "loss: [344807.3125]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 79us/step - loss: 120253.5625\n",
      "rewards:  -785.0 q-value:  0\n",
      "loss: [120253.5625]\n",
      "Exploring\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 83us/step - loss: 462861.5938\n",
      "rewards:  -783.0 q-value:  0\n",
      "loss: [462861.59375]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 73us/step - loss: 204211.6875\n",
      "rewards:  -803.0 q-value:  0\n",
      "loss: [204211.6875]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 100us/step - loss: 369667.4688\n",
      "rewards:  -803.0 q-value:  0\n",
      "loss: [369667.46875]\n",
      "Exploring\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 105us/step - loss: 176416.8125\n",
      "rewards:  -787.0 q-value:  0\n",
      "loss: [176416.8125]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 78us/step - loss: 420810.5625\n",
      "rewards:  -792.0 q-value:  0\n",
      "loss: [420810.5625]\n",
      "Exploring\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 73us/step - loss: 497800.3750\n",
      "rewards:  -796.0 q-value:  0\n",
      "loss: [497800.375]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 67us/step - loss: 156616.6875\n",
      "rewards:  -831.0 q-value:  0\n",
      "loss: [156616.6875]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 85us/step - loss: 387589.4062\n",
      "rewards:  -836.0 q-value:  0\n",
      "loss: [387589.40625]\n",
      "Exploiting\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 79us/step - loss: 333506.7188\n",
      "rewards:  -843.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [333506.71875]\n",
      "Number of actions available 6\n",
      "Episode : 23\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 80us/step - loss: 354795.6875\n",
      "rewards:  -5 q-value:  0\n",
      "loss: [354795.6875]\n",
      "Exploring\n",
      "Selected action  [3 2]\n",
      "[3 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 103us/step - loss: 343566.6562\n",
      "rewards:  1.0 q-value:  0\n",
      "loss: [343566.65625]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 72us/step - loss: 385562.4062\n",
      "rewards:  -4.0 q-value:  0\n",
      "loss: [385562.40625]\n",
      "Exploring\n",
      "Selected action  [3 0]\n",
      "[3 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 66us/step - loss: 312557.6875\n",
      "rewards:  -4.0 q-value:  0\n",
      "loss: [312557.6875]\n",
      "Exploring\n",
      "Selected action  [3 0]\n",
      "[3 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 93us/step - loss: 718305.5000\n",
      "rewards:  -4.0 q-value:  0\n",
      "loss: [718305.5]\n",
      "Exploiting\n",
      "Selected action  [3 2]\n",
      "[3 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 64us/step - loss: 200360.3438\n",
      "rewards:  28.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [200360.34375]\n",
      "Exploring\n",
      "Selected action  [2 3]\n",
      "[2 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 69us/step - loss: 554108.0000\n",
      "rewards:  36.0 q-value:  0\n",
      "loss: [554108.0]\n",
      "Exploring\n",
      "Selected action  [0 3]\n",
      "[0 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 63us/step - loss: 440723.5625\n",
      "rewards:  33.0 q-value:  0\n",
      "loss: [440723.5625]\n",
      "Exploring\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 75us/step - loss: 479713.3438\n",
      "rewards:  28.0 q-value:  0\n",
      "loss: [479713.34375]\n",
      "Exploring\n",
      "Selected action  [0 3]\n",
      "[0 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 82us/step - loss: 155045.8125\n",
      "rewards:  25.0 q-value:  0\n",
      "loss: [155045.8125]\n",
      "Exploiting\n",
      "Selected action  [3 0]\n",
      "[3 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 64us/step - loss: 354099.1562\n",
      "rewards:  37.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [354099.15625]\n",
      "Exploring\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 65us/step - loss: 435279.1875\n",
      "rewards:  21.0 q-value:  0\n",
      "loss: [435279.1875]\n",
      "Exploring\n",
      "Selected action  [1 3]\n",
      "[1 3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 79us/step - loss: 173472.7812\n",
      "rewards:  20.0 q-value:  0\n",
      "loss: [173472.78125]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 66us/step - loss: 83002.4375\n",
      "rewards:  15.0 q-value:  0\n",
      "loss: [83002.4375]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 81us/step - loss: 205683.7812\n",
      "rewards:  10.0 q-value:  0\n",
      "loss: [205683.78125]\n",
      "Exploring\n",
      "Selected action  [3 2]\n",
      "[3 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 79us/step - loss: 135877.6875\n",
      "rewards:  36.0 q-value:  0\n",
      "loss: [135877.6875]\n",
      "Exploring\n",
      "Selected action  [0 3]\n",
      "[0 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 71us/step - loss: 535296.5000\n",
      "rewards:  6.0 q-value:  0\n",
      "loss: [535296.5]\n",
      "Exploring\n",
      "Selected action  [3 0]\n",
      "[3 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 75us/step - loss: 187667.6875\n",
      "rewards:  6.0 q-value:  0\n",
      "loss: [187667.6875]\n",
      "Exploring\n",
      "Selected action  [0 3]\n",
      "[0 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 75us/step - loss: 678769.3125\n",
      "rewards:  6.0 q-value:  0\n",
      "loss: [678769.3125]\n",
      "Exploring\n",
      "Selected action  [0 3]\n",
      "[0 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 79us/step - loss: 527028.6250\n",
      "rewards:  6.0 q-value:  0\n",
      "loss: [527028.625]\n",
      "Exploiting\n",
      "Selected action  [3 2]\n",
      "[3 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 77us/step - loss: 331183.2500\n",
      "rewards:  18.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [331183.25]\n",
      "Exploiting\n",
      "Selected action  [3 0]\n",
      "[3 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 67us/step - loss: 154759.4688\n",
      "rewards:  12.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [154759.46875]\n",
      "Exploiting\n",
      "Selected action  [0 3]\n",
      "[0 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 70us/step - loss: 292918.3125\n",
      "rewards:  24.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [292918.3125]\n",
      "Exploring\n",
      "Selected action  [2 3]\n",
      "[2 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 59us/step - loss: 159814.4688\n",
      "rewards:  19.0 q-value:  0\n",
      "loss: [159814.46875]\n",
      "Exploring\n",
      "Selected action  [3 0]\n",
      "[3 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 87us/step - loss: 476780.3125\n",
      "rewards:  23.0 q-value:  0\n",
      "loss: [476780.3125]\n",
      "Exploring\n",
      "Selected action  [0 3]\n",
      "[0 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 59us/step - loss: 245910.7500\n",
      "rewards:  27.0 q-value:  0\n",
      "loss: [245910.75]\n",
      "Exploring\n",
      "Selected action  [0 3]\n",
      "[0 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 90us/step - loss: 411870.8438\n",
      "rewards:  26.0 q-value:  0\n",
      "loss: [411870.84375]\n",
      "Exploring\n",
      "Selected action  [3 0]\n",
      "[3 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 78us/step - loss: 563840.8750\n",
      "rewards:  30.0 q-value:  0\n",
      "loss: [563840.875]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 80us/step - loss: 116477.3438\n",
      "rewards:  25.0 q-value:  0\n",
      "loss: [116477.34375]\n",
      "Exploring\n",
      "Selected action  [3 2]\n",
      "[3 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 64us/step - loss: 216388.8125\n",
      "rewards:  36.0 q-value:  0\n",
      "loss: [216388.8125]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 68us/step - loss: 186421.6250\n",
      "rewards:  31.0 q-value:  0\n",
      "loss: [186421.625]\n",
      "Exploring\n",
      "Selected action  [3 2]\n",
      "[3 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 75us/step - loss: 625625.0000\n",
      "rewards:  3.0 q-value:  0\n",
      "loss: [625625.0]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 66us/step - loss: 328415.6875\n",
      "rewards:  -2.0 q-value:  0\n",
      "loss: [328415.6875]\n",
      "Exploring\n",
      "Selected action  [2 3]\n",
      "[2 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 61us/step - loss: 395841.6250\n",
      "rewards:  -15.0 q-value:  0\n",
      "loss: [395841.625]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 73us/step - loss: 420941.4062\n",
      "rewards:  -20.0 q-value:  0\n",
      "loss: [420941.40625]\n",
      "Exploring\n",
      "Selected action  [3 2]\n",
      "[3 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 75us/step - loss: 455076.7812\n",
      "rewards:  -48.0 q-value:  0\n",
      "loss: [455076.78125]\n",
      "Exploring\n",
      "Selected action  [0 3]\n",
      "[0 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 74us/step - loss: 304653.8438\n",
      "rewards:  -46.0 q-value:  0\n",
      "loss: [304653.84375]\n",
      "Exploring\n",
      "Selected action  [3 2]\n",
      "[3 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 77us/step - loss: 140748.4688\n",
      "rewards:  -30.0 q-value:  0\n",
      "loss: [140748.46875]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 97us/step - loss: 906443.0000\n",
      "rewards:  -35.0 q-value:  0\n",
      "loss: [906443.0]\n",
      "Exploring\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 75us/step - loss: 441971.8750\n",
      "rewards:  -61.0 q-value:  0\n",
      "loss: [441971.875]\n",
      "Exploring\n",
      "Selected action  [3 0]\n",
      "[3 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 59us/step - loss: 341943.0938\n",
      "rewards:  -53.0 q-value:  0\n",
      "loss: [341943.09375]\n",
      "Exploiting\n",
      "Selected action  [2 3]\n",
      "[2 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 77us/step - loss: 461737.1875\n",
      "rewards:  -48.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [461737.1875]\n",
      "Exploring\n",
      "Selected action  [0 3]\n",
      "[0 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 89us/step - loss: 402586.5938\n",
      "rewards:  -53.0 q-value:  0\n",
      "loss: [402586.59375]\n",
      "Exploring\n",
      "Selected action  [0 3]\n",
      "[0 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 60us/step - loss: 192681.2188\n",
      "rewards:  -59.0 q-value:  0\n",
      "loss: [192681.21875]\n",
      "Exploiting\n",
      "Selected action  [3 0]\n",
      "[3 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 79us/step - loss: 415915.2188\n",
      "rewards:  -39.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [415915.21875]\n",
      "Exploring\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 68us/step - loss: 348833.0938\n",
      "rewards:  -45.0 q-value:  0\n",
      "loss: [348833.09375]\n",
      "Exploring\n",
      "Selected action  [2 3]\n",
      "[2 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 69us/step - loss: 309203.6250\n",
      "rewards:  -45.0 q-value:  0\n",
      "loss: [309203.625]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 75us/step - loss: 109082.7812\n",
      "rewards:  -50.0 q-value:  0\n",
      "loss: [109082.78125]\n",
      "Exploring\n",
      "Selected action  [0 3]\n",
      "[0 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 91us/step - loss: 243881.2812\n",
      "rewards:  -38.0 q-value:  0\n",
      "loss: [243881.28125]\n",
      "Exploring\n",
      "Selected action  [0 3]\n",
      "[0 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 66us/step - loss: 542826.5000\n",
      "rewards:  -45.0 q-value:  0\n",
      "loss: [542826.5]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 94us/step - loss: 358365.2188\n",
      "rewards:  -50.0 q-value:  0\n",
      "loss: [358365.21875]\n",
      "Exploring\n",
      "Selected action  [3 0]\n",
      "[3 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 79us/step - loss: 96337.5625\n",
      "rewards:  -51.0 q-value:  0\n",
      "loss: [96337.5625]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 76us/step - loss: 426910.8125\n",
      "rewards:  -56.0 q-value:  0\n",
      "loss: [426910.8125]\n",
      "Exploring\n",
      "Selected action  [3 0]\n",
      "[3 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 67us/step - loss: 273881.1562\n",
      "rewards:  -57.0 q-value:  0\n",
      "loss: [273881.15625]\n",
      "Exploring\n",
      "Selected action  [3 2]\n",
      "[3 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 62us/step - loss: 93027.7812\n",
      "rewards:  -50.0 q-value:  0\n",
      "loss: [93027.78125]\n",
      "Exploiting\n",
      "Selected action  [3 0]\n",
      "[3 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 78us/step - loss: 180156.2500\n",
      "rewards:  -78.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [180156.25]\n",
      "Exploring\n",
      "Selected action  [3 2]\n",
      "[3 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 76us/step - loss: 266940.0312\n",
      "rewards:  -61.0 q-value:  0\n",
      "loss: [266940.03125]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 68us/step - loss: 723396.4375\n",
      "rewards:  -66.0 q-value:  0\n",
      "loss: [723396.4375]\n",
      "Exploring\n",
      "Selected action  [3 2]\n",
      "[3 2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 80us/step - loss: 318771.3438\n",
      "rewards:  -42.0 q-value:  0\n",
      "loss: [318771.34375]\n",
      "Exploring\n",
      "Selected action  [3 0]\n",
      "[3 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 78us/step - loss: 223860.9375\n",
      "rewards:  -28.0 q-value:  0\n",
      "loss: [223860.9375]\n",
      "Exploring\n",
      "Selected action  [2 3]\n",
      "[2 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 66us/step - loss: 654300.6875\n",
      "rewards:  -16.0 q-value:  0\n",
      "loss: [654300.6875]\n",
      "Exploiting\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 69us/step - loss: 196842.9375\n",
      "rewards:  -20.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [196842.9375]\n",
      "Exploiting\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 62us/step - loss: 373073.8125\n",
      "rewards:  -25.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [373073.8125]\n",
      "Exploring\n",
      "Selected action  [2 3]\n",
      "[2 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 81us/step - loss: 188635.8750\n",
      "rewards:  -24.0 q-value:  0\n",
      "loss: [188635.875]\n",
      "Exploring\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 74us/step - loss: 269394.0312\n",
      "rewards:  -24.0 q-value:  0\n",
      "loss: [269394.03125]\n",
      "Exploring\n",
      "Selected action  [3 2]\n",
      "[3 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 69us/step - loss: 485316.9375\n",
      "rewards:  8.0 q-value:  0\n",
      "loss: [485316.9375]\n",
      "Exploring\n",
      "Selected action  [3 2]\n",
      "[3 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 85us/step - loss: 666203.7500\n",
      "rewards:  6.0 q-value:  0\n",
      "loss: [666203.75]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 69us/step - loss: 137181.5625\n",
      "rewards:  1.0 q-value:  0\n",
      "loss: [137181.5625]\n",
      "Exploring\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 75us/step - loss: 267676.2188\n",
      "rewards:  11.0 q-value:  0\n",
      "loss: [267676.21875]\n",
      "Exploring\n",
      "Selected action  [2 3]\n",
      "[2 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 52us/step - loss: 293331.0312\n",
      "rewards:  5.0 q-value:  0\n",
      "loss: [293331.03125]\n",
      "Exploiting\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 71us/step - loss: 345813.3125\n",
      "rewards:  0.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [345813.3125]\n",
      "Exploiting\n",
      "Selected action  [0 3]\n",
      "[0 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 71us/step - loss: 50163.3750\n",
      "rewards:  12.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [50163.375]\n",
      "Exploring\n",
      "Selected action  [0 3]\n",
      "[0 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 66us/step - loss: 215235.3438\n",
      "rewards:  10.0 q-value:  0\n",
      "loss: [215235.34375]\n",
      "Exploring\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 80us/step - loss: 279061.4062\n",
      "rewards:  9.0 q-value:  0\n",
      "loss: [279061.40625]\n",
      "Exploring\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 65us/step - loss: 233135.5312\n",
      "rewards:  8.0 q-value:  0\n",
      "loss: [233135.53125]\n",
      "Exploiting\n",
      "Selected action  [0 3]\n",
      "[0 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 80us/step - loss: 345792.7812\n",
      "rewards:  8.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [345792.78125]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 63us/step - loss: 355857.5625\n",
      "rewards:  3.0 q-value:  0\n",
      "loss: [355857.5625]\n",
      "Exploring\n",
      "Selected action  [0 3]\n",
      "[0 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 64us/step - loss: 429033.3125\n",
      "rewards:  3.0 q-value:  0\n",
      "loss: [429033.3125]\n",
      "Exploiting\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 72us/step - loss: 643027.5625\n",
      "rewards:  -2.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [643027.5625]\n",
      "Exploring\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 69us/step - loss: 575202.0625\n",
      "rewards:  -8.0 q-value:  0\n",
      "loss: [575202.0625]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 70us/step - loss: 244983.8750\n",
      "rewards:  -13.0 q-value:  0\n",
      "loss: [244983.875]\n",
      "Exploring\n",
      "Selected action  [0 3]\n",
      "[0 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 70us/step - loss: 503433.0312\n",
      "rewards:  -13.0 q-value:  0\n",
      "loss: [503433.03125]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 67us/step - loss: 452483.0625\n",
      "rewards:  -18.0 q-value:  0\n",
      "loss: [452483.0625]\n",
      "Exploring\n",
      "Selected action  [0 3]\n",
      "[0 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 79us/step - loss: 617274.6250\n",
      "rewards:  -18.0 q-value:  0\n",
      "loss: [617274.625]\n",
      "Exploring\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 80us/step - loss: 507611.8125\n",
      "rewards:  -19.0 q-value:  0\n",
      "loss: [507611.8125]\n",
      "Exploiting\n",
      "Selected action  [3 2]\n",
      "[3 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 83us/step - loss: 418740.7188\n",
      "rewards:  -7.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [418740.71875]\n",
      "Exploring\n",
      "Selected action  [0 3]\n",
      "[0 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 62us/step - loss: 74313.4062\n",
      "rewards:  -37.0 q-value:  0\n",
      "loss: [74313.40625]\n",
      "Exploiting\n",
      "Selected action  [3 0]\n",
      "[3 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 59us/step - loss: 233595.1875\n",
      "rewards:  -37.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [233595.1875]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 63us/step - loss: 212876.9375\n",
      "rewards:  -42.0 q-value:  0\n",
      "loss: [212876.9375]\n",
      "Exploiting\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 73us/step - loss: 408170.5938\n",
      "rewards:  -47.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [408170.59375]\n",
      "Exploring\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 69us/step - loss: 1044012.6875\n",
      "rewards:  -53.0 q-value:  0\n",
      "loss: [1044012.6875]\n",
      "Exploring\n",
      "Selected action  [0 3]\n",
      "[0 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 90us/step - loss: 314636.9375\n",
      "rewards:  -59.0 q-value:  0\n",
      "loss: [314636.9375]\n",
      "Exploiting\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 80us/step - loss: 232546.4375\n",
      "rewards:  -64.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [232546.4375]\n",
      "Exploring\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 79us/step - loss: 192666.6562\n",
      "rewards:  -91.0 q-value:  0\n",
      "loss: [192666.65625]\n",
      "Exploring\n",
      "Selected action  [0 3]\n",
      "[0 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 76us/step - loss: 179265.0312\n",
      "rewards:  -94.0 q-value:  0\n",
      "loss: [179265.03125]\n",
      "Exploring\n",
      "Selected action  [2 3]\n",
      "[2 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 66us/step - loss: 621641.2500\n",
      "rewards:  -99.0 q-value:  0\n",
      "loss: [621641.25]\n",
      "Exploring\n",
      "Selected action  [3 2]\n",
      "[3 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 84us/step - loss: 146883.2812\n",
      "rewards:  -87.0 q-value:  0\n",
      "loss: [146883.28125]\n",
      "Exploiting\n",
      "Selected action  [3 2]\n",
      "[3 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 61us/step - loss: 463131.0625\n",
      "rewards:  -91.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [463131.0625]\n",
      "Exploiting\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 88us/step - loss: 454029.7812\n",
      "rewards:  -96.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [454029.78125]\n",
      "Exploring\n",
      "Selected action  [3 2]\n",
      "[3 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 71us/step - loss: 380216.0000\n",
      "rewards:  -85.0 q-value:  0\n",
      "loss: [380216.0]\n",
      "Exploring\n",
      "Selected action  [3 2]\n",
      "[3 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 77us/step - loss: 340646.2812\n",
      "rewards:  -88.0 q-value:  0\n",
      "loss: [340646.28125]\n",
      "Exploring\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 77us/step - loss: 522299.4375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rewards:  -100.0 q-value:  0\n",
      "loss: [522299.4375]\n",
      "Exploring\n",
      "Selected action  [0 3]\n",
      "[0 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 66us/step - loss: 443962.9375\n",
      "rewards:  -108.0 q-value:  0\n",
      "loss: [443962.9375]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 76us/step - loss: 202797.4375\n",
      "rewards:  -113.0 q-value:  0\n",
      "loss: [202797.4375]\n",
      "Exploring\n",
      "Selected action  [3 0]\n",
      "[3 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 66us/step - loss: 707807.2500\n",
      "rewards:  -115.0 q-value:  0\n",
      "loss: [707807.25]\n",
      "Exploring\n",
      "Selected action  [0 3]\n",
      "[0 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 95us/step - loss: 450348.9062\n",
      "rewards:  -107.0 q-value:  0\n",
      "loss: [450348.90625]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 70us/step - loss: 85939.1875\n",
      "rewards:  -112.0 q-value:  0\n",
      "loss: [85939.1875]\n",
      "Exploiting\n",
      "Selected action  [0 3]\n",
      "[0 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 64us/step - loss: 210401.0000\n",
      "rewards:  -104.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [210401.0]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 70us/step - loss: 314554.1562\n",
      "rewards:  -109.0 q-value:  0\n",
      "loss: [314554.15625]\n",
      "Exploring\n",
      "Selected action  [0 3]\n",
      "[0 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 85us/step - loss: 399967.2500\n",
      "rewards:  -101.0 q-value:  0\n",
      "loss: [399967.25]\n",
      "Exploring\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 77us/step - loss: 513756.5000\n",
      "rewards:  -104.0 q-value:  0\n",
      "loss: [513756.5]\n",
      "Exploring\n",
      "Selected action  [3 0]\n",
      "[3 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 69us/step - loss: 152797.7812\n",
      "rewards:  -84.0 q-value:  0\n",
      "loss: [152797.78125]\n",
      "Exploring\n",
      "Selected action  [3 0]\n",
      "[3 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 91us/step - loss: 175954.7500\n",
      "rewards:  -90.0 q-value:  0\n",
      "loss: [175954.75]\n",
      "Exploring\n",
      "Selected action  [3 2]\n",
      "[3 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 76us/step - loss: 423807.6875\n",
      "rewards:  -91.0 q-value:  0\n",
      "loss: [423807.6875]\n",
      "Exploiting\n",
      "Selected action  [3 0]\n",
      "[3 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 71us/step - loss: 454917.1562\n",
      "rewards:  -79.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [454917.15625]\n",
      "Exploring\n",
      "Selected action  [0 3]\n",
      "[0 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 77us/step - loss: 283376.9688\n",
      "rewards:  -67.0 q-value:  0\n",
      "loss: [283376.96875]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 76us/step - loss: 555871.6875\n",
      "rewards:  -72.0 q-value:  0\n",
      "loss: [555871.6875]\n",
      "Exploring\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 89us/step - loss: 169161.1250\n",
      "rewards:  -87.0 q-value:  0\n",
      "loss: [169161.125]\n",
      "Exploring\n",
      "Selected action  [0 3]\n",
      "[0 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 78us/step - loss: 65498.1250\n",
      "rewards:  -88.0 q-value:  0\n",
      "loss: [65498.125]\n",
      "Exploring\n",
      "Selected action  [3 2]\n",
      "[3 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 71us/step - loss: 357467.5938\n",
      "rewards:  -76.0 q-value:  0\n",
      "loss: [357467.59375]\n",
      "Exploring\n",
      "Selected action  [2 3]\n",
      "[2 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 69us/step - loss: 447308.0000\n",
      "rewards:  -64.0 q-value:  0\n",
      "loss: [447308.0]\n",
      "Exploring\n",
      "Selected action  [3 0]\n",
      "[3 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 60us/step - loss: 64713.2188\n",
      "rewards:  -52.0 q-value:  0\n",
      "loss: [64713.21875]\n",
      "Exploring\n",
      "Selected action  [2 3]\n",
      "[2 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 77us/step - loss: 424575.3750\n",
      "rewards:  -35.0 q-value:  0\n",
      "loss: [424575.375]\n",
      "Exploring\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 100us/step - loss: 69264.9375\n",
      "rewards:  -39.0 q-value:  0\n",
      "loss: [69264.9375]\n",
      "Exploring\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 56us/step - loss: 66377.0000\n",
      "rewards:  -43.0 q-value:  0\n",
      "loss: [66377.0]\n",
      "Exploring\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 71us/step - loss: 332015.8750\n",
      "rewards:  -47.0 q-value:  0\n",
      "loss: [332015.875]\n",
      "Exploiting\n",
      "Selected action  [0 3]\n",
      "[0 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 76us/step - loss: 363898.9375\n",
      "rewards:  -51.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [363898.9375]\n",
      "Exploiting\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 75us/step - loss: 81377.5938\n",
      "rewards:  -56.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [81377.59375]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 74us/step - loss: 575597.7500\n",
      "rewards:  -61.0 q-value:  0\n",
      "loss: [575597.75]\n",
      "Exploring\n",
      "Selected action  [3 2]\n",
      "[3 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 77us/step - loss: 117250.5000\n",
      "rewards:  -49.0 q-value:  0\n",
      "loss: [117250.5]\n",
      "Exploiting\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 77us/step - loss: 455333.2188\n",
      "rewards:  -54.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [455333.21875]\n",
      "Exploring\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 80us/step - loss: 566858.3750\n",
      "rewards:  -68.0 q-value:  0\n",
      "loss: [566858.375]\n",
      "Exploring\n",
      "Selected action  [3 0]\n",
      "[3 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 57us/step - loss: 450249.5938\n",
      "rewards:  -44.0 q-value:  0\n",
      "loss: [450249.59375]\n",
      "Exploring\n",
      "Selected action  [0 3]\n",
      "[0 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 67us/step - loss: 427752.4375\n",
      "rewards:  -32.0 q-value:  0\n",
      "loss: [427752.4375]\n",
      "Exploiting\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 78us/step - loss: 214885.5938\n",
      "rewards:  -37.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [214885.59375]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 84us/step - loss: 255636.4688\n",
      "rewards:  -42.0 q-value:  0\n",
      "loss: [255636.46875]\n",
      "Exploiting\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 72us/step - loss: 300346.9062\n",
      "rewards:  -47.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [300346.90625]\n",
      "Exploiting\n",
      "Selected action  [2 3]\n",
      "[2 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 63us/step - loss: 453404.2500\n",
      "rewards:  -30.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [453404.25]\n",
      "Exploring\n",
      "Selected action  [3 2]\n",
      "[3 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 68us/step - loss: 486423.8750\n",
      "rewards:  -22.0 q-value:  0\n",
      "loss: [486423.875]\n",
      "Exploiting\n",
      "Selected action  [3 0]\n",
      "[3 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 70us/step - loss: 417497.0312\n",
      "rewards:  -12.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [417497.03125]\n",
      "Exploring\n",
      "Selected action  [0 3]\n",
      "[0 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 87us/step - loss: 466995.4375\n",
      "rewards:  0.0 q-value:  0\n",
      "loss: [466995.4375]\n",
      "Number of actions available 7\n",
      "Episode : 24\n",
      "Exploiting\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 87us/step - loss: 916637.6250\n",
      "rewards:  -25.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [916637.625]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 78us/step - loss: 228111.8125\n",
      "rewards:  -29.0 q-value:  0\n",
      "loss: [228111.8125]\n",
      "Exploring\n",
      "Selected action  [0 2]\n",
      "[0 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 65us/step - loss: 663428.2500\n",
      "rewards:  -22.0 q-value:  0\n",
      "loss: [663428.25]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 87us/step - loss: 346100.6250\n",
      "rewards:  -27.0 q-value:  0\n",
      "loss: [346100.625]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 59us/step - loss: 99965.8438\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rewards:  -42.0 q-value:  0\n",
      "loss: [99965.84375]\n",
      "Exploring\n",
      "Selected action  [0 2]\n",
      "[0 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 82us/step - loss: 480910.6875\n",
      "rewards:  -35.0 q-value:  0\n",
      "loss: [480910.6875]\n",
      "Exploiting\n",
      "Selected action  [0 2]\n",
      "[0 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 86us/step - loss: 176190.4688\n",
      "rewards:  -40.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [176190.46875]\n",
      "Exploring\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 66us/step - loss: 446222.3438\n",
      "rewards:  -20.0 q-value:  0\n",
      "loss: [446222.34375]\n",
      "Exploring\n",
      "Selected action  [2 1]\n",
      "[2 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 74us/step - loss: 350487.1250\n",
      "rewards:  -10.0 q-value:  0\n",
      "loss: [350487.125]\n",
      "Exploring\n",
      "Selected action  [2 3]\n",
      "[2 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 73us/step - loss: 134024.1562\n",
      "rewards:  -52.0 q-value:  0\n",
      "loss: [134024.15625]\n",
      "Exploiting\n",
      "Selected action  [2 3]\n",
      "[2 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 91us/step - loss: 199768.6875\n",
      "rewards:  -54.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [199768.6875]\n",
      "Exploring\n",
      "Selected action  [2 3]\n",
      "[2 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 70us/step - loss: 112468.5000\n",
      "rewards:  -63.0 q-value:  0\n",
      "loss: [112468.5]\n",
      "Exploring\n",
      "Selected action  [2 1]\n",
      "[2 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 69us/step - loss: 201751.9688\n",
      "rewards:  -58.0 q-value:  0\n",
      "loss: [201751.96875]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 88us/step - loss: 242729.0625\n",
      "rewards:  -88.0 q-value:  0\n",
      "loss: [242729.0625]\n",
      "Exploiting\n",
      "Selected action  [2 1]\n",
      "[2 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 85us/step - loss: 50728.2500\n",
      "rewards:  -64.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [50728.25]\n",
      "Exploring\n",
      "Selected action  [0 2]\n",
      "[0 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 69us/step - loss: 193065.8438\n",
      "rewards:  -75.0 q-value:  0\n",
      "loss: [193065.84375]\n",
      "Exploring\n",
      "Selected action  [2 3]\n",
      "[2 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 90us/step - loss: 241532.7812\n",
      "rewards:  -63.0 q-value:  0\n",
      "loss: [241532.78125]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 59us/step - loss: 297588.9062\n",
      "rewards:  -68.0 q-value:  0\n",
      "loss: [297588.90625]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 79us/step - loss: 253678.2500\n",
      "rewards:  -70.0 q-value:  0\n",
      "loss: [253678.25]\n",
      "Exploring\n",
      "Selected action  [0 3]\n",
      "[0 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 90us/step - loss: 157361.3125\n",
      "rewards:  -86.0 q-value:  0\n",
      "loss: [157361.3125]\n",
      "Exploiting\n",
      "Selected action  [2 1]\n",
      "[2 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 73us/step - loss: 366302.5625\n",
      "rewards:  -62.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [366302.5625]\n",
      "Exploiting\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 75us/step - loss: 225116.1875\n",
      "rewards:  -67.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [225116.1875]\n",
      "Exploring\n",
      "Selected action  [0 3]\n",
      "[0 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 66us/step - loss: 159956.1562\n",
      "rewards:  -35.0 q-value:  0\n",
      "loss: [159956.15625]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 63us/step - loss: 296519.7188\n",
      "rewards:  -40.0 q-value:  0\n",
      "loss: [296519.71875]\n",
      "Exploring\n",
      "Selected action  [0 3]\n",
      "[0 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 81us/step - loss: 427087.1250\n",
      "rewards:  -32.0 q-value:  0\n",
      "loss: [427087.125]\n",
      "Exploring\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 64us/step - loss: 493192.5000\n",
      "rewards:  -20.0 q-value:  0\n",
      "loss: [493192.5]\n",
      "Exploring\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 73us/step - loss: 297752.8125\n",
      "rewards:  -23.0 q-value:  0\n",
      "loss: [297752.8125]\n",
      "Exploring\n",
      "Selected action  [2 1]\n",
      "[2 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 80us/step - loss: 35953.0625\n",
      "rewards:  -10.0 q-value:  0\n",
      "loss: [35953.0625]\n",
      "Exploring\n",
      "Selected action  [0 2]\n",
      "[0 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 68us/step - loss: 478124.5938\n",
      "rewards:  -22.0 q-value:  0\n",
      "loss: [478124.59375]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 84us/step - loss: 188014.9062\n",
      "rewards:  -18.0 q-value:  0\n",
      "loss: [188014.90625]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 93us/step - loss: 280747.1875\n",
      "rewards:  -23.0 q-value:  0\n",
      "loss: [280747.1875]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 69us/step - loss: 136864.0625\n",
      "rewards:  -29.0 q-value:  0\n",
      "loss: [136864.0625]\n",
      "Exploring\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 100us/step - loss: 388727.6250\n",
      "rewards:  -26.0 q-value:  0\n",
      "loss: [388727.625]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 66us/step - loss: 102312.1562\n",
      "rewards:  -31.0 q-value:  0\n",
      "loss: [102312.15625]\n",
      "Exploring\n",
      "Selected action  [2 1]\n",
      "[2 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 89us/step - loss: 212634.6250\n",
      "rewards:  -24.0 q-value:  0\n",
      "loss: [212634.625]\n",
      "Exploring\n",
      "Selected action  [2 3]\n",
      "[2 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 69us/step - loss: 282562.1562\n",
      "rewards:  -35.0 q-value:  0\n",
      "loss: [282562.15625]\n",
      "Exploring\n",
      "Selected action  [0 3]\n",
      "[0 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 74us/step - loss: 226074.7500\n",
      "rewards:  -36.0 q-value:  0\n",
      "loss: [226074.75]\n",
      "Exploiting\n",
      "Selected action  [0 3]\n",
      "[0 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 91us/step - loss: 576975.8750\n",
      "rewards:  -37.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [576975.875]\n",
      "Exploring\n",
      "Selected action  [0 2]\n",
      "[0 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 81us/step - loss: 384148.4688\n",
      "rewards:  -22.0 q-value:  0\n",
      "loss: [384148.46875]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 102us/step - loss: 168334.3125\n",
      "rewards:  -14.0 q-value:  0\n",
      "loss: [168334.3125]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 74us/step - loss: 348814.7812\n",
      "rewards:  -19.0 q-value:  0\n",
      "loss: [348814.78125]\n",
      "Exploiting\n",
      "Selected action  [2 3]\n",
      "[2 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 70us/step - loss: 433825.4062\n",
      "rewards:  -2.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [433825.40625]\n",
      "Exploiting\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 63us/step - loss: 918390.0000\n",
      "rewards:  -29.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [918390.0]\n",
      "Exploring\n",
      "Selected action  [0 3]\n",
      "[0 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 94us/step - loss: 355195.9375\n",
      "rewards:  -5.0 q-value:  0\n",
      "loss: [355195.9375]\n",
      "Exploring\n",
      "Selected action  [2 3]\n",
      "[2 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 77us/step - loss: 146388.1250\n",
      "rewards:  -13.0 q-value:  0\n",
      "loss: [146388.125]\n",
      "Exploring\n",
      "Selected action  [0 2]\n",
      "[0 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 77us/step - loss: 649246.3750\n",
      "rewards:  -8.0 q-value:  0\n",
      "loss: [649246.375]\n",
      "Exploiting\n",
      "Selected action  [0 2]\n",
      "[0 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 73us/step - loss: 130048.2188\n",
      "rewards:  -15.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [130048.21875]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 101us/step - loss: 67335.5312\n",
      "rewards:  -20.0 q-value:  0\n",
      "loss: [67335.53125]\n",
      "Exploring\n",
      "Selected action  [0 2]\n",
      "[0 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 88us/step - loss: 149932.8438\n",
      "rewards:  4.0 q-value:  0\n",
      "loss: [149932.84375]\n",
      "Exploring\n",
      "Selected action  [0 3]\n",
      "[0 3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 70us/step - loss: 508254.0312\n",
      "rewards:  -11.0 q-value:  0\n",
      "loss: [508254.03125]\n",
      "Exploring\n",
      "Selected action  [0 2]\n",
      "[0 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 77us/step - loss: 501665.0625\n",
      "rewards:  1.0 q-value:  0\n",
      "loss: [501665.0625]\n",
      "Exploring\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 83us/step - loss: 396551.4375\n",
      "rewards:  21.0 q-value:  0\n",
      "loss: [396551.4375]\n",
      "Exploiting\n",
      "Selected action  [0 2]\n",
      "[0 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 70us/step - loss: 131418.6562\n",
      "rewards:  29.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [131418.65625]\n",
      "Exploring\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 70us/step - loss: 310410.3438\n",
      "rewards:  37.0 q-value:  0\n",
      "loss: [310410.34375]\n",
      "Exploiting\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 57us/step - loss: 136845.7188\n",
      "rewards:  31.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [136845.71875]\n",
      "Exploiting\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 90us/step - loss: 374797.9375\n",
      "rewards:  26.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [374797.9375]\n",
      "Exploring\n",
      "Selected action  [0 2]\n",
      "[0 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 67us/step - loss: 280331.4375\n",
      "rewards:  34.0 q-value:  0\n",
      "loss: [280331.4375]\n",
      "Exploring\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 74us/step - loss: 412458.7188\n",
      "rewards:  58.0 q-value:  0\n",
      "loss: [412458.71875]\n",
      "Exploiting\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 72us/step - loss: 239455.3125\n",
      "rewards:  56.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [239455.3125]\n",
      "Exploring\n",
      "Selected action  [2 3]\n",
      "[2 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 72us/step - loss: 122816.6875\n",
      "rewards:  82.0 q-value:  0\n",
      "loss: [122816.6875]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 75us/step - loss: 401312.0312\n",
      "rewards:  77.0 q-value:  0\n",
      "loss: [401312.03125]\n",
      "Exploring\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 71us/step - loss: 392469.2500\n",
      "rewards:  71.0 q-value:  0\n",
      "loss: [392469.25]\n",
      "Exploring\n",
      "Selected action  [0 2]\n",
      "[0 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 95us/step - loss: 310895.9375\n",
      "rewards:  95.0 q-value:  0\n",
      "loss: [310895.9375]\n",
      "Exploiting\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 85us/step - loss: 572400.9375\n",
      "rewards:  90.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [572400.9375]\n",
      "Exploiting\n",
      "Selected action  [0 3]\n",
      "[0 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 69us/step - loss: 272388.2188\n",
      "rewards:  94.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [272388.21875]\n",
      "Exploiting\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 61us/step - loss: 128067.3750\n",
      "rewards:  83.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [128067.375]\n",
      "Exploring\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 71us/step - loss: 153030.3438\n",
      "rewards:  90.0 q-value:  0\n",
      "loss: [153030.34375]\n",
      "Exploiting\n",
      "Selected action  [2 1]\n",
      "[2 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 82us/step - loss: 328352.0000\n",
      "rewards:  87.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [328352.0]\n",
      "Exploring\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 70us/step - loss: 184927.0312\n",
      "rewards:  40.0 q-value:  0\n",
      "loss: [184927.03125]\n",
      "Exploring\n",
      "Selected action  [0 3]\n",
      "[0 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 72us/step - loss: 112516.6562\n",
      "rewards:  44.0 q-value:  0\n",
      "loss: [112516.65625]\n",
      "Exploring\n",
      "Selected action  [2 1]\n",
      "[2 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 90us/step - loss: 420586.2500\n",
      "rewards:  68.0 q-value:  0\n",
      "loss: [420586.25]\n",
      "Exploiting\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 83us/step - loss: 495841.9688\n",
      "rewards:  64.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [495841.96875]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 58us/step - loss: 365120.1875\n",
      "rewards:  59.0 q-value:  0\n",
      "loss: [365120.1875]\n",
      "Exploring\n",
      "Selected action  [2 3]\n",
      "[2 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 60us/step - loss: 305721.7812\n",
      "rewards:  70.0 q-value:  0\n",
      "loss: [305721.78125]\n",
      "Exploring\n",
      "Selected action  [2 3]\n",
      "[2 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 83us/step - loss: 62917.6875\n",
      "rewards:  66.0 q-value:  0\n",
      "loss: [62917.6875]\n",
      "Exploring\n",
      "Selected action  [0 3]\n",
      "[0 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 53us/step - loss: 42431.9688\n",
      "rewards:  64.0 q-value:  0\n",
      "loss: [42431.96875]\n",
      "Exploiting\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 86us/step - loss: 265760.6875\n",
      "rewards:  47.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [265760.6875]\n",
      "Exploiting\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 85us/step - loss: 481827.9688\n",
      "rewards:  49.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [481827.96875]\n",
      "Exploring\n",
      "Selected action  [2 1]\n",
      "[2 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 63us/step - loss: 407375.7812\n",
      "rewards:  62.0 q-value:  0\n",
      "loss: [407375.78125]\n",
      "Exploring\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 81us/step - loss: 509393.1250\n",
      "rewards:  65.0 q-value:  0\n",
      "loss: [509393.125]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 90us/step - loss: 113838.0625\n",
      "rewards:  60.0 q-value:  0\n",
      "loss: [113838.0625]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 68us/step - loss: 93927.7188\n",
      "rewards:  54.0 q-value:  0\n",
      "loss: [93927.71875]\n",
      "Exploring\n",
      "Selected action  [2 3]\n",
      "[2 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 86us/step - loss: 289429.4062\n",
      "rewards:  73.0 q-value:  0\n",
      "loss: [289429.40625]\n",
      "Exploring\n",
      "Selected action  [2 1]\n",
      "[2 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 93us/step - loss: 235946.6562\n",
      "rewards:  105.0 q-value:  0\n",
      "loss: [235946.65625]\n",
      "Exploiting\n",
      "Selected action  [2 3]\n",
      "[2 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 82us/step - loss: 368185.8125\n",
      "rewards:  94.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [368185.8125]\n",
      "Exploring\n",
      "Selected action  [2 3]\n",
      "[2 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 87us/step - loss: 161332.6562\n",
      "rewards:  91.0 q-value:  0\n",
      "loss: [161332.65625]\n",
      "Exploring\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 74us/step - loss: 510221.7812\n",
      "rewards:  63.0 q-value:  0\n",
      "loss: [510221.78125]\n",
      "Exploring\n",
      "Selected action  [2 3]\n",
      "[2 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 90us/step - loss: 473361.6250\n",
      "rewards:  80.0 q-value:  0\n",
      "loss: [473361.625]\n",
      "Exploiting\n",
      "Selected action  [0 2]\n",
      "[0 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 84us/step - loss: 276727.1250\n",
      "rewards:  88.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [276727.125]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 87us/step - loss: 636076.9375\n",
      "rewards:  120.0 q-value:  0\n",
      "loss: [636076.9375]\n",
      "Exploring\n",
      "Selected action  [2 1]\n",
      "[2 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 80us/step - loss: 448626.2188\n",
      "rewards:  128.0 q-value:  0\n",
      "loss: [448626.21875]\n",
      "Exploiting\n",
      "Selected action  [0 3]\n",
      "[0 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 53us/step - loss: 106763.5000\n",
      "rewards:  120.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [106763.5]\n",
      "Exploiting\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 89us/step - loss: 92798.1250\n",
      "rewards:  115.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [92798.125]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 96us/step - loss: 345705.0938\n",
      "rewards:  110.0 q-value:  0\n",
      "loss: [345705.09375]\n",
      "Exploring\n",
      "Selected action  [0 3]\n",
      "[0 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 66us/step - loss: 450371.0312\n",
      "rewards:  122.0 q-value:  0\n",
      "loss: [450371.03125]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 76us/step - loss: 381003.0625\n",
      "rewards:  97.0 q-value:  0\n",
      "loss: [381003.0625]\n",
      "Exploring\n",
      "Selected action  [0 2]\n",
      "[0 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 73us/step - loss: 979676.1250\n",
      "rewards:  120.0 q-value:  0\n",
      "loss: [979676.125]\n",
      "Exploring\n",
      "Selected action  [2 3]\n",
      "[2 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 82us/step - loss: 129005.5938\n",
      "rewards:  152.0 q-value:  0\n",
      "loss: [129005.59375]\n",
      "Exploring\n",
      "Selected action  [0 3]\n",
      "[0 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 80us/step - loss: 341930.6562\n",
      "rewards:  149.0 q-value:  0\n",
      "loss: [341930.65625]\n",
      "Exploiting\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 78us/step - loss: 291008.9688\n",
      "rewards:  147.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [291008.96875]\n",
      "Exploring\n",
      "Selected action  [2 1]\n",
      "[2 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 67us/step - loss: 342010.7188\n",
      "rewards:  162.0 q-value:  0\n",
      "loss: [342010.71875]\n",
      "Exploring\n",
      "Selected action  [2 3]\n",
      "[2 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 78us/step - loss: 877212.9375\n",
      "rewards:  120.0 q-value:  0\n",
      "loss: [877212.9375]\n",
      "Exploring\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 74us/step - loss: 89876.9375\n",
      "rewards:  134.0 q-value:  0\n",
      "loss: [89876.9375]\n",
      "Exploring\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 97us/step - loss: 257462.7500\n",
      "rewards:  132.0 q-value:  0\n",
      "loss: [257462.75]\n",
      "Exploring\n",
      "Selected action  [0 2]\n",
      "[0 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 84us/step - loss: 412870.3750\n",
      "rewards:  140.0 q-value:  0\n",
      "loss: [412870.375]\n",
      "Exploring\n",
      "Selected action  [2 3]\n",
      "[2 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 76us/step - loss: 340862.5312\n",
      "rewards:  152.0 q-value:  0\n",
      "loss: [340862.53125]\n",
      "Exploring\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 79us/step - loss: 299261.5938\n",
      "rewards:  161.0 q-value:  0\n",
      "loss: [299261.59375]\n",
      "Exploring\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 63us/step - loss: 370022.9375\n",
      "rewards:  155.0 q-value:  0\n",
      "loss: [370022.9375]\n",
      "Exploring\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 100us/step - loss: 58196.9375\n",
      "rewards:  149.0 q-value:  0\n",
      "loss: [58196.9375]\n",
      "Exploring\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 91us/step - loss: 437949.3750\n",
      "rewards:  146.0 q-value:  0\n",
      "loss: [437949.375]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 77us/step - loss: 631891.1250\n",
      "rewards:  141.0 q-value:  0\n",
      "loss: [631891.125]\n",
      "Exploiting\n",
      "Selected action  [2 1]\n",
      "[2 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 75us/step - loss: 192808.0938\n",
      "rewards:  175.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [192808.09375]\n",
      "Number of actions available 6\n",
      "Episode : 25\n",
      "Exploring\n",
      "Selected action  [1 2]\n",
      "[1 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 71us/step - loss: 333925.5938\n",
      "rewards:  8.0 q-value:  0\n",
      "loss: [333925.59375]\n",
      "Exploring\n",
      "Selected action  [0 4]\n",
      "[0 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 93us/step - loss: 300362.6875\n",
      "rewards:  -10.0 q-value:  0\n",
      "loss: [300362.6875]\n",
      "Exploring\n",
      "Selected action  [1 2]\n",
      "[1 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 66us/step - loss: 562641.8750\n",
      "rewards:  -12.0 q-value:  0\n",
      "loss: [562641.875]\n",
      "Exploring\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 64us/step - loss: 189563.2188\n",
      "rewards:  0.0 q-value:  0\n",
      "loss: [189563.21875]\n",
      "Exploring\n",
      "Selected action  [1 2]\n",
      "[1 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 70us/step - loss: 178976.2812\n",
      "rewards:  22.0 q-value:  0\n",
      "loss: [178976.28125]\n",
      "Exploiting\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 68us/step - loss: 88862.5625\n",
      "rewards:  30.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [88862.5625]\n",
      "Exploring\n",
      "Selected action  [1 2]\n",
      "[1 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 78us/step - loss: 167526.8125\n",
      "rewards:  40.0 q-value:  0\n",
      "loss: [167526.8125]\n",
      "Exploring\n",
      "Selected action  [1 2]\n",
      "[1 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 82us/step - loss: 629246.1250\n",
      "rewards:  30.0 q-value:  0\n",
      "loss: [629246.125]\n",
      "Exploring\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 69us/step - loss: 419443.9688\n",
      "rewards:  9.0 q-value:  0\n",
      "loss: [419443.96875]\n",
      "Exploiting\n",
      "Selected action  [0 3]\n",
      "[0 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 70us/step - loss: 554125.1250\n",
      "rewards:  9.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [554125.125]\n",
      "Exploring\n",
      "Selected action  [0 4]\n",
      "[0 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 64us/step - loss: 225976.1875\n",
      "rewards:  33.0 q-value:  0\n",
      "loss: [225976.1875]\n",
      "Exploiting\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 77us/step - loss: 393345.3750\n",
      "rewards:  28.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [393345.375]\n",
      "Exploring\n",
      "Selected action  [1 2]\n",
      "[1 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 72us/step - loss: 247296.5000\n",
      "rewards:  37.0 q-value:  0\n",
      "loss: [247296.5]\n",
      "Exploring\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 90us/step - loss: 637644.5000\n",
      "rewards:  61.0 q-value:  0\n",
      "loss: [637644.5]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 102us/step - loss: 371421.7188\n",
      "rewards:  56.0 q-value:  0\n",
      "loss: [371421.71875]\n",
      "Exploring\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 71us/step - loss: 533184.6250\n",
      "rewards:  29.0 q-value:  0\n",
      "loss: [533184.625]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 74us/step - loss: 268255.3750\n",
      "rewards:  24.0 q-value:  0\n",
      "loss: [268255.375]\n",
      "Exploring\n",
      "Selected action  [0 4]\n",
      "[0 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 73us/step - loss: 444608.4375\n",
      "rewards:  28.0 q-value:  0\n",
      "loss: [444608.4375]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 84us/step - loss: 163830.7500\n",
      "rewards:  23.0 q-value:  0\n",
      "loss: [163830.75]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 83us/step - loss: 137082.7500\n",
      "rewards:  18.0 q-value:  0\n",
      "loss: [137082.75]\n",
      "Exploring\n",
      "Selected action  [1 2]\n",
      "[1 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 91us/step - loss: 729423.5000\n",
      "rewards:  -5.0 q-value:  0\n",
      "loss: [729423.5]\n",
      "Exploring\n",
      "Selected action  [1 2]\n",
      "[1 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 89us/step - loss: 137656.7188\n",
      "rewards:  -16.0 q-value:  0\n",
      "loss: [137656.71875]\n",
      "Exploring\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 98us/step - loss: 574541.3750\n",
      "rewards:  -28.0 q-value:  0\n",
      "loss: [574541.375]\n",
      "Exploring\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 76us/step - loss: 190660.8125\n",
      "rewards:  -19.0 q-value:  0\n",
      "loss: [190660.8125]\n",
      "Exploring\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 195us/step - loss: 406686.2500\n",
      "rewards:  -20.0 q-value:  0\n",
      "loss: [406686.25]\n",
      "Exploring\n",
      "Selected action  [1 2]\n",
      "[1 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 85us/step - loss: 240598.0938\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rewards:  -46.0 q-value:  0\n",
      "loss: [240598.09375]\n",
      "Exploiting\n",
      "Selected action  [1 2]\n",
      "[1 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 81us/step - loss: 336944.8438\n",
      "rewards:  -47.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [336944.84375]\n",
      "Exploiting\n",
      "Selected action  [0 3]\n",
      "[0 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 70us/step - loss: 236796.9375\n",
      "rewards:  -79.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [236796.9375]\n",
      "Exploring\n",
      "Selected action  [0 3]\n",
      "[0 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 73us/step - loss: 87137.1875\n",
      "rewards:  -81.0 q-value:  0\n",
      "loss: [87137.1875]\n",
      "Exploring\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 129us/step - loss: 305934.6562\n",
      "rewards:  -69.0 q-value:  0\n",
      "loss: [305934.65625]\n",
      "Exploring\n",
      "Selected action  [1 2]\n",
      "[1 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 65us/step - loss: 412029.1562\n",
      "rewards:  -64.0 q-value:  0\n",
      "loss: [412029.15625]\n",
      "Exploring\n",
      "Selected action  [1 2]\n",
      "[1 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 113us/step - loss: 80828.4062\n",
      "rewards:  -65.0 q-value:  0\n",
      "loss: [80828.40625]\n",
      "Exploring\n",
      "Selected action  [1 2]\n",
      "[1 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 70us/step - loss: 109889.0000\n",
      "rewards:  -66.0 q-value:  0\n",
      "loss: [109889.0]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 95us/step - loss: 457845.4688\n",
      "rewards:  -71.0 q-value:  0\n",
      "loss: [457845.46875]\n",
      "Exploring\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 67us/step - loss: 605206.8750\n",
      "rewards:  -77.0 q-value:  0\n",
      "loss: [605206.875]\n",
      "Exploiting\n",
      "Selected action  [1 2]\n",
      "[1 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 67us/step - loss: 421651.9688\n",
      "rewards:  -50.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [421651.96875]\n",
      "Exploiting\n",
      "Selected action  [1 2]\n",
      "[1 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 72us/step - loss: 375301.0938\n",
      "rewards:  -57.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [375301.09375]\n",
      "Exploring\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 56us/step - loss: 202974.1562\n",
      "rewards:  -80.0 q-value:  0\n",
      "loss: [202974.15625]\n",
      "Exploring\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 94us/step - loss: 91791.2500\n",
      "rewards:  -81.0 q-value:  0\n",
      "loss: [91791.25]\n",
      "Exploiting\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 57us/step - loss: 635560.3750\n",
      "rewards:  -82.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [635560.375]\n",
      "Exploring\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 99us/step - loss: 92330.2812\n",
      "rewards:  -83.0 q-value:  0\n",
      "loss: [92330.28125]\n",
      "Exploring\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 73us/step - loss: 304463.0938\n",
      "rewards:  -84.0 q-value:  0\n",
      "loss: [304463.09375]\n",
      "Exploring\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 59us/step - loss: 466431.3750\n",
      "rewards:  -85.0 q-value:  0\n",
      "loss: [466431.375]\n",
      "Exploiting\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 67us/step - loss: 118495.9688\n",
      "rewards:  -90.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [118495.96875]\n",
      "Exploring\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 65us/step - loss: 269874.2500\n",
      "rewards:  -113.0 q-value:  0\n",
      "loss: [269874.25]\n",
      "Exploring\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 68us/step - loss: 76788.9062\n",
      "rewards:  -127.0 q-value:  0\n",
      "loss: [76788.90625]\n",
      "Exploring\n",
      "Selected action  [0 4]\n",
      "[0 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 113us/step - loss: 97301.9375\n",
      "rewards:  -123.0 q-value:  0\n",
      "loss: [97301.9375]\n",
      "Exploring\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 88us/step - loss: 270905.2812\n",
      "rewards:  -95.0 q-value:  0\n",
      "loss: [270905.28125]\n",
      "Exploring\n",
      "Selected action  [1 2]\n",
      "[1 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 99us/step - loss: 132591.7812\n",
      "rewards:  -76.0 q-value:  0\n",
      "loss: [132591.78125]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 85us/step - loss: 389123.6875\n",
      "rewards:  -81.0 q-value:  0\n",
      "loss: [389123.6875]\n",
      "Exploring\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 70us/step - loss: 546102.1250\n",
      "rewards:  -93.0 q-value:  0\n",
      "loss: [546102.125]\n",
      "Exploring\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 74us/step - loss: 376742.7812\n",
      "rewards:  -98.0 q-value:  0\n",
      "loss: [376742.78125]\n",
      "Exploiting\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 79us/step - loss: 177177.0938\n",
      "rewards:  -103.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [177177.09375]\n",
      "Exploring\n",
      "Selected action  [0 3]\n",
      "[0 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 68us/step - loss: 292019.3438\n",
      "rewards:  -79.0 q-value:  0\n",
      "loss: [292019.34375]\n",
      "Exploring\n",
      "Selected action  [1 2]\n",
      "[1 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 95us/step - loss: 47824.0312\n",
      "rewards:  -83.0 q-value:  0\n",
      "loss: [47824.03125]\n",
      "Exploring\n",
      "Selected action  [1 2]\n",
      "[1 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 90us/step - loss: 219138.2500\n",
      "rewards:  -85.0 q-value:  0\n",
      "loss: [219138.25]\n",
      "Exploring\n",
      "Selected action  [0 3]\n",
      "[0 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 96us/step - loss: 528042.8750\n",
      "rewards:  -100.0 q-value:  0\n",
      "loss: [528042.875]\n",
      "Exploring\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 75us/step - loss: 747839.2500\n",
      "rewards:  -128.0 q-value:  0\n",
      "loss: [747839.25]\n",
      "Exploring\n",
      "Selected action  [1 2]\n",
      "[1 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 91us/step - loss: 142403.8125\n",
      "rewards:  -106.0 q-value:  0\n",
      "loss: [142403.8125]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 95us/step - loss: 351700.6250\n",
      "rewards:  -111.0 q-value:  0\n",
      "loss: [351700.625]\n",
      "Exploring\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 75us/step - loss: 317080.0312\n",
      "rewards:  -101.0 q-value:  0\n",
      "loss: [317080.03125]\n",
      "Exploring\n",
      "Selected action  [0 4]\n",
      "[0 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 59us/step - loss: 120584.5000\n",
      "rewards:  -112.0 q-value:  0\n",
      "loss: [120584.5]\n",
      "Exploiting\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 87us/step - loss: 709770.2500\n",
      "rewards:  -118.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [709770.25]\n",
      "Exploiting\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 119us/step - loss: 136985.3750\n",
      "rewards:  -120.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [136985.375]\n",
      "Exploring\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 81us/step - loss: 365717.5625\n",
      "rewards:  -136.0 q-value:  0\n",
      "loss: [365717.5625]\n",
      "Exploring\n",
      "Selected action  [0 4]\n",
      "[0 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 82us/step - loss: 223923.4688\n",
      "rewards:  -134.0 q-value:  0\n",
      "loss: [223923.46875]\n",
      "Exploiting\n",
      "Selected action  [0 3]\n",
      "[0 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 79us/step - loss: 396506.0625\n",
      "rewards:  -164.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [396506.0625]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 80us/step - loss: 384394.9375\n",
      "rewards:  -169.0 q-value:  0\n",
      "loss: [384394.9375]\n",
      "Exploring\n",
      "Selected action  [1 2]\n",
      "[1 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 91us/step - loss: 358861.9688\n",
      "rewards:  -159.0 q-value:  0\n",
      "loss: [358861.96875]\n",
      "Exploring\n",
      "Selected action  [0 3]\n",
      "[0 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 80us/step - loss: 156097.9375\n",
      "rewards:  -165.0 q-value:  0\n",
      "loss: [156097.9375]\n",
      "Exploiting\n",
      "Selected action  [2 0]\n",
      "[2 0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 101us/step - loss: 122459.2188\n",
      "rewards:  -166.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [122459.21875]\n",
      "Exploring\n",
      "Selected action  [0 3]\n",
      "[0 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 128us/step - loss: 261341.0000\n",
      "rewards:  -162.0 q-value:  0\n",
      "loss: [261341.0]\n",
      "Exploring\n",
      "Selected action  [0 4]\n",
      "[0 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 95us/step - loss: 338711.2812\n",
      "rewards:  -163.0 q-value:  0\n",
      "loss: [338711.28125]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 89us/step - loss: 203469.4688\n",
      "rewards:  -168.0 q-value:  0\n",
      "loss: [203469.46875]\n",
      "Exploiting\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 54us/step - loss: 274881.0000\n",
      "rewards:  -173.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [274881.0]\n",
      "Exploring\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 90us/step - loss: 700743.7500\n",
      "rewards:  -176.0 q-value:  0\n",
      "loss: [700743.75]\n",
      "Exploiting\n",
      "Selected action  [0 4]\n",
      "[0 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 67us/step - loss: 219084.8438\n",
      "rewards:  -160.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [219084.84375]\n",
      "Exploring\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 81us/step - loss: 350203.7812\n",
      "rewards:  -162.0 q-value:  0\n",
      "loss: [350203.78125]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 140us/step - loss: 126311.1875\n",
      "rewards:  -167.0 q-value:  0\n",
      "loss: [126311.1875]\n",
      "Exploring\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 83us/step - loss: 425796.7500\n",
      "rewards:  -162.0 q-value:  0\n",
      "loss: [425796.75]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 78us/step - loss: 219498.0938\n",
      "rewards:  -167.0 q-value:  0\n",
      "loss: [219498.09375]\n",
      "Exploring\n",
      "Selected action  [0 3]\n",
      "[0 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 72us/step - loss: 578499.0625\n",
      "rewards:  -135.0 q-value:  0\n",
      "loss: [578499.0625]\n",
      "Exploiting\n",
      "Selected action  [0 4]\n",
      "[0 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 81us/step - loss: 471821.1562\n",
      "rewards:  -141.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [471821.15625]\n",
      "Exploring\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 71us/step - loss: 156471.5625\n",
      "rewards:  -147.0 q-value:  0\n",
      "loss: [156471.5625]\n",
      "Exploring\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 81us/step - loss: 82310.8125\n",
      "rewards:  -173.0 q-value:  0\n",
      "loss: [82310.8125]\n",
      "Exploring\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 97us/step - loss: 442024.0312\n",
      "rewards:  -174.0 q-value:  0\n",
      "loss: [442024.03125]\n",
      "Exploring\n",
      "Selected action  [0 4]\n",
      "[0 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 82us/step - loss: 888901.6250\n",
      "rewards:  -180.0 q-value:  0\n",
      "loss: [888901.625]\n",
      "Exploiting\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 69us/step - loss: 416254.5938\n",
      "rewards:  -191.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [416254.59375]\n",
      "Exploring\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 68us/step - loss: 594730.8750\n",
      "rewards:  -192.0 q-value:  0\n",
      "loss: [594730.875]\n",
      "Exploring\n",
      "Selected action  [0 4]\n",
      "[0 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 81us/step - loss: 565958.8750\n",
      "rewards:  -174.0 q-value:  0\n",
      "loss: [565958.875]\n",
      "Exploring\n",
      "Selected action  [0 4]\n",
      "[0 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 103us/step - loss: 409300.3438\n",
      "rewards:  -174.0 q-value:  0\n",
      "loss: [409300.34375]\n",
      "Exploring\n",
      "Selected action  [0 3]\n",
      "[0 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 85us/step - loss: 500040.0625\n",
      "rewards:  -154.0 q-value:  0\n",
      "loss: [500040.0625]\n",
      "Exploiting\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 77us/step - loss: 362998.2500\n",
      "rewards:  -157.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [362998.25]\n",
      "Exploring\n",
      "Selected action  [0 4]\n",
      "[0 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 63us/step - loss: 370427.9062\n",
      "rewards:  -179.0 q-value:  0\n",
      "loss: [370427.90625]\n",
      "Exploiting\n",
      "Selected action  [0 3]\n",
      "[0 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 92us/step - loss: 89740.6250\n",
      "rewards:  -159.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [89740.625]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 84us/step - loss: 144759.2500\n",
      "rewards:  -164.0 q-value:  0\n",
      "loss: [144759.25]\n",
      "Exploring\n",
      "Selected action  [0 4]\n",
      "[0 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 82us/step - loss: 295216.2188\n",
      "rewards:  -140.0 q-value:  0\n",
      "loss: [295216.21875]\n",
      "Exploiting\n",
      "Selected action  [1 2]\n",
      "[1 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 73us/step - loss: 516168.0312\n",
      "rewards:  -127.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [516168.03125]\n",
      "Exploiting\n",
      "Selected action  [0 3]\n",
      "[0 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 87us/step - loss: 636527.7500\n",
      "rewards:  -148.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [636527.75]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 81us/step - loss: 280052.5938\n",
      "rewards:  -153.0 q-value:  0\n",
      "loss: [280052.59375]\n",
      "Exploring\n",
      "Selected action  [0 3]\n",
      "[0 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 102us/step - loss: 320617.8438\n",
      "rewards:  -149.0 q-value:  0\n",
      "loss: [320617.84375]\n",
      "Exploring\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 72us/step - loss: 473638.2188\n",
      "rewards:  -144.0 q-value:  0\n",
      "loss: [473638.21875]\n",
      "Exploring\n",
      "Selected action  [1 2]\n",
      "[1 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 95us/step - loss: 403972.1875\n",
      "rewards:  -155.0 q-value:  0\n",
      "loss: [403972.1875]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 78us/step - loss: 395150.0938\n",
      "rewards:  -160.0 q-value:  0\n",
      "loss: [395150.09375]\n",
      "Exploring\n",
      "Selected action  [0 4]\n",
      "[0 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 78us/step - loss: 42156.5312\n",
      "rewards:  -144.0 q-value:  0\n",
      "loss: [42156.53125]\n",
      "Exploiting\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 86us/step - loss: 322241.6562\n",
      "rewards:  -132.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [322241.65625]\n",
      "Exploring\n",
      "Selected action  [0 4]\n",
      "[0 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 62us/step - loss: 153680.4375\n",
      "rewards:  -125.0 q-value:  0\n",
      "loss: [153680.4375]\n",
      "Exploiting\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 87us/step - loss: 622513.3750\n",
      "rewards:  -114.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [622513.375]\n",
      "Exploring\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 84us/step - loss: 218734.6250\n",
      "rewards:  -118.0 q-value:  0\n",
      "loss: [218734.625]\n",
      "Exploring\n",
      "Selected action  [0 4]\n",
      "[0 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 82us/step - loss: 293761.4688\n",
      "rewards:  -148.0 q-value:  0\n",
      "loss: [293761.46875]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 60us/step - loss: 358594.5000\n",
      "rewards:  -153.0 q-value:  0\n",
      "loss: [358594.5]\n",
      "Exploring\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 92us/step - loss: 389482.4062\n",
      "rewards:  -160.0 q-value:  0\n",
      "loss: [389482.40625]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 92us/step - loss: 231693.5000\n",
      "rewards:  -165.0 q-value:  0\n",
      "loss: [231693.5]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 72us/step - loss: 330279.6562\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rewards:  -170.0 q-value:  0\n",
      "loss: [330279.65625]\n",
      "Exploring\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 86us/step - loss: 425277.2500\n",
      "rewards:  -182.0 q-value:  0\n",
      "loss: [425277.25]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 248us/step - loss: 957602.5625\n",
      "rewards:  -187.0 q-value:  0\n",
      "loss: [957602.5625]\n",
      "Exploring\n",
      "Selected action  [1 2]\n",
      "[1 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 88us/step - loss: 250573.9844\n",
      "rewards:  -183.0 q-value:  0\n",
      "loss: [250573.984375]\n",
      "Exploiting\n",
      "Selected action  [1 2]\n",
      "[1 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 79us/step - loss: 24197.5312\n",
      "rewards:  -190.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [24197.53125]\n",
      "Exploring\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 80us/step - loss: 336532.2188\n",
      "rewards:  -194.0 q-value:  0\n",
      "loss: [336532.21875]\n",
      "Exploring\n",
      "Selected action  [0 4]\n",
      "[0 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 57us/step - loss: 287276.0938\n",
      "rewards:  -197.0 q-value:  0\n",
      "loss: [287276.09375]\n",
      "Exploiting\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 78us/step - loss: 695784.0000\n",
      "rewards:  -185.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [695784.0]\n",
      "Exploring\n",
      "Selected action  [1 2]\n",
      "[1 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 92us/step - loss: 153484.0000\n",
      "rewards:  -187.0 q-value:  0\n",
      "loss: [153484.0]\n",
      "Exploring\n",
      "Selected action  [0 3]\n",
      "[0 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 74us/step - loss: 520007.0625\n",
      "rewards:  -200.0 q-value:  0\n",
      "loss: [520007.0625]\n",
      "Exploiting\n",
      "Selected action  [0 4]\n",
      "[0 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 69us/step - loss: 42653.9062\n",
      "rewards:  -183.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [42653.90625]\n",
      "Exploring\n",
      "Selected action  [1 2]\n",
      "[1 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 73us/step - loss: 369574.8438\n",
      "rewards:  -158.0 q-value:  0\n",
      "loss: [369574.84375]\n",
      "Exploring\n",
      "Selected action  [0 4]\n",
      "[0 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 85us/step - loss: 322252.3125\n",
      "rewards:  -156.0 q-value:  0\n",
      "loss: [322252.3125]\n",
      "Number of actions available 9\n",
      "Episode : 26\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 76us/step - loss: 79419.6250\n",
      "rewards:  4.0 q-value:  0\n",
      "loss: [79419.625]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 255us/step - loss: 347717.4688\n",
      "rewards:  -2.0 q-value:  0\n",
      "loss: [347717.46875]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 67us/step - loss: 411509.4062\n",
      "rewards:  -7.0 q-value:  0\n",
      "loss: [411509.40625]\n",
      "Exploring\n",
      "Selected action  [0 4]\n",
      "[0 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 94us/step - loss: 285595.5000\n",
      "rewards:  -3.0 q-value:  0\n",
      "loss: [285595.5]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 74us/step - loss: 295168.6562\n",
      "rewards:  -8.0 q-value:  0\n",
      "loss: [295168.65625]\n",
      "Exploiting\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 78us/step - loss: 213528.7188\n",
      "rewards:  -13.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [213528.71875]\n",
      "Exploiting\n",
      "Selected action  [3 1]\n",
      "[3 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 80us/step - loss: 329340.5312\n",
      "rewards:  -13.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [329340.53125]\n",
      "Exploiting\n",
      "Selected action  [3 1]\n",
      "[3 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 82us/step - loss: 74002.4375\n",
      "rewards:  -13.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [74002.4375]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 109us/step - loss: 374819.6562\n",
      "rewards:  -5.0 q-value:  0\n",
      "loss: [374819.65625]\n",
      "Exploring\n",
      "Selected action  [0 4]\n",
      "[0 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 70us/step - loss: 137206.6562\n",
      "rewards:  27.0 q-value:  0\n",
      "loss: [137206.65625]\n",
      "Exploiting\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 66us/step - loss: 288908.4688\n",
      "rewards:  15.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [288908.46875]\n",
      "Exploring\n",
      "Selected action  [2 1]\n",
      "[2 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 77us/step - loss: 146618.5938\n",
      "rewards:  25.0 q-value:  0\n",
      "loss: [146618.59375]\n",
      "Exploring\n",
      "Selected action  [2 1]\n",
      "[2 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 61us/step - loss: 330156.3438\n",
      "rewards:  15.0 q-value:  0\n",
      "loss: [330156.34375]\n",
      "Exploring\n",
      "Selected action  [3 2]\n",
      "[3 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 62us/step - loss: 277800.9375\n",
      "rewards:  22.0 q-value:  0\n",
      "loss: [277800.9375]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 75us/step - loss: 375154.0312\n",
      "rewards:  5.0 q-value:  0\n",
      "loss: [375154.03125]\n",
      "Exploiting\n",
      "Selected action  [2 1]\n",
      "[2 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 74us/step - loss: 324677.1250\n",
      "rewards:  -1.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [324677.125]\n",
      "Exploring\n",
      "Selected action  [3 1]\n",
      "[3 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 83us/step - loss: 220304.4375\n",
      "rewards:  -3.0 q-value:  0\n",
      "loss: [220304.4375]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 88us/step - loss: 753941.5625\n",
      "rewards:  25.0 q-value:  0\n",
      "loss: [753941.5625]\n",
      "Exploring\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 55us/step - loss: 36622.3125\n",
      "rewards:  22.0 q-value:  0\n",
      "loss: [36622.3125]\n",
      "Exploring\n",
      "Selected action  [0 3]\n",
      "[0 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 82us/step - loss: 550955.1250\n",
      "rewards:  26.0 q-value:  0\n",
      "loss: [550955.125]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 64us/step - loss: 138059.2812\n",
      "rewards:  28.0 q-value:  0\n",
      "loss: [138059.28125]\n",
      "Exploring\n",
      "Selected action  [2 1]\n",
      "[2 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 65us/step - loss: 746355.7500\n",
      "rewards:  62.0 q-value:  0\n",
      "loss: [746355.75]\n",
      "Exploring\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 91us/step - loss: 876892.2500\n",
      "rewards:  66.0 q-value:  0\n",
      "loss: [876892.25]\n",
      "Exploiting\n",
      "Selected action  [0 4]\n",
      "[0 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 79us/step - loss: 885271.1250\n",
      "rewards:  70.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [885271.125]\n",
      "Exploring\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 79us/step - loss: 39325.5625\n",
      "rewards:  64.0 q-value:  0\n",
      "loss: [39325.5625]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 109us/step - loss: 113773.7188\n",
      "rewards:  58.0 q-value:  0\n",
      "loss: [113773.71875]\n",
      "Exploring\n",
      "Selected action  [2 1]\n",
      "[2 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 80us/step - loss: 123010.4375\n",
      "rewards:  46.0 q-value:  0\n",
      "loss: [123010.4375]\n",
      "Exploring\n",
      "Selected action  [2 3]\n",
      "[2 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 85us/step - loss: 327080.9688\n",
      "rewards:  16.0 q-value:  0\n",
      "loss: [327080.96875]\n",
      "Exploring\n",
      "Selected action  [2 3]\n",
      "[2 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 71us/step - loss: 247695.4062\n",
      "rewards:  11.0 q-value:  0\n",
      "loss: [247695.40625]\n",
      "Exploring\n",
      "Selected action  [3 1]\n",
      "[3 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 106us/step - loss: 232562.8125\n",
      "rewards:  27.0 q-value:  0\n",
      "loss: [232562.8125]\n",
      "Exploiting\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 82us/step - loss: 246348.3438\n",
      "rewards:  22.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [246348.34375]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 83us/step - loss: 209486.4688\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rewards:  17.0 q-value:  0\n",
      "loss: [209486.46875]\n",
      "Exploring\n",
      "Selected action  [0 4]\n",
      "[0 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 92us/step - loss: 270763.4375\n",
      "rewards:  41.0 q-value:  0\n",
      "loss: [270763.4375]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 67us/step - loss: 427984.5938\n",
      "rewards:  36.0 q-value:  0\n",
      "loss: [427984.59375]\n",
      "Exploring\n",
      "Selected action  [0 4]\n",
      "[0 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 57us/step - loss: 281886.4688\n",
      "rewards:  40.0 q-value:  0\n",
      "loss: [281886.46875]\n",
      "Exploring\n",
      "Selected action  [2 1]\n",
      "[2 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 99us/step - loss: 159489.7812\n",
      "rewards:  63.0 q-value:  0\n",
      "loss: [159489.78125]\n",
      "Exploring\n",
      "Selected action  [0 3]\n",
      "[0 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 95us/step - loss: 180508.0938\n",
      "rewards:  27.0 q-value:  0\n",
      "loss: [180508.09375]\n",
      "Exploring\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 75us/step - loss: 136904.8438\n",
      "rewards:  32.0 q-value:  0\n",
      "loss: [136904.84375]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 100us/step - loss: 549666.2500\n",
      "rewards:  29.0 q-value:  0\n",
      "loss: [549666.25]\n",
      "Exploring\n",
      "Selected action  [0 3]\n",
      "[0 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 80us/step - loss: 186582.5625\n",
      "rewards:  33.0 q-value:  0\n",
      "loss: [186582.5625]\n",
      "Exploring\n",
      "Selected action  [3 1]\n",
      "[3 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 69us/step - loss: 125732.8438\n",
      "rewards:  45.0 q-value:  0\n",
      "loss: [125732.84375]\n",
      "Exploring\n",
      "Selected action  [0 3]\n",
      "[0 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 105us/step - loss: 376807.1250\n",
      "rewards:  14.0 q-value:  0\n",
      "loss: [376807.125]\n",
      "Exploiting\n",
      "Selected action  [0 4]\n",
      "[0 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 75us/step - loss: 248841.0312\n",
      "rewards:  -2.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [248841.03125]\n",
      "Exploring\n",
      "Selected action  [3 1]\n",
      "[3 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 91us/step - loss: 589120.5000\n",
      "rewards:  4.0 q-value:  0\n",
      "loss: [589120.5]\n",
      "Exploring\n",
      "Selected action  [3 2]\n",
      "[3 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 83us/step - loss: 221343.8125\n",
      "rewards:  28.0 q-value:  0\n",
      "loss: [221343.8125]\n",
      "Exploring\n",
      "Selected action  [3 1]\n",
      "[3 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 77us/step - loss: 415172.0625\n",
      "rewards:  -4.0 q-value:  0\n",
      "loss: [415172.0625]\n",
      "Exploring\n",
      "Selected action  [3 2]\n",
      "[3 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 86us/step - loss: 233343.0938\n",
      "rewards:  6.0 q-value:  0\n",
      "loss: [233343.09375]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 77us/step - loss: 172465.9375\n",
      "rewards:  1.0 q-value:  0\n",
      "loss: [172465.9375]\n",
      "Exploring\n",
      "Selected action  [0 3]\n",
      "[0 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 85us/step - loss: 369571.5312\n",
      "rewards:  13.0 q-value:  0\n",
      "loss: [369571.53125]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 67us/step - loss: 186492.8438\n",
      "rewards:  17.0 q-value:  0\n",
      "loss: [186492.84375]\n",
      "Exploring\n",
      "Selected action  [3 2]\n",
      "[3 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 95us/step - loss: 329669.6562\n",
      "rewards:  26.0 q-value:  0\n",
      "loss: [329669.65625]\n",
      "Exploring\n",
      "Selected action  [3 2]\n",
      "[3 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 67us/step - loss: 169044.2188\n",
      "rewards:  18.0 q-value:  0\n",
      "loss: [169044.21875]\n",
      "Exploring\n",
      "Selected action  [0 3]\n",
      "[0 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 79us/step - loss: 549904.8750\n",
      "rewards:  5.0 q-value:  0\n",
      "loss: [549904.875]\n",
      "Exploring\n",
      "Selected action  [2 1]\n",
      "[2 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 77us/step - loss: 635607.5000\n",
      "rewards:  -5.0 q-value:  0\n",
      "loss: [635607.5]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 65us/step - loss: 345026.7188\n",
      "rewards:  -10.0 q-value:  0\n",
      "loss: [345026.71875]\n",
      "Exploring\n",
      "Selected action  [2 3]\n",
      "[2 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 79us/step - loss: 328378.3438\n",
      "rewards:  -32.0 q-value:  0\n",
      "loss: [328378.34375]\n",
      "Exploring\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 83us/step - loss: 265062.7500\n",
      "rewards:  -18.0 q-value:  0\n",
      "loss: [265062.75]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 82us/step - loss: 342416.1562\n",
      "rewards:  -23.0 q-value:  0\n",
      "loss: [342416.15625]\n",
      "Exploiting\n",
      "Selected action  [0 4]\n",
      "[0 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 76us/step - loss: 599913.2500\n",
      "rewards:  -11.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [599913.25]\n",
      "Exploring\n",
      "Selected action  [3 2]\n",
      "[3 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 86us/step - loss: 304627.9375\n",
      "rewards:  -20.0 q-value:  0\n",
      "loss: [304627.9375]\n",
      "Exploring\n",
      "Selected action  [0 4]\n",
      "[0 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 74us/step - loss: 176054.7188\n",
      "rewards:  -46.0 q-value:  0\n",
      "loss: [176054.71875]\n",
      "Exploring\n",
      "Selected action  [3 1]\n",
      "[3 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 75us/step - loss: 98667.0625\n",
      "rewards:  -47.0 q-value:  0\n",
      "loss: [98667.0625]\n",
      "Exploring\n",
      "Selected action  [3 2]\n",
      "[3 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 102us/step - loss: 631884.0000\n",
      "rewards:  -37.0 q-value:  0\n",
      "loss: [631884.0]\n",
      "Exploring\n",
      "Selected action  [2 1]\n",
      "[2 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 83us/step - loss: 353710.6875\n",
      "rewards:  -25.0 q-value:  0\n",
      "loss: [353710.6875]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 71us/step - loss: 51472.7812\n",
      "rewards:  3.0 q-value:  0\n",
      "loss: [51472.78125]\n",
      "Exploring\n",
      "Selected action  [2 3]\n",
      "[2 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 81us/step - loss: 250891.1250\n",
      "rewards:  -10.0 q-value:  0\n",
      "loss: [250891.125]\n",
      "Exploiting\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 59us/step - loss: 54399.4062\n",
      "rewards:  -15.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [54399.40625]\n",
      "Exploring\n",
      "Selected action  [0 3]\n",
      "[0 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 91us/step - loss: 303872.1562\n",
      "rewards:  17.0 q-value:  0\n",
      "loss: [303872.15625]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 71us/step - loss: 221850.0312\n",
      "rewards:  43.0 q-value:  0\n",
      "loss: [221850.03125]\n",
      "Exploiting\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 70us/step - loss: 42135.0938\n",
      "rewards:  35.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [42135.09375]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 95us/step - loss: 493089.7812\n",
      "rewards:  30.0 q-value:  0\n",
      "loss: [493089.78125]\n",
      "Exploiting\n",
      "Selected action  [3 1]\n",
      "[3 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 71us/step - loss: 204146.7500\n",
      "rewards:  12.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [204146.75]\n",
      "Exploring\n",
      "Selected action  [0 3]\n",
      "[0 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 59us/step - loss: 249894.1250\n",
      "rewards:  12.0 q-value:  0\n",
      "loss: [249894.125]\n",
      "Exploring\n",
      "Selected action  [0 3]\n",
      "[0 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 66us/step - loss: 334745.0312\n",
      "rewards:  7.0 q-value:  0\n",
      "loss: [334745.03125]\n",
      "Exploring\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 72us/step - loss: 413956.2188\n",
      "rewards:  27.0 q-value:  0\n",
      "loss: [413956.21875]\n",
      "Exploring\n",
      "Selected action  [3 2]\n",
      "[3 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 78us/step - loss: 419402.4062\n",
      "rewards:  16.0 q-value:  0\n",
      "loss: [419402.40625]\n",
      "Exploring\n",
      "Selected action  [3 2]\n",
      "[3 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 76us/step - loss: 364296.8438\n",
      "rewards:  13.0 q-value:  0\n",
      "loss: [364296.84375]\n",
      "Exploiting\n",
      "Selected action  [0 4]\n",
      "[0 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 75us/step - loss: 116739.3750\n",
      "rewards:  14.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [116739.375]\n",
      "Exploring\n",
      "Selected action  [2 0]\n",
      "[2 0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 74us/step - loss: 22646.3125\n",
      "rewards:  16.0 q-value:  0\n",
      "loss: [22646.3125]\n",
      "Exploiting\n",
      "Selected action  [0 3]\n",
      "[0 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 83us/step - loss: 348806.5312\n",
      "rewards:  20.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [348806.53125]\n",
      "Exploring\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 79us/step - loss: 19379.0312\n",
      "rewards:  6.0 q-value:  0\n",
      "loss: [19379.03125]\n",
      "Exploring\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 68us/step - loss: 1004859.8750\n",
      "rewards:  -1.0 q-value:  0\n",
      "loss: [1004859.875]\n",
      "Exploring\n",
      "Selected action  [0 4]\n",
      "[0 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 75us/step - loss: 291803.2812\n",
      "rewards:  -1.0 q-value:  0\n",
      "loss: [291803.28125]\n",
      "Exploring\n",
      "Selected action  [2 3]\n",
      "[2 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 75us/step - loss: 364744.6250\n",
      "rewards:  -33.0 q-value:  0\n",
      "loss: [364744.625]\n",
      "Exploiting\n",
      "Selected action  [0 4]\n",
      "[0 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 60us/step - loss: 362656.6250\n",
      "rewards:  -63.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [362656.625]\n",
      "Exploring\n",
      "Selected action  [2 1]\n",
      "[2 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 78us/step - loss: 449772.2812\n",
      "rewards:  -59.0 q-value:  0\n",
      "loss: [449772.28125]\n",
      "Exploring\n",
      "Selected action  [2 1]\n",
      "[2 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 65us/step - loss: 164266.8125\n",
      "rewards:  -65.0 q-value:  0\n",
      "loss: [164266.8125]\n",
      "Exploring\n",
      "Selected action  [3 1]\n",
      "[3 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 56us/step - loss: 400425.2188\n",
      "rewards:  -69.0 q-value:  0\n",
      "loss: [400425.21875]\n",
      "Exploring\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 73us/step - loss: 71803.0625\n",
      "rewards:  -65.0 q-value:  0\n",
      "loss: [71803.0625]\n",
      "Exploring\n",
      "Selected action  [2 3]\n",
      "[2 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 66us/step - loss: 616502.1875\n",
      "rewards:  -48.0 q-value:  0\n",
      "loss: [616502.1875]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 60us/step - loss: 209574.1875\n",
      "rewards:  -40.0 q-value:  0\n",
      "loss: [209574.1875]\n",
      "Exploring\n",
      "Selected action  [2 1]\n",
      "[2 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 83us/step - loss: 696614.5000\n",
      "rewards:  -33.0 q-value:  0\n",
      "loss: [696614.5]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 64us/step - loss: 227804.9688\n",
      "rewards:  -38.0 q-value:  0\n",
      "loss: [227804.96875]\n",
      "Exploring\n",
      "Selected action  [3 2]\n",
      "[3 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 76us/step - loss: 353650.0312\n",
      "rewards:  -45.0 q-value:  0\n",
      "loss: [353650.03125]\n",
      "Exploring\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 63us/step - loss: 310871.5938\n",
      "rewards:  -21.0 q-value:  0\n",
      "loss: [310871.59375]\n",
      "Exploring\n",
      "Selected action  [3 1]\n",
      "[3 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 96us/step - loss: 38116.3750\n",
      "rewards:  -27.0 q-value:  0\n",
      "loss: [38116.375]\n",
      "Exploring\n",
      "Selected action  [2 3]\n",
      "[2 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 65us/step - loss: 55416.6562\n",
      "rewards:  4.0 q-value:  0\n",
      "loss: [55416.65625]\n",
      "Exploring\n",
      "Selected action  [0 4]\n",
      "[0 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 68us/step - loss: 40104.4688\n",
      "rewards:  -22.0 q-value:  0\n",
      "loss: [40104.46875]\n",
      "Exploiting\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 75us/step - loss: 420717.1562\n",
      "rewards:  2.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [420717.15625]\n",
      "Number of actions available 10\n",
      "Episode : 27\n",
      "Exploring\n",
      "Selected action  [3 1]\n",
      "[3 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 87us/step - loss: 269583.3750\n",
      "rewards:  16.0 q-value:  0\n",
      "loss: [269583.375]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 67us/step - loss: 231771.0312\n",
      "rewards:  40.0 q-value:  0\n",
      "loss: [231771.03125]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 85us/step - loss: 263127.6875\n",
      "rewards:  35.0 q-value:  0\n",
      "loss: [263127.6875]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 97us/step - loss: 30197.8438\n",
      "rewards:  30.0 q-value:  0\n",
      "loss: [30197.84375]\n",
      "Exploring\n",
      "Selected action  [3 2]\n",
      "[3 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 74us/step - loss: 67210.7500\n",
      "rewards:  62.0 q-value:  0\n",
      "loss: [67210.75]\n",
      "Exploring\n",
      "Selected action  [0 4]\n",
      "[0 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 70us/step - loss: 32441.7812\n",
      "rewards:  69.0 q-value:  0\n",
      "loss: [32441.78125]\n",
      "Exploring\n",
      "Selected action  [0 4]\n",
      "[0 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 77us/step - loss: 47168.9375\n",
      "rewards:  68.0 q-value:  0\n",
      "loss: [47168.9375]\n",
      "Exploring\n",
      "Selected action  [2 3]\n",
      "[2 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 93us/step - loss: 248325.0000\n",
      "rewards:  46.0 q-value:  0\n",
      "loss: [248325.0]\n",
      "Exploring\n",
      "Selected action  [4 3]\n",
      "[4 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 59us/step - loss: 255578.6875\n",
      "rewards:  39.0 q-value:  0\n",
      "loss: [255578.6875]\n",
      "Exploring\n",
      "Selected action  [2 3]\n",
      "[2 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 77us/step - loss: 392275.1562\n",
      "rewards:  30.0 q-value:  0\n",
      "loss: [392275.15625]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 80us/step - loss: 248078.2812\n",
      "rewards:  25.0 q-value:  0\n",
      "loss: [248078.28125]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 65us/step - loss: 36323.9375\n",
      "rewards:  37.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [36323.9375]\n",
      "Exploring\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 73us/step - loss: 258391.9062\n",
      "rewards:  34.0 q-value:  0\n",
      "loss: [258391.90625]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 70us/step - loss: 61869.9688\n",
      "rewards:  29.0 q-value:  0\n",
      "loss: [61869.96875]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 71us/step - loss: 537717.3125\n",
      "rewards:  57.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [537717.3125]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 70us/step - loss: 247006.7188\n",
      "rewards:  50.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [247006.71875]\n",
      "Exploring\n",
      "Selected action  [3 1]\n",
      "[3 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 93us/step - loss: 245270.5625\n",
      "rewards:  48.0 q-value:  0\n",
      "loss: [245270.5625]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 72us/step - loss: 198823.0312\n",
      "rewards:  60.0 q-value:  0\n",
      "loss: [198823.03125]\n",
      "Exploring\n",
      "Selected action  [3 2]\n",
      "[3 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 104us/step - loss: 384483.0000\n",
      "rewards:  32.0 q-value:  0\n",
      "loss: [384483.0]\n",
      "Exploring\n",
      "Selected action  [3 2]\n",
      "[3 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 67us/step - loss: 41488.9922\n",
      "rewards:  29.0 q-value:  0\n",
      "loss: [41488.9921875]\n",
      "Exploring\n",
      "Selected action  [4 3]\n",
      "[4 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 83us/step - loss: 273866.4688\n",
      "rewards:  33.0 q-value:  0\n",
      "loss: [273866.46875]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 92us/step - loss: 29400.0000\n",
      "rewards:  28.0 q-value:  0\n",
      "loss: [29400.0]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 80us/step - loss: 49954.2500\n",
      "rewards:  52.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [49954.25]\n",
      "Exploring\n",
      "Selected action  [2 3]\n",
      "[2 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 83us/step - loss: 57512.5938\n",
      "rewards:  33.0 q-value:  0\n",
      "loss: [57512.59375]\n",
      "Exploring\n",
      "Selected action  [3 1]\n",
      "[3 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 74us/step - loss: 384746.4688\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rewards:  37.0 q-value:  0\n",
      "loss: [384746.46875]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 61us/step - loss: 58670.2812\n",
      "rewards:  57.0 q-value:  0\n",
      "loss: [58670.28125]\n",
      "Exploring\n",
      "Selected action  [1 2]\n",
      "[1 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 84us/step - loss: 223569.7812\n",
      "rewards:  60.0 q-value:  0\n",
      "loss: [223569.78125]\n",
      "Exploring\n",
      "Selected action  [1 2]\n",
      "[1 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 80us/step - loss: 214233.3125\n",
      "rewards:  59.0 q-value:  0\n",
      "loss: [214233.3125]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 95us/step - loss: 411218.2188\n",
      "rewards:  65.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [411218.21875]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 90us/step - loss: 61313.9688\n",
      "rewards:  81.0 q-value:  0\n",
      "loss: [61313.96875]\n",
      "Exploring\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 73us/step - loss: 35760.9062\n",
      "rewards:  89.0 q-value:  0\n",
      "loss: [35760.90625]\n",
      "Exploring\n",
      "Selected action  [3 2]\n",
      "[3 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 67us/step - loss: 52723.8125\n",
      "rewards:  84.0 q-value:  0\n",
      "loss: [52723.8125]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 81us/step - loss: 61653.1562\n",
      "rewards:  67.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [61653.15625]\n",
      "Exploring\n",
      "Selected action  [4 3]\n",
      "[4 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 102us/step - loss: 449450.6875\n",
      "rewards:  64.0 q-value:  0\n",
      "loss: [449450.6875]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 89us/step - loss: 58219.6875\n",
      "rewards:  57.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [58219.6875]\n",
      "Exploring\n",
      "Selected action  [4 3]\n",
      "[4 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 90us/step - loss: 256007.1875\n",
      "rewards:  47.0 q-value:  0\n",
      "loss: [256007.1875]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 66us/step - loss: 43292.5625\n",
      "rewards:  44.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [43292.5625]\n",
      "Exploring\n",
      "Selected action  [3 1]\n",
      "[3 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 70us/step - loss: 55936.4062\n",
      "rewards:  41.0 q-value:  0\n",
      "loss: [55936.40625]\n",
      "Exploring\n",
      "Selected action  [3 1]\n",
      "[3 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 83us/step - loss: 12007.5625\n",
      "rewards:  38.0 q-value:  0\n",
      "loss: [12007.5625]\n",
      "Exploring\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 120us/step - loss: 230544.7188\n",
      "rewards:  38.0 q-value:  0\n",
      "loss: [230544.71875]\n",
      "Exploring\n",
      "Selected action  [1 2]\n",
      "[1 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 76us/step - loss: 39105.1875\n",
      "rewards:  74.0 q-value:  0\n",
      "loss: [39105.1875]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 64us/step - loss: 234968.8750\n",
      "rewards:  59.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [234968.875]\n",
      "Exploring\n",
      "Selected action  [4 3]\n",
      "[4 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 91us/step - loss: 43765.1875\n",
      "rewards:  83.0 q-value:  0\n",
      "loss: [43765.1875]\n",
      "Exploring\n",
      "Selected action  [0 4]\n",
      "[0 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 71us/step - loss: 233851.9688\n",
      "rewards:  72.0 q-value:  0\n",
      "loss: [233851.96875]\n",
      "Exploring\n",
      "Selected action  [4 3]\n",
      "[4 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 97us/step - loss: 444938.7188\n",
      "rewards:  96.0 q-value:  0\n",
      "loss: [444938.71875]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 76us/step - loss: 38086.6250\n",
      "rewards:  90.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [38086.625]\n",
      "Exploring\n",
      "Selected action  [0 4]\n",
      "[0 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 98us/step - loss: 237585.6875\n",
      "rewards:  72.0 q-value:  0\n",
      "loss: [237585.6875]\n",
      "Exploring\n",
      "Selected action  [0 4]\n",
      "[0 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 80us/step - loss: 58949.9375\n",
      "rewards:  71.0 q-value:  0\n",
      "loss: [58949.9375]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 70us/step - loss: 223564.9375\n",
      "rewards:  66.0 q-value:  0\n",
      "loss: [223564.9375]\n",
      "Exploring\n",
      "Selected action  [1 2]\n",
      "[1 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 74us/step - loss: 69500.9062\n",
      "rewards:  64.0 q-value:  0\n",
      "loss: [69500.90625]\n",
      "Exploring\n",
      "Selected action  [3 1]\n",
      "[3 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 76us/step - loss: 77901.0312\n",
      "rewards:  24.0 q-value:  0\n",
      "loss: [77901.03125]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 79us/step - loss: 57238.1562\n",
      "rewards:  22.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [57238.15625]\n",
      "Exploring\n",
      "Selected action  [1 2]\n",
      "[1 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 68us/step - loss: 36098.7500\n",
      "rewards:  54.0 q-value:  0\n",
      "loss: [36098.75]\n",
      "Exploring\n",
      "Selected action  [0 4]\n",
      "[0 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 82us/step - loss: 31230.3438\n",
      "rewards:  48.0 q-value:  0\n",
      "loss: [31230.34375]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 76us/step - loss: 207724.9375\n",
      "rewards:  51.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [207724.9375]\n",
      "Exploring\n",
      "Selected action  [2 3]\n",
      "[2 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 82us/step - loss: 43102.0312\n",
      "rewards:  50.0 q-value:  0\n",
      "loss: [43102.03125]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 65us/step - loss: 35998.5312\n",
      "rewards:  71.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [35998.53125]\n",
      "Exploring\n",
      "Selected action  [4 3]\n",
      "[4 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 72us/step - loss: 50717.6875\n",
      "rewards:  71.0 q-value:  0\n",
      "loss: [50717.6875]\n",
      "Exploring\n",
      "Selected action  [2 3]\n",
      "[2 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 80us/step - loss: 40206.5312\n",
      "rewards:  65.0 q-value:  0\n",
      "loss: [40206.53125]\n",
      "Exploring\n",
      "Selected action  [2 3]\n",
      "[2 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 88us/step - loss: 43589.5938\n",
      "rewards:  60.0 q-value:  0\n",
      "loss: [43589.59375]\n",
      "Exploring\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 60us/step - loss: 65238.4375\n",
      "rewards:  83.0 q-value:  0\n",
      "loss: [65238.4375]\n",
      "Exploring\n",
      "Selected action  [3 2]\n",
      "[3 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 78us/step - loss: 25861.2500\n",
      "rewards:  89.0 q-value:  0\n",
      "loss: [25861.25]\n",
      "Exploring\n",
      "Selected action  [3 1]\n",
      "[3 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 71us/step - loss: 65141.1562\n",
      "rewards:  77.0 q-value:  0\n",
      "loss: [65141.15625]\n",
      "Exploring\n",
      "Selected action  [2 3]\n",
      "[2 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 89us/step - loss: 47732.7188\n",
      "rewards:  64.0 q-value:  0\n",
      "loss: [47732.71875]\n",
      "Exploring\n",
      "Selected action  [3 2]\n",
      "[3 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 65us/step - loss: 54965.6875\n",
      "rewards:  76.0 q-value:  0\n",
      "loss: [54965.6875]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 81us/step - loss: 34650.4375\n",
      "rewards:  82.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [34650.4375]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 74us/step - loss: 27613.2812\n",
      "rewards:  76.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [27613.28125]\n",
      "Exploring\n",
      "Selected action  [0 4]\n",
      "[0 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 84us/step - loss: 24532.5938\n",
      "rewards:  74.0 q-value:  0\n",
      "loss: [24532.59375]\n",
      "Exploring\n",
      "Selected action  [3 1]\n",
      "[3 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 135us/step - loss: 59613.1875\n",
      "rewards:  76.0 q-value:  0\n",
      "loss: [59613.1875]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 63us/step - loss: 28333.3438\n",
      "rewards:  69.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [28333.34375]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 76us/step - loss: 63107.3438\n",
      "rewards:  85.0 q-value:  0\n",
      "loss: [63107.34375]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 73us/step - loss: 28446.3750\n",
      "rewards:  93.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [28446.375]\n",
      "Exploring\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 67us/step - loss: 21638.0312\n",
      "rewards:  97.0 q-value:  0\n",
      "loss: [21638.03125]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 82us/step - loss: 40659.8555\n",
      "rewards:  90.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [40659.85546875]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 88us/step - loss: 47393.0000\n",
      "rewards:  83.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [47393.0]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 87us/step - loss: 74734.5938\n",
      "rewards:  78.0 q-value:  0\n",
      "loss: [74734.59375]\n",
      "Exploring\n",
      "Selected action  [3 1]\n",
      "[3 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 65us/step - loss: 44546.4688\n",
      "rewards:  85.0 q-value:  0\n",
      "loss: [44546.46875]\n",
      "Exploring\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 90us/step - loss: 39510.2812\n",
      "rewards:  77.0 q-value:  0\n",
      "loss: [39510.28125]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 97us/step - loss: 21809.1875\n",
      "rewards:  70.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [21809.1875]\n",
      "Exploring\n",
      "Selected action  [3 1]\n",
      "[3 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 85us/step - loss: 28978.3164\n",
      "rewards:  66.0 q-value:  0\n",
      "loss: [28978.31640625]\n",
      "Exploring\n",
      "Selected action  [4 3]\n",
      "[4 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 73us/step - loss: 48978.4375\n",
      "rewards:  69.0 q-value:  0\n",
      "loss: [48978.4375]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 89us/step - loss: 48730.5000\n",
      "rewards:  64.0 q-value:  0\n",
      "loss: [48730.5]\n",
      "Exploring\n",
      "Selected action  [1 2]\n",
      "[1 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 86us/step - loss: 66228.7812\n",
      "rewards:  83.0 q-value:  0\n",
      "loss: [66228.78125]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 84us/step - loss: 26603.2812\n",
      "rewards:  78.0 q-value:  0\n",
      "loss: [26603.28125]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 89us/step - loss: 35781.0312\n",
      "rewards:  94.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [35781.03125]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 86us/step - loss: 43876.0000\n",
      "rewards:  110.0 q-value:  0\n",
      "loss: [43876.0]\n",
      "Exploring\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 81us/step - loss: 66423.3125\n",
      "rewards:  96.0 q-value:  0\n",
      "loss: [66423.3125]\n",
      "Exploring\n",
      "Selected action  [0 4]\n",
      "[0 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 88us/step - loss: 49874.4688\n",
      "rewards:  93.0 q-value:  0\n",
      "loss: [49874.46875]\n",
      "Exploring\n",
      "Selected action  [3 1]\n",
      "[3 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 93us/step - loss: 31911.3125\n",
      "rewards:  74.0 q-value:  0\n",
      "loss: [31911.3125]\n",
      "Exploring\n",
      "Selected action  [1 2]\n",
      "[1 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 79us/step - loss: 39901.7812\n",
      "rewards:  82.0 q-value:  0\n",
      "loss: [39901.78125]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 62us/step - loss: 60248.8438\n",
      "rewards:  75.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [60248.84375]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 85us/step - loss: 23659.0000\n",
      "rewards:  73.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [23659.0]\n",
      "Exploring\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 75us/step - loss: 55553.2812\n",
      "rewards:  71.0 q-value:  0\n",
      "loss: [55553.28125]\n",
      "Exploring\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 71us/step - loss: 20672.2188\n",
      "rewards:  71.0 q-value:  0\n",
      "loss: [20672.21875]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 86us/step - loss: 40670.7812\n",
      "rewards:  64.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [40670.78125]\n",
      "Exploring\n",
      "Selected action  [3 2]\n",
      "[3 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 93us/step - loss: 37773.2812\n",
      "rewards:  72.0 q-value:  0\n",
      "loss: [37773.28125]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 98us/step - loss: 44746.1562\n",
      "rewards:  70.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [44746.15625]\n",
      "Exploring\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 93us/step - loss: 50635.6562\n",
      "rewards:  90.0 q-value:  0\n",
      "loss: [50635.65625]\n",
      "Exploring\n",
      "Selected action  [3 1]\n",
      "[3 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 83us/step - loss: 62523.5938\n",
      "rewards:  94.0 q-value:  0\n",
      "loss: [62523.59375]\n",
      "Exploring\n",
      "Selected action  [0 4]\n",
      "[0 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 121us/step - loss: 49345.7500\n",
      "rewards:  53.0 q-value:  0\n",
      "loss: [49345.75]\n",
      "Exploring\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 66us/step - loss: 25331.0625\n",
      "rewards:  84.0 q-value:  0\n",
      "loss: [25331.0625]\n",
      "Exploring\n",
      "Selected action  [1 2]\n",
      "[1 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 89us/step - loss: 42882.4688\n",
      "rewards:  104.0 q-value:  0\n",
      "loss: [42882.46875]\n",
      "Exploring\n",
      "Selected action  [3 2]\n",
      "[3 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 75us/step - loss: 17811.3125\n",
      "rewards:  98.0 q-value:  0\n",
      "loss: [17811.3125]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 93us/step - loss: 56152.9375\n",
      "rewards:  96.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [56152.9375]\n",
      "Exploring\n",
      "Selected action  [4 3]\n",
      "[4 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 100us/step - loss: 17478.1562\n",
      "rewards:  120.0 q-value:  0\n",
      "loss: [17478.15625]\n",
      "Number of actions available 7\n",
      "Episode : 28\n",
      "Exploiting\n",
      "Selected action  [1 4]\n",
      "[1 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 88us/step - loss: 54124.5938\n",
      "rewards:  -12.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [54124.59375]\n",
      "Exploiting\n",
      "Selected action  [4 0]\n",
      "[4 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 80us/step - loss: 47819.9062\n",
      "rewards:  -8.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [47819.90625]\n",
      "Exploiting\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 69us/step - loss: 50760.5938\n",
      "rewards:  -13.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [50760.59375]\n",
      "Exploring\n",
      "Selected action  [1 4]\n",
      "[1 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 80us/step - loss: 21764.7188\n",
      "rewards:  -15.0 q-value:  0\n",
      "loss: [21764.71875]\n",
      "Exploiting\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 81us/step - loss: 57570.3750\n",
      "rewards:  -20.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [57570.375]\n",
      "Exploiting\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 76us/step - loss: 51881.4062\n",
      "rewards:  -25.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [51881.40625]\n",
      "Exploring\n",
      "Selected action  [0 2]\n",
      "[0 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 84us/step - loss: 44033.4375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rewards:  -13.0 q-value:  0\n",
      "loss: [44033.4375]\n",
      "Exploring\n",
      "Selected action  [0 4]\n",
      "[0 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 89us/step - loss: 47028.4375\n",
      "rewards:  -24.0 q-value:  0\n",
      "loss: [47028.4375]\n",
      "Exploiting\n",
      "Selected action  [3 1]\n",
      "[3 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 92us/step - loss: 29849.4688\n",
      "rewards:  -39.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [29849.46875]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 81us/step - loss: 38531.7188\n",
      "rewards:  -44.0 q-value:  0\n",
      "loss: [38531.71875]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 105us/step - loss: 55951.5938\n",
      "rewards:  -49.0 q-value:  0\n",
      "loss: [55951.59375]\n",
      "Exploring\n",
      "Selected action  [4 2]\n",
      "[4 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 75us/step - loss: 44369.5938\n",
      "rewards:  -54.0 q-value:  0\n",
      "loss: [44369.59375]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 71us/step - loss: 57103.8750\n",
      "rewards:  -59.0 q-value:  0\n",
      "loss: [57103.875]\n",
      "Exploiting\n",
      "Selected action  [3 1]\n",
      "[3 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 127us/step - loss: 52490.4062\n",
      "rewards:  -59.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [52490.40625]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 87us/step - loss: 31728.6875\n",
      "rewards:  -64.0 q-value:  0\n",
      "loss: [31728.6875]\n",
      "Exploring\n",
      "Selected action  [3 1]\n",
      "[3 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 73us/step - loss: 55912.5938\n",
      "rewards:  -64.0 q-value:  0\n",
      "loss: [55912.59375]\n",
      "Exploiting\n",
      "Selected action  [4 2]\n",
      "[4 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 94us/step - loss: 32344.6250\n",
      "rewards:  -74.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [32344.625]\n",
      "Exploiting\n",
      "Selected action  [4 2]\n",
      "[4 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 89us/step - loss: 24577.4062\n",
      "rewards:  -74.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [24577.40625]\n",
      "Exploring\n",
      "Selected action  [4 2]\n",
      "[4 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 113us/step - loss: 21639.1562\n",
      "rewards:  -74.0 q-value:  0\n",
      "loss: [21639.15625]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 70us/step - loss: 44001.4062\n",
      "rewards:  -79.0 q-value:  0\n",
      "loss: [44001.40625]\n",
      "Exploring\n",
      "Selected action  [4 0]\n",
      "[4 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 64us/step - loss: 29982.8438\n",
      "rewards:  -80.0 q-value:  0\n",
      "loss: [29982.84375]\n",
      "Exploring\n",
      "Selected action  [4 2]\n",
      "[4 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 77us/step - loss: 35746.5312\n",
      "rewards:  -112.0 q-value:  0\n",
      "loss: [35746.53125]\n",
      "Exploring\n",
      "Selected action  [0 2]\n",
      "[0 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 74us/step - loss: 36694.1562\n",
      "rewards:  -117.0 q-value:  0\n",
      "loss: [36694.15625]\n",
      "Exploiting\n",
      "Selected action  [4 2]\n",
      "[4 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 82us/step - loss: 65939.3750\n",
      "rewards:  -118.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [65939.375]\n",
      "Exploring\n",
      "Selected action  [3 1]\n",
      "[3 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 81us/step - loss: 32110.5000\n",
      "rewards:  -128.0 q-value:  0\n",
      "loss: [32110.5]\n",
      "Exploring\n",
      "Selected action  [4 0]\n",
      "[4 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 86us/step - loss: 51294.2188\n",
      "rewards:  -139.0 q-value:  0\n",
      "loss: [51294.21875]\n",
      "Exploring\n",
      "Selected action  [1 4]\n",
      "[1 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 80us/step - loss: 42370.6875\n",
      "rewards:  -172.0 q-value:  0\n",
      "loss: [42370.6875]\n",
      "Exploring\n",
      "Selected action  [3 1]\n",
      "[3 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 85us/step - loss: 29280.5000\n",
      "rewards:  -203.0 q-value:  0\n",
      "loss: [29280.5]\n",
      "Exploring\n",
      "Selected action  [0 4]\n",
      "[0 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 81us/step - loss: 46103.1875\n",
      "rewards:  -211.0 q-value:  0\n",
      "loss: [46103.1875]\n",
      "Exploring\n",
      "Selected action  [3 1]\n",
      "[3 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 60us/step - loss: 39123.7188\n",
      "rewards:  -252.0 q-value:  0\n",
      "loss: [39123.71875]\n",
      "Exploring\n",
      "Selected action  [1 4]\n",
      "[1 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 114us/step - loss: 37005.4062\n",
      "rewards:  -252.0 q-value:  0\n",
      "loss: [37005.40625]\n",
      "Exploring\n",
      "Selected action  [1 4]\n",
      "[1 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 79us/step - loss: 66465.0938\n",
      "rewards:  -252.0 q-value:  0\n",
      "loss: [66465.09375]\n",
      "Exploring\n",
      "Selected action  [4 2]\n",
      "[4 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 86us/step - loss: 17587.2188\n",
      "rewards:  -244.0 q-value:  0\n",
      "loss: [17587.21875]\n",
      "Exploring\n",
      "Selected action  [4 0]\n",
      "[4 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 115us/step - loss: 75587.2812\n",
      "rewards:  -220.0 q-value:  0\n",
      "loss: [75587.28125]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 74us/step - loss: 50814.3438\n",
      "rewards:  -225.0 q-value:  0\n",
      "loss: [50814.34375]\n",
      "Exploiting\n",
      "Selected action  [4 0]\n",
      "[4 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 71us/step - loss: 83322.7812\n",
      "rewards:  -226.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [83322.78125]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 89us/step - loss: 41094.9688\n",
      "rewards:  -231.0 q-value:  0\n",
      "loss: [41094.96875]\n",
      "Exploring\n",
      "Selected action  [4 2]\n",
      "[4 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 96us/step - loss: 29634.7500\n",
      "rewards:  -236.0 q-value:  0\n",
      "loss: [29634.75]\n",
      "Exploring\n",
      "Selected action  [4 0]\n",
      "[4 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 95us/step - loss: 32202.2812\n",
      "rewards:  -232.0 q-value:  0\n",
      "loss: [32202.28125]\n",
      "Exploiting\n",
      "Selected action  [0 2]\n",
      "[0 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 89us/step - loss: 64006.0312\n",
      "rewards:  -208.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [64006.03125]\n",
      "Exploiting\n",
      "Selected action  [3 1]\n",
      "[3 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 89us/step - loss: 25900.3438\n",
      "rewards:  -225.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [25900.34375]\n",
      "Exploring\n",
      "Selected action  [1 4]\n",
      "[1 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 91us/step - loss: 38175.7500\n",
      "rewards:  -217.0 q-value:  0\n",
      "loss: [38175.75]\n",
      "Exploiting\n",
      "Selected action  [4 0]\n",
      "[4 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 74us/step - loss: 44134.5938\n",
      "rewards:  -213.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [44134.59375]\n",
      "Exploring\n",
      "Selected action  [4 2]\n",
      "[4 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 95us/step - loss: 87649.1250\n",
      "rewards:  -214.0 q-value:  0\n",
      "loss: [87649.125]\n",
      "Exploring\n",
      "Selected action  [0 4]\n",
      "[0 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 82us/step - loss: 40704.8750\n",
      "rewards:  -225.0 q-value:  0\n",
      "loss: [40704.875]\n",
      "Exploring\n",
      "Selected action  [1 4]\n",
      "[1 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 96us/step - loss: 57081.5625\n",
      "rewards:  -225.0 q-value:  0\n",
      "loss: [57081.5625]\n",
      "Exploiting\n",
      "Selected action  [4 0]\n",
      "[4 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 82us/step - loss: 38408.5312\n",
      "rewards:  -221.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [38408.53125]\n",
      "Exploiting\n",
      "Selected action  [3 1]\n",
      "[3 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 62us/step - loss: 59460.8125\n",
      "rewards:  -218.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [59460.8125]\n",
      "Exploiting\n",
      "Selected action  [0 4]\n",
      "[0 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 91us/step - loss: 71236.7812\n",
      "rewards:  -217.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [71236.78125]\n",
      "Exploring\n",
      "Selected action  [3 1]\n",
      "[3 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 70us/step - loss: 36435.6562\n",
      "rewards:  -219.0 q-value:  0\n",
      "loss: [36435.65625]\n",
      "Exploiting\n",
      "Selected action  [0 4]\n",
      "[0 4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 85us/step - loss: 66360.3438\n",
      "rewards:  -230.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [66360.34375]\n",
      "Exploiting\n",
      "Selected action  [4 2]\n",
      "[4 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 82us/step - loss: 47049.4688\n",
      "rewards:  -226.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [47049.46875]\n",
      "Exploring\n",
      "Selected action  [0 2]\n",
      "[0 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 79us/step - loss: 64587.9062\n",
      "rewards:  -231.0 q-value:  0\n",
      "loss: [64587.90625]\n",
      "Exploiting\n",
      "Selected action  [1 4]\n",
      "[1 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 96us/step - loss: 48039.8750\n",
      "rewards:  -223.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [48039.875]\n",
      "Exploring\n",
      "Selected action  [4 0]\n",
      "[4 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 86us/step - loss: 57105.0938\n",
      "rewards:  -219.0 q-value:  0\n",
      "loss: [57105.09375]\n",
      "Exploring\n",
      "Selected action  [0 4]\n",
      "[0 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 64us/step - loss: 28737.3438\n",
      "rewards:  -215.0 q-value:  0\n",
      "loss: [28737.34375]\n",
      "Exploiting\n",
      "Selected action  [0 4]\n",
      "[0 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 88us/step - loss: 33247.6875\n",
      "rewards:  -216.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [33247.6875]\n",
      "Exploring\n",
      "Selected action  [0 4]\n",
      "[0 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 81us/step - loss: 33137.3125\n",
      "rewards:  -217.0 q-value:  0\n",
      "loss: [33137.3125]\n",
      "Exploring\n",
      "Selected action  [4 0]\n",
      "[4 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 83us/step - loss: 40507.1562\n",
      "rewards:  -189.0 q-value:  0\n",
      "loss: [40507.15625]\n",
      "Exploring\n",
      "Selected action  [4 0]\n",
      "[4 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 95us/step - loss: 85241.9062\n",
      "rewards:  -189.0 q-value:  0\n",
      "loss: [85241.90625]\n",
      "Exploring\n",
      "Selected action  [4 2]\n",
      "[4 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 72us/step - loss: 59333.0312\n",
      "rewards:  -181.0 q-value:  0\n",
      "loss: [59333.03125]\n",
      "Exploring\n",
      "Selected action  [0 4]\n",
      "[0 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 85us/step - loss: 41158.9688\n",
      "rewards:  -196.0 q-value:  0\n",
      "loss: [41158.96875]\n",
      "Exploring\n",
      "Selected action  [4 2]\n",
      "[4 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 104us/step - loss: 39037.7812\n",
      "rewards:  -188.0 q-value:  0\n",
      "loss: [39037.78125]\n",
      "Exploring\n",
      "Selected action  [0 4]\n",
      "[0 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 71us/step - loss: 25109.7812\n",
      "rewards:  -203.0 q-value:  0\n",
      "loss: [25109.78125]\n",
      "Exploring\n",
      "Selected action  [3 1]\n",
      "[3 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 67us/step - loss: 64117.8438\n",
      "rewards:  -201.0 q-value:  0\n",
      "loss: [64117.84375]\n",
      "Exploring\n",
      "Selected action  [4 2]\n",
      "[4 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 85us/step - loss: 74754.2188\n",
      "rewards:  -211.0 q-value:  0\n",
      "loss: [74754.21875]\n",
      "Exploiting\n",
      "Selected action  [4 0]\n",
      "[4 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 122us/step - loss: 40814.2812\n",
      "rewards:  -216.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [40814.28125]\n",
      "Exploiting\n",
      "Selected action  [0 2]\n",
      "[0 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 76us/step - loss: 34258.5625\n",
      "rewards:  -208.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [34258.5625]\n",
      "Exploring\n",
      "Selected action  [3 1]\n",
      "[3 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 77us/step - loss: 56344.0312\n",
      "rewards:  -222.0 q-value:  0\n",
      "loss: [56344.03125]\n",
      "Exploring\n",
      "Selected action  [0 2]\n",
      "[0 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 77us/step - loss: 75299.7188\n",
      "rewards:  -212.0 q-value:  0\n",
      "loss: [75299.71875]\n",
      "Exploiting\n",
      "Selected action  [4 0]\n",
      "[4 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 89us/step - loss: 74361.7500\n",
      "rewards:  -213.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [74361.75]\n",
      "Exploiting\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 79us/step - loss: 47652.2812\n",
      "rewards:  -218.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [47652.28125]\n",
      "Exploring\n",
      "Selected action  [4 0]\n",
      "[4 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 77us/step - loss: 43726.2812\n",
      "rewards:  -219.0 q-value:  0\n",
      "loss: [43726.28125]\n",
      "Exploring\n",
      "Selected action  [1 4]\n",
      "[1 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 80us/step - loss: 23589.6875\n",
      "rewards:  -242.0 q-value:  0\n",
      "loss: [23589.6875]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 87us/step - loss: 32125.0938\n",
      "rewards:  -247.0 q-value:  0\n",
      "loss: [32125.09375]\n",
      "Exploring\n",
      "Selected action  [1 4]\n",
      "[1 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 89us/step - loss: 50075.1875\n",
      "rewards:  -270.0 q-value:  0\n",
      "loss: [50075.1875]\n",
      "Exploring\n",
      "Selected action  [4 0]\n",
      "[4 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 96us/step - loss: 74585.6875\n",
      "rewards:  -270.0 q-value:  0\n",
      "loss: [74585.6875]\n",
      "Exploring\n",
      "Selected action  [4 2]\n",
      "[4 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 75us/step - loss: 32331.0938\n",
      "rewards:  -238.0 q-value:  0\n",
      "loss: [32331.09375]\n",
      "Exploring\n",
      "Selected action  [4 2]\n",
      "[4 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 86us/step - loss: 54540.2812\n",
      "rewards:  -240.0 q-value:  0\n",
      "loss: [54540.28125]\n",
      "Exploiting\n",
      "Selected action  [0 4]\n",
      "[0 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 93us/step - loss: 75351.8125\n",
      "rewards:  -248.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [75351.8125]\n",
      "Exploring\n",
      "Selected action  [4 2]\n",
      "[4 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 90us/step - loss: 41833.8438\n",
      "rewards:  -248.0 q-value:  0\n",
      "loss: [41833.84375]\n",
      "Exploring\n",
      "Selected action  [3 1]\n",
      "[3 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 68us/step - loss: 58631.8750\n",
      "rewards:  -266.0 q-value:  0\n",
      "loss: [58631.875]\n",
      "Exploring\n",
      "Selected action  [1 4]\n",
      "[1 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 80us/step - loss: 39708.2188\n",
      "rewards:  -262.0 q-value:  0\n",
      "loss: [39708.21875]\n",
      "Exploring\n",
      "Selected action  [3 1]\n",
      "[3 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 67us/step - loss: 53180.7500\n",
      "rewards:  -256.0 q-value:  0\n",
      "loss: [53180.75]\n",
      "Exploiting\n",
      "Selected action  [4 2]\n",
      "[4 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 84us/step - loss: 27543.0000\n",
      "rewards:  -261.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [27543.0]\n",
      "Exploring\n",
      "Selected action  [0 4]\n",
      "[0 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 69us/step - loss: 44237.8750\n",
      "rewards:  -292.0 q-value:  0\n",
      "loss: [44237.875]\n",
      "Exploiting\n",
      "Selected action  [4 2]\n",
      "[4 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 84us/step - loss: 66327.3750\n",
      "rewards:  -260.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [66327.375]\n",
      "Exploring\n",
      "Selected action  [0 2]\n",
      "[0 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 78us/step - loss: 35411.3438\n",
      "rewards:  -264.0 q-value:  0\n",
      "loss: [35411.34375]\n",
      "Exploiting\n",
      "Selected action  [0 4]\n",
      "[0 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 76us/step - loss: 30630.6875\n",
      "rewards:  -285.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [30630.6875]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 78us/step - loss: 40515.2500\n",
      "rewards:  -290.0 q-value:  0\n",
      "loss: [40515.25]\n",
      "Exploiting\n",
      "Selected action  [4 2]\n",
      "[4 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 79us/step - loss: 60719.9062\n",
      "rewards:  -295.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [60719.90625]\n",
      "Exploring\n",
      "Selected action  [3 1]\n",
      "[3 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 58us/step - loss: 54706.2188\n",
      "rewards:  -312.0 q-value:  0\n",
      "loss: [54706.21875]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 78us/step - loss: 47081.2188\n",
      "rewards:  -317.0 q-value:  0\n",
      "loss: [47081.21875]\n",
      "Exploring\n",
      "Selected action  [4 0]\n",
      "[4 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 72us/step - loss: 74921.6562\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rewards:  -318.0 q-value:  0\n",
      "loss: [74921.65625]\n",
      "Exploring\n",
      "Selected action  [4 0]\n",
      "[4 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 80us/step - loss: 52000.1250\n",
      "rewards:  -319.0 q-value:  0\n",
      "loss: [52000.125]\n",
      "Exploring\n",
      "Selected action  [1 4]\n",
      "[1 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 84us/step - loss: 45468.0000\n",
      "rewards:  -331.0 q-value:  0\n",
      "loss: [45468.0]\n",
      "Exploring\n",
      "Selected action  [0 2]\n",
      "[0 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 70us/step - loss: 39008.8438\n",
      "rewards:  -308.0 q-value:  0\n",
      "loss: [39008.84375]\n",
      "Exploring\n",
      "Selected action  [0 4]\n",
      "[0 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 106us/step - loss: 24636.2500\n",
      "rewards:  -326.0 q-value:  0\n",
      "loss: [24636.25]\n",
      "Exploring\n",
      "Selected action  [4 0]\n",
      "[4 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 76us/step - loss: 37181.7500\n",
      "rewards:  -314.0 q-value:  0\n",
      "loss: [37181.75]\n",
      "Exploring\n",
      "Selected action  [1 4]\n",
      "[1 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 71us/step - loss: 37314.6250\n",
      "rewards:  -316.0 q-value:  0\n",
      "loss: [37314.625]\n",
      "Exploring\n",
      "Selected action  [0 2]\n",
      "[0 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 77us/step - loss: 33569.9688\n",
      "rewards:  -309.0 q-value:  0\n",
      "loss: [33569.96875]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 102us/step - loss: 44977.7812\n",
      "rewards:  -314.0 q-value:  0\n",
      "loss: [44977.78125]\n",
      "Exploring\n",
      "Selected action  [0 4]\n",
      "[0 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 91us/step - loss: 52684.1875\n",
      "rewards:  -282.0 q-value:  0\n",
      "loss: [52684.1875]\n",
      "Exploring\n",
      "Selected action  [1 4]\n",
      "[1 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 78us/step - loss: 42230.5312\n",
      "rewards:  -286.0 q-value:  0\n",
      "loss: [42230.53125]\n",
      "Exploring\n",
      "Selected action  [1 4]\n",
      "[1 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 87us/step - loss: 24575.3438\n",
      "rewards:  -289.0 q-value:  0\n",
      "loss: [24575.34375]\n",
      "Exploiting\n",
      "Selected action  [0 2]\n",
      "[0 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 67us/step - loss: 28927.6250\n",
      "rewards:  -270.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [28927.625]\n",
      "Exploiting\n",
      "Selected action  [0 2]\n",
      "[0 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 63us/step - loss: 44396.1250\n",
      "rewards:  -272.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [44396.125]\n",
      "Exploring\n",
      "Selected action  [3 1]\n",
      "[3 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 65us/step - loss: 40468.4062\n",
      "rewards:  -283.0 q-value:  0\n",
      "loss: [40468.40625]\n",
      "Exploring\n",
      "Selected action  [1 4]\n",
      "[1 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 81us/step - loss: 35857.8750\n",
      "rewards:  -267.0 q-value:  0\n",
      "loss: [35857.875]\n",
      "Exploiting\n",
      "Selected action  [0 4]\n",
      "[0 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 71us/step - loss: 41223.2188\n",
      "rewards:  -273.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [41223.21875]\n",
      "Exploring\n",
      "Selected action  [0 4]\n",
      "[0 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 78us/step - loss: 42154.3750\n",
      "rewards:  -274.0 q-value:  0\n",
      "loss: [42154.375]\n",
      "Exploiting\n",
      "Selected action  [4 0]\n",
      "[4 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 79us/step - loss: 54606.4375\n",
      "rewards:  -270.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [54606.4375]\n",
      "Exploring\n",
      "Selected action  [4 2]\n",
      "[4 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 84us/step - loss: 60635.5625\n",
      "rewards:  -255.0 q-value:  0\n",
      "loss: [60635.5625]\n",
      "Exploring\n",
      "Selected action  [0 2]\n",
      "[0 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 72us/step - loss: 64502.5938\n",
      "rewards:  -258.0 q-value:  0\n",
      "loss: [64502.59375]\n",
      "Exploring\n",
      "Selected action  [3 1]\n",
      "[3 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 78us/step - loss: 46017.3750\n",
      "rewards:  -265.0 q-value:  0\n",
      "loss: [46017.375]\n",
      "Exploring\n",
      "Selected action  [4 0]\n",
      "[4 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 78us/step - loss: 42373.0000\n",
      "rewards:  -261.0 q-value:  0\n",
      "loss: [42373.0]\n",
      "Exploiting\n",
      "Selected action  [3 1]\n",
      "[3 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 76us/step - loss: 46480.6250\n",
      "rewards:  -258.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [46480.625]\n",
      "Exploring\n",
      "Selected action  [0 2]\n",
      "[0 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 81us/step - loss: 48632.8438\n",
      "rewards:  -265.0 q-value:  0\n",
      "loss: [48632.84375]\n",
      "Exploring\n",
      "Selected action  [1 4]\n",
      "[1 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 81us/step - loss: 61137.8125\n",
      "rewards:  -320.0 q-value:  0\n",
      "loss: [61137.8125]\n",
      "Exploring\n",
      "Selected action  [0 4]\n",
      "[0 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 77us/step - loss: 46152.7812\n",
      "rewards:  -324.0 q-value:  0\n",
      "loss: [46152.78125]\n",
      "Exploiting\n",
      "Selected action  [4 2]\n",
      "[4 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 91us/step - loss: 52349.5000\n",
      "rewards:  -320.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [52349.5]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 94us/step - loss: 32393.3438\n",
      "rewards:  -325.0 q-value:  0\n",
      "loss: [32393.34375]\n",
      "Exploring\n",
      "Selected action  [4 0]\n",
      "[4 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 101us/step - loss: 90523.6562\n",
      "rewards:  -326.0 q-value:  0\n",
      "loss: [90523.65625]\n",
      "Exploring\n",
      "Selected action  [4 2]\n",
      "[4 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 82us/step - loss: 51566.4062\n",
      "rewards:  -327.0 q-value:  0\n",
      "loss: [51566.40625]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 95us/step - loss: 58620.1562\n",
      "rewards:  -332.0 q-value:  0\n",
      "loss: [58620.15625]\n",
      "Exploiting\n",
      "Selected action  [1 4]\n",
      "[1 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 78us/step - loss: 58129.3750\n",
      "rewards:  -331.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [58129.375]\n",
      "Exploiting\n",
      "Selected action  [3 1]\n",
      "[3 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 80us/step - loss: 55854.5938\n",
      "rewards:  -353.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [55854.59375]\n",
      "Exploring\n",
      "Selected action  [1 4]\n",
      "[1 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 92us/step - loss: 33634.7500\n",
      "rewards:  -325.0 q-value:  0\n",
      "loss: [33634.75]\n",
      "Exploring\n",
      "Selected action  [0 4]\n",
      "[0 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 77us/step - loss: 29192.9375\n",
      "rewards:  -332.0 q-value:  0\n",
      "loss: [29192.9375]\n",
      "Exploring\n",
      "Selected action  [4 0]\n",
      "[4 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 76us/step - loss: 41039.4375\n",
      "rewards:  -332.0 q-value:  0\n",
      "loss: [41039.4375]\n",
      "Exploiting\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 78us/step - loss: 57442.1875\n",
      "rewards:  -337.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [57442.1875]\n",
      "Exploiting\n",
      "Selected action  [3 1]\n",
      "[3 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 72us/step - loss: 61141.6875\n",
      "rewards:  -350.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [61141.6875]\n",
      "Exploring\n",
      "Selected action  [0 2]\n",
      "[0 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 79us/step - loss: 35383.5312\n",
      "rewards:  -363.0 q-value:  0\n",
      "loss: [35383.53125]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 64us/step - loss: 47251.5625\n",
      "rewards:  -368.0 q-value:  0\n",
      "loss: [47251.5625]\n",
      "Exploring\n",
      "Selected action  [1 4]\n",
      "[1 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 89us/step - loss: 34234.3750\n",
      "rewards:  -379.0 q-value:  0\n",
      "loss: [34234.375]\n",
      "Exploring\n",
      "Selected action  [0 4]\n",
      "[0 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 83us/step - loss: 60288.5938\n",
      "rewards:  -379.0 q-value:  0\n",
      "loss: [60288.59375]\n",
      "Exploring\n",
      "Selected action  [0 2]\n",
      "[0 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 74us/step - loss: 75958.4688\n",
      "rewards:  -371.0 q-value:  0\n",
      "loss: [75958.46875]\n",
      "Exploring\n",
      "Selected action  [4 2]\n",
      "[4 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 83us/step - loss: 57918.5938\n",
      "rewards:  -372.0 q-value:  0\n",
      "loss: [57918.59375]\n",
      "Exploiting\n",
      "Selected action  [4 2]\n",
      "[4 2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 73us/step - loss: 56353.9062\n",
      "rewards:  -373.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [56353.90625]\n",
      "Exploring\n",
      "Selected action  [4 0]\n",
      "[4 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 80us/step - loss: 76096.2500\n",
      "rewards:  -378.0 q-value:  0\n",
      "loss: [76096.25]\n",
      "Exploring\n",
      "Selected action  [1 4]\n",
      "[1 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 95us/step - loss: 34384.0625\n",
      "rewards:  -398.0 q-value:  0\n",
      "loss: [34384.0625]\n",
      "Exploring\n",
      "Selected action  [4 0]\n",
      "[4 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 82us/step - loss: 48393.2188\n",
      "rewards:  -398.0 q-value:  0\n",
      "loss: [48393.21875]\n",
      "Exploring\n",
      "Selected action  [0 4]\n",
      "[0 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 90us/step - loss: 39767.2812\n",
      "rewards:  -398.0 q-value:  0\n",
      "loss: [39767.28125]\n",
      "Exploring\n",
      "Selected action  [0 4]\n",
      "[0 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 81us/step - loss: 36991.9062\n",
      "rewards:  -398.0 q-value:  0\n",
      "loss: [36991.90625]\n",
      "Exploring\n",
      "Selected action  [4 0]\n",
      "[4 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 77us/step - loss: 44770.5312\n",
      "rewards:  -398.0 q-value:  0\n",
      "loss: [44770.53125]\n",
      "Exploiting\n",
      "Selected action  [4 0]\n",
      "[4 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 74us/step - loss: 76856.2188\n",
      "rewards:  -398.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [76856.21875]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 79us/step - loss: 51018.2188\n",
      "rewards:  -403.0 q-value:  0\n",
      "loss: [51018.21875]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 84us/step - loss: 61791.0938\n",
      "rewards:  -408.0 q-value:  0\n",
      "loss: [61791.09375]\n",
      "Exploring\n",
      "Selected action  [0 2]\n",
      "[0 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 78us/step - loss: 79743.9688\n",
      "rewards:  -400.0 q-value:  0\n",
      "loss: [79743.96875]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 73us/step - loss: 73540.7500\n",
      "rewards:  -405.0 q-value:  0\n",
      "loss: [73540.75]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 104us/step - loss: 72870.7500\n",
      "rewards:  -410.0 q-value:  0\n",
      "loss: [72870.75]\n",
      "Exploring\n",
      "Selected action  [0 4]\n",
      "[0 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 83us/step - loss: 48344.5312\n",
      "rewards:  -386.0 q-value:  0\n",
      "loss: [48344.53125]\n",
      "Exploring\n",
      "Selected action  [0 4]\n",
      "[0 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 100us/step - loss: 34816.1250\n",
      "rewards:  -387.0 q-value:  0\n",
      "loss: [34816.125]\n",
      "Exploring\n",
      "Selected action  [1 4]\n",
      "[1 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 90us/step - loss: 76078.2188\n",
      "rewards:  -390.0 q-value:  0\n",
      "loss: [76078.21875]\n",
      "Exploring\n",
      "Selected action  [4 0]\n",
      "[4 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 72us/step - loss: 85356.0938\n",
      "rewards:  -386.0 q-value:  0\n",
      "loss: [85356.09375]\n",
      "Exploring\n",
      "Selected action  [3 1]\n",
      "[3 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 70us/step - loss: 37751.6875\n",
      "rewards:  -379.0 q-value:  0\n",
      "loss: [37751.6875]\n",
      "Exploiting\n",
      "Selected action  [0 4]\n",
      "[0 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 73us/step - loss: 31985.5938\n",
      "rewards:  -419.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [31985.59375]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 93us/step - loss: 41439.3125\n",
      "rewards:  -424.0 q-value:  0\n",
      "loss: [41439.3125]\n",
      "Exploring\n",
      "Selected action  [3 1]\n",
      "[3 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 76us/step - loss: 38845.4062\n",
      "rewards:  -417.0 q-value:  0\n",
      "loss: [38845.40625]\n",
      "Exploring\n",
      "Selected action  [3 1]\n",
      "[3 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 87us/step - loss: 42204.8438\n",
      "rewards:  -418.0 q-value:  0\n",
      "loss: [42204.84375]\n",
      "Exploring\n",
      "Selected action  [4 2]\n",
      "[4 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 79us/step - loss: 41318.7188\n",
      "rewards:  -420.0 q-value:  0\n",
      "loss: [41318.71875]\n",
      "Exploiting\n",
      "Selected action  [4 2]\n",
      "[4 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 91us/step - loss: 31458.0625\n",
      "rewards:  -422.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [31458.0625]\n",
      "Exploring\n",
      "Selected action  [4 0]\n",
      "[4 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 76us/step - loss: 60725.9062\n",
      "rewards:  -416.0 q-value:  0\n",
      "loss: [60725.90625]\n",
      "Exploring\n",
      "Selected action  [1 4]\n",
      "[1 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 61us/step - loss: 51642.2812\n",
      "rewards:  -451.0 q-value:  0\n",
      "loss: [51642.28125]\n",
      "Exploring\n",
      "Selected action  [4 0]\n",
      "[4 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 76us/step - loss: 50013.5625\n",
      "rewards:  -439.0 q-value:  0\n",
      "loss: [50013.5625]\n",
      "Exploring\n",
      "Selected action  [0 4]\n",
      "[0 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 87us/step - loss: 64256.5938\n",
      "rewards:  -435.0 q-value:  0\n",
      "loss: [64256.59375]\n",
      "Exploring\n",
      "Selected action  [0 4]\n",
      "[0 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 73us/step - loss: 44161.1250\n",
      "rewards:  -436.0 q-value:  0\n",
      "loss: [44161.125]\n",
      "Exploiting\n",
      "Selected action  [4 0]\n",
      "[4 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 78us/step - loss: 46027.6250\n",
      "rewards:  -432.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [46027.625]\n",
      "Exploring\n",
      "Selected action  [3 1]\n",
      "[3 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 93us/step - loss: 38856.5312\n",
      "rewards:  -436.0 q-value:  0\n",
      "loss: [38856.53125]\n",
      "Exploiting\n",
      "Selected action  [0 2]\n",
      "[0 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 67us/step - loss: 36188.3438\n",
      "rewards:  -433.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [36188.34375]\n",
      "Exploring\n",
      "Selected action  [0 2]\n",
      "[0 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 89us/step - loss: 34467.2188\n",
      "rewards:  -437.0 q-value:  0\n",
      "loss: [34467.21875]\n",
      "Exploring\n",
      "Selected action  [4 2]\n",
      "[4 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 84us/step - loss: 87885.4375\n",
      "rewards:  -437.0 q-value:  0\n",
      "loss: [87885.4375]\n",
      "Exploring\n",
      "Selected action  [0 4]\n",
      "[0 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 68us/step - loss: 57631.9062\n",
      "rewards:  -458.0 q-value:  0\n",
      "loss: [57631.90625]\n",
      "Exploring\n",
      "Selected action  [3 1]\n",
      "[3 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 62us/step - loss: 60326.2500\n",
      "rewards:  -480.0 q-value:  0\n",
      "loss: [60326.25]\n",
      "Exploiting\n",
      "Selected action  [0 4]\n",
      "[0 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 60us/step - loss: 55789.3125\n",
      "rewards:  -496.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [55789.3125]\n",
      "Exploring\n",
      "Selected action  [0 4]\n",
      "[0 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 67us/step - loss: 58787.0312\n",
      "rewards:  -497.0 q-value:  0\n",
      "loss: [58787.03125]\n",
      "Exploring\n",
      "Selected action  [3 1]\n",
      "[3 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 81us/step - loss: 48024.6250\n",
      "rewards:  -519.0 q-value:  0\n",
      "loss: [48024.625]\n",
      "Number of actions available 6\n",
      "Episode : 29\n",
      "Exploring\n",
      "Selected action  [4 0]\n",
      "[4 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 73us/step - loss: 74613.9688\n",
      "rewards:  -6.0 q-value:  0\n",
      "loss: [74613.96875]\n",
      "Exploring\n",
      "Selected action  [4 3]\n",
      "[4 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 88us/step - loss: 56300.6250\n",
      "rewards:  -3.0 q-value:  0\n",
      "loss: [56300.625]\n",
      "Exploiting\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 75us/step - loss: 70066.4062\n",
      "rewards:  1.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [70066.40625]\n",
      "Exploring\n",
      "Selected action  [4 3]\n",
      "[4 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 84us/step - loss: 59970.8750\n",
      "rewards:  8.0 q-value:  0\n",
      "loss: [59970.875]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 71us/step - loss: 24932.9375\n",
      "rewards:  3.0 q-value:  0\n",
      "loss: [24932.9375]\n",
      "Exploiting\n",
      "Selected action  [4 3]\n",
      "[4 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 81us/step - loss: 111435.2500\n",
      "rewards:  10.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [111435.25]\n",
      "Exploring\n",
      "Selected action  [0 4]\n",
      "[0 4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 65us/step - loss: 38622.1250\n",
      "rewards:  27.0 q-value:  0\n",
      "loss: [38622.125]\n",
      "Exploiting\n",
      "Selected action  [4 3]\n",
      "[4 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 77us/step - loss: 70217.8750\n",
      "rewards:  35.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [70217.875]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 147us/step - loss: 66261.3750\n",
      "rewards:  9.0 q-value:  0\n",
      "loss: [66261.375]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 60us/step - loss: 33436.1250\n",
      "rewards:  8.0 q-value:  0\n",
      "loss: [33436.125]\n",
      "Exploiting\n",
      "Selected action  [4 0]\n",
      "[4 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 103us/step - loss: 36255.2500\n",
      "rewards:  12.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [36255.25]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 79us/step - loss: 79304.8750\n",
      "rewards:  6.0 q-value:  0\n",
      "loss: [79304.875]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 84us/step - loss: 46050.0938\n",
      "rewards:  1.0 q-value:  0\n",
      "loss: [46050.09375]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 65us/step - loss: 21216.3438\n",
      "rewards:  -3.0 q-value:  0\n",
      "loss: [21216.34375]\n",
      "Exploring\n",
      "Selected action  [0 4]\n",
      "[0 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 87us/step - loss: 32823.5312\n",
      "rewards:  9.0 q-value:  0\n",
      "loss: [32823.53125]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 73us/step - loss: 24858.2500\n",
      "rewards:  4.0 q-value:  0\n",
      "loss: [24858.25]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 65us/step - loss: 41913.8125\n",
      "rewards:  -26.0 q-value:  0\n",
      "loss: [41913.8125]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 78us/step - loss: 77416.8125\n",
      "rewards:  -38.0 q-value:  0\n",
      "loss: [77416.8125]\n",
      "Exploring\n",
      "Selected action  [4 3]\n",
      "[4 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 75us/step - loss: 34535.4375\n",
      "rewards:  -48.0 q-value:  0\n",
      "loss: [34535.4375]\n",
      "Exploring\n",
      "Selected action  [4 3]\n",
      "[4 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 78us/step - loss: 76388.9688\n",
      "rewards:  -53.0 q-value:  0\n",
      "loss: [76388.96875]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 65us/step - loss: 58032.7812\n",
      "rewards:  -58.0 q-value:  0\n",
      "loss: [58032.78125]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 67us/step - loss: 43688.4375\n",
      "rewards:  -68.0 q-value:  0\n",
      "loss: [43688.4375]\n",
      "Exploring\n",
      "Selected action  [0 4]\n",
      "[0 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 67us/step - loss: 83395.6562\n",
      "rewards:  -69.0 q-value:  0\n",
      "loss: [83395.65625]\n",
      "Exploring\n",
      "Selected action  [4 0]\n",
      "[4 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 84us/step - loss: 46134.8438\n",
      "rewards:  -65.0 q-value:  0\n",
      "loss: [46134.84375]\n",
      "Exploring\n",
      "Selected action  [0 4]\n",
      "[0 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 68us/step - loss: 58352.7500\n",
      "rewards:  -61.0 q-value:  0\n",
      "loss: [58352.75]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 77us/step - loss: 33342.4062\n",
      "rewards:  -66.0 q-value:  0\n",
      "loss: [33342.40625]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 105us/step - loss: 46073.4688\n",
      "rewards:  -73.0 q-value:  0\n",
      "loss: [46073.46875]\n",
      "Exploiting\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 80us/step - loss: 35513.7500\n",
      "rewards:  -78.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [35513.75]\n",
      "Exploring\n",
      "Selected action  [4 3]\n",
      "[4 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 96us/step - loss: 68523.4688\n",
      "rewards:  -90.0 q-value:  0\n",
      "loss: [68523.46875]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 87us/step - loss: 70555.3438\n",
      "rewards:  -103.0 q-value:  0\n",
      "loss: [70555.34375]\n",
      "Exploring\n",
      "Selected action  [4 3]\n",
      "[4 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 80us/step - loss: 29412.3125\n",
      "rewards:  -104.0 q-value:  0\n",
      "loss: [29412.3125]\n",
      "Exploiting\n",
      "Selected action  [4 3]\n",
      "[4 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 87us/step - loss: 42330.1875\n",
      "rewards:  -105.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [42330.1875]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 99us/step - loss: 43351.7812\n",
      "rewards:  -104.0 q-value:  0\n",
      "loss: [43351.78125]\n",
      "Exploring\n",
      "Selected action  [4 0]\n",
      "[4 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 76us/step - loss: 54993.6875\n",
      "rewards:  -92.0 q-value:  0\n",
      "loss: [54993.6875]\n",
      "Exploring\n",
      "Selected action  [0 4]\n",
      "[0 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 72us/step - loss: 27910.6562\n",
      "rewards:  -88.0 q-value:  0\n",
      "loss: [27910.65625]\n",
      "Exploiting\n",
      "Selected action  [0 4]\n",
      "[0 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 60us/step - loss: 31449.5938\n",
      "rewards:  -89.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [31449.59375]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 87us/step - loss: 30543.6562\n",
      "rewards:  -91.0 q-value:  0\n",
      "loss: [30543.65625]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 86us/step - loss: 51928.6562\n",
      "rewards:  -67.0 q-value:  0\n",
      "loss: [51928.65625]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 81us/step - loss: 27321.5000\n",
      "rewards:  -72.0 q-value:  0\n",
      "loss: [27321.5]\n",
      "Exploiting\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 84us/step - loss: 29859.9062\n",
      "rewards:  -77.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [29859.90625]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 89us/step - loss: 77926.1562\n",
      "rewards:  -82.0 q-value:  0\n",
      "loss: [77926.15625]\n",
      "Exploiting\n",
      "Selected action  [0 4]\n",
      "[0 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 114us/step - loss: 50256.0000\n",
      "rewards:  -54.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [50256.0]\n",
      "Exploiting\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 89us/step - loss: 43777.3438\n",
      "rewards:  -56.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [43777.34375]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 66us/step - loss: 33795.8750\n",
      "rewards:  -60.0 q-value:  0\n",
      "loss: [33795.875]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 59us/step - loss: 73617.7500\n",
      "rewards:  -65.0 q-value:  0\n",
      "loss: [73617.75]\n",
      "Exploring\n",
      "Selected action  [4 3]\n",
      "[4 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 92us/step - loss: 67443.6562\n",
      "rewards:  -41.0 q-value:  0\n",
      "loss: [67443.65625]\n",
      "Exploring\n",
      "Selected action  [0 4]\n",
      "[0 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 70us/step - loss: 64847.5000\n",
      "rewards:  -32.0 q-value:  0\n",
      "loss: [64847.5]\n",
      "Exploring\n",
      "Selected action  [0 4]\n",
      "[0 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 92us/step - loss: 40313.8438\n",
      "rewards:  -33.0 q-value:  0\n",
      "loss: [40313.84375]\n",
      "Exploiting\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 83us/step - loss: 30827.0625\n",
      "rewards:  -38.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [30827.0625]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 72us/step - loss: 59081.4688\n",
      "rewards:  -43.0 q-value:  0\n",
      "loss: [59081.46875]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 63us/step - loss: 30041.7812\n",
      "rewards:  -48.0 q-value:  0\n",
      "loss: [30041.78125]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 63us/step - loss: 72552.4688\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rewards:  -53.0 q-value:  0\n",
      "loss: [72552.46875]\n",
      "Exploring\n",
      "Selected action  [4 3]\n",
      "[4 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 63us/step - loss: 74295.3438\n",
      "rewards:  -33.0 q-value:  0\n",
      "loss: [74295.34375]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 89us/step - loss: 48103.0000\n",
      "rewards:  -16.0 q-value:  0\n",
      "loss: [48103.0]\n",
      "Exploring\n",
      "Selected action  [4 0]\n",
      "[4 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 72us/step - loss: 34793.7500\n",
      "rewards:  -19.0 q-value:  0\n",
      "loss: [34793.75]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 72us/step - loss: 55645.0000\n",
      "rewards:  -24.0 q-value:  0\n",
      "loss: [55645.0]\n",
      "Exploring\n",
      "Selected action  [4 3]\n",
      "[4 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 74us/step - loss: 62713.8125\n",
      "rewards:  -23.0 q-value:  0\n",
      "loss: [62713.8125]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 94us/step - loss: 36093.5312\n",
      "rewards:  -78.0 q-value:  0\n",
      "loss: [36093.53125]\n",
      "Exploring\n",
      "Selected action  [4 0]\n",
      "[4 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 70us/step - loss: 65071.6250\n",
      "rewards:  -74.0 q-value:  0\n",
      "loss: [65071.625]\n",
      "Exploring\n",
      "Selected action  [0 4]\n",
      "[0 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 75us/step - loss: 41786.7812\n",
      "rewards:  -70.0 q-value:  0\n",
      "loss: [41786.78125]\n",
      "Exploring\n",
      "Selected action  [4 3]\n",
      "[4 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 75us/step - loss: 93768.6875\n",
      "rewards:  -62.0 q-value:  0\n",
      "loss: [93768.6875]\n",
      "Exploiting\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 82us/step - loss: 40904.2188\n",
      "rewards:  -67.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [40904.21875]\n",
      "Exploring\n",
      "Selected action  [4 3]\n",
      "[4 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 81us/step - loss: 51463.6250\n",
      "rewards:  -51.0 q-value:  0\n",
      "loss: [51463.625]\n",
      "Exploring\n",
      "Selected action  [4 3]\n",
      "[4 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 78us/step - loss: 37281.9062\n",
      "rewards:  -55.0 q-value:  0\n",
      "loss: [37281.90625]\n",
      "Exploring\n",
      "Selected action  [4 3]\n",
      "[4 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 71us/step - loss: 78463.9688\n",
      "rewards:  -61.0 q-value:  0\n",
      "loss: [78463.96875]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 83us/step - loss: 92888.8750\n",
      "rewards:  -66.0 q-value:  0\n",
      "loss: [92888.875]\n",
      "Exploring\n",
      "Selected action  [0 4]\n",
      "[0 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 92us/step - loss: 46830.0938\n",
      "rewards:  -62.0 q-value:  0\n",
      "loss: [46830.09375]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 66us/step - loss: 60685.2188\n",
      "rewards:  -56.0 q-value:  0\n",
      "loss: [60685.21875]\n",
      "Exploring\n",
      "Selected action  [0 4]\n",
      "[0 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 73us/step - loss: 41441.6250\n",
      "rewards:  -52.0 q-value:  0\n",
      "loss: [41441.625]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 70us/step - loss: 28726.0625\n",
      "rewards:  -57.0 q-value:  0\n",
      "loss: [28726.0625]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 70us/step - loss: 87386.1875\n",
      "rewards:  -68.0 q-value:  0\n",
      "loss: [87386.1875]\n",
      "Exploring\n",
      "Selected action  [4 3]\n",
      "[4 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 71us/step - loss: 38045.0000\n",
      "rewards:  -61.0 q-value:  0\n",
      "loss: [38045.0]\n",
      "Exploring\n",
      "Selected action  [4 3]\n",
      "[4 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 81us/step - loss: 37344.5312\n",
      "rewards:  -64.0 q-value:  0\n",
      "loss: [37344.53125]\n",
      "Exploiting\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 79us/step - loss: 25076.5000\n",
      "rewards:  -69.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [25076.5]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 82us/step - loss: 19792.9688\n",
      "rewards:  -71.0 q-value:  0\n",
      "loss: [19792.96875]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 83us/step - loss: 46765.2812\n",
      "rewards:  -88.0 q-value:  0\n",
      "loss: [46765.28125]\n",
      "Exploiting\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 76us/step - loss: 32939.0625\n",
      "rewards:  -93.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [32939.0625]\n",
      "Exploiting\n",
      "Selected action  [4 0]\n",
      "[4 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 93us/step - loss: 65302.8125\n",
      "rewards:  -101.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [65302.8125]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 77us/step - loss: 41058.5938\n",
      "rewards:  -106.0 q-value:  0\n",
      "loss: [41058.59375]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 80us/step - loss: 35026.2500\n",
      "rewards:  -115.0 q-value:  0\n",
      "loss: [35026.25]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 73us/step - loss: 44413.2812\n",
      "rewards:  -120.0 q-value:  0\n",
      "loss: [44413.28125]\n",
      "Exploring\n",
      "Selected action  [4 3]\n",
      "[4 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 77us/step - loss: 47338.5625\n",
      "rewards:  -99.0 q-value:  0\n",
      "loss: [47338.5625]\n",
      "Exploring\n",
      "Selected action  [0 4]\n",
      "[0 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 70us/step - loss: 39262.2188\n",
      "rewards:  -125.0 q-value:  0\n",
      "loss: [39262.21875]\n",
      "Exploiting\n",
      "Selected action  [4 3]\n",
      "[4 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 79us/step - loss: 34986.0938\n",
      "rewards:  -105.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [34986.09375]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 103us/step - loss: 49556.2188\n",
      "rewards:  -110.0 q-value:  0\n",
      "loss: [49556.21875]\n",
      "Exploring\n",
      "Selected action  [4 3]\n",
      "[4 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 64us/step - loss: 41845.1875\n",
      "rewards:  -87.0 q-value:  0\n",
      "loss: [41845.1875]\n",
      "Exploring\n",
      "Selected action  [0 4]\n",
      "[0 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 92us/step - loss: 29280.1562\n",
      "rewards:  -88.0 q-value:  0\n",
      "loss: [29280.15625]\n",
      "Exploring\n",
      "Selected action  [4 3]\n",
      "[4 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 95us/step - loss: 60527.0625\n",
      "rewards:  -64.0 q-value:  0\n",
      "loss: [60527.0625]\n",
      "Exploiting\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 110us/step - loss: 47116.0938\n",
      "rewards:  -69.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [47116.09375]\n",
      "Exploiting\n",
      "Selected action  [4 3]\n",
      "[4 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 73us/step - loss: 61709.0000\n",
      "rewards:  -81.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [61709.0]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 82us/step - loss: 28023.5000\n",
      "rewards:  -93.0 q-value:  0\n",
      "loss: [28023.5]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 68us/step - loss: 49903.2812\n",
      "rewards:  -101.0 q-value:  0\n",
      "loss: [49903.28125]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 82us/step - loss: 68376.4062\n",
      "rewards:  -122.0 q-value:  0\n",
      "loss: [68376.40625]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 83us/step - loss: 40351.5625\n",
      "rewards:  -127.0 q-value:  0\n",
      "loss: [40351.5625]\n",
      "Exploring\n",
      "Selected action  [0 4]\n",
      "[0 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 72us/step - loss: 39860.6562\n",
      "rewards:  -123.0 q-value:  0\n",
      "loss: [39860.65625]\n",
      "Exploiting\n",
      "Selected action  [4 3]\n",
      "[4 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 69us/step - loss: 66597.5312\n",
      "rewards:  -99.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [66597.53125]\n",
      "Exploiting\n",
      "Selected action  [4 3]\n",
      "[4 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 86us/step - loss: 34753.4688\n",
      "rewards:  -105.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [34753.46875]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 80us/step - loss: 54063.5312\n",
      "rewards:  -117.0 q-value:  0\n",
      "loss: [54063.53125]\n",
      "Exploring\n",
      "Selected action  [4 0]\n",
      "[4 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 70us/step - loss: 28948.7812\n",
      "rewards:  -89.0 q-value:  0\n",
      "loss: [28948.78125]\n",
      "Exploiting\n",
      "Selected action  [0 4]\n",
      "[0 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 82us/step - loss: 59349.2500\n",
      "rewards:  -89.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [59349.25]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 86us/step - loss: 84655.5938\n",
      "rewards:  -94.0 q-value:  0\n",
      "loss: [84655.59375]\n",
      "Exploiting\n",
      "Selected action  [4 0]\n",
      "[4 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 124us/step - loss: 71641.4688\n",
      "rewards:  -94.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [71641.46875]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 107us/step - loss: 56187.8125\n",
      "rewards:  -101.0 q-value:  0\n",
      "loss: [56187.8125]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 71us/step - loss: 54886.7500\n",
      "rewards:  -103.0 q-value:  0\n",
      "loss: [54886.75]\n",
      "Exploring\n",
      "Selected action  [4 3]\n",
      "[4 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 85us/step - loss: 80624.0625\n",
      "rewards:  -91.0 q-value:  0\n",
      "loss: [80624.0625]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 89us/step - loss: 51833.1875\n",
      "rewards:  -96.0 q-value:  0\n",
      "loss: [51833.1875]\n",
      "Exploring\n",
      "Selected action  [4 0]\n",
      "[4 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 67us/step - loss: 23171.0000\n",
      "rewards:  -98.0 q-value:  0\n",
      "loss: [23171.0]\n",
      "Exploring\n",
      "Selected action  [4 0]\n",
      "[4 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 90us/step - loss: 80293.0625\n",
      "rewards:  -98.0 q-value:  0\n",
      "loss: [80293.0625]\n",
      "Exploiting\n",
      "Selected action  [4 3]\n",
      "[4 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 79us/step - loss: 35097.7500\n",
      "rewards:  -74.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [35097.75]\n",
      "Exploring\n",
      "Selected action  [4 0]\n",
      "[4 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 88us/step - loss: 71068.2812\n",
      "rewards:  -80.0 q-value:  0\n",
      "loss: [71068.28125]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 96us/step - loss: 90731.5938\n",
      "rewards:  -91.0 q-value:  0\n",
      "loss: [90731.59375]\n",
      "Exploiting\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 84us/step - loss: 54975.1562\n",
      "rewards:  -92.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [54975.15625]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 77us/step - loss: 24795.9062\n",
      "rewards:  -97.0 q-value:  0\n",
      "loss: [24795.90625]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 76us/step - loss: 73468.7812\n",
      "rewards:  -102.0 q-value:  0\n",
      "loss: [73468.78125]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 84us/step - loss: 44191.3750\n",
      "rewards:  -107.0 q-value:  0\n",
      "loss: [44191.375]\n",
      "Exploring\n",
      "Selected action  [0 4]\n",
      "[0 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 65us/step - loss: 56639.5625\n",
      "rewards:  -103.0 q-value:  0\n",
      "loss: [56639.5625]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 83us/step - loss: 50695.3750\n",
      "rewards:  -104.0 q-value:  0\n",
      "loss: [50695.375]\n",
      "Exploiting\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 110us/step - loss: 55213.8438\n",
      "rewards:  -105.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [55213.84375]\n",
      "Exploring\n",
      "Selected action  [4 3]\n",
      "[4 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 87us/step - loss: 35804.6562\n",
      "rewards:  -93.0 q-value:  0\n",
      "loss: [35804.65625]\n",
      "Exploiting\n",
      "Selected action  [4 3]\n",
      "[4 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 83us/step - loss: 42984.0312\n",
      "rewards:  -98.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [42984.03125]\n",
      "Exploiting\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 81us/step - loss: 25990.4688\n",
      "rewards:  -103.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [25990.46875]\n",
      "Exploring\n",
      "Selected action  [0 4]\n",
      "[0 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 74us/step - loss: 40916.8750\n",
      "rewards:  -87.0 q-value:  0\n",
      "loss: [40916.875]\n",
      "Exploiting\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 99us/step - loss: 32899.0938\n",
      "rewards:  -92.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [32899.09375]\n",
      "Exploring\n",
      "Selected action  [4 3]\n",
      "[4 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 131us/step - loss: 29608.1562\n",
      "rewards:  -92.0 q-value:  0\n",
      "loss: [29608.15625]\n",
      "Exploiting\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 76us/step - loss: 33253.0312\n",
      "rewards:  -97.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [33253.03125]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 104us/step - loss: 29413.3125\n",
      "rewards:  -117.0 q-value:  0\n",
      "loss: [29413.3125]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 89us/step - loss: 41252.2188\n",
      "rewards:  -117.0 q-value:  0\n",
      "loss: [41252.21875]\n",
      "Exploring\n",
      "Selected action  [4 3]\n",
      "[4 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 79us/step - loss: 70400.0938\n",
      "rewards:  -101.0 q-value:  0\n",
      "loss: [70400.09375]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 89us/step - loss: 26799.1562\n",
      "rewards:  -156.0 q-value:  0\n",
      "loss: [26799.15625]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 86us/step - loss: 54615.5625\n",
      "rewards:  -161.0 q-value:  0\n",
      "loss: [54615.5625]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 80us/step - loss: 45783.0312\n",
      "rewards:  -161.0 q-value:  0\n",
      "loss: [45783.03125]\n",
      "Exploiting\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 88us/step - loss: 56265.5938\n",
      "rewards:  -161.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [56265.59375]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 79us/step - loss: 42420.3125\n",
      "rewards:  -166.0 q-value:  0\n",
      "loss: [42420.3125]\n",
      "Exploring\n",
      "Selected action  [4 3]\n",
      "[4 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 86us/step - loss: 37823.7500\n",
      "rewards:  -163.0 q-value:  0\n",
      "loss: [37823.75]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 89us/step - loss: 30497.3438\n",
      "rewards:  -218.0 q-value:  0\n",
      "loss: [30497.34375]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 101us/step - loss: 67045.3750\n",
      "rewards:  -218.0 q-value:  0\n",
      "loss: [67045.375]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 84us/step - loss: 33380.0000\n",
      "rewards:  -223.0 q-value:  0\n",
      "loss: [33380.0]\n",
      "Exploiting\n",
      "Selected action  [0 4]\n",
      "[0 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 92us/step - loss: 27675.1562\n",
      "rewards:  -219.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [27675.15625]\n",
      "Exploiting\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 69us/step - loss: 50921.2812\n",
      "rewards:  -219.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [50921.28125]\n",
      "Exploring\n",
      "Selected action  [4 3]\n",
      "[4 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 94us/step - loss: 26342.1875\n",
      "rewards:  -211.0 q-value:  0\n",
      "loss: [26342.1875]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 121us/step - loss: 61638.4375\n",
      "rewards:  -216.0 q-value:  0\n",
      "loss: [61638.4375]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 88us/step - loss: 15810.4062\n",
      "rewards:  -221.0 q-value:  0\n",
      "loss: [15810.40625]\n",
      "Exploiting\n",
      "Selected action  [0 4]\n",
      "[0 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 96us/step - loss: 74838.7188\n",
      "rewards:  -221.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [74838.71875]\n",
      "Exploring\n",
      "Selected action  [0 4]\n",
      "[0 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 86us/step - loss: 44553.5625\n",
      "rewards:  -221.0 q-value:  0\n",
      "loss: [44553.5625]\n",
      "Exploring\n",
      "Selected action  [0 4]\n",
      "[0 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 101us/step - loss: 82683.7500\n",
      "rewards:  -221.0 q-value:  0\n",
      "loss: [82683.75]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 73us/step - loss: 56483.5312\n",
      "rewards:  -226.0 q-value:  0\n",
      "loss: [56483.53125]\n",
      "Exploring\n",
      "Selected action  [0 4]\n",
      "[0 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 101us/step - loss: 51365.0938\n",
      "rewards:  -226.0 q-value:  0\n",
      "loss: [51365.09375]\n",
      "Exploiting\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 87us/step - loss: 52539.1875\n",
      "rewards:  -234.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [52539.1875]\n",
      "Exploring\n",
      "Selected action  [4 0]\n",
      "[4 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 101us/step - loss: 48053.4062\n",
      "rewards:  -234.0 q-value:  0\n",
      "loss: [48053.40625]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 90us/step - loss: 25476.8438\n",
      "rewards:  -239.0 q-value:  0\n",
      "loss: [25476.84375]\n",
      "Exploiting\n",
      "Selected action  [0 4]\n",
      "[0 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 74us/step - loss: 37739.9688\n",
      "rewards:  -239.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [37739.96875]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 79us/step - loss: 51075.1875\n",
      "rewards:  -244.0 q-value:  0\n",
      "loss: [51075.1875]\n",
      "Exploring\n",
      "Selected action  [0 4]\n",
      "[0 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 109us/step - loss: 23351.1875\n",
      "rewards:  -244.0 q-value:  0\n",
      "loss: [23351.1875]\n",
      "Exploring\n",
      "Selected action  [0 4]\n",
      "[0 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 91us/step - loss: 34818.6562\n",
      "rewards:  -244.0 q-value:  0\n",
      "loss: [34818.65625]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 81us/step - loss: 49339.9688\n",
      "rewards:  -244.0 q-value:  0\n",
      "loss: [49339.96875]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 82us/step - loss: 25854.6250\n",
      "rewards:  -244.0 q-value:  0\n",
      "loss: [25854.625]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 84us/step - loss: 26075.8438\n",
      "rewards:  -244.0 q-value:  0\n",
      "loss: [26075.84375]\n",
      "Exploring\n",
      "Selected action  [0 4]\n",
      "[0 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 111us/step - loss: 53397.8750\n",
      "rewards:  -244.0 q-value:  0\n",
      "loss: [53397.875]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 59us/step - loss: 35547.4375\n",
      "rewards:  -228.0 q-value:  0\n",
      "loss: [35547.4375]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 98us/step - loss: 51168.8750\n",
      "rewards:  -253.0 q-value:  0\n",
      "loss: [51168.875]\n",
      "Exploiting\n",
      "Selected action  [0 4]\n",
      "[0 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 73us/step - loss: 36434.8750\n",
      "rewards:  -254.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [36434.875]\n",
      "Exploring\n",
      "Selected action  [4 3]\n",
      "[4 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 120us/step - loss: 29768.5625\n",
      "rewards:  -230.0 q-value:  0\n",
      "loss: [29768.5625]\n",
      "Exploiting\n",
      "Selected action  [4 0]\n",
      "[4 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 97us/step - loss: 36924.9688\n",
      "rewards:  -236.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [36924.96875]\n",
      "Exploiting\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 64us/step - loss: 64772.4688\n",
      "rewards:  -241.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [64772.46875]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 115us/step - loss: 51334.8750\n",
      "rewards:  -247.0 q-value:  0\n",
      "loss: [51334.875]\n",
      "Exploiting\n",
      "Selected action  [4 0]\n",
      "[4 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 91us/step - loss: 47658.8750\n",
      "rewards:  -250.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [47658.875]\n",
      "Exploiting\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 128us/step - loss: 47014.9375\n",
      "rewards:  -265.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [47014.9375]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 100us/step - loss: 51337.9375\n",
      "rewards:  -267.0 q-value:  0\n",
      "loss: [51337.9375]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 86us/step - loss: 47091.1562\n",
      "rewards:  -282.0 q-value:  0\n",
      "loss: [47091.15625]\n",
      "Exploiting\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 108us/step - loss: 65817.0312\n",
      "rewards:  -287.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [65817.03125]\n",
      "Exploring\n",
      "Selected action  [0 4]\n",
      "[0 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 80us/step - loss: 52051.0625\n",
      "rewards:  -283.0 q-value:  0\n",
      "loss: [52051.0625]\n",
      "Exploiting\n",
      "Selected action  [4 3]\n",
      "[4 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 69us/step - loss: 61686.6250\n",
      "rewards:  -271.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [61686.625]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 88us/step - loss: 53920.9688\n",
      "rewards:  -263.0 q-value:  0\n",
      "loss: [53920.96875]\n",
      "Exploiting\n",
      "Selected action  [0 4]\n",
      "[0 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 95us/step - loss: 19056.5000\n",
      "rewards:  -231.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [19056.5]\n",
      "Exploiting\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 114us/step - loss: 51103.5312\n",
      "rewards:  -243.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [51103.53125]\n",
      "Number of actions available 5\n",
      "Episode : 30\n",
      "Exploiting\n",
      "Selected action  [2 1]\n",
      "[2 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 88us/step - loss: 34257.5000\n",
      "rewards:  -17.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [34257.5]\n",
      "Exploring\n",
      "Selected action  [1 4]\n",
      "[1 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 70us/step - loss: 40235.9062\n",
      "rewards:  11.0 q-value:  0\n",
      "loss: [40235.90625]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 101us/step - loss: 46742.6250\n",
      "rewards:  6.0 q-value:  0\n",
      "loss: [46742.625]\n",
      "Exploring\n",
      "Selected action  [1 4]\n",
      "[1 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 95us/step - loss: 29811.3750\n",
      "rewards:  4.0 q-value:  0\n",
      "loss: [29811.375]\n",
      "Exploring\n",
      "Selected action  [1 4]\n",
      "[1 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 84us/step - loss: 36899.1875\n",
      "rewards:  1.0 q-value:  0\n",
      "loss: [36899.1875]\n",
      "Exploring\n",
      "Selected action  [3 1]\n",
      "[3 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 104us/step - loss: 48267.3438\n",
      "rewards:  -14.0 q-value:  0\n",
      "loss: [48267.34375]\n",
      "Exploring\n",
      "Selected action  [3 2]\n",
      "[3 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 98us/step - loss: 71926.8750\n",
      "rewards:  -6.0 q-value:  0\n",
      "loss: [71926.875]\n",
      "Exploring\n",
      "Selected action  [1 4]\n",
      "[1 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 77us/step - loss: 34536.1875\n",
      "rewards:  -15.0 q-value:  0\n",
      "loss: [34536.1875]\n",
      "Exploring\n",
      "Selected action  [3 1]\n",
      "[3 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 84us/step - loss: 49899.0938\n",
      "rewards:  -5.0 q-value:  0\n",
      "loss: [49899.09375]\n",
      "Exploring\n",
      "Selected action  [1 4]\n",
      "[1 4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 87us/step - loss: 44114.4062\n",
      "rewards:  7.0 q-value:  0\n",
      "loss: [44114.40625]\n",
      "Exploring\n",
      "Selected action  [2 1]\n",
      "[2 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 79us/step - loss: 29409.8438\n",
      "rewards:  1.0 q-value:  0\n",
      "loss: [29409.84375]\n",
      "Exploiting\n",
      "Selected action  [3 1]\n",
      "[3 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 68us/step - loss: 48559.4375\n",
      "rewards:  0.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [48559.4375]\n",
      "Exploring\n",
      "Selected action  [3 1]\n",
      "[3 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 76us/step - loss: 49234.8438\n",
      "rewards:  -1.0 q-value:  0\n",
      "loss: [49234.84375]\n",
      "Exploring\n",
      "Selected action  [1 4]\n",
      "[1 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 82us/step - loss: 65674.4062\n",
      "rewards:  -1.0 q-value:  0\n",
      "loss: [65674.40625]\n",
      "Exploiting\n",
      "Selected action  [3 1]\n",
      "[3 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 72us/step - loss: 79474.5312\n",
      "rewards:  -42.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [79474.53125]\n",
      "Exploring\n",
      "Selected action  [3 2]\n",
      "[3 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 104us/step - loss: 22989.5312\n",
      "rewards:  -11.0 q-value:  0\n",
      "loss: [22989.53125]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 86us/step - loss: 29322.8750\n",
      "rewards:  -16.0 q-value:  0\n",
      "loss: [29322.875]\n",
      "Exploring\n",
      "Selected action  [2 1]\n",
      "[2 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 89us/step - loss: 71809.5625\n",
      "rewards:  -22.0 q-value:  0\n",
      "loss: [71809.5625]\n",
      "Exploring\n",
      "Selected action  [3 1]\n",
      "[3 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 72us/step - loss: 70037.0625\n",
      "rewards:  -24.0 q-value:  0\n",
      "loss: [70037.0625]\n",
      "Exploiting\n",
      "Selected action  [3 2]\n",
      "[3 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 67us/step - loss: 42981.1562\n",
      "rewards:  -14.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [42981.15625]\n",
      "Exploring\n",
      "Selected action  [1 4]\n",
      "[1 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 71us/step - loss: 73657.7500\n",
      "rewards:  -29.0 q-value:  0\n",
      "loss: [73657.75]\n",
      "Exploring\n",
      "Selected action  [3 1]\n",
      "[3 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 88us/step - loss: 47271.5938\n",
      "rewards:  -51.0 q-value:  0\n",
      "loss: [47271.59375]\n",
      "Exploring\n",
      "Selected action  [1 4]\n",
      "[1 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 61us/step - loss: 65620.7500\n",
      "rewards:  -51.0 q-value:  0\n",
      "loss: [65620.75]\n",
      "Exploring\n",
      "Selected action  [3 1]\n",
      "[3 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 102us/step - loss: 47672.0312\n",
      "rewards:  -73.0 q-value:  0\n",
      "loss: [47672.03125]\n",
      "Exploring\n",
      "Selected action  [1 4]\n",
      "[1 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 85us/step - loss: 34961.4375\n",
      "rewards:  -73.0 q-value:  0\n",
      "loss: [34961.4375]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 75us/step - loss: 66639.6875\n",
      "rewards:  -78.0 q-value:  0\n",
      "loss: [66639.6875]\n",
      "Exploring\n",
      "Selected action  [2 1]\n",
      "[2 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 66us/step - loss: 53723.2188\n",
      "rewards:  -44.0 q-value:  0\n",
      "loss: [53723.21875]\n",
      "Exploring\n",
      "Selected action  [2 1]\n",
      "[2 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 87us/step - loss: 32114.1562\n",
      "rewards:  -49.0 q-value:  0\n",
      "loss: [32114.15625]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 71us/step - loss: 35677.1875\n",
      "rewards:  -54.0 q-value:  0\n",
      "loss: [35677.1875]\n",
      "Exploring\n",
      "Selected action  [3 1]\n",
      "[3 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 87us/step - loss: 21493.5000\n",
      "rewards:  -86.0 q-value:  0\n",
      "loss: [21493.5]\n",
      "Exploiting\n",
      "Selected action  [3 2]\n",
      "[3 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 79us/step - loss: 45622.2500\n",
      "rewards:  -75.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [45622.25]\n",
      "Exploring\n",
      "Selected action  [2 1]\n",
      "[2 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 102us/step - loss: 75899.5312\n",
      "rewards:  -71.0 q-value:  0\n",
      "loss: [75899.53125]\n",
      "Exploiting\n",
      "Selected action  [1 4]\n",
      "[1 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 67us/step - loss: 53347.2812\n",
      "rewards:  -71.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [53347.28125]\n",
      "Exploiting\n",
      "Selected action  [3 2]\n",
      "[3 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 96us/step - loss: 39046.4688\n",
      "rewards:  -85.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [39046.46875]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 80us/step - loss: 69127.2812\n",
      "rewards:  -90.0 q-value:  0\n",
      "loss: [69127.28125]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 92us/step - loss: 41217.6250\n",
      "rewards:  -95.0 q-value:  0\n",
      "loss: [41217.625]\n",
      "Exploiting\n",
      "Selected action  [1 4]\n",
      "[1 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 84us/step - loss: 59270.6562\n",
      "rewards:  -113.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [59270.65625]\n",
      "Exploring\n",
      "Selected action  [3 1]\n",
      "[3 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 100us/step - loss: 44901.6875\n",
      "rewards:  -111.0 q-value:  0\n",
      "loss: [44901.6875]\n",
      "Exploiting\n",
      "Selected action  [3 1]\n",
      "[3 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 81us/step - loss: 21869.9375\n",
      "rewards:  -114.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [21869.9375]\n",
      "Exploring\n",
      "Selected action  [2 1]\n",
      "[2 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 89us/step - loss: 29059.2188\n",
      "rewards:  -124.0 q-value:  0\n",
      "loss: [29059.21875]\n",
      "Exploring\n",
      "Selected action  [3 2]\n",
      "[3 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 89us/step - loss: 25027.1875\n",
      "rewards:  -120.0 q-value:  0\n",
      "loss: [25027.1875]\n",
      "Exploring\n",
      "Selected action  [2 1]\n",
      "[2 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 119us/step - loss: 55523.4375\n",
      "rewards:  -88.0 q-value:  0\n",
      "loss: [55523.4375]\n",
      "Exploring\n",
      "Selected action  [1 4]\n",
      "[1 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 70us/step - loss: 76256.1250\n",
      "rewards:  -64.0 q-value:  0\n",
      "loss: [76256.125]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 109us/step - loss: 42317.5000\n",
      "rewards:  -69.0 q-value:  0\n",
      "loss: [42317.5]\n",
      "Exploring\n",
      "Selected action  [3 2]\n",
      "[3 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 108us/step - loss: 80593.1875\n",
      "rewards:  -52.0 q-value:  0\n",
      "loss: [80593.1875]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 86us/step - loss: 35232.8438\n",
      "rewards:  -57.0 q-value:  0\n",
      "loss: [35232.84375]\n",
      "Exploring\n",
      "Selected action  [1 4]\n",
      "[1 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 81us/step - loss: 66867.8125\n",
      "rewards:  -92.0 q-value:  0\n",
      "loss: [66867.8125]\n",
      "Exploring\n",
      "Selected action  [2 1]\n",
      "[2 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 106us/step - loss: 45224.8438\n",
      "rewards:  -52.0 q-value:  0\n",
      "loss: [45224.84375]\n",
      "Exploring\n",
      "Selected action  [1 4]\n",
      "[1 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 91us/step - loss: 28108.2812\n",
      "rewards:  -32.0 q-value:  0\n",
      "loss: [28108.28125]\n",
      "Exploiting\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 84us/step - loss: 37247.5000\n",
      "rewards:  -37.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [37247.5]\n",
      "Exploring\n",
      "Selected action  [2 1]\n",
      "[2 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 86us/step - loss: 66897.5625\n",
      "rewards:  -28.0 q-value:  0\n",
      "loss: [66897.5625]\n",
      "Exploring\n",
      "Selected action  [3 1]\n",
      "[3 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 85us/step - loss: 67962.7188\n",
      "rewards:  -30.0 q-value:  0\n",
      "loss: [67962.71875]\n",
      "Exploring\n",
      "Selected action  [2 1]\n",
      "[2 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 93us/step - loss: 68950.3125\n",
      "rewards:  -37.0 q-value:  0\n",
      "loss: [68950.3125]\n",
      "Exploiting\n",
      "Selected action  [2 1]\n",
      "[2 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 96us/step - loss: 53603.5938\n",
      "rewards:  -41.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [53603.59375]\n",
      "Exploring\n",
      "Selected action  [3 1]\n",
      "[3 1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 101us/step - loss: 51901.7812\n",
      "rewards:  -45.0 q-value:  0\n",
      "loss: [51901.78125]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 87us/step - loss: 34478.0000\n",
      "rewards:  -50.0 q-value:  0\n",
      "loss: [34478.0]\n",
      "Exploiting\n",
      "Selected action  [1 4]\n",
      "[1 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 97us/step - loss: 64134.4688\n",
      "rewards:  -52.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [64134.46875]\n",
      "Exploiting\n",
      "Selected action  [2 1]\n",
      "[2 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 86us/step - loss: 36584.1562\n",
      "rewards:  -44.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [36584.15625]\n",
      "Exploiting\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 91us/step - loss: 79895.0625\n",
      "rewards:  -49.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [79895.0625]\n",
      "Exploring\n",
      "Selected action  [3 2]\n",
      "[3 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 84us/step - loss: 75014.5000\n",
      "rewards:  -56.0 q-value:  0\n",
      "loss: [75014.5]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 85us/step - loss: 40895.7812\n",
      "rewards:  -61.0 q-value:  0\n",
      "loss: [40895.78125]\n",
      "Exploring\n",
      "Selected action  [3 2]\n",
      "[3 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 112us/step - loss: 37212.1875\n",
      "rewards:  -68.0 q-value:  0\n",
      "loss: [37212.1875]\n",
      "Exploiting\n",
      "Selected action  [3 2]\n",
      "[3 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 114us/step - loss: 39054.1875\n",
      "rewards:  -70.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [39054.1875]\n",
      "Exploring\n",
      "Selected action  [2 1]\n",
      "[2 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 75us/step - loss: 41203.9062\n",
      "rewards:  -50.0 q-value:  0\n",
      "loss: [41203.90625]\n",
      "Exploring\n",
      "Selected action  [3 1]\n",
      "[3 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 97us/step - loss: 17536.5938\n",
      "rewards:  -51.0 q-value:  0\n",
      "loss: [17536.59375]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 106us/step - loss: 46316.6250\n",
      "rewards:  -56.0 q-value:  0\n",
      "loss: [46316.625]\n",
      "Exploring\n",
      "Selected action  [2 1]\n",
      "[2 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 78us/step - loss: 55564.5312\n",
      "rewards:  -46.0 q-value:  0\n",
      "loss: [55564.53125]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 99us/step - loss: 30674.2812\n",
      "rewards:  -51.0 q-value:  0\n",
      "loss: [30674.28125]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 82us/step - loss: 50223.2188\n",
      "rewards:  -56.0 q-value:  0\n",
      "loss: [50223.21875]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 70us/step - loss: 46668.8125\n",
      "rewards:  -61.0 q-value:  0\n",
      "loss: [46668.8125]\n",
      "Exploiting\n",
      "Selected action  [3 2]\n",
      "[3 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 105us/step - loss: 80736.3750\n",
      "rewards:  -35.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [80736.375]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 74us/step - loss: 61139.9688\n",
      "rewards:  -40.0 q-value:  0\n",
      "loss: [61139.96875]\n",
      "Exploring\n",
      "Selected action  [3 2]\n",
      "[3 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 94us/step - loss: 50396.8125\n",
      "rewards:  -46.0 q-value:  0\n",
      "loss: [50396.8125]\n",
      "Exploring\n",
      "Selected action  [3 2]\n",
      "[3 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 86us/step - loss: 55442.9062\n",
      "rewards:  -51.0 q-value:  0\n",
      "loss: [55442.90625]\n",
      "Exploring\n",
      "Selected action  [2 1]\n",
      "[2 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 78us/step - loss: 42390.2812\n",
      "rewards:  -39.0 q-value:  0\n",
      "loss: [42390.28125]\n",
      "Exploring\n",
      "Selected action  [2 1]\n",
      "[2 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 88us/step - loss: 40270.6562\n",
      "rewards:  -42.0 q-value:  0\n",
      "loss: [40270.65625]\n",
      "Exploring\n",
      "Selected action  [3 1]\n",
      "[3 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 83us/step - loss: 44307.5312\n",
      "rewards:  -44.0 q-value:  0\n",
      "loss: [44307.53125]\n",
      "Exploring\n",
      "Selected action  [1 4]\n",
      "[1 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 86us/step - loss: 60999.9688\n",
      "rewards:  -44.0 q-value:  0\n",
      "loss: [60999.96875]\n",
      "Exploring\n",
      "Selected action  [3 2]\n",
      "[3 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 81us/step - loss: 32089.0938\n",
      "rewards:  -38.0 q-value:  0\n",
      "loss: [32089.09375]\n",
      "Exploring\n",
      "Selected action  [3 1]\n",
      "[3 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 107us/step - loss: 56055.6562\n",
      "rewards:  -33.0 q-value:  0\n",
      "loss: [56055.65625]\n",
      "Exploiting\n",
      "Selected action  [1 4]\n",
      "[1 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 99us/step - loss: 28075.9688\n",
      "rewards:  -5.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [28075.96875]\n",
      "Exploiting\n",
      "Selected action  [3 1]\n",
      "[3 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 91us/step - loss: 72651.5312\n",
      "rewards:  -31.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [72651.53125]\n",
      "Exploring\n",
      "Selected action  [3 2]\n",
      "[3 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 107us/step - loss: 30064.9062\n",
      "rewards:  -20.0 q-value:  0\n",
      "loss: [30064.90625]\n",
      "Exploiting\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 81us/step - loss: 58640.8125\n",
      "rewards:  -25.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [58640.8125]\n",
      "Exploring\n",
      "Selected action  [2 1]\n",
      "[2 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 74us/step - loss: 62620.4688\n",
      "rewards:  -37.0 q-value:  0\n",
      "loss: [62620.46875]\n",
      "Exploring\n",
      "Selected action  [2 1]\n",
      "[2 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 103us/step - loss: 68596.4688\n",
      "rewards:  -44.0 q-value:  0\n",
      "loss: [68596.46875]\n",
      "Exploring\n",
      "Selected action  [3 1]\n",
      "[3 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 91us/step - loss: 62430.9062\n",
      "rewards:  -47.0 q-value:  0\n",
      "loss: [62430.90625]\n",
      "Exploring\n",
      "Selected action  [3 1]\n",
      "[3 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 91us/step - loss: 26211.2812\n",
      "rewards:  -50.0 q-value:  0\n",
      "loss: [26211.28125]\n",
      "Exploring\n",
      "Selected action  [3 1]\n",
      "[3 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 74us/step - loss: 44776.3125\n",
      "rewards:  -54.0 q-value:  0\n",
      "loss: [44776.3125]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 84us/step - loss: 44355.7188\n",
      "rewards:  -59.0 q-value:  0\n",
      "loss: [44355.71875]\n",
      "Exploiting\n",
      "Selected action  [3 2]\n",
      "[3 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 87us/step - loss: 26710.4375\n",
      "rewards:  -74.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [26710.4375]\n",
      "Exploiting\n",
      "Selected action  [1 4]\n",
      "[1 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 82us/step - loss: 47234.5938\n",
      "rewards:  -114.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [47234.59375]\n",
      "Exploring\n",
      "Selected action  [2 1]\n",
      "[2 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 69us/step - loss: 111158.2188\n",
      "rewards:  -82.0 q-value:  0\n",
      "loss: [111158.21875]\n",
      "Exploring\n",
      "Selected action  [2 1]\n",
      "[2 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 87us/step - loss: 58151.7812\n",
      "rewards:  -89.0 q-value:  0\n",
      "loss: [58151.78125]\n",
      "Exploring\n",
      "Selected action  [2 1]\n",
      "[2 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 104us/step - loss: 33603.2500\n",
      "rewards:  -96.0 q-value:  0\n",
      "loss: [33603.25]\n",
      "Exploiting\n",
      "Selected action  [1 4]\n",
      "[1 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 72us/step - loss: 46269.1250\n",
      "rewards:  -88.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [46269.125]\n",
      "Exploring\n",
      "Selected action  [2 1]\n",
      "[2 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 81us/step - loss: 44346.3750\n",
      "rewards:  -48.0 q-value:  0\n",
      "loss: [44346.375]\n",
      "Exploring\n",
      "Selected action  [2 1]\n",
      "[2 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 74us/step - loss: 27801.0000\n",
      "rewards:  -57.0 q-value:  0\n",
      "loss: [27801.0]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 100us/step - loss: 69158.8125\n",
      "rewards:  -62.0 q-value:  0\n",
      "loss: [69158.8125]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 84us/step - loss: 78267.1250\n",
      "rewards:  -67.0 q-value:  0\n",
      "loss: [78267.125]\n",
      "Exploring\n",
      "Selected action  [1 4]\n",
      "[1 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 83us/step - loss: 59509.0938\n",
      "rewards:  -87.0 q-value:  0\n",
      "loss: [59509.09375]\n",
      "Exploring\n",
      "Selected action  [2 1]\n",
      "[2 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 101us/step - loss: 63068.1562\n",
      "rewards:  -79.0 q-value:  0\n",
      "loss: [63068.15625]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 89us/step - loss: 41316.0938\n",
      "rewards:  -84.0 q-value:  0\n",
      "loss: [41316.09375]\n",
      "Exploring\n",
      "Selected action  [3 2]\n",
      "[3 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 97us/step - loss: 31646.7500\n",
      "rewards:  -72.0 q-value:  0\n",
      "loss: [31646.75]\n",
      "Exploring\n",
      "Selected action  [3 1]\n",
      "[3 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 71us/step - loss: 55060.9688\n",
      "rewards:  -89.0 q-value:  0\n",
      "loss: [55060.96875]\n",
      "Exploring\n",
      "Selected action  [1 4]\n",
      "[1 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 92us/step - loss: 59996.2188\n",
      "rewards:  -81.0 q-value:  0\n",
      "loss: [59996.21875]\n",
      "Exploring\n",
      "Selected action  [3 2]\n",
      "[3 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 86us/step - loss: 39846.6562\n",
      "rewards:  -55.0 q-value:  0\n",
      "loss: [39846.65625]\n",
      "Exploiting\n",
      "Selected action  [3 1]\n",
      "[3 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 95us/step - loss: 99883.2188\n",
      "rewards:  -95.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [99883.21875]\n",
      "Exploring\n",
      "Selected action  [3 2]\n",
      "[3 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 80us/step - loss: 30466.0000\n",
      "rewards:  -63.0 q-value:  0\n",
      "loss: [30466.0]\n",
      "Exploring\n",
      "Selected action  [3 1]\n",
      "[3 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 97us/step - loss: 46390.4062\n",
      "rewards:  -73.0 q-value:  0\n",
      "loss: [46390.40625]\n",
      "Exploring\n",
      "Selected action  [3 1]\n",
      "[3 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 75us/step - loss: 64388.0312\n",
      "rewards:  -73.0 q-value:  0\n",
      "loss: [64388.03125]\n",
      "Exploring\n",
      "Selected action  [3 2]\n",
      "[3 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 71us/step - loss: 32791.1562\n",
      "rewards:  -65.0 q-value:  0\n",
      "loss: [32791.15625]\n",
      "Exploring\n",
      "Selected action  [3 2]\n",
      "[3 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 78us/step - loss: 71388.7500\n",
      "rewards:  -67.0 q-value:  0\n",
      "loss: [71388.75]\n",
      "Exploring\n",
      "Selected action  [3 1]\n",
      "[3 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 105us/step - loss: 35056.4062\n",
      "rewards:  -77.0 q-value:  0\n",
      "loss: [35056.40625]\n",
      "Number of actions available 6\n",
      "Episode : 31\n",
      "Exploring\n",
      "Selected action  [1 2]\n",
      "[1 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 81us/step - loss: 60974.0625\n",
      "rewards:  8.0 q-value:  0\n",
      "loss: [60974.0625]\n",
      "Exploiting\n",
      "Selected action  [0 2]\n",
      "[0 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 85us/step - loss: 32794.1875\n",
      "rewards:  2.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [32794.1875]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 93us/step - loss: 39562.8125\n",
      "rewards:  -3.0 q-value:  0\n",
      "loss: [39562.8125]\n",
      "Exploring\n",
      "Selected action  [1 2]\n",
      "[1 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 69us/step - loss: 47031.2500\n",
      "rewards:  -5.0 q-value:  0\n",
      "loss: [47031.25]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 108us/step - loss: 51468.8438\n",
      "rewards:  -10.0 q-value:  0\n",
      "loss: [51468.84375]\n",
      "Exploiting\n",
      "Selected action  [1 2]\n",
      "[1 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 95us/step - loss: 46500.0312\n",
      "rewards:  12.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [46500.03125]\n",
      "Exploiting\n",
      "Selected action  [3 4]\n",
      "[3 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 80us/step - loss: 22281.1250\n",
      "rewards:  -10.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [22281.125]\n",
      "Exploring\n",
      "Selected action  [2 3]\n",
      "[2 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 71us/step - loss: 30479.2188\n",
      "rewards:  9.0 q-value:  0\n",
      "loss: [30479.21875]\n",
      "Exploring\n",
      "Selected action  [0 2]\n",
      "[0 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 67us/step - loss: 83410.7812\n",
      "rewards:  18.0 q-value:  0\n",
      "loss: [83410.78125]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 83us/step - loss: 30032.0938\n",
      "rewards:  13.0 q-value:  0\n",
      "loss: [30032.09375]\n",
      "Exploring\n",
      "Selected action  [1 2]\n",
      "[1 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 98us/step - loss: 28444.2812\n",
      "rewards:  -3.0 q-value:  0\n",
      "loss: [28444.28125]\n",
      "Exploring\n",
      "Selected action  [1 2]\n",
      "[1 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 102us/step - loss: 50407.2500\n",
      "rewards:  -4.0 q-value:  0\n",
      "loss: [50407.25]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 80us/step - loss: 75407.8125\n",
      "rewards:  -9.0 q-value:  0\n",
      "loss: [75407.8125]\n",
      "Exploiting\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 83us/step - loss: 65206.8438\n",
      "rewards:  -14.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [65206.84375]\n",
      "Exploring\n",
      "Selected action  [0 2]\n",
      "[0 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 85us/step - loss: 27511.4062\n",
      "rewards:  10.0 q-value:  0\n",
      "loss: [27511.40625]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 87us/step - loss: 113991.1875\n",
      "rewards:  5.0 q-value:  0\n",
      "loss: [113991.1875]\n",
      "Exploring\n",
      "Selected action  [0 2]\n",
      "[0 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 68us/step - loss: 17572.5938\n",
      "rewards:  29.0 q-value:  0\n",
      "loss: [17572.59375]\n",
      "Exploiting\n",
      "Selected action  [3 2]\n",
      "[3 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 91us/step - loss: 63711.0938\n",
      "rewards:  24.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [63711.09375]\n",
      "Exploiting\n",
      "Selected action  [2 3]\n",
      "[2 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 105us/step - loss: 44361.2500\n",
      "rewards:  44.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [44361.25]\n",
      "Exploring\n",
      "Selected action  [2 3]\n",
      "[2 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 71us/step - loss: 62979.9062\n",
      "rewards:  41.0 q-value:  0\n",
      "loss: [62979.90625]\n",
      "Exploiting\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 87us/step - loss: 42385.2812\n",
      "rewards:  36.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [42385.28125]\n",
      "Exploring\n",
      "Selected action  [0 2]\n",
      "[0 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 95us/step - loss: 39405.7500\n",
      "rewards:  44.0 q-value:  0\n",
      "loss: [39405.75]\n",
      "Exploiting\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 90us/step - loss: 55254.1250\n",
      "rewards:  39.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [55254.125]\n",
      "Exploiting\n",
      "Selected action  [1 2]\n",
      "[1 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 74us/step - loss: 27005.0312\n",
      "rewards:  68.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [27005.03125]\n",
      "Exploiting\n",
      "Selected action  [2 3]\n",
      "[2 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 87us/step - loss: 69786.8750\n",
      "rewards:  80.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [69786.875]\n",
      "Exploring\n",
      "Selected action  [3 4]\n",
      "[3 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 88us/step - loss: 49961.1875\n",
      "rewards:  104.0 q-value:  0\n",
      "loss: [49961.1875]\n",
      "Exploiting\n",
      "Selected action  [3 2]\n",
      "[3 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 101us/step - loss: 51444.6250\n",
      "rewards:  90.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [51444.625]\n",
      "Exploring\n",
      "Selected action  [0 2]\n",
      "[0 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 76us/step - loss: 56596.0000\n",
      "rewards:  82.0 q-value:  0\n",
      "loss: [56596.0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exploring\n",
      "Selected action  [0 2]\n",
      "[0 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 83us/step - loss: 25320.8750\n",
      "rewards:  79.0 q-value:  0\n",
      "loss: [25320.875]\n",
      "Exploring\n",
      "Selected action  [3 2]\n",
      "[3 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 68us/step - loss: 69239.0312\n",
      "rewards:  74.0 q-value:  0\n",
      "loss: [69239.03125]\n",
      "Exploiting\n",
      "Selected action  [1 2]\n",
      "[1 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 83us/step - loss: 64523.0625\n",
      "rewards:  73.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [64523.0625]\n",
      "Exploring\n",
      "Selected action  [0 2]\n",
      "[0 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 83us/step - loss: 45708.3750\n",
      "rewards:  71.0 q-value:  0\n",
      "loss: [45708.375]\n",
      "Exploring\n",
      "Selected action  [1 2]\n",
      "[1 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 107us/step - loss: 63936.4375\n",
      "rewards:  70.0 q-value:  0\n",
      "loss: [63936.4375]\n",
      "Exploiting\n",
      "Selected action  [2 3]\n",
      "[2 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 73us/step - loss: 52878.7812\n",
      "rewards:  94.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [52878.78125]\n",
      "Exploring\n",
      "Selected action  [0 2]\n",
      "[0 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 83us/step - loss: 16114.0625\n",
      "rewards:  99.0 q-value:  0\n",
      "loss: [16114.0625]\n",
      "Exploring\n",
      "Selected action  [0 2]\n",
      "[0 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 108us/step - loss: 60282.0000\n",
      "rewards:  96.0 q-value:  0\n",
      "loss: [60282.0]\n",
      "Exploring\n",
      "Selected action  [3 4]\n",
      "[3 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 100us/step - loss: 27473.6875\n",
      "rewards:  101.0 q-value:  0\n",
      "loss: [27473.6875]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 88us/step - loss: 55268.9062\n",
      "rewards:  96.0 q-value:  0\n",
      "loss: [55268.90625]\n",
      "Exploring\n",
      "Selected action  [1 2]\n",
      "[1 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 80us/step - loss: 25879.7500\n",
      "rewards:  85.0 q-value:  0\n",
      "loss: [25879.75]\n",
      "Exploring\n",
      "Selected action  [2 3]\n",
      "[2 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 72us/step - loss: 57609.8438\n",
      "rewards:  117.0 q-value:  0\n",
      "loss: [57609.84375]\n",
      "Exploring\n",
      "Selected action  [0 2]\n",
      "[0 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 79us/step - loss: 85715.2500\n",
      "rewards:  128.0 q-value:  0\n",
      "loss: [85715.25]\n",
      "Exploring\n",
      "Selected action  [3 4]\n",
      "[3 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 91us/step - loss: 34489.5000\n",
      "rewards:  81.0 q-value:  0\n",
      "loss: [34489.5]\n",
      "Exploring\n",
      "Selected action  [0 2]\n",
      "[0 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 69us/step - loss: 45655.9688\n",
      "rewards:  104.0 q-value:  0\n",
      "loss: [45655.96875]\n",
      "Exploring\n",
      "Selected action  [2 3]\n",
      "[2 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 66us/step - loss: 27081.9062\n",
      "rewards:  112.0 q-value:  0\n",
      "loss: [27081.90625]\n",
      "Exploiting\n",
      "Selected action  [3 4]\n",
      "[3 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 75us/step - loss: 26069.1875\n",
      "rewards:  136.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [26069.1875]\n",
      "Exploiting\n",
      "Selected action  [3 4]\n",
      "[3 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 72us/step - loss: 36311.1250\n",
      "rewards:  130.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [36311.125]\n",
      "Exploring\n",
      "Selected action  [2 3]\n",
      "[2 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 86us/step - loss: 14277.8438\n",
      "rewards:  141.0 q-value:  0\n",
      "loss: [14277.84375]\n",
      "Exploring\n",
      "Selected action  [1 2]\n",
      "[1 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 70us/step - loss: 45506.9375\n",
      "rewards:  137.0 q-value:  0\n",
      "loss: [45506.9375]\n",
      "Exploring\n",
      "Selected action  [2 3]\n",
      "[2 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 112us/step - loss: 83983.6562\n",
      "rewards:  169.0 q-value:  0\n",
      "loss: [83983.65625]\n",
      "Exploring\n",
      "Selected action  [1 2]\n",
      "[1 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 87us/step - loss: 35267.2500\n",
      "rewards:  201.0 q-value:  0\n",
      "loss: [35267.25]\n",
      "Exploiting\n",
      "Selected action  [0 2]\n",
      "[0 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 100us/step - loss: 39530.8750\n",
      "rewards:  199.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [39530.875]\n",
      "Exploring\n",
      "Selected action  [2 3]\n",
      "[2 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 85us/step - loss: 33835.5312\n",
      "rewards:  207.0 q-value:  0\n",
      "loss: [33835.53125]\n",
      "Exploring\n",
      "Selected action  [2 3]\n",
      "[2 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 84us/step - loss: 41248.9062\n",
      "rewards:  205.0 q-value:  0\n",
      "loss: [41248.90625]\n",
      "Exploring\n",
      "Selected action  [3 4]\n",
      "[3 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 97us/step - loss: 74524.0000\n",
      "rewards:  233.0 q-value:  0\n",
      "loss: [74524.0]\n",
      "Exploiting\n",
      "Selected action  [3 2]\n",
      "[3 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 84us/step - loss: 20068.2812\n",
      "rewards:  220.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [20068.28125]\n",
      "Exploiting\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 79us/step - loss: 36584.6250\n",
      "rewards:  215.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [36584.625]\n",
      "Exploring\n",
      "Selected action  [1 2]\n",
      "[1 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 74us/step - loss: 58842.0938\n",
      "rewards:  225.0 q-value:  0\n",
      "loss: [58842.09375]\n",
      "Exploiting\n",
      "Selected action  [3 2]\n",
      "[3 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 84us/step - loss: 76431.0000\n",
      "rewards:  219.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [76431.0]\n",
      "Exploring\n",
      "Selected action  [3 2]\n",
      "[3 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 85us/step - loss: 36091.1250\n",
      "rewards:  214.0 q-value:  0\n",
      "loss: [36091.125]\n",
      "Exploring\n",
      "Selected action  [3 2]\n",
      "[3 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 73us/step - loss: 57863.3438\n",
      "rewards:  211.0 q-value:  0\n",
      "loss: [57863.34375]\n",
      "Exploring\n",
      "Selected action  [1 2]\n",
      "[1 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 86us/step - loss: 43103.8125\n",
      "rewards:  208.0 q-value:  0\n",
      "loss: [43103.8125]\n",
      "Exploring\n",
      "Selected action  [3 4]\n",
      "[3 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 86us/step - loss: 60700.3438\n",
      "rewards:  196.0 q-value:  0\n",
      "loss: [60700.34375]\n",
      "Exploring\n",
      "Selected action  [2 3]\n",
      "[2 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 125us/step - loss: 57232.5312\n",
      "rewards:  202.0 q-value:  0\n",
      "loss: [57232.53125]\n",
      "Exploring\n",
      "Selected action  [2 3]\n",
      "[2 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 61us/step - loss: 81897.3438\n",
      "rewards:  199.0 q-value:  0\n",
      "loss: [81897.34375]\n",
      "Exploring\n",
      "Selected action  [3 2]\n",
      "[3 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 78us/step - loss: 44516.5625\n",
      "rewards:  211.0 q-value:  0\n",
      "loss: [44516.5625]\n",
      "Exploring\n",
      "Selected action  [1 2]\n",
      "[1 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 94us/step - loss: 64120.7188\n",
      "rewards:  207.0 q-value:  0\n",
      "loss: [64120.71875]\n",
      "Exploiting\n",
      "Selected action  [3 4]\n",
      "[3 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 82us/step - loss: 36897.8438\n",
      "rewards:  216.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [36897.84375]\n",
      "Exploiting\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 77us/step - loss: 60048.7812\n",
      "rewards:  211.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [60048.78125]\n",
      "Exploring\n",
      "Selected action  [3 4]\n",
      "[3 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 67us/step - loss: 23421.9062\n",
      "rewards:  225.0 q-value:  0\n",
      "loss: [23421.90625]\n",
      "Exploiting\n",
      "Selected action  [3 4]\n",
      "[3 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 75us/step - loss: 77742.4688\n",
      "rewards:  221.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [77742.46875]\n",
      "Exploring\n",
      "Selected action  [1 2]\n",
      "[1 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 91us/step - loss: 52950.0312\n",
      "rewards:  239.0 q-value:  0\n",
      "loss: [52950.03125]\n",
      "Exploring\n",
      "Selected action  [3 4]\n",
      "[3 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 87us/step - loss: 35676.2812\n",
      "rewards:  226.0 q-value:  0\n",
      "loss: [35676.28125]\n",
      "Exploring\n",
      "Selected action  [3 4]\n",
      "[3 4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 74us/step - loss: 43050.2500\n",
      "rewards:  220.0 q-value:  0\n",
      "loss: [43050.25]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 77us/step - loss: 90242.2812\n",
      "rewards:  215.0 q-value:  0\n",
      "loss: [90242.28125]\n",
      "Exploring\n",
      "Selected action  [1 2]\n",
      "[1 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 97us/step - loss: 47262.7188\n",
      "rewards:  237.0 q-value:  0\n",
      "loss: [47262.71875]\n",
      "Exploring\n",
      "Selected action  [3 4]\n",
      "[3 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 125us/step - loss: 50008.0000\n",
      "rewards:  219.0 q-value:  0\n",
      "loss: [50008.0]\n",
      "Exploring\n",
      "Selected action  [3 2]\n",
      "[3 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 64us/step - loss: 52003.3438\n",
      "rewards:  206.0 q-value:  0\n",
      "loss: [52003.34375]\n",
      "Exploring\n",
      "Selected action  [3 2]\n",
      "[3 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 77us/step - loss: 17513.2500\n",
      "rewards:  203.0 q-value:  0\n",
      "loss: [17513.25]\n",
      "Exploring\n",
      "Selected action  [1 2]\n",
      "[1 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 95us/step - loss: 43536.2188\n",
      "rewards:  202.0 q-value:  0\n",
      "loss: [43536.21875]\n",
      "Exploiting\n",
      "Selected action  [3 4]\n",
      "[3 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 79us/step - loss: 45041.5625\n",
      "rewards:  182.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [45041.5625]\n",
      "Exploiting\n",
      "Selected action  [2 3]\n",
      "[2 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 70us/step - loss: 47595.5938\n",
      "rewards:  206.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [47595.59375]\n",
      "Exploiting\n",
      "Selected action  [3 4]\n",
      "[3 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 87us/step - loss: 45167.5312\n",
      "rewards:  214.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [45167.53125]\n",
      "Exploring\n",
      "Selected action  [0 2]\n",
      "[0 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 76us/step - loss: 63270.9375\n",
      "rewards:  237.0 q-value:  0\n",
      "loss: [63270.9375]\n",
      "Exploring\n",
      "Selected action  [3 4]\n",
      "[3 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 60us/step - loss: 33679.3125\n",
      "rewards:  243.0 q-value:  0\n",
      "loss: [33679.3125]\n",
      "Exploiting\n",
      "Selected action  [3 2]\n",
      "[3 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 101us/step - loss: 52006.3750\n",
      "rewards:  245.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [52006.375]\n",
      "Exploiting\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 100us/step - loss: 31310.5938\n",
      "rewards:  240.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [31310.59375]\n",
      "Exploring\n",
      "Selected action  [1 2]\n",
      "[1 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 87us/step - loss: 49390.1562\n",
      "rewards:  244.0 q-value:  0\n",
      "loss: [49390.15625]\n",
      "Exploring\n",
      "Selected action  [2 3]\n",
      "[2 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 99us/step - loss: 62646.6875\n",
      "rewards:  280.0 q-value:  0\n",
      "loss: [62646.6875]\n",
      "Exploring\n",
      "Selected action  [0 2]\n",
      "[0 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 77us/step - loss: 83561.3438\n",
      "rewards:  292.0 q-value:  0\n",
      "loss: [83561.34375]\n",
      "Exploiting\n",
      "Selected action  [3 4]\n",
      "[3 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 71us/step - loss: 100648.7500\n",
      "rewards:  264.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [100648.75]\n",
      "Exploring\n",
      "Selected action  [3 4]\n",
      "[3 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 91us/step - loss: 50488.5000\n",
      "rewards:  261.0 q-value:  0\n",
      "loss: [50488.5]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 90us/step - loss: 51654.4375\n",
      "rewards:  256.0 q-value:  0\n",
      "loss: [51654.4375]\n",
      "Exploring\n",
      "Selected action  [3 4]\n",
      "[3 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 96us/step - loss: 41230.5312\n",
      "rewards:  253.0 q-value:  0\n",
      "loss: [41230.53125]\n",
      "Exploring\n",
      "Selected action  [0 2]\n",
      "[0 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 73us/step - loss: 38558.3125\n",
      "rewards:  256.0 q-value:  0\n",
      "loss: [38558.3125]\n",
      "Exploiting\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 95us/step - loss: 38743.0938\n",
      "rewards:  251.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [38743.09375]\n",
      "Exploring\n",
      "Selected action  [0 2]\n",
      "[0 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 75us/step - loss: 32090.4688\n",
      "rewards:  259.0 q-value:  0\n",
      "loss: [32090.46875]\n",
      "Exploring\n",
      "Selected action  [3 2]\n",
      "[3 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 98us/step - loss: 45921.0312\n",
      "rewards:  253.0 q-value:  0\n",
      "loss: [45921.03125]\n",
      "Exploring\n",
      "Selected action  [1 2]\n",
      "[1 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 96us/step - loss: 27929.3750\n",
      "rewards:  243.0 q-value:  0\n",
      "loss: [27929.375]\n",
      "Exploring\n",
      "Selected action  [0 2]\n",
      "[0 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 79us/step - loss: 32354.3438\n",
      "rewards:  237.0 q-value:  0\n",
      "loss: [32354.34375]\n",
      "Exploring\n",
      "Selected action  [2 3]\n",
      "[2 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 94us/step - loss: 48615.1875\n",
      "rewards:  261.0 q-value:  0\n",
      "loss: [48615.1875]\n",
      "Exploring\n",
      "Selected action  [2 3]\n",
      "[2 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 71us/step - loss: 42881.9688\n",
      "rewards:  256.0 q-value:  0\n",
      "loss: [42881.96875]\n",
      "Exploring\n",
      "Selected action  [1 2]\n",
      "[1 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 79us/step - loss: 69410.1562\n",
      "rewards:  258.0 q-value:  0\n",
      "loss: [69410.15625]\n",
      "Exploring\n",
      "Selected action  [0 2]\n",
      "[0 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 90us/step - loss: 62239.5000\n",
      "rewards:  255.0 q-value:  0\n",
      "loss: [62239.5]\n",
      "Exploring\n",
      "Selected action  [1 2]\n",
      "[1 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 84us/step - loss: 46876.4688\n",
      "rewards:  244.0 q-value:  0\n",
      "loss: [46876.46875]\n",
      "Number of actions available 8\n",
      "Episode : 32\n",
      "Exploring\n",
      "Selected action  [0 3]\n",
      "[0 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 92us/step - loss: 39510.6875\n",
      "rewards:  -6.0 q-value:  0\n",
      "loss: [39510.6875]\n",
      "Exploring\n",
      "Selected action  [3 1]\n",
      "[3 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 92us/step - loss: 36367.1562\n",
      "rewards:  10.0 q-value:  0\n",
      "loss: [36367.15625]\n",
      "Exploring\n",
      "Selected action  [3 1]\n",
      "[3 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 86us/step - loss: 27168.3750\n",
      "rewards:  10.0 q-value:  0\n",
      "loss: [27168.375]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 122us/step - loss: 47417.5625\n",
      "rewards:  0.0 q-value:  0\n",
      "loss: [47417.5625]\n",
      "Exploring\n",
      "Selected action  [3 1]\n",
      "[3 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 94us/step - loss: 42199.3750\n",
      "rewards:  -15.0 q-value:  0\n",
      "loss: [42199.375]\n",
      "Exploring\n",
      "Selected action  [4 1]\n",
      "[4 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 78us/step - loss: 68696.1250\n",
      "rewards:  -17.0 q-value:  0\n",
      "loss: [68696.125]\n",
      "Exploiting\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 72us/step - loss: 59026.9688\n",
      "rewards:  -27.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [59026.96875]\n",
      "Exploiting\n",
      "Selected action  [3 1]\n",
      "[3 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 83us/step - loss: 51673.6562\n",
      "rewards:  -42.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [51673.65625]\n",
      "Exploiting\n",
      "Selected action  [1 4]\n",
      "[1 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 71us/step - loss: 40002.4062\n",
      "rewards:  -34.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [40002.40625]\n",
      "Exploiting\n",
      "Selected action  [4 1]\n",
      "[4 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 70us/step - loss: 44961.0625\n",
      "rewards:  -26.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [44961.0625]\n",
      "Exploring\n",
      "Selected action  [4 1]\n",
      "[4 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 75us/step - loss: 44057.7188\n",
      "rewards:  -29.0 q-value:  0\n",
      "loss: [44057.71875]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 117us/step - loss: 14224.6562\n",
      "rewards:  -61.0 q-value:  0\n",
      "loss: [14224.65625]\n",
      "Exploring\n",
      "Selected action  [3 1]\n",
      "[3 1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 77us/step - loss: 34045.3438\n",
      "rewards:  -51.0 q-value:  0\n",
      "loss: [34045.34375]\n",
      "Exploring\n",
      "Selected action  [3 0]\n",
      "[3 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 100us/step - loss: 63721.6875\n",
      "rewards:  -36.0 q-value:  0\n",
      "loss: [63721.6875]\n",
      "Exploring\n",
      "Selected action  [1 4]\n",
      "[1 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 85us/step - loss: 80159.2188\n",
      "rewards:  -56.0 q-value:  0\n",
      "loss: [80159.21875]\n",
      "Exploring\n",
      "Selected action  [3 0]\n",
      "[3 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 74us/step - loss: 28867.9688\n",
      "rewards:  -93.0 q-value:  0\n",
      "loss: [28867.96875]\n",
      "Exploring\n",
      "Selected action  [2 1]\n",
      "[2 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 87us/step - loss: 77471.1250\n",
      "rewards:  -99.0 q-value:  0\n",
      "loss: [77471.125]\n",
      "Exploiting\n",
      "Selected action  [2 1]\n",
      "[2 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 85us/step - loss: 47630.9375\n",
      "rewards:  -104.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [47630.9375]\n",
      "Exploiting\n",
      "Selected action  [1 4]\n",
      "[1 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 81us/step - loss: 65239.0625\n",
      "rewards:  -88.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [65239.0625]\n",
      "Exploring\n",
      "Selected action  [0 3]\n",
      "[0 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 108us/step - loss: 61506.2500\n",
      "rewards:  -69.0 q-value:  0\n",
      "loss: [61506.25]\n",
      "Exploiting\n",
      "Selected action  [4 1]\n",
      "[4 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 68us/step - loss: 27161.7500\n",
      "rewards:  -96.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [27161.75]\n",
      "Exploiting\n",
      "Selected action  [3 0]\n",
      "[3 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 85us/step - loss: 74830.9688\n",
      "rewards:  -94.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [74830.96875]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 85us/step - loss: 35092.2500\n",
      "rewards:  -99.0 q-value:  0\n",
      "loss: [35092.25]\n",
      "Exploiting\n",
      "Selected action  [3 0]\n",
      "[3 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 75us/step - loss: 34352.5938\n",
      "rewards:  -100.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [34352.59375]\n",
      "Exploring\n",
      "Selected action  [2 1]\n",
      "[2 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 77us/step - loss: 49536.0312\n",
      "rewards:  -103.0 q-value:  0\n",
      "loss: [49536.03125]\n",
      "Exploiting\n",
      "Selected action  [2 1]\n",
      "[2 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 88us/step - loss: 36064.5312\n",
      "rewards:  -114.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [36064.53125]\n",
      "Exploiting\n",
      "Selected action  [1 4]\n",
      "[1 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 77us/step - loss: 67355.0312\n",
      "rewards:  -98.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [67355.03125]\n",
      "Exploiting\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 83us/step - loss: 34712.4062\n",
      "rewards:  -102.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [34712.40625]\n",
      "Exploiting\n",
      "Selected action  [1 4]\n",
      "[1 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 102us/step - loss: 71740.0625\n",
      "rewards:  -102.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [71740.0625]\n",
      "Exploring\n",
      "Selected action  [2 1]\n",
      "[2 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 97us/step - loss: 61205.7188\n",
      "rewards:  -108.0 q-value:  0\n",
      "loss: [61205.71875]\n",
      "Exploring\n",
      "Selected action  [3 0]\n",
      "[3 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 85us/step - loss: 59752.1250\n",
      "rewards:  -105.0 q-value:  0\n",
      "loss: [59752.125]\n",
      "Exploring\n",
      "Selected action  [0 3]\n",
      "[0 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 88us/step - loss: 50526.9375\n",
      "rewards:  -97.0 q-value:  0\n",
      "loss: [50526.9375]\n",
      "Exploring\n",
      "Selected action  [0 3]\n",
      "[0 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 89us/step - loss: 19327.8438\n",
      "rewards:  -99.0 q-value:  0\n",
      "loss: [19327.84375]\n",
      "Exploring\n",
      "Selected action  [3 1]\n",
      "[3 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 107us/step - loss: 75787.3750\n",
      "rewards:  -95.0 q-value:  0\n",
      "loss: [75787.375]\n",
      "Exploring\n",
      "Selected action  [3 1]\n",
      "[3 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 81us/step - loss: 50966.4688\n",
      "rewards:  -96.0 q-value:  0\n",
      "loss: [50966.46875]\n",
      "Exploring\n",
      "Selected action  [2 1]\n",
      "[2 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 92us/step - loss: 37748.5000\n",
      "rewards:  -103.0 q-value:  0\n",
      "loss: [37748.5]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 83us/step - loss: 45135.0625\n",
      "rewards:  -108.0 q-value:  0\n",
      "loss: [45135.0625]\n",
      "Exploring\n",
      "Selected action  [4 1]\n",
      "[4 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 90us/step - loss: 62068.4688\n",
      "rewards:  -100.0 q-value:  0\n",
      "loss: [62068.46875]\n",
      "Exploring\n",
      "Selected action  [3 1]\n",
      "[3 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 81us/step - loss: 40899.6562\n",
      "rewards:  -103.0 q-value:  0\n",
      "loss: [40899.65625]\n",
      "Exploring\n",
      "Selected action  [3 0]\n",
      "[3 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 82us/step - loss: 31194.0625\n",
      "rewards:  -94.0 q-value:  0\n",
      "loss: [31194.0625]\n",
      "Exploiting\n",
      "Selected action  [1 4]\n",
      "[1 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 99us/step - loss: 59697.4688\n",
      "rewards:  -114.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [59697.46875]\n",
      "Exploring\n",
      "Selected action  [1 4]\n",
      "[1 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 71us/step - loss: 27854.8438\n",
      "rewards:  -114.0 q-value:  0\n",
      "loss: [27854.84375]\n",
      "Exploring\n",
      "Selected action  [2 1]\n",
      "[2 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 69us/step - loss: 57030.6875\n",
      "rewards:  -115.0 q-value:  0\n",
      "loss: [57030.6875]\n",
      "Exploring\n",
      "Selected action  [3 0]\n",
      "[3 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 90us/step - loss: 50340.1875\n",
      "rewards:  -115.0 q-value:  0\n",
      "loss: [50340.1875]\n",
      "Exploiting\n",
      "Selected action  [4 1]\n",
      "[4 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 68us/step - loss: 32036.0000\n",
      "rewards:  -145.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [32036.0]\n",
      "Exploring\n",
      "Selected action  [2 1]\n",
      "[2 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 101us/step - loss: 51020.9062\n",
      "rewards:  -153.0 q-value:  0\n",
      "loss: [51020.90625]\n",
      "Exploring\n",
      "Selected action  [1 4]\n",
      "[1 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 78us/step - loss: 84841.5938\n",
      "rewards:  -129.0 q-value:  0\n",
      "loss: [84841.59375]\n",
      "Exploiting\n",
      "Selected action  [1 4]\n",
      "[1 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 77us/step - loss: 43226.7188\n",
      "rewards:  -131.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [43226.71875]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 61us/step - loss: 35143.7812\n",
      "rewards:  -133.0 q-value:  0\n",
      "loss: [35143.78125]\n",
      "Exploring\n",
      "Selected action  [4 1]\n",
      "[4 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 88us/step - loss: 58693.9688\n",
      "rewards:  -125.0 q-value:  0\n",
      "loss: [58693.96875]\n",
      "Exploiting\n",
      "Selected action  [0 3]\n",
      "[0 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 94us/step - loss: 28094.1562\n",
      "rewards:  -156.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [28094.15625]\n",
      "Exploiting\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 68us/step - loss: 28081.5312\n",
      "rewards:  -186.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [28081.53125]\n",
      "Exploring\n",
      "Selected action  [3 0]\n",
      "[3 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 91us/step - loss: 41320.1250\n",
      "rewards:  -202.0 q-value:  0\n",
      "loss: [41320.125]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 112us/step - loss: 39767.6875\n",
      "rewards:  -222.0 q-value:  0\n",
      "loss: [39767.6875]\n",
      "Exploring\n",
      "Selected action  [3 0]\n",
      "[3 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 75us/step - loss: 34854.2188\n",
      "rewards:  -238.0 q-value:  0\n",
      "loss: [34854.21875]\n",
      "Exploring\n",
      "Selected action  [0 3]\n",
      "[0 3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 75us/step - loss: 38829.4375\n",
      "rewards:  -234.0 q-value:  0\n",
      "loss: [38829.4375]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 114us/step - loss: 40219.2812\n",
      "rewards:  -239.0 q-value:  0\n",
      "loss: [40219.28125]\n",
      "Exploiting\n",
      "Selected action  [2 1]\n",
      "[2 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 74us/step - loss: 50857.2812\n",
      "rewards:  -219.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [50857.28125]\n",
      "Exploring\n",
      "Selected action  [3 1]\n",
      "[3 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 79us/step - loss: 37035.0625\n",
      "rewards:  -223.0 q-value:  0\n",
      "loss: [37035.0625]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 105us/step - loss: 29400.9062\n",
      "rewards:  -233.0 q-value:  0\n",
      "loss: [29400.90625]\n",
      "Exploring\n",
      "Selected action  [1 4]\n",
      "[1 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 68us/step - loss: 32363.3438\n",
      "rewards:  -233.0 q-value:  0\n",
      "loss: [32363.34375]\n",
      "Exploiting\n",
      "Selected action  [2 1]\n",
      "[2 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 98us/step - loss: 77105.5000\n",
      "rewards:  -225.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [77105.5]\n",
      "Exploring\n",
      "Selected action  [4 1]\n",
      "[4 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 117us/step - loss: 56396.8125\n",
      "rewards:  -225.0 q-value:  0\n",
      "loss: [56396.8125]\n",
      "Exploring\n",
      "Selected action  [0 3]\n",
      "[0 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 74us/step - loss: 69982.4062\n",
      "rewards:  -229.0 q-value:  0\n",
      "loss: [69982.40625]\n",
      "Exploring\n",
      "Selected action  [0 3]\n",
      "[0 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 75us/step - loss: 35353.5312\n",
      "rewards:  -232.0 q-value:  0\n",
      "loss: [35353.53125]\n",
      "Exploring\n",
      "Selected action  [1 4]\n",
      "[1 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 76us/step - loss: 54059.4062\n",
      "rewards:  -234.0 q-value:  0\n",
      "loss: [54059.40625]\n",
      "Exploring\n",
      "Selected action  [0 3]\n",
      "[0 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 103us/step - loss: 45164.2188\n",
      "rewards:  -227.0 q-value:  0\n",
      "loss: [45164.21875]\n",
      "Exploring\n",
      "Selected action  [0 3]\n",
      "[0 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 89us/step - loss: 62163.3750\n",
      "rewards:  -233.0 q-value:  0\n",
      "loss: [62163.375]\n",
      "Exploring\n",
      "Selected action  [3 1]\n",
      "[3 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 89us/step - loss: 38103.7812\n",
      "rewards:  -217.0 q-value:  0\n",
      "loss: [38103.78125]\n",
      "Exploring\n",
      "Selected action  [4 1]\n",
      "[4 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 85us/step - loss: 50115.4375\n",
      "rewards:  -219.0 q-value:  0\n",
      "loss: [50115.4375]\n",
      "Exploring\n",
      "Selected action  [1 4]\n",
      "[1 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 85us/step - loss: 29028.8125\n",
      "rewards:  -211.0 q-value:  0\n",
      "loss: [29028.8125]\n",
      "Exploring\n",
      "Selected action  [0 3]\n",
      "[0 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 84us/step - loss: 49905.5312\n",
      "rewards:  -216.0 q-value:  0\n",
      "loss: [49905.53125]\n",
      "Exploiting\n",
      "Selected action  [0 3]\n",
      "[0 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 88us/step - loss: 87075.8750\n",
      "rewards:  -216.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [87075.875]\n",
      "Exploring\n",
      "Selected action  [4 1]\n",
      "[4 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 116us/step - loss: 72477.7812\n",
      "rewards:  -223.0 q-value:  0\n",
      "loss: [72477.78125]\n",
      "Exploring\n",
      "Selected action  [0 3]\n",
      "[0 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 100us/step - loss: 48008.6250\n",
      "rewards:  -221.0 q-value:  0\n",
      "loss: [48008.625]\n",
      "Exploring\n",
      "Selected action  [3 0]\n",
      "[3 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 66us/step - loss: 73883.5312\n",
      "rewards:  -209.0 q-value:  0\n",
      "loss: [73883.53125]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 108us/step - loss: 24211.1562\n",
      "rewards:  -214.0 q-value:  0\n",
      "loss: [24211.15625]\n",
      "Exploring\n",
      "Selected action  [3 0]\n",
      "[3 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 78us/step - loss: 47543.7812\n",
      "rewards:  -224.0 q-value:  0\n",
      "loss: [47543.78125]\n",
      "Exploring\n",
      "Selected action  [0 3]\n",
      "[0 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 72us/step - loss: 48491.2500\n",
      "rewards:  -212.0 q-value:  0\n",
      "loss: [48491.25]\n",
      "Exploiting\n",
      "Selected action  [3 0]\n",
      "[3 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 93us/step - loss: 44991.5000\n",
      "rewards:  -204.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [44991.5]\n",
      "Exploiting\n",
      "Selected action  [3 1]\n",
      "[3 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 68us/step - loss: 27680.8438\n",
      "rewards:  -210.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [27680.84375]\n",
      "Exploring\n",
      "Selected action  [0 3]\n",
      "[0 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 75us/step - loss: 72317.9062\n",
      "rewards:  -222.0 q-value:  0\n",
      "loss: [72317.90625]\n",
      "Exploring\n",
      "Selected action  [1 4]\n",
      "[1 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 108us/step - loss: 63376.9062\n",
      "rewards:  -211.0 q-value:  0\n",
      "loss: [63376.90625]\n",
      "Exploring\n",
      "Selected action  [1 4]\n",
      "[1 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 75us/step - loss: 61844.7188\n",
      "rewards:  -215.0 q-value:  0\n",
      "loss: [61844.71875]\n",
      "Exploiting\n",
      "Selected action  [2 1]\n",
      "[2 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 76us/step - loss: 59607.0938\n",
      "rewards:  -191.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [59607.09375]\n",
      "Exploring\n",
      "Selected action  [3 1]\n",
      "[3 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 116us/step - loss: 55547.7500\n",
      "rewards:  -193.0 q-value:  0\n",
      "loss: [55547.75]\n",
      "Exploiting\n",
      "Selected action  [0 3]\n",
      "[0 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 73us/step - loss: 40455.1875\n",
      "rewards:  -216.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [40455.1875]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 96us/step - loss: 75190.8750\n",
      "rewards:  -221.0 q-value:  0\n",
      "loss: [75190.875]\n",
      "Exploring\n",
      "Selected action  [3 0]\n",
      "[3 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 107us/step - loss: 39331.9688\n",
      "rewards:  -222.0 q-value:  0\n",
      "loss: [39331.96875]\n",
      "Exploring\n",
      "Selected action  [1 4]\n",
      "[1 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 116us/step - loss: 38224.9062\n",
      "rewards:  -257.0 q-value:  0\n",
      "loss: [38224.90625]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 83us/step - loss: 50389.3125\n",
      "rewards:  -258.0 q-value:  0\n",
      "loss: [50389.3125]\n",
      "Exploring\n",
      "Selected action  [0 3]\n",
      "[0 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 73us/step - loss: 52597.1562\n",
      "rewards:  -259.0 q-value:  0\n",
      "loss: [52597.15625]\n",
      "Exploring\n",
      "Selected action  [2 1]\n",
      "[2 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 88us/step - loss: 87177.3750\n",
      "rewards:  -262.0 q-value:  0\n",
      "loss: [87177.375]\n",
      "Exploring\n",
      "Selected action  [2 1]\n",
      "[2 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 108us/step - loss: 44663.6562\n",
      "rewards:  -273.0 q-value:  0\n",
      "loss: [44663.65625]\n",
      "Exploring\n",
      "Selected action  [3 1]\n",
      "[3 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 88us/step - loss: 39430.5938\n",
      "rewards:  -275.0 q-value:  0\n",
      "loss: [39430.59375]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 124us/step - loss: 40766.2500\n",
      "rewards:  -279.0 q-value:  0\n",
      "loss: [40766.25]\n",
      "Exploring\n",
      "Selected action  [0 3]\n",
      "[0 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 75us/step - loss: 42467.5938\n",
      "rewards:  -276.0 q-value:  0\n",
      "loss: [42467.59375]\n",
      "Exploiting\n",
      "Selected action  [4 1]\n",
      "[4 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 109us/step - loss: 48911.6562\n",
      "rewards:  -306.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [48911.65625]\n",
      "Exploring\n",
      "Selected action  [3 1]\n",
      "[3 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 136us/step - loss: 33169.4062\n",
      "rewards:  -307.0 q-value:  0\n",
      "loss: [33169.40625]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 98us/step - loss: 65598.1562\n",
      "rewards:  -304.0 q-value:  0\n",
      "loss: [65598.15625]\n",
      "Exploring\n",
      "Selected action  [4 1]\n",
      "[4 1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 90us/step - loss: 52732.6875\n",
      "rewards:  -304.0 q-value:  0\n",
      "loss: [52732.6875]\n",
      "Exploiting\n",
      "Selected action  [1 4]\n",
      "[1 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 102us/step - loss: 47703.3438\n",
      "rewards:  -304.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [47703.34375]\n",
      "Exploring\n",
      "Selected action  [4 1]\n",
      "[4 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 90us/step - loss: 37568.0938\n",
      "rewards:  -304.0 q-value:  0\n",
      "loss: [37568.09375]\n",
      "Exploring\n",
      "Selected action  [0 3]\n",
      "[0 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 75us/step - loss: 47886.5000\n",
      "rewards:  -326.0 q-value:  0\n",
      "loss: [47886.5]\n",
      "Exploiting\n",
      "Selected action  [3 1]\n",
      "[3 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 78us/step - loss: 40936.0312\n",
      "rewards:  -322.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [40936.03125]\n",
      "Exploring\n",
      "Selected action  [3 0]\n",
      "[3 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 111us/step - loss: 69390.0625\n",
      "rewards:  -319.0 q-value:  0\n",
      "loss: [69390.0625]\n",
      "Exploring\n",
      "Selected action  [3 0]\n",
      "[3 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 88us/step - loss: 34283.2188\n",
      "rewards:  -321.0 q-value:  0\n",
      "loss: [34283.21875]\n",
      "Exploring\n",
      "Selected action  [4 1]\n",
      "[4 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 110us/step - loss: 27434.6875\n",
      "rewards:  -313.0 q-value:  0\n",
      "loss: [27434.6875]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 87us/step - loss: 50690.0938\n",
      "rewards:  -318.0 q-value:  0\n",
      "loss: [50690.09375]\n",
      "Exploring\n",
      "Selected action  [3 0]\n",
      "[3 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 99us/step - loss: 51647.6562\n",
      "rewards:  -323.0 q-value:  0\n",
      "loss: [51647.65625]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 89us/step - loss: 34491.6250\n",
      "rewards:  -328.0 q-value:  0\n",
      "loss: [34491.625]\n",
      "Exploiting\n",
      "Selected action  [1 4]\n",
      "[1 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 86us/step - loss: 51541.7500\n",
      "rewards:  -339.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [51541.75]\n",
      "Exploiting\n",
      "Selected action  [0 3]\n",
      "[0 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 67us/step - loss: 75633.8750\n",
      "rewards:  -319.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [75633.875]\n",
      "Exploring\n",
      "Selected action  [4 1]\n",
      "[4 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 81us/step - loss: 75539.7500\n",
      "rewards:  -349.0 q-value:  0\n",
      "loss: [75539.75]\n",
      "Exploring\n",
      "Selected action  [3 0]\n",
      "[3 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 93us/step - loss: 18443.0625\n",
      "rewards:  -342.0 q-value:  0\n",
      "loss: [18443.0625]\n",
      "Exploring\n",
      "Selected action  [3 1]\n",
      "[3 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 96us/step - loss: 54299.9062\n",
      "rewards:  -353.0 q-value:  0\n",
      "loss: [54299.90625]\n",
      "Exploring\n",
      "Selected action  [3 0]\n",
      "[3 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 106us/step - loss: 58213.1562\n",
      "rewards:  -346.0 q-value:  0\n",
      "loss: [58213.15625]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 115us/step - loss: 47528.3750\n",
      "rewards:  -351.0 q-value:  0\n",
      "loss: [47528.375]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 79us/step - loss: 48411.4062\n",
      "rewards:  -362.0 q-value:  0\n",
      "loss: [48411.40625]\n",
      "Exploring\n",
      "Selected action  [0 3]\n",
      "[0 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 115us/step - loss: 17208.1562\n",
      "rewards:  -339.0 q-value:  0\n",
      "loss: [17208.15625]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 86us/step - loss: 33746.5312\n",
      "rewards:  -344.0 q-value:  0\n",
      "loss: [33746.53125]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 75us/step - loss: 56845.7188\n",
      "rewards:  -349.0 q-value:  0\n",
      "loss: [56845.71875]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 131us/step - loss: 42072.5938\n",
      "rewards:  -342.0 q-value:  0\n",
      "loss: [42072.59375]\n",
      "Exploring\n",
      "Selected action  [4 1]\n",
      "[4 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 87us/step - loss: 29381.2500\n",
      "rewards:  -334.0 q-value:  0\n",
      "loss: [29381.25]\n",
      "Exploring\n",
      "Selected action  [2 1]\n",
      "[2 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 89us/step - loss: 64135.0312\n",
      "rewards:  -344.0 q-value:  0\n",
      "loss: [64135.03125]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 108us/step - loss: 51746.4062\n",
      "rewards:  -349.0 q-value:  0\n",
      "loss: [51746.40625]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 75us/step - loss: 55234.2812\n",
      "rewards:  -384.0 q-value:  0\n",
      "loss: [55234.28125]\n",
      "Exploring\n",
      "Selected action  [3 1]\n",
      "[3 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 116us/step - loss: 61013.2188\n",
      "rewards:  -378.0 q-value:  0\n",
      "loss: [61013.21875]\n",
      "Exploiting\n",
      "Selected action  [2 1]\n",
      "[2 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 73us/step - loss: 50536.1875\n",
      "rewards:  -389.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [50536.1875]\n",
      "Exploring\n",
      "Selected action  [1 4]\n",
      "[1 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 93us/step - loss: 53621.2500\n",
      "rewards:  -381.0 q-value:  0\n",
      "loss: [53621.25]\n",
      "Exploring\n",
      "Selected action  [1 4]\n",
      "[1 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 90us/step - loss: 50750.0000\n",
      "rewards:  -383.0 q-value:  0\n",
      "loss: [50750.0]\n",
      "Exploring\n",
      "Selected action  [2 1]\n",
      "[2 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 75us/step - loss: 50236.3438\n",
      "rewards:  -380.0 q-value:  0\n",
      "loss: [50236.34375]\n",
      "Exploring\n",
      "Selected action  [4 1]\n",
      "[4 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 92us/step - loss: 48286.4375\n",
      "rewards:  -387.0 q-value:  0\n",
      "loss: [48286.4375]\n",
      "Exploiting\n",
      "Selected action  [4 1]\n",
      "[4 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 77us/step - loss: 57406.1875\n",
      "rewards:  -389.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [57406.1875]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 83us/step - loss: 52794.3438\n",
      "rewards:  -394.0 q-value:  0\n",
      "loss: [52794.34375]\n",
      "Exploiting\n",
      "Selected action  [0 3]\n",
      "[0 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 93us/step - loss: 40057.4688\n",
      "rewards:  -394.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [40057.46875]\n",
      "Exploring\n",
      "Selected action  [0 3]\n",
      "[0 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 71us/step - loss: 44621.0625\n",
      "rewards:  -394.0 q-value:  0\n",
      "loss: [44621.0625]\n",
      "Exploring\n",
      "Selected action  [4 1]\n",
      "[4 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 89us/step - loss: 45638.6875\n",
      "rewards:  -401.0 q-value:  0\n",
      "loss: [45638.6875]\n",
      "Exploiting\n",
      "Selected action  [3 1]\n",
      "[3 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 116us/step - loss: 50336.5938\n",
      "rewards:  -401.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [50336.59375]\n",
      "Exploiting\n",
      "Selected action  [3 0]\n",
      "[3 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 84us/step - loss: 57697.2500\n",
      "rewards:  -389.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [57697.25]\n",
      "Exploiting\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 100us/step - loss: 39783.2188\n",
      "rewards:  -394.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [39783.21875]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 94us/step - loss: 34677.4062\n",
      "rewards:  -399.0 q-value:  0\n",
      "loss: [34677.40625]\n",
      "Exploring\n",
      "Selected action  [3 1]\n",
      "[3 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 94us/step - loss: 60288.0312\n",
      "rewards:  -414.0 q-value:  0\n",
      "loss: [60288.03125]\n",
      "Number of actions available 6\n",
      "Episode : 33\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 107us/step - loss: 26649.5312\n",
      "rewards:  -5 q-value:  0\n",
      "loss: [26649.53125]\n",
      "Exploring\n",
      "Selected action  [1 2]\n",
      "[1 2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 79us/step - loss: 53213.5625\n",
      "rewards:  -7.0 q-value:  0\n",
      "loss: [53213.5625]\n",
      "Exploiting\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 85us/step - loss: 35345.0625\n",
      "rewards:  -12.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [35345.0625]\n",
      "Exploring\n",
      "Selected action  [3 4]\n",
      "[3 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 75us/step - loss: 37026.5938\n",
      "rewards:  1.0 q-value:  0\n",
      "loss: [37026.59375]\n",
      "Exploring\n",
      "Selected action  [0 3]\n",
      "[0 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 88us/step - loss: 66946.4688\n",
      "rewards:  -4.0 q-value:  0\n",
      "loss: [66946.46875]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 77us/step - loss: 48341.0938\n",
      "rewards:  -44.0 q-value:  0\n",
      "loss: [48341.09375]\n",
      "Exploring\n",
      "Selected action  [3 4]\n",
      "[3 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 122us/step - loss: 61454.8438\n",
      "rewards:  -47.0 q-value:  0\n",
      "loss: [61454.84375]\n",
      "Exploring\n",
      "Selected action  [4 1]\n",
      "[4 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 129us/step - loss: 59065.7188\n",
      "rewards:  -35.0 q-value:  0\n",
      "loss: [59065.71875]\n",
      "Exploring\n",
      "Selected action  [1 2]\n",
      "[1 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 83us/step - loss: 41701.9375\n",
      "rewards:  -3.0 q-value:  0\n",
      "loss: [41701.9375]\n",
      "Exploring\n",
      "Selected action  [3 4]\n",
      "[3 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 110us/step - loss: 84517.6562\n",
      "rewards:  15.0 q-value:  0\n",
      "loss: [84517.65625]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 74us/step - loss: 43687.2188\n",
      "rewards:  10.0 q-value:  0\n",
      "loss: [43687.21875]\n",
      "Exploiting\n",
      "Selected action  [4 1]\n",
      "[4 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 91us/step - loss: 57690.6250\n",
      "rewards:  -5.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [57690.625]\n",
      "Exploiting\n",
      "Selected action  [1 2]\n",
      "[1 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 100us/step - loss: 75910.3438\n",
      "rewards:  -1.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [75910.34375]\n",
      "Exploiting\n",
      "Selected action  [4 1]\n",
      "[4 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 80us/step - loss: 38912.9375\n",
      "rewards:  -11.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [38912.9375]\n",
      "Exploring\n",
      "Selected action  [1 2]\n",
      "[1 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 85us/step - loss: 64328.8438\n",
      "rewards:  -7.0 q-value:  0\n",
      "loss: [64328.84375]\n",
      "Exploring\n",
      "Selected action  [4 1]\n",
      "[4 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 110us/step - loss: 30085.6250\n",
      "rewards:  -17.0 q-value:  0\n",
      "loss: [30085.625]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 81us/step - loss: 37977.5938\n",
      "rewards:  -14.0 q-value:  0\n",
      "loss: [37977.59375]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 131us/step - loss: 34682.4688\n",
      "rewards:  -19.0 q-value:  0\n",
      "loss: [34682.46875]\n",
      "Exploring\n",
      "Selected action  [0 3]\n",
      "[0 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 84us/step - loss: 28994.0625\n",
      "rewards:  -19.0 q-value:  0\n",
      "loss: [28994.0625]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 85us/step - loss: 35593.1562\n",
      "rewards:  -34.0 q-value:  0\n",
      "loss: [35593.15625]\n",
      "Exploring\n",
      "Selected action  [1 2]\n",
      "[1 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 89us/step - loss: 31866.8750\n",
      "rewards:  -34.0 q-value:  0\n",
      "loss: [31866.875]\n",
      "Exploiting\n",
      "Selected action  [0 3]\n",
      "[0 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 84us/step - loss: 40670.4375\n",
      "rewards:  -64.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [40670.4375]\n",
      "Exploiting\n",
      "Selected action  [3 4]\n",
      "[3 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 77us/step - loss: 34721.4375\n",
      "rewards:  -44.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [34721.4375]\n",
      "Exploiting\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 80us/step - loss: 14382.6875\n",
      "rewards:  -49.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [14382.6875]\n",
      "Exploring\n",
      "Selected action  [4 1]\n",
      "[4 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 82us/step - loss: 40634.6250\n",
      "rewards:  -50.0 q-value:  0\n",
      "loss: [40634.625]\n",
      "Exploring\n",
      "Selected action  [1 2]\n",
      "[1 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 103us/step - loss: 42547.5000\n",
      "rewards:  -26.0 q-value:  0\n",
      "loss: [42547.5]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 88us/step - loss: 57272.2500\n",
      "rewards:  -31.0 q-value:  0\n",
      "loss: [57272.25]\n",
      "Exploring\n",
      "Selected action  [1 2]\n",
      "[1 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 90us/step - loss: 47506.6875\n",
      "rewards:  -30.0 q-value:  0\n",
      "loss: [47506.6875]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 95us/step - loss: 42765.3750\n",
      "rewards:  -22.0 q-value:  0\n",
      "loss: [42765.375]\n",
      "Exploring\n",
      "Selected action  [4 1]\n",
      "[4 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 96us/step - loss: 45374.0625\n",
      "rewards:  -22.0 q-value:  0\n",
      "loss: [45374.0625]\n",
      "Exploring\n",
      "Selected action  [1 2]\n",
      "[1 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 97us/step - loss: 60540.0312\n",
      "rewards:  22.0 q-value:  0\n",
      "loss: [60540.03125]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 82us/step - loss: 35007.8750\n",
      "rewards:  17.0 q-value:  0\n",
      "loss: [35007.875]\n",
      "Exploring\n",
      "Selected action  [4 1]\n",
      "[4 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 91us/step - loss: 51494.0938\n",
      "rewards:  30.0 q-value:  0\n",
      "loss: [51494.09375]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 97us/step - loss: 68118.9375\n",
      "rewards:  25.0 q-value:  0\n",
      "loss: [68118.9375]\n",
      "Exploring\n",
      "Selected action  [1 2]\n",
      "[1 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 91us/step - loss: 42625.7188\n",
      "rewards:  -1.0 q-value:  0\n",
      "loss: [42625.71875]\n",
      "Exploiting\n",
      "Selected action  [3 4]\n",
      "[3 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 102us/step - loss: 46883.1562\n",
      "rewards:  3.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [46883.15625]\n",
      "Exploring\n",
      "Selected action  [4 1]\n",
      "[4 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 104us/step - loss: 33317.7500\n",
      "rewards:  15.0 q-value:  0\n",
      "loss: [33317.75]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 93us/step - loss: 32680.5625\n",
      "rewards:  -12.0 q-value:  0\n",
      "loss: [32680.5625]\n",
      "Exploiting\n",
      "Selected action  [4 1]\n",
      "[4 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 69us/step - loss: 57985.3750\n",
      "rewards:  -4.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [57985.375]\n",
      "Exploring\n",
      "Selected action  [3 4]\n",
      "[3 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 80us/step - loss: 60752.0625\n",
      "rewards:  -7.0 q-value:  0\n",
      "loss: [60752.0625]\n",
      "Exploring\n",
      "Selected action  [4 1]\n",
      "[4 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 109us/step - loss: 51816.6250\n",
      "rewards:  17.0 q-value:  0\n",
      "loss: [51816.625]\n",
      "Exploring\n",
      "Selected action  [4 1]\n",
      "[4 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 73us/step - loss: 14768.4375\n",
      "rewards:  17.0 q-value:  0\n",
      "loss: [14768.4375]\n",
      "Exploring\n",
      "Selected action  [3 4]\n",
      "[3 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 118us/step - loss: 45883.3750\n",
      "rewards:  21.0 q-value:  0\n",
      "loss: [45883.375]\n",
      "Exploring\n",
      "Selected action  [1 2]\n",
      "[1 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 90us/step - loss: 28599.7812\n",
      "rewards:  53.0 q-value:  0\n",
      "loss: [28599.78125]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 84us/step - loss: 22587.9688\n",
      "rewards:  57.0 q-value:  0\n",
      "loss: [22587.96875]\n",
      "Exploiting\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 123us/step - loss: 49709.4062\n",
      "rewards:  49.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [49709.40625]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 94us/step - loss: 22966.1250\n",
      "rewards:  47.0 q-value:  0\n",
      "loss: [22966.125]\n",
      "Exploring\n",
      "Selected action  [4 1]\n",
      "[4 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 79us/step - loss: 41223.4062\n",
      "rewards:  55.0 q-value:  0\n",
      "loss: [41223.40625]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 77us/step - loss: 65671.0625\n",
      "rewards:  50.0 q-value:  0\n",
      "loss: [65671.0625]\n",
      "Exploiting\n",
      "Selected action  [3 4]\n",
      "[3 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 75us/step - loss: 67672.0625\n",
      "rewards:  61.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [67672.0625]\n",
      "Exploiting\n",
      "Selected action  [3 4]\n",
      "[3 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 78us/step - loss: 49650.6250\n",
      "rewards:  57.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [49650.625]\n",
      "Exploring\n",
      "Selected action  [0 3]\n",
      "[0 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 74us/step - loss: 38455.5938\n",
      "rewards:  68.0 q-value:  0\n",
      "loss: [38455.59375]\n",
      "Exploring\n",
      "Selected action  [3 4]\n",
      "[3 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 67us/step - loss: 22417.3750\n",
      "rewards:  84.0 q-value:  0\n",
      "loss: [22417.375]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 96us/step - loss: 43578.1562\n",
      "rewards:  76.0 q-value:  0\n",
      "loss: [43578.15625]\n",
      "Exploiting\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 84us/step - loss: 57721.2188\n",
      "rewards:  76.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [57721.21875]\n",
      "Exploring\n",
      "Selected action  [4 1]\n",
      "[4 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 104us/step - loss: 36517.6250\n",
      "rewards:  84.0 q-value:  0\n",
      "loss: [36517.625]\n",
      "Exploring\n",
      "Selected action  [0 3]\n",
      "[0 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 79us/step - loss: 48331.5000\n",
      "rewards:  76.0 q-value:  0\n",
      "loss: [48331.5]\n",
      "Exploiting\n",
      "Selected action  [4 1]\n",
      "[4 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 98us/step - loss: 55868.9375\n",
      "rewards:  54.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [55868.9375]\n",
      "Exploring\n",
      "Selected action  [4 1]\n",
      "[4 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 86us/step - loss: 32605.4375\n",
      "rewards:  52.0 q-value:  0\n",
      "loss: [32605.4375]\n",
      "Exploring\n",
      "Selected action  [3 4]\n",
      "[3 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 113us/step - loss: 27138.2812\n",
      "rewards:  40.0 q-value:  0\n",
      "loss: [27138.28125]\n",
      "Exploring\n",
      "Selected action  [0 3]\n",
      "[0 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 78us/step - loss: 74576.3125\n",
      "rewards:  59.0 q-value:  0\n",
      "loss: [74576.3125]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 93us/step - loss: 27244.6875\n",
      "rewards:  45.0 q-value:  0\n",
      "loss: [27244.6875]\n",
      "Exploiting\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 86us/step - loss: 34101.8750\n",
      "rewards:  40.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [34101.875]\n",
      "Exploiting\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 83us/step - loss: 57713.6562\n",
      "rewards:  35.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [57713.65625]\n",
      "Exploiting\n",
      "Selected action  [1 2]\n",
      "[1 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 80us/step - loss: 48165.8438\n",
      "rewards:  33.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [48165.84375]\n",
      "Exploiting\n",
      "Selected action  [4 1]\n",
      "[4 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 93us/step - loss: 54438.7812\n",
      "rewards:  41.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [54438.78125]\n",
      "Exploring\n",
      "Selected action  [0 3]\n",
      "[0 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 105us/step - loss: 33412.0000\n",
      "rewards:  43.0 q-value:  0\n",
      "loss: [33412.0]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 80us/step - loss: 24383.7188\n",
      "rewards:  38.0 q-value:  0\n",
      "loss: [24383.71875]\n",
      "Exploiting\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 86us/step - loss: 42208.2188\n",
      "rewards:  21.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [42208.21875]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 70us/step - loss: 50767.5000\n",
      "rewards:  20.0 q-value:  0\n",
      "loss: [50767.5]\n",
      "Exploiting\n",
      "Selected action  [4 1]\n",
      "[4 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 83us/step - loss: 67198.0000\n",
      "rewards:  36.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [67198.0]\n",
      "Exploring\n",
      "Selected action  [0 3]\n",
      "[0 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 89us/step - loss: 31369.9688\n",
      "rewards:  66.0 q-value:  0\n",
      "loss: [31369.96875]\n",
      "Exploring\n",
      "Selected action  [1 2]\n",
      "[1 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 80us/step - loss: 52564.3125\n",
      "rewards:  65.0 q-value:  0\n",
      "loss: [52564.3125]\n",
      "Exploring\n",
      "Selected action  [0 3]\n",
      "[0 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 79us/step - loss: 73478.8125\n",
      "rewards:  63.0 q-value:  0\n",
      "loss: [73478.8125]\n",
      "Exploiting\n",
      "Selected action  [4 1]\n",
      "[4 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 74us/step - loss: 49673.4688\n",
      "rewards:  54.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [49673.46875]\n",
      "Exploring\n",
      "Selected action  [4 1]\n",
      "[4 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 75us/step - loss: 26352.8750\n",
      "rewards:  50.0 q-value:  0\n",
      "loss: [26352.875]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 90us/step - loss: 27558.5625\n",
      "rewards:  20.0 q-value:  0\n",
      "loss: [27558.5625]\n",
      "Exploring\n",
      "Selected action  [0 3]\n",
      "[0 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 76us/step - loss: 28962.2812\n",
      "rewards:  39.0 q-value:  0\n",
      "loss: [28962.28125]\n",
      "Exploiting\n",
      "Selected action  [1 2]\n",
      "[1 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 105us/step - loss: 26361.5625\n",
      "rewards:  65.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [26361.5625]\n",
      "Exploring\n",
      "Selected action  [3 4]\n",
      "[3 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 83us/step - loss: 38963.5938\n",
      "rewards:  74.0 q-value:  0\n",
      "loss: [38963.59375]\n",
      "Exploiting\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 80us/step - loss: 42943.1250\n",
      "rewards:  69.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [42943.125]\n",
      "Exploiting\n",
      "Selected action  [0 3]\n",
      "[0 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 78us/step - loss: 24894.3125\n",
      "rewards:  73.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [24894.3125]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 92us/step - loss: 38076.3750\n",
      "rewards:  68.0 q-value:  0\n",
      "loss: [38076.375]\n",
      "Exploiting\n",
      "Selected action  [0 3]\n",
      "[0 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 91us/step - loss: 46597.4375\n",
      "rewards:  100.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [46597.4375]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 72us/step - loss: 40364.1250\n",
      "rewards:  95.0 q-value:  0\n",
      "loss: [40364.125]\n",
      "Exploring\n",
      "Selected action  [1 2]\n",
      "[1 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 81us/step - loss: 17822.0625\n",
      "rewards:  66.0 q-value:  0\n",
      "loss: [17822.0625]\n",
      "Exploring\n",
      "Selected action  [4 1]\n",
      "[4 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 85us/step - loss: 38818.5000\n",
      "rewards:  56.0 q-value:  0\n",
      "loss: [38818.5]\n",
      "Exploring\n",
      "Selected action  [4 1]\n",
      "[4 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 96us/step - loss: 98191.2812\n",
      "rewards:  56.0 q-value:  0\n",
      "loss: [98191.28125]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 107us/step - loss: 33885.6250\n",
      "rewards:  51.0 q-value:  0\n",
      "loss: [33885.625]\n",
      "Exploring\n",
      "Selected action  [1 2]\n",
      "[1 2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 94us/step - loss: 50309.2812\n",
      "rewards:  25.0 q-value:  0\n",
      "loss: [50309.28125]\n",
      "Exploring\n",
      "Selected action  [1 2]\n",
      "[1 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 94us/step - loss: 40938.6875\n",
      "rewards:  24.0 q-value:  0\n",
      "loss: [40938.6875]\n",
      "Exploring\n",
      "Selected action  [0 3]\n",
      "[0 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 89us/step - loss: 17286.8750\n",
      "rewards:  27.0 q-value:  0\n",
      "loss: [17286.875]\n",
      "Exploiting\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 81us/step - loss: 51374.6250\n",
      "rewards:  22.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [51374.625]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 82us/step - loss: 39420.4688\n",
      "rewards:  17.0 q-value:  0\n",
      "loss: [39420.46875]\n",
      "Exploiting\n",
      "Selected action  [3 4]\n",
      "[3 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 103us/step - loss: 31463.9688\n",
      "rewards:  31.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [31463.96875]\n",
      "Exploring\n",
      "Selected action  [3 4]\n",
      "[3 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 77us/step - loss: 29234.3438\n",
      "rewards:  27.0 q-value:  0\n",
      "loss: [29234.34375]\n",
      "Exploring\n",
      "Selected action  [1 2]\n",
      "[1 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 98us/step - loss: 38243.4062\n",
      "rewards:  45.0 q-value:  0\n",
      "loss: [38243.40625]\n",
      "Exploring\n",
      "Selected action  [3 4]\n",
      "[3 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 84us/step - loss: 40280.4062\n",
      "rewards:  32.0 q-value:  0\n",
      "loss: [40280.40625]\n",
      "Exploring\n",
      "Selected action  [0 3]\n",
      "[0 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 84us/step - loss: 50102.2812\n",
      "rewards:  52.0 q-value:  0\n",
      "loss: [50102.28125]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 100us/step - loss: 14919.5000\n",
      "rewards:  47.0 q-value:  0\n",
      "loss: [14919.5]\n",
      "Exploring\n",
      "Selected action  [0 3]\n",
      "[0 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 98us/step - loss: 44126.7188\n",
      "rewards:  67.0 q-value:  0\n",
      "loss: [44126.71875]\n",
      "Exploring\n",
      "Selected action  [1 2]\n",
      "[1 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 93us/step - loss: 54361.0000\n",
      "rewards:  94.0 q-value:  0\n",
      "loss: [54361.0]\n",
      "Exploring\n",
      "Selected action  [0 3]\n",
      "[0 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 100us/step - loss: 38517.3750\n",
      "rewards:  73.0 q-value:  0\n",
      "loss: [38517.375]\n",
      "Exploring\n",
      "Selected action  [0 3]\n",
      "[0 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 98us/step - loss: 61944.2500\n",
      "rewards:  72.0 q-value:  0\n",
      "loss: [61944.25]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 87us/step - loss: 55358.3750\n",
      "rewards:  67.0 q-value:  0\n",
      "loss: [55358.375]\n",
      "Exploring\n",
      "Selected action  [1 2]\n",
      "[1 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 101us/step - loss: 59975.6875\n",
      "rewards:  55.0 q-value:  0\n",
      "loss: [59975.6875]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 84us/step - loss: 85149.7812\n",
      "rewards:  63.0 q-value:  0\n",
      "loss: [85149.78125]\n",
      "Exploiting\n",
      "Selected action  [1 2]\n",
      "[1 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 96us/step - loss: 29306.2188\n",
      "rewards:  57.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [29306.21875]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 95us/step - loss: 56656.0000\n",
      "rewards:  52.0 q-value:  0\n",
      "loss: [56656.0]\n",
      "Exploiting\n",
      "Selected action  [0 3]\n",
      "[0 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 100us/step - loss: 27271.1562\n",
      "rewards:  56.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [27271.15625]\n",
      "Exploiting\n",
      "Selected action  [3 4]\n",
      "[3 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 103us/step - loss: 39316.0000\n",
      "rewards:  72.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [39316.0]\n",
      "Exploiting\n",
      "Selected action  [3 4]\n",
      "[3 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 90us/step - loss: 45128.6250\n",
      "rewards:  68.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [45128.625]\n",
      "Exploiting\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 124us/step - loss: 31744.4688\n",
      "rewards:  68.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [31744.46875]\n",
      "Exploring\n",
      "Selected action  [3 4]\n",
      "[3 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 91us/step - loss: 24478.3750\n",
      "rewards:  66.0 q-value:  0\n",
      "loss: [24478.375]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 75us/step - loss: 18490.1875\n",
      "rewards:  66.0 q-value:  0\n",
      "loss: [18490.1875]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 78us/step - loss: 47579.0938\n",
      "rewards:  66.0 q-value:  0\n",
      "loss: [47579.09375]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 69us/step - loss: 48173.8125\n",
      "rewards:  66.0 q-value:  0\n",
      "loss: [48173.8125]\n",
      "Exploiting\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 91us/step - loss: 54276.5625\n",
      "rewards:  61.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [54276.5625]\n",
      "Exploring\n",
      "Selected action  [3 4]\n",
      "[3 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 74us/step - loss: 63974.1562\n",
      "rewards:  49.0 q-value:  0\n",
      "loss: [63974.15625]\n",
      "Exploring\n",
      "Selected action  [0 3]\n",
      "[0 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 76us/step - loss: 40441.5312\n",
      "rewards:  73.0 q-value:  0\n",
      "loss: [40441.53125]\n",
      "Exploiting\n",
      "Selected action  [0 3]\n",
      "[0 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 84us/step - loss: 37075.1562\n",
      "rewards:  69.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [37075.15625]\n",
      "Exploring\n",
      "Selected action  [3 4]\n",
      "[3 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 81us/step - loss: 31198.0625\n",
      "rewards:  93.0 q-value:  0\n",
      "loss: [31198.0625]\n",
      "Exploring\n",
      "Selected action  [3 4]\n",
      "[3 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 72us/step - loss: 35232.0938\n",
      "rewards:  87.0 q-value:  0\n",
      "loss: [35232.09375]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 86us/step - loss: 34744.6250\n",
      "rewards:  82.0 q-value:  0\n",
      "loss: [34744.625]\n",
      "Exploring\n",
      "Selected action  [0 3]\n",
      "[0 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 105us/step - loss: 36843.6250\n",
      "rewards:  79.0 q-value:  0\n",
      "loss: [36843.625]\n",
      "Exploring\n",
      "Selected action  [0 3]\n",
      "[0 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 87us/step - loss: 20296.8750\n",
      "rewards:  79.0 q-value:  0\n",
      "loss: [20296.875]\n",
      "Exploiting\n",
      "Selected action  [0 3]\n",
      "[0 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 99us/step - loss: 32451.5312\n",
      "rewards:  79.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [32451.53125]\n",
      "Exploring\n",
      "Selected action  [1 2]\n",
      "[1 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 65us/step - loss: 30947.9688\n",
      "rewards:  87.0 q-value:  0\n",
      "loss: [30947.96875]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 66us/step - loss: 75404.0625\n",
      "rewards:  87.0 q-value:  0\n",
      "loss: [75404.0625]\n",
      "Exploring\n",
      "Selected action  [1 2]\n",
      "[1 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 97us/step - loss: 40687.0938\n",
      "rewards:  85.0 q-value:  0\n",
      "loss: [40687.09375]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 104us/step - loss: 35494.6250\n",
      "rewards:  80.0 q-value:  0\n",
      "loss: [35494.625]\n",
      "Exploring\n",
      "Selected action  [3 4]\n",
      "[3 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 85us/step - loss: 56108.8438\n",
      "rewards:  92.0 q-value:  0\n",
      "loss: [56108.84375]\n",
      "Exploiting\n",
      "Selected action  [0 3]\n",
      "[0 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 80us/step - loss: 34174.1875\n",
      "rewards:  64.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [34174.1875]\n",
      "Exploring\n",
      "Selected action  [4 1]\n",
      "[4 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 75us/step - loss: 36747.4062\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rewards:  61.0 q-value:  0\n",
      "loss: [36747.40625]\n",
      "Exploiting\n",
      "Selected action  [0 3]\n",
      "[0 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 76us/step - loss: 38121.6562\n",
      "rewards:  91.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [38121.65625]\n",
      "Exploiting\n",
      "Selected action  [0 3]\n",
      "[0 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 96us/step - loss: 23806.5312\n",
      "rewards:  89.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [23806.53125]\n",
      "Number of actions available 6\n",
      "Episode : 34\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 73us/step - loss: 77959.1875\n",
      "rewards:  -6.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [77959.1875]\n",
      "Exploring\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 77us/step - loss: 31203.7188\n",
      "rewards:  -2.0 q-value:  0\n",
      "loss: [31203.71875]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 79us/step - loss: 30707.3750\n",
      "rewards:  6.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [30707.375]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 93us/step - loss: 29825.2188\n",
      "rewards:  4.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [29825.21875]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 83us/step - loss: 27198.3438\n",
      "rewards:  2.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [27198.34375]\n",
      "Exploring\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 98us/step - loss: 29232.3750\n",
      "rewards:  0.0 q-value:  0\n",
      "loss: [29232.375]\n",
      "Exploring\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 75us/step - loss: 39464.2188\n",
      "rewards:  -2.0 q-value:  0\n",
      "loss: [39464.21875]\n",
      "Exploring\n",
      "Selected action  [4 3]\n",
      "[4 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 90us/step - loss: 52096.9688\n",
      "rewards:  -14.0 q-value:  0\n",
      "loss: [52096.96875]\n",
      "Exploring\n",
      "Selected action  [4 2]\n",
      "[4 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 86us/step - loss: 31962.0000\n",
      "rewards:  -20.0 q-value:  0\n",
      "loss: [31962.0]\n",
      "Exploring\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 94us/step - loss: 42702.0938\n",
      "rewards:  -12.0 q-value:  0\n",
      "loss: [42702.09375]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 87us/step - loss: 37608.6875\n",
      "rewards:  24.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [37608.6875]\n",
      "Exploring\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 87us/step - loss: 54848.2188\n",
      "rewards:  20.0 q-value:  0\n",
      "loss: [54848.21875]\n",
      "Exploring\n",
      "Selected action  [4 2]\n",
      "[4 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 86us/step - loss: 33271.8750\n",
      "rewards:  0.0 q-value:  0\n",
      "loss: [33271.875]\n",
      "Exploring\n",
      "Selected action  [4 3]\n",
      "[4 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 87us/step - loss: 79011.3125\n",
      "rewards:  20.0 q-value:  0\n",
      "loss: [79011.3125]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 93us/step - loss: 51038.4688\n",
      "rewards:  15.0 q-value:  0\n",
      "loss: [51038.46875]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 110us/step - loss: 29635.9688\n",
      "rewards:  27.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [29635.96875]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 106us/step - loss: 53838.6250\n",
      "rewards:  24.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [53838.625]\n",
      "Exploring\n",
      "Selected action  [4 3]\n",
      "[4 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 75us/step - loss: 52899.1562\n",
      "rewards:  42.0 q-value:  0\n",
      "loss: [52899.15625]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 109us/step - loss: 40013.3438\n",
      "rewards:  37.0 q-value:  0\n",
      "loss: [40013.34375]\n",
      "Exploring\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 84us/step - loss: 41228.0312\n",
      "rewards:  65.0 q-value:  0\n",
      "loss: [41228.03125]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 115us/step - loss: 51207.6562\n",
      "rewards:  62.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [51207.65625]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 89us/step - loss: 33491.3125\n",
      "rewards:  59.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [33491.3125]\n",
      "Exploring\n",
      "Selected action  [4 3]\n",
      "[4 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 86us/step - loss: 42707.4375\n",
      "rewards:  43.0 q-value:  0\n",
      "loss: [42707.4375]\n",
      "Exploring\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 87us/step - loss: 24926.9688\n",
      "rewards:  15.0 q-value:  0\n",
      "loss: [24926.96875]\n",
      "Exploring\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 69us/step - loss: 28981.3750\n",
      "rewards:  6.0 q-value:  0\n",
      "loss: [28981.375]\n",
      "Exploring\n",
      "Selected action  [4 2]\n",
      "[4 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 79us/step - loss: 59097.2188\n",
      "rewards:  14.0 q-value:  0\n",
      "loss: [59097.21875]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 102us/step - loss: 86090.1875\n",
      "rewards:  33.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [86090.1875]\n",
      "Exploring\n",
      "Selected action  [4 3]\n",
      "[4 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 91us/step - loss: 37968.2500\n",
      "rewards:  34.0 q-value:  0\n",
      "loss: [37968.25]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 82us/step - loss: 48999.5312\n",
      "rewards:  29.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [48999.53125]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 99us/step - loss: 29533.5312\n",
      "rewards:  57.0 q-value:  0\n",
      "loss: [29533.53125]\n",
      "Exploring\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 93us/step - loss: 59359.6250\n",
      "rewards:  55.0 q-value:  0\n",
      "loss: [59359.625]\n",
      "Exploring\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 109us/step - loss: 30957.3438\n",
      "rewards:  71.0 q-value:  0\n",
      "loss: [30957.34375]\n",
      "Exploring\n",
      "Selected action  [4 2]\n",
      "[4 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 79us/step - loss: 42392.5312\n",
      "rewards:  71.0 q-value:  0\n",
      "loss: [42392.53125]\n",
      "Exploring\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 73us/step - loss: 42200.5312\n",
      "rewards:  54.0 q-value:  0\n",
      "loss: [42200.53125]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 90us/step - loss: 59536.1562\n",
      "rewards:  52.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [59536.15625]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 97us/step - loss: 17870.7188\n",
      "rewards:  47.0 q-value:  0\n",
      "loss: [17870.71875]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 77us/step - loss: 24887.4375\n",
      "rewards:  40.0 q-value:  0\n",
      "loss: [24887.4375]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 84us/step - loss: 79287.8750\n",
      "rewards:  72.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [79287.875]\n",
      "Exploring\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 93us/step - loss: 27497.3125\n",
      "rewards:  69.0 q-value:  0\n",
      "loss: [27497.3125]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 81us/step - loss: 55901.6562\n",
      "rewards:  62.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [55901.65625]\n",
      "Exploring\n",
      "Selected action  [4 3]\n",
      "[4 3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 92us/step - loss: 14315.6562\n",
      "rewards:  65.0 q-value:  0\n",
      "loss: [14315.65625]\n",
      "Exploring\n",
      "Selected action  [4 2]\n",
      "[4 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 90us/step - loss: 52538.7812\n",
      "rewards:  55.0 q-value:  0\n",
      "loss: [52538.78125]\n",
      "Exploring\n",
      "Selected action  [4 2]\n",
      "[4 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 75us/step - loss: 28718.5312\n",
      "rewards:  55.0 q-value:  0\n",
      "loss: [28718.53125]\n",
      "Exploring\n",
      "Selected action  [4 2]\n",
      "[4 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 63us/step - loss: 28781.1250\n",
      "rewards:  55.0 q-value:  0\n",
      "loss: [28781.125]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 105us/step - loss: 40468.1562\n",
      "rewards:  50.0 q-value:  0\n",
      "loss: [40468.15625]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 66us/step - loss: 36671.9688\n",
      "rewards:  50.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [36671.96875]\n",
      "Exploring\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 88us/step - loss: 35000.3750\n",
      "rewards:  50.0 q-value:  0\n",
      "loss: [35000.375]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 123us/step - loss: 57500.5000\n",
      "rewards:  45.0 q-value:  0\n",
      "loss: [57500.5]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 88us/step - loss: 39910.5312\n",
      "rewards:  40.0 q-value:  0\n",
      "loss: [39910.53125]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 70us/step - loss: 20925.1250\n",
      "rewards:  40.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [20925.125]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 102us/step - loss: 19230.0312\n",
      "rewards:  35.0 q-value:  0\n",
      "loss: [19230.03125]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 67us/step - loss: 58764.2188\n",
      "rewards:  30.0 q-value:  0\n",
      "loss: [58764.21875]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 89us/step - loss: 55521.5000\n",
      "rewards:  30.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [55521.5]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 88us/step - loss: 35870.8438\n",
      "rewards:  30.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [35870.84375]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 114us/step - loss: 22960.0625\n",
      "rewards:  30.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [22960.0625]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 90us/step - loss: 41093.5938\n",
      "rewards:  30.0 q-value:  0\n",
      "loss: [41093.59375]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 96us/step - loss: 41998.9062\n",
      "rewards:  30.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [41998.90625]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 117us/step - loss: 67243.1562\n",
      "rewards:  25.0 q-value:  0\n",
      "loss: [67243.15625]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 108us/step - loss: 58935.3438\n",
      "rewards:  20.0 q-value:  0\n",
      "loss: [58935.34375]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 105us/step - loss: 70032.8750\n",
      "rewards:  20.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [70032.875]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 90us/step - loss: 47372.4062\n",
      "rewards:  20.0 q-value:  0\n",
      "loss: [47372.40625]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 81us/step - loss: 35339.8438\n",
      "rewards:  20.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [35339.84375]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 93us/step - loss: 54572.8750\n",
      "rewards:  20.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [54572.875]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 103us/step - loss: 44834.1562\n",
      "rewards:  20.0 q-value:  0\n",
      "loss: [44834.15625]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 93us/step - loss: 32709.2812\n",
      "rewards:  20.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [32709.28125]\n",
      "Exploring\n",
      "Selected action  [4 2]\n",
      "[4 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 102us/step - loss: 63202.4062\n",
      "rewards:  15.0 q-value:  0\n",
      "loss: [63202.40625]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 126us/step - loss: 28828.8125\n",
      "rewards:  -20.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [28828.8125]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 87us/step - loss: 25406.8438\n",
      "rewards:  -20.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [25406.84375]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 67us/step - loss: 31132.8438\n",
      "rewards:  -20.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [31132.84375]\n",
      "Exploring\n",
      "Selected action  [4 2]\n",
      "[4 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 108us/step - loss: 25213.3125\n",
      "rewards:  -25.0 q-value:  0\n",
      "loss: [25213.3125]\n",
      "Exploring\n",
      "Selected action  [4 2]\n",
      "[4 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 76us/step - loss: 71389.0625\n",
      "rewards:  -25.0 q-value:  0\n",
      "loss: [71389.0625]\n",
      "Exploring\n",
      "Selected action  [4 3]\n",
      "[4 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 78us/step - loss: 27865.0312\n",
      "rewards:  -17.0 q-value:  0\n",
      "loss: [27865.03125]\n",
      "Exploring\n",
      "Selected action  [4 3]\n",
      "[4 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 81us/step - loss: 52293.5938\n",
      "rewards:  -21.0 q-value:  0\n",
      "loss: [52293.59375]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 87us/step - loss: 70989.2500\n",
      "rewards:  -21.0 q-value:  0\n",
      "loss: [70989.25]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 79us/step - loss: 27246.0625\n",
      "rewards:  -5.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [27246.0625]\n",
      "Exploring\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 92us/step - loss: 34786.6562\n",
      "rewards:  -9.0 q-value:  0\n",
      "loss: [34786.65625]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 96us/step - loss: 18500.6875\n",
      "rewards:  -14.0 q-value:  0\n",
      "loss: [18500.6875]\n",
      "Exploring\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 82us/step - loss: 38203.4688\n",
      "rewards:  2.0 q-value:  0\n",
      "loss: [38203.46875]\n",
      "Exploring\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 81us/step - loss: 51915.4375\n",
      "rewards:  -5.0 q-value:  0\n",
      "loss: [51915.4375]\n",
      "Exploring\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 86us/step - loss: 28765.1562\n",
      "rewards:  -11.0 q-value:  0\n",
      "loss: [28765.15625]\n",
      "Exploring\n",
      "Selected action  [4 2]\n",
      "[4 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 83us/step - loss: 19211.7812\n",
      "rewards:  -16.0 q-value:  0\n",
      "loss: [19211.78125]\n",
      "Exploring\n",
      "Selected action  [4 2]\n",
      "[4 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 87us/step - loss: 31711.6562\n",
      "rewards:  -16.0 q-value:  0\n",
      "loss: [31711.65625]\n",
      "Exploring\n",
      "Selected action  [4 3]\n",
      "[4 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 99us/step - loss: 27692.6875\n",
      "rewards:  -4.0 q-value:  0\n",
      "loss: [27692.6875]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 102us/step - loss: 30768.0625\n",
      "rewards:  -11.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [30768.0625]\n",
      "Exploring\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 83us/step - loss: 46173.2812\n",
      "rewards:  -31.0 q-value:  0\n",
      "loss: [46173.28125]\n",
      "Exploring\n",
      "Selected action  [4 3]\n",
      "[4 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 98us/step - loss: 48638.3438\n",
      "rewards:  -28.0 q-value:  0\n",
      "loss: [48638.34375]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 76us/step - loss: 74727.6250\n",
      "rewards:  -45.0 q-value:  0\n",
      "loss: [74727.625]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 109us/step - loss: 66992.6250\n",
      "rewards:  -9.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [66992.625]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 82us/step - loss: 54162.3750\n",
      "rewards:  -13.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [54162.375]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 108us/step - loss: 72657.2500\n",
      "rewards:  -15.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [72657.25]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 80us/step - loss: 19310.5938\n",
      "rewards:  -17.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [19310.59375]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 101us/step - loss: 59182.0000\n",
      "rewards:  -19.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [59182.0]\n",
      "Exploring\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 89us/step - loss: 19523.3125\n",
      "rewards:  -22.0 q-value:  0\n",
      "loss: [19523.3125]\n",
      "Exploring\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 74us/step - loss: 41864.6562\n",
      "rewards:  -25.0 q-value:  0\n",
      "loss: [41864.65625]\n",
      "Exploring\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 89us/step - loss: 27584.3438\n",
      "rewards:  -32.0 q-value:  0\n",
      "loss: [27584.34375]\n",
      "Exploring\n",
      "Selected action  [4 3]\n",
      "[4 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 112us/step - loss: 41800.5000\n",
      "rewards:  -8.0 q-value:  0\n",
      "loss: [41800.5]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 77us/step - loss: 47170.4688\n",
      "rewards:  -1.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [47170.46875]\n",
      "Exploring\n",
      "Selected action  [4 2]\n",
      "[4 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 89us/step - loss: 48956.2500\n",
      "rewards:  7.0 q-value:  0\n",
      "loss: [48956.25]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 116us/step - loss: 52276.8438\n",
      "rewards:  -6.0 q-value:  0\n",
      "loss: [52276.84375]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 113us/step - loss: 72703.3750\n",
      "rewards:  6.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [72703.375]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 85us/step - loss: 44652.8750\n",
      "rewards:  -3.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [44652.875]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 71us/step - loss: 41210.4375\n",
      "rewards:  21.0 q-value:  0\n",
      "loss: [41210.4375]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 84us/step - loss: 27755.6875\n",
      "rewards:  15.0 q-value:  0\n",
      "loss: [27755.6875]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 102us/step - loss: 77272.5625\n",
      "rewards:  35.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [77272.5625]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 92us/step - loss: 41501.7812\n",
      "rewards:  63.0 q-value:  0\n",
      "loss: [41501.78125]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 72us/step - loss: 73798.0000\n",
      "rewards:  79.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [73798.0]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 84us/step - loss: 27360.1250\n",
      "rewards:  74.0 q-value:  0\n",
      "loss: [27360.125]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 85us/step - loss: 36171.5938\n",
      "rewards:  82.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [36171.59375]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 108us/step - loss: 59619.0938\n",
      "rewards:  90.0 q-value:  0\n",
      "loss: [59619.09375]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 92us/step - loss: 37485.2812\n",
      "rewards:  85.0 q-value:  0\n",
      "loss: [37485.28125]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 74us/step - loss: 62397.0938\n",
      "rewards:  78.0 q-value:  0\n",
      "loss: [62397.09375]\n",
      "Exploring\n",
      "Selected action  [4 3]\n",
      "[4 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 96us/step - loss: 40285.5625\n",
      "rewards:  98.0 q-value:  0\n",
      "loss: [40285.5625]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 81us/step - loss: 46814.7188\n",
      "rewards:  95.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [46814.71875]\n",
      "Exploring\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 85us/step - loss: 34575.0000\n",
      "rewards:  92.0 q-value:  0\n",
      "loss: [34575.0]\n",
      "Exploring\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 116us/step - loss: 53525.0312\n",
      "rewards:  58.0 q-value:  0\n",
      "loss: [53525.03125]\n",
      "Exploring\n",
      "Selected action  [4 3]\n",
      "[4 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 105us/step - loss: 34549.9688\n",
      "rewards:  59.0 q-value:  0\n",
      "loss: [34549.96875]\n",
      "Exploring\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 96us/step - loss: 38408.9688\n",
      "rewards:  39.0 q-value:  0\n",
      "loss: [38408.96875]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 117us/step - loss: 40875.5312\n",
      "rewards:  39.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [40875.53125]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 86us/step - loss: 13691.6875\n",
      "rewards:  39.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [13691.6875]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 77us/step - loss: 49000.5625\n",
      "rewards:  39.0 q-value:  0\n",
      "loss: [49000.5625]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 90us/step - loss: 37730.3125\n",
      "rewards:  39.0 q-value:  0\n",
      "loss: [37730.3125]\n",
      "Exploring\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 78us/step - loss: 22950.3438\n",
      "rewards:  32.0 q-value:  0\n",
      "loss: [22950.34375]\n",
      "Exploring\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 82us/step - loss: 39318.9062\n",
      "rewards:  25.0 q-value:  0\n",
      "loss: [39318.90625]\n",
      "Exploring\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 83us/step - loss: 49294.2500\n",
      "rewards:  21.0 q-value:  0\n",
      "loss: [49294.25]\n",
      "Exploring\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 92us/step - loss: 66011.7188\n",
      "rewards:  16.0 q-value:  0\n",
      "loss: [66011.71875]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 89us/step - loss: 23459.7812\n",
      "rewards:  40.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [23459.78125]\n",
      "Exploring\n",
      "Selected action  [4 2]\n",
      "[4 2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 87us/step - loss: 36800.8750\n",
      "rewards:  21.0 q-value:  0\n",
      "loss: [36800.875]\n",
      "Exploring\n",
      "Selected action  [4 3]\n",
      "[4 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 125us/step - loss: 69963.9062\n",
      "rewards:  29.0 q-value:  0\n",
      "loss: [69963.90625]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 87us/step - loss: 28276.2188\n",
      "rewards:  22.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [28276.21875]\n",
      "Exploring\n",
      "Selected action  [4 2]\n",
      "[4 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 91us/step - loss: 49602.7812\n",
      "rewards:  15.0 q-value:  0\n",
      "loss: [49602.78125]\n",
      "Exploring\n",
      "Selected action  [4 3]\n",
      "[4 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 97us/step - loss: 40881.9062\n",
      "rewards:  17.0 q-value:  0\n",
      "loss: [40881.90625]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 87us/step - loss: 68707.5000\n",
      "rewards:  -25.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [68707.5]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 93us/step - loss: 64386.1875\n",
      "rewards:  -27.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [64386.1875]\n",
      "Exploring\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 85us/step - loss: 68079.9688\n",
      "rewards:  -44.0 q-value:  0\n",
      "loss: [68079.96875]\n",
      "Exploring\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 96us/step - loss: 39973.8125\n",
      "rewards:  -8.0 q-value:  0\n",
      "loss: [39973.8125]\n",
      "Exploring\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 86us/step - loss: 46023.9688\n",
      "rewards:  -5.0 q-value:  0\n",
      "loss: [46023.96875]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 102us/step - loss: 29294.8125\n",
      "rewards:  3.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [29294.8125]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 86us/step - loss: 19445.1250\n",
      "rewards:  -2.0 q-value:  0\n",
      "loss: [19445.125]\n",
      "Exploring\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 121us/step - loss: 38508.8438\n",
      "rewards:  6.0 q-value:  0\n",
      "loss: [38508.84375]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 107us/step - loss: 40894.4062\n",
      "rewards:  1.0 q-value:  0\n",
      "loss: [40894.40625]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 95us/step - loss: 51082.2188\n",
      "rewards:  -4.0 q-value:  0\n",
      "loss: [51082.21875]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 122us/step - loss: 41370.2812\n",
      "rewards:  -9.0 q-value:  0\n",
      "loss: [41370.28125]\n",
      "Exploring\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 110us/step - loss: 59959.7812\n",
      "rewards:  -15.0 q-value:  0\n",
      "loss: [59959.78125]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 93us/step - loss: 36041.7500\n",
      "rewards:  -18.0 q-value:  0\n",
      "loss: [36041.75]\n",
      "Exploring\n",
      "Selected action  [4 2]\n",
      "[4 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 94us/step - loss: 45353.5312\n",
      "rewards:  -3.0 q-value:  0\n",
      "loss: [45353.53125]\n",
      "Number of actions available 6\n",
      "Episode : 35\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 92us/step - loss: 89501.5312\n",
      "rewards:  -5 q-value:  0\n",
      "loss: [89501.53125]\n",
      "Exploiting\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 84us/step - loss: 34735.3438\n",
      "rewards:  -19.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [34735.34375]\n",
      "Exploring\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 81us/step - loss: 53832.4375\n",
      "rewards:  -23.0 q-value:  0\n",
      "loss: [53832.4375]\n",
      "Exploiting\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 129us/step - loss: 38931.1250\n",
      "rewards:  -27.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [38931.125]\n",
      "Exploiting\n",
      "Selected action  [1 2]\n",
      "[1 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 105us/step - loss: 37012.1875\n",
      "rewards:  -19.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [37012.1875]\n",
      "Exploiting\n",
      "Selected action  [0 3]\n",
      "[0 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 118us/step - loss: 51880.3125\n",
      "rewards:  -34.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [51880.3125]\n",
      "Exploring\n",
      "Selected action  [1 2]\n",
      "[1 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 73us/step - loss: 25803.6250\n",
      "rewards:  -26.0 q-value:  0\n",
      "loss: [25803.625]\n",
      "Exploiting\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 85us/step - loss: 35188.8125\n",
      "rewards:  -31.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [35188.8125]\n",
      "Exploring\n",
      "Selected action  [1 2]\n",
      "[1 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 86us/step - loss: 75748.9688\n",
      "rewards:  -9.0 q-value:  0\n",
      "loss: [75748.96875]\n",
      "Exploring\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 89us/step - loss: 51654.6562\n",
      "rewards:  -14.0 q-value:  0\n",
      "loss: [51654.65625]\n",
      "Exploring\n",
      "Selected action  [1 4]\n",
      "[1 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 112us/step - loss: 53989.7188\n",
      "rewards:  -7.0 q-value:  0\n",
      "loss: [53989.71875]\n",
      "Exploring\n",
      "Selected action  [1 2]\n",
      "[1 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 87us/step - loss: 44176.9688\n",
      "rewards:  18.0 q-value:  0\n",
      "loss: [44176.96875]\n",
      "Exploiting\n",
      "Selected action  [1 2]\n",
      "[1 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 113us/step - loss: 52282.6250\n",
      "rewards:  13.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [52282.625]\n",
      "Exploring\n",
      "Selected action  [1 2]\n",
      "[1 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 107us/step - loss: 56277.9062\n",
      "rewards:  7.0 q-value:  0\n",
      "loss: [56277.90625]\n",
      "Exploring\n",
      "Selected action  [2 1]\n",
      "[2 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 85us/step - loss: 42150.3750\n",
      "rewards:  43.0 q-value:  0\n",
      "loss: [42150.375]\n",
      "Exploring\n",
      "Selected action  [1 4]\n",
      "[1 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 94us/step - loss: 40297.5625\n",
      "rewards:  43.0 q-value:  0\n",
      "loss: [40297.5625]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 104us/step - loss: 63098.9375\n",
      "rewards:  38.0 q-value:  0\n",
      "loss: [63098.9375]\n",
      "Exploiting\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 107us/step - loss: 34858.2500\n",
      "rewards:  11.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [34858.25]\n",
      "Exploring\n",
      "Selected action  [0 3]\n",
      "[0 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 79us/step - loss: 32928.1875\n",
      "rewards:  10.0 q-value:  0\n",
      "loss: [32928.1875]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 81us/step - loss: 33119.3438\n",
      "rewards:  5.0 q-value:  0\n",
      "loss: [33119.34375]\n",
      "Exploring\n",
      "Selected action  [2 1]\n",
      "[2 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 96us/step - loss: 54623.1562\n",
      "rewards:  39.0 q-value:  0\n",
      "loss: [54623.15625]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 110us/step - loss: 42456.9375\n",
      "rewards:  34.0 q-value:  0\n",
      "loss: [42456.9375]\n",
      "Exploring\n",
      "Selected action  [2 1]\n",
      "[2 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 89us/step - loss: 21875.3125\n",
      "rewards:  20.0 q-value:  0\n",
      "loss: [21875.3125]\n",
      "Exploiting\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 104us/step - loss: 88298.2188\n",
      "rewards:  28.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [88298.21875]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 116us/step - loss: 36485.6562\n",
      "rewards:  23.0 q-value:  0\n",
      "loss: [36485.65625]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 80us/step - loss: 57239.3438\n",
      "rewards:  18.0 q-value:  0\n",
      "loss: [57239.34375]\n",
      "Exploiting\n",
      "Selected action  [1 4]\n",
      "[1 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 90us/step - loss: 31871.7188\n",
      "rewards:  -12.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [31871.71875]\n",
      "Exploring\n",
      "Selected action  [0 3]\n",
      "[0 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 118us/step - loss: 53210.9375\n",
      "rewards:  -9.0 q-value:  0\n",
      "loss: [53210.9375]\n",
      "Exploiting\n",
      "Selected action  [1 2]\n",
      "[1 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 73us/step - loss: 39782.7188\n",
      "rewards:  -10.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [39782.71875]\n",
      "Exploiting\n",
      "Selected action  [2 1]\n",
      "[2 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 79us/step - loss: 46293.8438\n",
      "rewards:  -6.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [46293.84375]\n",
      "Exploiting\n",
      "Selected action  [0 3]\n",
      "[0 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 119us/step - loss: 26696.1875\n",
      "rewards:  -28.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [26696.1875]\n",
      "Exploiting\n",
      "Selected action  [1 2]\n",
      "[1 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 91us/step - loss: 40216.7188\n",
      "rewards:  -5.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [40216.71875]\n",
      "Exploring\n",
      "Selected action  [0 3]\n",
      "[0 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 83us/step - loss: 32150.0625\n",
      "rewards:  0.0 q-value:  0\n",
      "loss: [32150.0625]\n",
      "Exploring\n",
      "Selected action  [0 3]\n",
      "[0 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 97us/step - loss: 49454.3750\n",
      "rewards:  -6.0 q-value:  0\n",
      "loss: [49454.375]\n",
      "Exploring\n",
      "Selected action  [2 1]\n",
      "[2 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 89us/step - loss: 23118.8125\n",
      "rewards:  -32.0 q-value:  0\n",
      "loss: [23118.8125]\n",
      "Exploring\n",
      "Selected action  [2 1]\n",
      "[2 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 79us/step - loss: 36031.3125\n",
      "rewards:  -33.0 q-value:  0\n",
      "loss: [36031.3125]\n",
      "Exploring\n",
      "Selected action  [0 3]\n",
      "[0 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 92us/step - loss: 36111.0625\n",
      "rewards:  -33.0 q-value:  0\n",
      "loss: [36111.0625]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 94us/step - loss: 63609.5000\n",
      "rewards:  -38.0 q-value:  0\n",
      "loss: [63609.5]\n",
      "Exploiting\n",
      "Selected action  [2 1]\n",
      "[2 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 102us/step - loss: 41814.5000\n",
      "rewards:  -31.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [41814.5]\n",
      "Exploring\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 95us/step - loss: 17301.6562\n",
      "rewards:  -11.0 q-value:  0\n",
      "loss: [17301.65625]\n",
      "Exploring\n",
      "Selected action  [1 2]\n",
      "[1 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 101us/step - loss: 64102.4375\n",
      "rewards:  2.0 q-value:  0\n",
      "loss: [64102.4375]\n",
      "Exploring\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 108us/step - loss: 64802.2500\n",
      "rewards:  1.0 q-value:  0\n",
      "loss: [64802.25]\n",
      "Exploring\n",
      "Selected action  [2 1]\n",
      "[2 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 98us/step - loss: 63629.7812\n",
      "rewards:  -35.0 q-value:  0\n",
      "loss: [63629.78125]\n",
      "Exploring\n",
      "Selected action  [0 3]\n",
      "[0 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 78us/step - loss: 16555.4375\n",
      "rewards:  -66.0 q-value:  0\n",
      "loss: [16555.4375]\n",
      "Exploring\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 95us/step - loss: 56518.1875\n",
      "rewards:  -69.0 q-value:  0\n",
      "loss: [56518.1875]\n",
      "Exploiting\n",
      "Selected action  [1 4]\n",
      "[1 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 83us/step - loss: 50019.9375\n",
      "rewards:  -84.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [50019.9375]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 83us/step - loss: 14612.7500\n",
      "rewards:  -89.0 q-value:  0\n",
      "loss: [14612.75]\n",
      "Exploiting\n",
      "Selected action  [2 1]\n",
      "[2 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 88us/step - loss: 32297.5938\n",
      "rewards:  -69.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [32297.59375]\n",
      "Exploring\n",
      "Selected action  [2 1]\n",
      "[2 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 107us/step - loss: 18310.3125\n",
      "rewards:  -80.0 q-value:  0\n",
      "loss: [18310.3125]\n",
      "Exploiting\n",
      "Selected action  [0 3]\n",
      "[0 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 134us/step - loss: 37588.9062\n",
      "rewards:  -88.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [37588.90625]\n",
      "Exploiting\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 115us/step - loss: 56979.1875\n",
      "rewards:  -93.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [56979.1875]\n",
      "Exploring\n",
      "Selected action  [1 2]\n",
      "[1 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 86us/step - loss: 33367.5000\n",
      "rewards:  -89.0 q-value:  0\n",
      "loss: [33367.5]\n",
      "Exploring\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 98us/step - loss: 24487.9062\n",
      "rewards:  -108.0 q-value:  0\n",
      "loss: [24487.90625]\n",
      "Exploiting\n",
      "Selected action  [1 4]\n",
      "[1 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 94us/step - loss: 92445.4688\n",
      "rewards:  -100.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [92445.46875]\n",
      "Exploring\n",
      "Selected action  [0 3]\n",
      "[0 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 104us/step - loss: 44228.6250\n",
      "rewards:  -105.0 q-value:  0\n",
      "loss: [44228.625]\n",
      "Exploiting\n",
      "Selected action  [1 4]\n",
      "[1 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 92us/step - loss: 39089.0000\n",
      "rewards:  -97.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [39089.0]\n",
      "Exploring\n",
      "Selected action  [1 2]\n",
      "[1 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 98us/step - loss: 53060.7812\n",
      "rewards:  -99.0 q-value:  0\n",
      "loss: [53060.78125]\n",
      "Exploring\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 102us/step - loss: 35796.5000\n",
      "rewards:  -139.0 q-value:  0\n",
      "loss: [35796.5]\n",
      "Exploring\n",
      "Selected action  [2 1]\n",
      "[2 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 96us/step - loss: 58439.3750\n",
      "rewards:  -117.0 q-value:  0\n",
      "loss: [58439.375]\n",
      "Exploiting\n",
      "Selected action  [0 3]\n",
      "[0 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 104us/step - loss: 64680.0312\n",
      "rewards:  -87.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [64680.03125]\n",
      "Exploring\n",
      "Selected action  [1 4]\n",
      "[1 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 114us/step - loss: 23155.0625\n",
      "rewards:  -92.0 q-value:  0\n",
      "loss: [23155.0625]\n",
      "Exploiting\n",
      "Selected action  [1 4]\n",
      "[1 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 104us/step - loss: 20418.0000\n",
      "rewards:  -92.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [20418.0]\n",
      "Exploring\n",
      "Selected action  [1 4]\n",
      "[1 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 112us/step - loss: 27046.7812\n",
      "rewards:  -92.0 q-value:  0\n",
      "loss: [27046.78125]\n",
      "Exploring\n",
      "Selected action  [1 2]\n",
      "[1 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 124us/step - loss: 50597.2500\n",
      "rewards:  -88.0 q-value:  0\n",
      "loss: [50597.25]\n",
      "Exploring\n",
      "Selected action  [1 2]\n",
      "[1 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 107us/step - loss: 41638.9062\n",
      "rewards:  -89.0 q-value:  0\n",
      "loss: [41638.90625]\n",
      "Exploiting\n",
      "Selected action  [0 3]\n",
      "[0 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 90us/step - loss: 30164.3438\n",
      "rewards:  -91.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [30164.34375]\n",
      "Exploiting\n",
      "Selected action  [0 3]\n",
      "[0 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 79us/step - loss: 88089.1562\n",
      "rewards:  -93.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [88089.15625]\n",
      "Exploring\n",
      "Selected action  [1 2]\n",
      "[1 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 108us/step - loss: 48599.9375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rewards:  -78.0 q-value:  0\n",
      "loss: [48599.9375]\n",
      "Exploring\n",
      "Selected action  [0 3]\n",
      "[0 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 100us/step - loss: 69281.8438\n",
      "rewards:  -84.0 q-value:  0\n",
      "loss: [69281.84375]\n",
      "Exploring\n",
      "Selected action  [1 4]\n",
      "[1 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 92us/step - loss: 46611.8438\n",
      "rewards:  -86.0 q-value:  0\n",
      "loss: [46611.84375]\n",
      "Exploring\n",
      "Selected action  [0 3]\n",
      "[0 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 112us/step - loss: 51789.0625\n",
      "rewards:  -79.0 q-value:  0\n",
      "loss: [51789.0625]\n",
      "Exploring\n",
      "Selected action  [0 3]\n",
      "[0 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 107us/step - loss: 36817.4062\n",
      "rewards:  -82.0 q-value:  0\n",
      "loss: [36817.40625]\n",
      "Exploiting\n",
      "Selected action  [2 1]\n",
      "[2 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 104us/step - loss: 52300.2188\n",
      "rewards:  -85.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [52300.21875]\n",
      "Exploring\n",
      "Selected action  [1 2]\n",
      "[1 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 104us/step - loss: 61454.7812\n",
      "rewards:  -73.0 q-value:  0\n",
      "loss: [61454.78125]\n",
      "Exploring\n",
      "Selected action  [1 2]\n",
      "[1 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 97us/step - loss: 25853.0625\n",
      "rewards:  -84.0 q-value:  0\n",
      "loss: [25853.0625]\n",
      "Exploring\n",
      "Selected action  [1 4]\n",
      "[1 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 114us/step - loss: 50596.7500\n",
      "rewards:  -76.0 q-value:  0\n",
      "loss: [50596.75]\n",
      "Exploiting\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 99us/step - loss: 44372.0000\n",
      "rewards:  -72.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [44372.0]\n",
      "Exploiting\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 96us/step - loss: 52352.0938\n",
      "rewards:  -77.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [52352.09375]\n",
      "Exploring\n",
      "Selected action  [0 3]\n",
      "[0 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 109us/step - loss: 63250.5625\n",
      "rewards:  -69.0 q-value:  0\n",
      "loss: [63250.5625]\n",
      "Exploiting\n",
      "Selected action  [1 2]\n",
      "[1 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 99us/step - loss: 24223.9375\n",
      "rewards:  -70.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [24223.9375]\n",
      "Exploiting\n",
      "Selected action  [0 3]\n",
      "[0 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 74us/step - loss: 39371.0000\n",
      "rewards:  -102.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [39371.0]\n",
      "Exploiting\n",
      "Selected action  [1 4]\n",
      "[1 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 78us/step - loss: 90813.5625\n",
      "rewards:  -95.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [90813.5625]\n",
      "Exploiting\n",
      "Selected action  [1 4]\n",
      "[1 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 78us/step - loss: 39187.0938\n",
      "rewards:  -98.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [39187.09375]\n",
      "Exploiting\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 86us/step - loss: 56990.1250\n",
      "rewards:  -103.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [56990.125]\n",
      "Exploring\n",
      "Selected action  [2 1]\n",
      "[2 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 77us/step - loss: 37959.3750\n",
      "rewards:  -90.0 q-value:  0\n",
      "loss: [37959.375]\n",
      "Exploring\n",
      "Selected action  [0 3]\n",
      "[0 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 70us/step - loss: 36866.7188\n",
      "rewards:  -101.0 q-value:  0\n",
      "loss: [36866.71875]\n",
      "Exploring\n",
      "Selected action  [2 1]\n",
      "[2 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 110us/step - loss: 44248.8125\n",
      "rewards:  -127.0 q-value:  0\n",
      "loss: [44248.8125]\n",
      "Exploiting\n",
      "Selected action  [1 4]\n",
      "[1 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 141us/step - loss: 56906.3750\n",
      "rewards:  -127.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [56906.375]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 105us/step - loss: 29352.1562\n",
      "rewards:  -132.0 q-value:  0\n",
      "loss: [29352.15625]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 119us/step - loss: 33989.5938\n",
      "rewards:  -137.0 q-value:  0\n",
      "loss: [33989.59375]\n",
      "Exploring\n",
      "Selected action  [0 3]\n",
      "[0 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 78us/step - loss: 39372.8125\n",
      "rewards:  -117.0 q-value:  0\n",
      "loss: [39372.8125]\n",
      "Exploiting\n",
      "Selected action  [0 3]\n",
      "[0 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 115us/step - loss: 47003.8438\n",
      "rewards:  -120.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [47003.84375]\n",
      "Exploring\n",
      "Selected action  [0 3]\n",
      "[0 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 95us/step - loss: 31021.8438\n",
      "rewards:  -127.0 q-value:  0\n",
      "loss: [31021.84375]\n",
      "Exploiting\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 101us/step - loss: 31891.7812\n",
      "rewards:  -132.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [31891.78125]\n",
      "Exploring\n",
      "Selected action  [2 1]\n",
      "[2 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 115us/step - loss: 57456.7812\n",
      "rewards:  -129.0 q-value:  0\n",
      "loss: [57456.78125]\n",
      "Exploring\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 86us/step - loss: 44394.2500\n",
      "rewards:  -125.0 q-value:  0\n",
      "loss: [44394.25]\n",
      "Exploring\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 87us/step - loss: 39984.8438\n",
      "rewards:  -126.0 q-value:  0\n",
      "loss: [39984.84375]\n",
      "Exploiting\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 80us/step - loss: 32105.1875\n",
      "rewards:  -131.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [32105.1875]\n",
      "Exploiting\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 82us/step - loss: 35575.7188\n",
      "rewards:  -136.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [35575.71875]\n",
      "Exploiting\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 83us/step - loss: 24079.7500\n",
      "rewards:  -141.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [24079.75]\n",
      "Exploiting\n",
      "Selected action  [2 1]\n",
      "[2 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 111us/step - loss: 55330.0000\n",
      "rewards:  -152.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [55330.0]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 114us/step - loss: 56654.8125\n",
      "rewards:  -157.0 q-value:  0\n",
      "loss: [56654.8125]\n",
      "Exploring\n",
      "Selected action  [2 1]\n",
      "[2 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 90us/step - loss: 55927.4062\n",
      "rewards:  -168.0 q-value:  0\n",
      "loss: [55927.40625]\n",
      "Exploiting\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 109us/step - loss: 24538.1875\n",
      "rewards:  -173.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [24538.1875]\n",
      "Exploiting\n",
      "Selected action  [1 4]\n",
      "[1 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 102us/step - loss: 61939.2188\n",
      "rewards:  -208.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [61939.21875]\n",
      "Exploiting\n",
      "Selected action  [1 4]\n",
      "[1 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 99us/step - loss: 36611.8750\n",
      "rewards:  -208.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [36611.875]\n",
      "Exploiting\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 84us/step - loss: 55864.5312\n",
      "rewards:  -213.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [55864.53125]\n",
      "Exploiting\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 75us/step - loss: 84501.8125\n",
      "rewards:  -218.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [84501.8125]\n",
      "Exploring\n",
      "Selected action  [1 3]\n",
      "[1 3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 78us/step - loss: 29482.4062\n",
      "rewards:  -241.0 q-value:  0\n",
      "loss: [29482.40625]\n",
      "Exploring\n",
      "Selected action  [2 1]\n",
      "[2 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 131us/step - loss: 51192.6250\n",
      "rewards:  -231.0 q-value:  0\n",
      "loss: [51192.625]\n",
      "Exploring\n",
      "Selected action  [2 1]\n",
      "[2 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 95us/step - loss: 26923.5938\n",
      "rewards:  -242.0 q-value:  0\n",
      "loss: [26923.59375]\n",
      "Exploiting\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 81us/step - loss: 44389.6250\n",
      "rewards:  -247.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [44389.625]\n",
      "Exploiting\n",
      "Selected action  [1 2]\n",
      "[1 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 106us/step - loss: 58964.2812\n",
      "rewards:  -243.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [58964.28125]\n",
      "Exploring\n",
      "Selected action  [1 2]\n",
      "[1 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 83us/step - loss: 66030.9688\n",
      "rewards:  -250.0 q-value:  0\n",
      "loss: [66030.96875]\n",
      "Exploring\n",
      "Selected action  [2 1]\n",
      "[2 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 113us/step - loss: 24209.5000\n",
      "rewards:  -234.0 q-value:  0\n",
      "loss: [24209.5]\n",
      "Exploring\n",
      "Selected action  [1 4]\n",
      "[1 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 91us/step - loss: 35981.7188\n",
      "rewards:  -206.0 q-value:  0\n",
      "loss: [35981.71875]\n",
      "Exploiting\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 95us/step - loss: 38459.7812\n",
      "rewards:  -221.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [38459.78125]\n",
      "Exploiting\n",
      "Selected action  [0 3]\n",
      "[0 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 161us/step - loss: 42815.8750\n",
      "rewards:  -224.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [42815.875]\n",
      "Exploring\n",
      "Selected action  [0 3]\n",
      "[0 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 122us/step - loss: 39053.5312\n",
      "rewards:  -227.0 q-value:  0\n",
      "loss: [39053.53125]\n",
      "Number of actions available 10\n",
      "Episode : 36\n",
      "Exploring\n",
      "Selected action  [4 0]\n",
      "[4 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 84us/step - loss: 69995.8438\n",
      "rewards:  -6.0 q-value:  0\n",
      "loss: [69995.84375]\n",
      "Exploring\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 101us/step - loss: 50494.6562\n",
      "rewards:  -20.0 q-value:  0\n",
      "loss: [50494.65625]\n",
      "Exploring\n",
      "Selected action  [4 2]\n",
      "[4 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 86us/step - loss: 24414.8438\n",
      "rewards:  -39.0 q-value:  0\n",
      "loss: [24414.84375]\n",
      "Exploring\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 126us/step - loss: 47202.2812\n",
      "rewards:  -49.0 q-value:  0\n",
      "loss: [47202.28125]\n",
      "Exploiting\n",
      "Selected action  [4 3]\n",
      "[4 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 112us/step - loss: 46436.9375\n",
      "rewards:  -52.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [46436.9375]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 116us/step - loss: 37660.9375\n",
      "rewards:  -57.0 q-value:  0\n",
      "loss: [37660.9375]\n",
      "Exploring\n",
      "Selected action  [1 4]\n",
      "[1 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 74us/step - loss: 63314.2188\n",
      "rewards:  -59.0 q-value:  0\n",
      "loss: [63314.21875]\n",
      "Exploring\n",
      "Selected action  [2 1]\n",
      "[2 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 90us/step - loss: 26279.6875\n",
      "rewards:  -51.0 q-value:  0\n",
      "loss: [26279.6875]\n",
      "Exploring\n",
      "Selected action  [4 2]\n",
      "[4 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 97us/step - loss: 41953.8438\n",
      "rewards:  -58.0 q-value:  0\n",
      "loss: [41953.84375]\n",
      "Exploiting\n",
      "Selected action  [4 2]\n",
      "[4 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 106us/step - loss: 66162.7812\n",
      "rewards:  -60.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [66162.78125]\n",
      "Exploring\n",
      "Selected action  [2 1]\n",
      "[2 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 87us/step - loss: 34736.5000\n",
      "rewards:  -28.0 q-value:  0\n",
      "loss: [34736.5]\n",
      "Exploring\n",
      "Selected action  [3 1]\n",
      "[3 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 101us/step - loss: 85276.2188\n",
      "rewards:  -29.0 q-value:  0\n",
      "loss: [85276.21875]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 119us/step - loss: 39532.0625\n",
      "rewards:  7.0 q-value:  0\n",
      "loss: [39532.0625]\n",
      "Exploring\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 87us/step - loss: 29996.0625\n",
      "rewards:  -9.0 q-value:  0\n",
      "loss: [29996.0625]\n",
      "Exploring\n",
      "Selected action  [1 4]\n",
      "[1 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 86us/step - loss: 21409.6562\n",
      "rewards:  2.0 q-value:  0\n",
      "loss: [21409.65625]\n",
      "Exploiting\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 101us/step - loss: 67539.9062\n",
      "rewards:  -14.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [67539.90625]\n",
      "Exploring\n",
      "Selected action  [2 1]\n",
      "[2 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 103us/step - loss: 57606.7812\n",
      "rewards:  -9.0 q-value:  0\n",
      "loss: [57606.78125]\n",
      "Exploring\n",
      "Selected action  [3 1]\n",
      "[3 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 81us/step - loss: 53993.0000\n",
      "rewards:  -15.0 q-value:  0\n",
      "loss: [53993.0]\n",
      "Exploring\n",
      "Selected action  [3 1]\n",
      "[3 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 84us/step - loss: 29832.6562\n",
      "rewards:  -17.0 q-value:  0\n",
      "loss: [29832.65625]\n",
      "Exploring\n",
      "Selected action  [2 1]\n",
      "[2 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 96us/step - loss: 48846.7812\n",
      "rewards:  -20.0 q-value:  0\n",
      "loss: [48846.78125]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 111us/step - loss: 57529.1562\n",
      "rewards:  8.0 q-value:  0\n",
      "loss: [57529.15625]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 106us/step - loss: 18083.5000\n",
      "rewards:  5.0 q-value:  0\n",
      "loss: [18083.5]\n",
      "Exploring\n",
      "Selected action  [4 0]\n",
      "[4 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 100us/step - loss: 33244.2812\n",
      "rewards:  4.0 q-value:  0\n",
      "loss: [33244.28125]\n",
      "Exploiting\n",
      "Selected action  [1 4]\n",
      "[1 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 98us/step - loss: 59763.0625\n",
      "rewards:  5.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [59763.0625]\n",
      "Exploring\n",
      "Selected action  [4 2]\n",
      "[4 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 108us/step - loss: 40033.2812\n",
      "rewards:  21.0 q-value:  0\n",
      "loss: [40033.28125]\n",
      "Exploring\n",
      "Selected action  [1 4]\n",
      "[1 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 121us/step - loss: 46969.7500\n",
      "rewards:  29.0 q-value:  0\n",
      "loss: [46969.75]\n",
      "Exploring\n",
      "Selected action  [4 2]\n",
      "[4 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 88us/step - loss: 54805.5312\n",
      "rewards:  37.0 q-value:  0\n",
      "loss: [54805.53125]\n",
      "Exploring\n",
      "Selected action  [4 0]\n",
      "[4 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 98us/step - loss: 28855.4375\n",
      "rewards:  55.0 q-value:  0\n",
      "loss: [28855.4375]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 85us/step - loss: 35903.6250\n",
      "rewards:  50.0 q-value:  0\n",
      "loss: [35903.625]\n",
      "Exploiting\n",
      "Selected action  [4 0]\n",
      "[4 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 119us/step - loss: 62130.2812\n",
      "rewards:  48.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [62130.28125]\n",
      "Exploring\n",
      "Selected action  [1 4]\n",
      "[1 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 88us/step - loss: 67367.2188\n",
      "rewards:  37.0 q-value:  0\n",
      "loss: [67367.21875]\n",
      "Exploring\n",
      "Selected action  [4 0]\n",
      "[4 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 85us/step - loss: 70806.9062\n",
      "rewards:  37.0 q-value:  0\n",
      "loss: [70806.90625]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 120us/step - loss: 66456.1875\n",
      "rewards:  32.0 q-value:  0\n",
      "loss: [66456.1875]\n",
      "Exploring\n",
      "Selected action  [1 4]\n",
      "[1 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 108us/step - loss: 28538.5000\n",
      "rewards:  12.0 q-value:  0\n",
      "loss: [28538.5]\n",
      "Exploiting\n",
      "Selected action  [3 1]\n",
      "[3 1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 92us/step - loss: 44945.6250\n",
      "rewards:  -2.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [44945.625]\n",
      "Exploring\n",
      "Selected action  [4 0]\n",
      "[4 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 114us/step - loss: 42195.3438\n",
      "rewards:  22.0 q-value:  0\n",
      "loss: [42195.34375]\n",
      "Exploring\n",
      "Selected action  [3 1]\n",
      "[3 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 97us/step - loss: 33144.4375\n",
      "rewards:  7.0 q-value:  0\n",
      "loss: [33144.4375]\n",
      "Exploring\n",
      "Selected action  [1 4]\n",
      "[1 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 99us/step - loss: 91312.0312\n",
      "rewards:  31.0 q-value:  0\n",
      "loss: [91312.03125]\n",
      "Exploring\n",
      "Selected action  [1 4]\n",
      "[1 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 78us/step - loss: 37691.3438\n",
      "rewards:  29.0 q-value:  0\n",
      "loss: [37691.34375]\n",
      "Exploring\n",
      "Selected action  [3 0]\n",
      "[3 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 96us/step - loss: 37496.7500\n",
      "rewards:  16.0 q-value:  0\n",
      "loss: [37496.75]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 131us/step - loss: 32839.8438\n",
      "rewards:  13.0 q-value:  0\n",
      "loss: [32839.84375]\n",
      "Exploring\n",
      "Selected action  [3 1]\n",
      "[3 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 116us/step - loss: 74718.1250\n",
      "rewards:  20.0 q-value:  0\n",
      "loss: [74718.125]\n",
      "Exploiting\n",
      "Selected action  [4 3]\n",
      "[4 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 84us/step - loss: 30569.5000\n",
      "rewards:  36.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [30569.5]\n",
      "Exploiting\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 107us/step - loss: 45185.8750\n",
      "rewards:  32.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [45185.875]\n",
      "Exploring\n",
      "Selected action  [4 0]\n",
      "[4 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 112us/step - loss: 20819.4375\n",
      "rewards:  12.0 q-value:  0\n",
      "loss: [20819.4375]\n",
      "Exploiting\n",
      "Selected action  [4 0]\n",
      "[4 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 96us/step - loss: 39990.6250\n",
      "rewards:  12.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [39990.625]\n",
      "Exploiting\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 74us/step - loss: 66854.3125\n",
      "rewards:  7.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [66854.3125]\n",
      "Exploring\n",
      "Selected action  [3 0]\n",
      "[3 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 79us/step - loss: 64917.9062\n",
      "rewards:  1.0 q-value:  0\n",
      "loss: [64917.90625]\n",
      "Exploring\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 96us/step - loss: 30038.9375\n",
      "rewards:  -11.0 q-value:  0\n",
      "loss: [30038.9375]\n",
      "Exploring\n",
      "Selected action  [3 1]\n",
      "[3 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 76us/step - loss: 34970.1250\n",
      "rewards:  -3.0 q-value:  0\n",
      "loss: [34970.125]\n",
      "Exploring\n",
      "Selected action  [4 3]\n",
      "[4 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 97us/step - loss: 52666.5938\n",
      "rewards:  21.0 q-value:  0\n",
      "loss: [52666.59375]\n",
      "Exploring\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 76us/step - loss: 29431.3125\n",
      "rewards:  19.0 q-value:  0\n",
      "loss: [29431.3125]\n",
      "Exploiting\n",
      "Selected action  [4 0]\n",
      "[4 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 87us/step - loss: 51067.5000\n",
      "rewards:  13.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [51067.5]\n",
      "Exploring\n",
      "Selected action  [4 2]\n",
      "[4 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 130us/step - loss: 34364.9375\n",
      "rewards:  28.0 q-value:  0\n",
      "loss: [34364.9375]\n",
      "Exploring\n",
      "Selected action  [1 4]\n",
      "[1 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 102us/step - loss: 33737.9375\n",
      "rewards:  36.0 q-value:  0\n",
      "loss: [33737.9375]\n",
      "Exploring\n",
      "Selected action  [2 1]\n",
      "[2 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 80us/step - loss: 27176.9062\n",
      "rewards:  44.0 q-value:  0\n",
      "loss: [27176.90625]\n",
      "Exploring\n",
      "Selected action  [4 0]\n",
      "[4 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 90us/step - loss: 49521.7500\n",
      "rewards:  38.0 q-value:  0\n",
      "loss: [49521.75]\n",
      "Exploring\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 94us/step - loss: 23437.9375\n",
      "rewards:  28.0 q-value:  0\n",
      "loss: [23437.9375]\n",
      "Exploiting\n",
      "Selected action  [4 0]\n",
      "[4 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 77us/step - loss: 53088.3750\n",
      "rewards:  17.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [53088.375]\n",
      "Exploiting\n",
      "Selected action  [2 1]\n",
      "[2 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 130us/step - loss: 59384.7500\n",
      "rewards:  24.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [59384.75]\n",
      "Exploring\n",
      "Selected action  [2 1]\n",
      "[2 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 102us/step - loss: 26424.0938\n",
      "rewards:  19.0 q-value:  0\n",
      "loss: [26424.09375]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 90us/step - loss: 50576.5000\n",
      "rewards:  14.0 q-value:  0\n",
      "loss: [50576.5]\n",
      "Exploring\n",
      "Selected action  [4 2]\n",
      "[4 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 139us/step - loss: 27064.2812\n",
      "rewards:  33.0 q-value:  0\n",
      "loss: [27064.28125]\n",
      "Exploring\n",
      "Selected action  [1 4]\n",
      "[1 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 103us/step - loss: 17552.8438\n",
      "rewards:  28.0 q-value:  0\n",
      "loss: [17552.84375]\n",
      "Exploring\n",
      "Selected action  [3 1]\n",
      "[3 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 98us/step - loss: 32427.7188\n",
      "rewards:  -13.0 q-value:  0\n",
      "loss: [32427.71875]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 88us/step - loss: 20117.7812\n",
      "rewards:  -18.0 q-value:  0\n",
      "loss: [20117.78125]\n",
      "Exploiting\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 101us/step - loss: 18512.2500\n",
      "rewards:  -22.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [18512.25]\n",
      "Exploring\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 100us/step - loss: 46966.7812\n",
      "rewards:  -28.0 q-value:  0\n",
      "loss: [46966.78125]\n",
      "Exploring\n",
      "Selected action  [3 1]\n",
      "[3 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 101us/step - loss: 37175.6562\n",
      "rewards:  -24.0 q-value:  0\n",
      "loss: [37175.65625]\n",
      "Exploring\n",
      "Selected action  [3 1]\n",
      "[3 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 107us/step - loss: 35506.7188\n",
      "rewards:  -25.0 q-value:  0\n",
      "loss: [35506.71875]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 98us/step - loss: 45439.7500\n",
      "rewards:  -30.0 q-value:  0\n",
      "loss: [45439.75]\n",
      "Exploiting\n",
      "Selected action  [4 3]\n",
      "[4 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 91us/step - loss: 24697.7812\n",
      "rewards:  -40.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [24697.78125]\n",
      "Exploring\n",
      "Selected action  [3 1]\n",
      "[3 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 87us/step - loss: 30316.0312\n",
      "rewards:  -16.0 q-value:  0\n",
      "loss: [30316.03125]\n",
      "Exploring\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 87us/step - loss: 53782.5000\n",
      "rewards:  -8.0 q-value:  0\n",
      "loss: [53782.5]\n",
      "Exploring\n",
      "Selected action  [4 0]\n",
      "[4 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 90us/step - loss: 60389.9375\n",
      "rewards:  -39.0 q-value:  0\n",
      "loss: [60389.9375]\n",
      "Exploring\n",
      "Selected action  [4 3]\n",
      "[4 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 109us/step - loss: 43904.2812\n",
      "rewards:  -16.0 q-value:  0\n",
      "loss: [43904.28125]\n",
      "Exploring\n",
      "Selected action  [1 4]\n",
      "[1 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 91us/step - loss: 39377.7188\n",
      "rewards:  -26.0 q-value:  0\n",
      "loss: [39377.71875]\n",
      "Exploring\n",
      "Selected action  [3 0]\n",
      "[3 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 114us/step - loss: 60283.8750\n",
      "rewards:  -32.0 q-value:  0\n",
      "loss: [60283.875]\n",
      "Exploring\n",
      "Selected action  [2 1]\n",
      "[2 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 89us/step - loss: 25292.7188\n",
      "rewards:  2.0 q-value:  0\n",
      "loss: [25292.71875]\n",
      "Exploring\n",
      "Selected action  [4 3]\n",
      "[4 3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 128us/step - loss: 61233.8750\n",
      "rewards:  -9.0 q-value:  0\n",
      "loss: [61233.875]\n",
      "Exploring\n",
      "Selected action  [1 4]\n",
      "[1 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 91us/step - loss: 35805.0312\n",
      "rewards:  -14.0 q-value:  0\n",
      "loss: [35805.03125]\n",
      "Exploiting\n",
      "Selected action  [4 3]\n",
      "[4 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 125us/step - loss: 40733.4375\n",
      "rewards:  10.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [40733.4375]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 111us/step - loss: 69924.9062\n",
      "rewards:  29.0 q-value:  0\n",
      "loss: [69924.90625]\n",
      "Exploring\n",
      "Selected action  [3 1]\n",
      "[3 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 156us/step - loss: 19627.4375\n",
      "rewards:  16.0 q-value:  0\n",
      "loss: [19627.4375]\n",
      "Exploring\n",
      "Selected action  [3 0]\n",
      "[3 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 123us/step - loss: 61600.5312\n",
      "rewards:  21.0 q-value:  0\n",
      "loss: [61600.53125]\n",
      "Exploring\n",
      "Selected action  [3 0]\n",
      "[3 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 129us/step - loss: 34996.2188\n",
      "rewards:  15.0 q-value:  0\n",
      "loss: [34996.21875]\n",
      "Exploring\n",
      "Selected action  [3 0]\n",
      "[3 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 108us/step - loss: 21426.9688\n",
      "rewards:  10.0 q-value:  0\n",
      "loss: [21426.96875]\n",
      "Exploring\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 106us/step - loss: 70305.2188\n",
      "rewards:  4.0 q-value:  0\n",
      "loss: [70305.21875]\n",
      "Exploring\n",
      "Selected action  [3 1]\n",
      "[3 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 84us/step - loss: 52416.8125\n",
      "rewards:  8.0 q-value:  0\n",
      "loss: [52416.8125]\n",
      "Exploring\n",
      "Selected action  [4 0]\n",
      "[4 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 96us/step - loss: 24285.4688\n",
      "rewards:  32.0 q-value:  0\n",
      "loss: [24285.46875]\n",
      "Exploiting\n",
      "Selected action  [4 2]\n",
      "[4 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 99us/step - loss: 16987.0312\n",
      "rewards:  31.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [16987.03125]\n",
      "Exploring\n",
      "Selected action  [4 3]\n",
      "[4 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 91us/step - loss: 46023.9375\n",
      "rewards:  38.0 q-value:  0\n",
      "loss: [46023.9375]\n",
      "Exploiting\n",
      "Selected action  [4 2]\n",
      "[4 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 101us/step - loss: 25416.0312\n",
      "rewards:  45.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [25416.03125]\n",
      "Exploiting\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 83us/step - loss: 46307.0625\n",
      "rewards:  44.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [46307.0625]\n",
      "Exploiting\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 105us/step - loss: 86679.8438\n",
      "rewards:  43.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [86679.84375]\n",
      "Exploring\n",
      "Selected action  [4 2]\n",
      "[4 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 107us/step - loss: 39873.6562\n",
      "rewards:  26.0 q-value:  0\n",
      "loss: [39873.65625]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 110us/step - loss: 38092.1250\n",
      "rewards:  21.0 q-value:  0\n",
      "loss: [38092.125]\n",
      "Exploring\n",
      "Selected action  [4 0]\n",
      "[4 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 107us/step - loss: 50554.8750\n",
      "rewards:  18.0 q-value:  0\n",
      "loss: [50554.875]\n",
      "Exploring\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 119us/step - loss: 51863.9688\n",
      "rewards:  -5.0 q-value:  0\n",
      "loss: [51863.96875]\n",
      "Exploring\n",
      "Selected action  [3 0]\n",
      "[3 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 110us/step - loss: 44831.5000\n",
      "rewards:  11.0 q-value:  0\n",
      "loss: [44831.5]\n",
      "Exploiting\n",
      "Selected action  [3 0]\n",
      "[3 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 76us/step - loss: 40280.7188\n",
      "rewards:  7.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [40280.71875]\n",
      "Exploring\n",
      "Selected action  [1 4]\n",
      "[1 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 91us/step - loss: 55390.3750\n",
      "rewards:  2.0 q-value:  0\n",
      "loss: [55390.375]\n",
      "Exploring\n",
      "Selected action  [3 0]\n",
      "[3 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 110us/step - loss: 48513.0625\n",
      "rewards:  -12.0 q-value:  0\n",
      "loss: [48513.0625]\n",
      "Exploiting\n",
      "Selected action  [2 1]\n",
      "[2 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 93us/step - loss: 36436.5000\n",
      "rewards:  -13.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [36436.5]\n",
      "Exploiting\n",
      "Selected action  [3 0]\n",
      "[3 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 109us/step - loss: 56046.1875\n",
      "rewards:  -9.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [56046.1875]\n",
      "Exploring\n",
      "Selected action  [3 1]\n",
      "[3 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 92us/step - loss: 47993.7188\n",
      "rewards:  -8.0 q-value:  0\n",
      "loss: [47993.71875]\n",
      "Exploring\n",
      "Selected action  [4 0]\n",
      "[4 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 86us/step - loss: 30819.0312\n",
      "rewards:  -31.0 q-value:  0\n",
      "loss: [30819.03125]\n",
      "Exploiting\n",
      "Selected action  [4 3]\n",
      "[4 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 93us/step - loss: 72497.6562\n",
      "rewards:  -24.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [72497.65625]\n",
      "Exploiting\n",
      "Selected action  [1 4]\n",
      "[1 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 97us/step - loss: 12807.5625\n",
      "rewards:  -16.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [12807.5625]\n",
      "Exploring\n",
      "Selected action  [4 3]\n",
      "[4 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 91us/step - loss: 24492.7500\n",
      "rewards:  -4.0 q-value:  0\n",
      "loss: [24492.75]\n",
      "Exploring\n",
      "Selected action  [4 0]\n",
      "[4 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 89us/step - loss: 45978.3438\n",
      "rewards:  13.0 q-value:  0\n",
      "loss: [45978.34375]\n",
      "Exploring\n",
      "Selected action  [3 1]\n",
      "[3 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 92us/step - loss: 62496.1250\n",
      "rewards:  -17.0 q-value:  0\n",
      "loss: [62496.125]\n",
      "Exploring\n",
      "Selected action  [2 1]\n",
      "[2 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 94us/step - loss: 65137.7188\n",
      "rewards:  -27.0 q-value:  0\n",
      "loss: [65137.71875]\n",
      "Exploring\n",
      "Selected action  [2 1]\n",
      "[2 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 104us/step - loss: 19876.7500\n",
      "rewards:  -32.0 q-value:  0\n",
      "loss: [19876.75]\n",
      "Exploiting\n",
      "Selected action  [3 1]\n",
      "[3 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 111us/step - loss: 41359.3750\n",
      "rewards:  -38.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [41359.375]\n",
      "Exploiting\n",
      "Selected action  [4 0]\n",
      "[4 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 127us/step - loss: 71469.8125\n",
      "rewards:  -44.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [71469.8125]\n",
      "Number of actions available 6\n",
      "Episode : 37\n",
      "Exploring\n",
      "Selected action  [4 2]\n",
      "[4 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 102us/step - loss: 62318.1562\n",
      "rewards:  10.0 q-value:  0\n",
      "loss: [62318.15625]\n",
      "Exploring\n",
      "Selected action  [2 1]\n",
      "[2 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 78us/step - loss: 24082.2812\n",
      "rewards:  26.0 q-value:  0\n",
      "loss: [24082.28125]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 117us/step - loss: 47164.2812\n",
      "rewards:  24.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [47164.28125]\n",
      "Exploring\n",
      "Selected action  [4 2]\n",
      "[4 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 133us/step - loss: 35184.7188\n",
      "rewards:  14.0 q-value:  0\n",
      "loss: [35184.71875]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 136us/step - loss: 68437.2812\n",
      "rewards:  7.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [68437.28125]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 104us/step - loss: 50233.1562\n",
      "rewards:  15.0 q-value:  0\n",
      "loss: [50233.15625]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 125us/step - loss: 18727.1875\n",
      "rewards:  13.0 q-value:  0\n",
      "loss: [18727.1875]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 128us/step - loss: 52454.2188\n",
      "rewards:  11.0 q-value:  0\n",
      "loss: [52454.21875]\n",
      "Exploring\n",
      "Selected action  [2 1]\n",
      "[2 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 143us/step - loss: 25107.8125\n",
      "rewards:  18.0 q-value:  0\n",
      "loss: [25107.8125]\n",
      "Exploring\n",
      "Selected action  [2 1]\n",
      "[2 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 104us/step - loss: 31047.6875\n",
      "rewards:  8.0 q-value:  0\n",
      "loss: [31047.6875]\n",
      "Exploring\n",
      "Selected action  [4 2]\n",
      "[4 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 92us/step - loss: 36590.2188\n",
      "rewards:  16.0 q-value:  0\n",
      "loss: [36590.21875]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 117us/step - loss: 17204.5625\n",
      "rewards:  -6.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [17204.5625]\n",
      "Exploring\n",
      "Selected action  [4 2]\n",
      "[4 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 127us/step - loss: 24232.9688\n",
      "rewards:  -26.0 q-value:  0\n",
      "loss: [24232.96875]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 111us/step - loss: 32885.4688\n",
      "rewards:  -31.0 q-value:  0\n",
      "loss: [32885.46875]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 93us/step - loss: 33559.1562\n",
      "rewards:  -23.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [33559.15625]\n",
      "Exploring\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 131us/step - loss: 39977.8438\n",
      "rewards:  -25.0 q-value:  0\n",
      "loss: [39977.84375]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 109us/step - loss: 42009.1250\n",
      "rewards:  -28.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [42009.125]\n",
      "Exploring\n",
      "Selected action  [2 1]\n",
      "[2 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 133us/step - loss: 95701.2812\n",
      "rewards:  -34.0 q-value:  0\n",
      "loss: [95701.28125]\n",
      "Exploring\n",
      "Selected action  [0 3]\n",
      "[0 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 108us/step - loss: 29225.1875\n",
      "rewards:  -57.0 q-value:  0\n",
      "loss: [29225.1875]\n",
      "Exploring\n",
      "Selected action  [2 1]\n",
      "[2 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 119us/step - loss: 30459.1875\n",
      "rewards:  -60.0 q-value:  0\n",
      "loss: [30459.1875]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 102us/step - loss: 38764.4062\n",
      "rewards:  -65.0 q-value:  0\n",
      "loss: [38764.40625]\n",
      "Exploring\n",
      "Selected action  [0 3]\n",
      "[0 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 116us/step - loss: 40976.1562\n",
      "rewards:  -61.0 q-value:  0\n",
      "loss: [40976.15625]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 115us/step - loss: 30691.5625\n",
      "rewards:  -38.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [30691.5625]\n",
      "Exploring\n",
      "Selected action  [0 3]\n",
      "[0 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 114us/step - loss: 38418.1875\n",
      "rewards:  -49.0 q-value:  0\n",
      "loss: [38418.1875]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 125us/step - loss: 24287.0000\n",
      "rewards:  -62.0 q-value:  0\n",
      "loss: [24287.0]\n",
      "Exploring\n",
      "Selected action  [4 2]\n",
      "[4 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 77us/step - loss: 23793.1562\n",
      "rewards:  -63.0 q-value:  0\n",
      "loss: [23793.15625]\n",
      "Exploring\n",
      "Selected action  [2 1]\n",
      "[2 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 139us/step - loss: 33713.6875\n",
      "rewards:  -43.0 q-value:  0\n",
      "loss: [33713.6875]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 105us/step - loss: 57299.6875\n",
      "rewards:  -48.0 q-value:  0\n",
      "loss: [57299.6875]\n",
      "Exploring\n",
      "Selected action  [2 1]\n",
      "[2 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 140us/step - loss: 33110.5000\n",
      "rewards:  -62.0 q-value:  0\n",
      "loss: [33110.5]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 138us/step - loss: 37075.1875\n",
      "rewards:  -38.0 q-value:  0\n",
      "loss: [37075.1875]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 103us/step - loss: 111198.4375\n",
      "rewards:  -43.0 q-value:  0\n",
      "loss: [111198.4375]\n",
      "Exploring\n",
      "Selected action  [4 2]\n",
      "[4 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 106us/step - loss: 13239.5312\n",
      "rewards:  -70.0 q-value:  0\n",
      "loss: [13239.53125]\n",
      "Exploring\n",
      "Selected action  [0 3]\n",
      "[0 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 113us/step - loss: 86293.1875\n",
      "rewards:  -102.0 q-value:  0\n",
      "loss: [86293.1875]\n",
      "Exploring\n",
      "Selected action  [0 3]\n",
      "[0 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 100us/step - loss: 21123.5938\n",
      "rewards:  -104.0 q-value:  0\n",
      "loss: [21123.59375]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 130us/step - loss: 32064.4062\n",
      "rewards:  -99.0 q-value:  0\n",
      "loss: [32064.40625]\n",
      "Exploring\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 99us/step - loss: 27327.4375\n",
      "rewards:  -71.0 q-value:  0\n",
      "loss: [27327.4375]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 120us/step - loss: 47210.1562\n",
      "rewards:  -76.0 q-value:  0\n",
      "loss: [47210.15625]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 101us/step - loss: 37567.5312\n",
      "rewards:  -60.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [37567.53125]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 96us/step - loss: 32924.4062\n",
      "rewards:  -65.0 q-value:  0\n",
      "loss: [32924.40625]\n",
      "Exploring\n",
      "Selected action  [4 2]\n",
      "[4 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 138us/step - loss: 33833.9375\n",
      "rewards:  -61.0 q-value:  0\n",
      "loss: [33833.9375]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 75us/step - loss: 46562.0625\n",
      "rewards:  -78.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [46562.0625]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 95us/step - loss: 45538.5938\n",
      "rewards:  -83.0 q-value:  0\n",
      "loss: [45538.59375]\n",
      "Exploring\n",
      "Selected action  [0 3]\n",
      "[0 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 96us/step - loss: 50562.4375\n",
      "rewards:  -71.0 q-value:  0\n",
      "loss: [50562.4375]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 108us/step - loss: 36635.2500\n",
      "rewards:  -78.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [36635.25]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 102us/step - loss: 31395.5625\n",
      "rewards:  -83.0 q-value:  0\n",
      "loss: [31395.5625]\n",
      "Exploring\n",
      "Selected action  [4 2]\n",
      "[4 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 105us/step - loss: 41073.5000\n",
      "rewards:  -84.0 q-value:  0\n",
      "loss: [41073.5]\n",
      "Exploring\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 117us/step - loss: 56882.2812\n",
      "rewards:  -71.0 q-value:  0\n",
      "loss: [56882.28125]\n",
      "Exploring\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 90us/step - loss: 19541.7812\n",
      "rewards:  -79.0 q-value:  0\n",
      "loss: [19541.78125]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 102us/step - loss: 38472.8125\n",
      "rewards:  -82.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [38472.8125]\n",
      "Exploring\n",
      "Selected action  [0 3]\n",
      "[0 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 91us/step - loss: 56026.4062\n",
      "rewards:  -113.0 q-value:  0\n",
      "loss: [56026.40625]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 126us/step - loss: 45092.3125\n",
      "rewards:  -90.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [45092.3125]\n",
      "Exploring\n",
      "Selected action  [4 2]\n",
      "[4 2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 130us/step - loss: 15034.5938\n",
      "rewards:  -95.0 q-value:  0\n",
      "loss: [15034.59375]\n",
      "Exploring\n",
      "Selected action  [2 1]\n",
      "[2 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 97us/step - loss: 11277.6875\n",
      "rewards:  -59.0 q-value:  0\n",
      "loss: [11277.6875]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 121us/step - loss: 44434.8125\n",
      "rewards:  -63.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [44434.8125]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 110us/step - loss: 102980.3438\n",
      "rewards:  -67.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [102980.34375]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 100us/step - loss: 17261.4375\n",
      "rewards:  -72.0 q-value:  0\n",
      "loss: [17261.4375]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 97us/step - loss: 34083.0312\n",
      "rewards:  -77.0 q-value:  0\n",
      "loss: [34083.03125]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 113us/step - loss: 17058.5938\n",
      "rewards:  -81.0 q-value:  0\n",
      "loss: [17058.59375]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 99us/step - loss: 17626.4375\n",
      "rewards:  -86.0 q-value:  0\n",
      "loss: [17626.4375]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 115us/step - loss: 56669.6250\n",
      "rewards:  -62.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [56669.625]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 135us/step - loss: 60414.6250\n",
      "rewards:  -68.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [60414.625]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 88us/step - loss: 35141.4375\n",
      "rewards:  -60.0 q-value:  0\n",
      "loss: [35141.4375]\n",
      "Exploring\n",
      "Selected action  [2 1]\n",
      "[2 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 103us/step - loss: 43274.8750\n",
      "rewards:  -67.0 q-value:  0\n",
      "loss: [43274.875]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 97us/step - loss: 36126.5000\n",
      "rewards:  -72.0 q-value:  0\n",
      "loss: [36126.5]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 116us/step - loss: 28864.3125\n",
      "rewards:  -64.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [28864.3125]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 133us/step - loss: 25051.4375\n",
      "rewards:  -56.0 q-value:  0\n",
      "loss: [25051.4375]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 115us/step - loss: 49566.1250\n",
      "rewards:  -48.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [49566.125]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 182us/step - loss: 40213.7188\n",
      "rewards:  -50.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [40213.71875]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 87us/step - loss: 34028.7500\n",
      "rewards:  -52.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [34028.75]\n",
      "Exploring\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 81us/step - loss: 54625.7812\n",
      "rewards:  -54.0 q-value:  0\n",
      "loss: [54625.78125]\n",
      "Exploring\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 107us/step - loss: 37940.6250\n",
      "rewards:  -56.0 q-value:  0\n",
      "loss: [37940.625]\n",
      "Exploring\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 126us/step - loss: 30984.7500\n",
      "rewards:  -65.0 q-value:  0\n",
      "loss: [30984.75]\n",
      "Exploring\n",
      "Selected action  [2 1]\n",
      "[2 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 122us/step - loss: 28161.8438\n",
      "rewards:  -66.0 q-value:  0\n",
      "loss: [28161.84375]\n",
      "Exploring\n",
      "Selected action  [4 2]\n",
      "[4 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 110us/step - loss: 92377.2812\n",
      "rewards:  -58.0 q-value:  0\n",
      "loss: [92377.28125]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 110us/step - loss: 19713.9688\n",
      "rewards:  -80.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [19713.96875]\n",
      "Exploring\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 166us/step - loss: 77442.2812\n",
      "rewards:  -82.0 q-value:  0\n",
      "loss: [77442.28125]\n",
      "Exploring\n",
      "Selected action  [4 2]\n",
      "[4 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 124us/step - loss: 33082.8125\n",
      "rewards:  -102.0 q-value:  0\n",
      "loss: [33082.8125]\n",
      "Exploring\n",
      "Selected action  [4 2]\n",
      "[4 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 165us/step - loss: 22920.9688\n",
      "rewards:  -102.0 q-value:  0\n",
      "loss: [22920.96875]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 108us/step - loss: 65916.0938\n",
      "rewards:  -107.0 q-value:  0\n",
      "loss: [65916.09375]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 105us/step - loss: 28287.5000\n",
      "rewards:  -99.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [28287.5]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 104us/step - loss: 29318.5938\n",
      "rewards:  -102.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [29318.59375]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 87us/step - loss: 71378.7812\n",
      "rewards:  -107.0 q-value:  0\n",
      "loss: [71378.78125]\n",
      "Exploring\n",
      "Selected action  [2 1]\n",
      "[2 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 114us/step - loss: 89679.5938\n",
      "rewards:  -113.0 q-value:  0\n",
      "loss: [89679.59375]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 108us/step - loss: 44138.5938\n",
      "rewards:  -118.0 q-value:  0\n",
      "loss: [44138.59375]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 88us/step - loss: 30789.8125\n",
      "rewards:  -125.0 q-value:  0\n",
      "loss: [30789.8125]\n",
      "Exploring\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 139us/step - loss: 41817.2188\n",
      "rewards:  -97.0 q-value:  0\n",
      "loss: [41817.21875]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 149us/step - loss: 49514.9062\n",
      "rewards:  -85.0 q-value:  0\n",
      "loss: [49514.90625]\n",
      "Exploring\n",
      "Selected action  [4 2]\n",
      "[4 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 96us/step - loss: 31541.0312\n",
      "rewards:  -86.0 q-value:  0\n",
      "loss: [31541.03125]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 122us/step - loss: 47053.8438\n",
      "rewards:  -99.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [47053.84375]\n",
      "Exploring\n",
      "Selected action  [0 3]\n",
      "[0 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 129us/step - loss: 14101.0000\n",
      "rewards:  -112.0 q-value:  0\n",
      "loss: [14101.0]\n",
      "Exploring\n",
      "Selected action  [4 2]\n",
      "[4 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 100us/step - loss: 24634.0000\n",
      "rewards:  -134.0 q-value:  0\n",
      "loss: [24634.0]\n",
      "Exploring\n",
      "Selected action  [4 2]\n",
      "[4 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 92us/step - loss: 25822.9375\n",
      "rewards:  -136.0 q-value:  0\n",
      "loss: [25822.9375]\n",
      "Exploring\n",
      "Selected action  [2 1]\n",
      "[2 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 131us/step - loss: 21619.4062\n",
      "rewards:  -108.0 q-value:  0\n",
      "loss: [21619.40625]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 93us/step - loss: 62952.5312\n",
      "rewards:  -88.0 q-value:  0\n",
      "loss: [62952.53125]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 161us/step - loss: 50316.7812\n",
      "rewards:  -95.0 q-value:  0\n",
      "loss: [50316.78125]\n",
      "Exploring\n",
      "Selected action  [2 1]\n",
      "[2 1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 108us/step - loss: 32068.3438\n",
      "rewards:  -101.0 q-value:  0\n",
      "loss: [32068.34375]\n",
      "Exploring\n",
      "Selected action  [0 3]\n",
      "[0 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 103us/step - loss: 10998.0938\n",
      "rewards:  -101.0 q-value:  0\n",
      "loss: [10998.09375]\n",
      "Exploring\n",
      "Selected action  [0 3]\n",
      "[0 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 127us/step - loss: 50006.2812\n",
      "rewards:  -104.0 q-value:  0\n",
      "loss: [50006.28125]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 117us/step - loss: 21954.6875\n",
      "rewards:  -111.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [21954.6875]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 98us/step - loss: 22008.4688\n",
      "rewards:  -118.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [22008.46875]\n",
      "Exploring\n",
      "Selected action  [0 3]\n",
      "[0 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 100us/step - loss: 38813.6562\n",
      "rewards:  -154.0 q-value:  0\n",
      "loss: [38813.65625]\n",
      "Exploring\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 99us/step - loss: 27707.1875\n",
      "rewards:  -127.0 q-value:  0\n",
      "loss: [27707.1875]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 97us/step - loss: 29596.1562\n",
      "rewards:  -130.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [29596.15625]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 132us/step - loss: 34587.2188\n",
      "rewards:  -137.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [34587.21875]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 126us/step - loss: 35025.3750\n",
      "rewards:  -137.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [35025.375]\n",
      "Exploring\n",
      "Selected action  [4 2]\n",
      "[4 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 148us/step - loss: 55880.0625\n",
      "rewards:  -142.0 q-value:  0\n",
      "loss: [55880.0625]\n",
      "Exploring\n",
      "Selected action  [0 3]\n",
      "[0 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 109us/step - loss: 68111.0312\n",
      "rewards:  -161.0 q-value:  0\n",
      "loss: [68111.03125]\n",
      "Exploring\n",
      "Selected action  [0 3]\n",
      "[0 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 123us/step - loss: 11384.7812\n",
      "rewards:  -167.0 q-value:  0\n",
      "loss: [11384.78125]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 107us/step - loss: 39317.1875\n",
      "rewards:  -171.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [39317.1875]\n",
      "Exploring\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 93us/step - loss: 32636.7188\n",
      "rewards:  -175.0 q-value:  0\n",
      "loss: [32636.71875]\n",
      "Exploring\n",
      "Selected action  [2 1]\n",
      "[2 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 89us/step - loss: 38262.5938\n",
      "rewards:  -181.0 q-value:  0\n",
      "loss: [38262.59375]\n",
      "Exploring\n",
      "Selected action  [2 1]\n",
      "[2 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 143us/step - loss: 11902.8750\n",
      "rewards:  -188.0 q-value:  0\n",
      "loss: [11902.875]\n",
      "Exploring\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 94us/step - loss: 46756.3438\n",
      "rewards:  -194.0 q-value:  0\n",
      "loss: [46756.34375]\n",
      "Exploring\n",
      "Selected action  [4 2]\n",
      "[4 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 94us/step - loss: 63628.6875\n",
      "rewards:  -204.0 q-value:  0\n",
      "loss: [63628.6875]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 118us/step - loss: 67651.5938\n",
      "rewards:  -206.0 q-value:  0\n",
      "loss: [67651.59375]\n",
      "Exploring\n",
      "Selected action  [2 1]\n",
      "[2 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 171us/step - loss: 47124.0312\n",
      "rewards:  -199.0 q-value:  0\n",
      "loss: [47124.03125]\n",
      "Number of actions available 8\n",
      "Episode : 38\n",
      "Exploring\n",
      "Selected action  [3 0]\n",
      "[3 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 108us/step - loss: 26804.1250\n",
      "rewards:  24.0 q-value:  0\n",
      "loss: [26804.125]\n",
      "Exploiting\n",
      "Selected action  [2 3]\n",
      "[2 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 140us/step - loss: 25697.3125\n",
      "rewards:  18.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [25697.3125]\n",
      "Exploring\n",
      "Selected action  [2 1]\n",
      "[2 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 116us/step - loss: 36644.6562\n",
      "rewards:  -14.0 q-value:  0\n",
      "loss: [36644.65625]\n",
      "Exploiting\n",
      "Selected action  [1 4]\n",
      "[1 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 92us/step - loss: 46287.4375\n",
      "rewards:  -6.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [46287.4375]\n",
      "Exploring\n",
      "Selected action  [3 0]\n",
      "[3 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 103us/step - loss: 18010.3125\n",
      "rewards:  -9.0 q-value:  0\n",
      "loss: [18010.3125]\n",
      "Exploring\n",
      "Selected action  [1 4]\n",
      "[1 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 87us/step - loss: 33261.8750\n",
      "rewards:  -7.0 q-value:  0\n",
      "loss: [33261.875]\n",
      "Exploiting\n",
      "Selected action  [2 3]\n",
      "[2 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 118us/step - loss: 46659.6250\n",
      "rewards:  12.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [46659.625]\n",
      "Exploring\n",
      "Selected action  [1 4]\n",
      "[1 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 110us/step - loss: 17861.1562\n",
      "rewards:  19.0 q-value:  0\n",
      "loss: [17861.15625]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 140us/step - loss: 16190.9688\n",
      "rewards:  14.0 q-value:  0\n",
      "loss: [16190.96875]\n",
      "Exploring\n",
      "Selected action  [2 1]\n",
      "[2 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 141us/step - loss: 51038.9062\n",
      "rewards:  24.0 q-value:  0\n",
      "loss: [51038.90625]\n",
      "Exploring\n",
      "Selected action  [3 0]\n",
      "[3 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 124us/step - loss: 21610.7500\n",
      "rewards:  19.0 q-value:  0\n",
      "loss: [21610.75]\n",
      "Exploring\n",
      "Selected action  [1 4]\n",
      "[1 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 95us/step - loss: 23344.4375\n",
      "rewards:  25.0 q-value:  0\n",
      "loss: [23344.4375]\n",
      "Exploiting\n",
      "Selected action  [4 0]\n",
      "[4 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 139us/step - loss: 52383.0000\n",
      "rewards:  29.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [52383.0]\n",
      "Exploring\n",
      "Selected action  [3 0]\n",
      "[3 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 100us/step - loss: 17313.8750\n",
      "rewards:  23.0 q-value:  0\n",
      "loss: [17313.875]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 106us/step - loss: 48961.0312\n",
      "rewards:  16.0 q-value:  0\n",
      "loss: [48961.03125]\n",
      "Exploring\n",
      "Selected action  [4 3]\n",
      "[4 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 93us/step - loss: 22687.0312\n",
      "rewards:  35.0 q-value:  0\n",
      "loss: [22687.03125]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 103us/step - loss: 32648.3750\n",
      "rewards:  30.0 q-value:  0\n",
      "loss: [32648.375]\n",
      "Exploiting\n",
      "Selected action  [3 0]\n",
      "[3 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 97us/step - loss: 24264.8125\n",
      "rewards:  29.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [24264.8125]\n",
      "Exploring\n",
      "Selected action  [3 0]\n",
      "[3 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 95us/step - loss: 48325.0312\n",
      "rewards:  28.0 q-value:  0\n",
      "loss: [48325.03125]\n",
      "Exploring\n",
      "Selected action  [1 4]\n",
      "[1 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 114us/step - loss: 43587.7812\n",
      "rewards:  13.0 q-value:  0\n",
      "loss: [43587.78125]\n",
      "Exploiting\n",
      "Selected action  [3 0]\n",
      "[3 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 100us/step - loss: 84395.4688\n",
      "rewards:  7.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [84395.46875]\n",
      "Exploring\n",
      "Selected action  [4 0]\n",
      "[4 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 128us/step - loss: 49615.4375\n",
      "rewards:  3.0 q-value:  0\n",
      "loss: [49615.4375]\n",
      "Exploring\n",
      "Selected action  [4 0]\n",
      "[4 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 81us/step - loss: 25261.4375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rewards:  2.0 q-value:  0\n",
      "loss: [25261.4375]\n",
      "Exploring\n",
      "Selected action  [3 0]\n",
      "[3 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 90us/step - loss: 6692.6875\n",
      "rewards:  -6.0 q-value:  0\n",
      "loss: [6692.6875]\n",
      "Exploring\n",
      "Selected action  [1 4]\n",
      "[1 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 112us/step - loss: 23793.0938\n",
      "rewards:  -36.0 q-value:  0\n",
      "loss: [23793.09375]\n",
      "Exploiting\n",
      "Selected action  [3 0]\n",
      "[3 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 118us/step - loss: 9490.1562\n",
      "rewards:  -58.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [9490.15625]\n",
      "Exploring\n",
      "Selected action  [2 3]\n",
      "[2 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 77us/step - loss: 34674.3125\n",
      "rewards:  -47.0 q-value:  0\n",
      "loss: [34674.3125]\n",
      "Exploring\n",
      "Selected action  [4 0]\n",
      "[4 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 104us/step - loss: 16854.3750\n",
      "rewards:  -39.0 q-value:  0\n",
      "loss: [16854.375]\n",
      "Exploiting\n",
      "Selected action  [4 3]\n",
      "[4 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 114us/step - loss: 11010.7188\n",
      "rewards:  -31.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [11010.71875]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 108us/step - loss: 28818.0938\n",
      "rewards:  -36.0 q-value:  0\n",
      "loss: [28818.09375]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 88us/step - loss: 42908.2812\n",
      "rewards:  -41.0 q-value:  0\n",
      "loss: [42908.28125]\n",
      "Exploiting\n",
      "Selected action  [2 1]\n",
      "[2 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 98us/step - loss: 35785.0312\n",
      "rewards:  -28.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [35785.03125]\n",
      "Exploiting\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 118us/step - loss: 22157.4375\n",
      "rewards:  0.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [22157.4375]\n",
      "Exploiting\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 92us/step - loss: 18246.2812\n",
      "rewards:  -4.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [18246.28125]\n",
      "Exploiting\n",
      "Selected action  [2 3]\n",
      "[2 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 119us/step - loss: 12850.5625\n",
      "rewards:  -29.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [12850.5625]\n",
      "Exploring\n",
      "Selected action  [4 0]\n",
      "[4 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 111us/step - loss: 27177.1250\n",
      "rewards:  -35.0 q-value:  0\n",
      "loss: [27177.125]\n",
      "Exploring\n",
      "Selected action  [2 1]\n",
      "[2 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 139us/step - loss: 35118.8125\n",
      "rewards:  -22.0 q-value:  0\n",
      "loss: [35118.8125]\n",
      "Exploring\n",
      "Selected action  [2 1]\n",
      "[2 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 111us/step - loss: 31377.1250\n",
      "rewards:  -29.0 q-value:  0\n",
      "loss: [31377.125]\n",
      "Exploiting\n",
      "Selected action  [4 0]\n",
      "[4 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 129us/step - loss: 32624.9688\n",
      "rewards:  -23.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [32624.96875]\n",
      "Exploiting\n",
      "Selected action  [4 0]\n",
      "[4 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 153us/step - loss: 33081.0000\n",
      "rewards:  -26.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [33081.0]\n",
      "Exploiting\n",
      "Selected action  [2 1]\n",
      "[2 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 120us/step - loss: 12693.5938\n",
      "rewards:  -25.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [12693.59375]\n",
      "Exploiting\n",
      "Selected action  [1 4]\n",
      "[1 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 99us/step - loss: 17199.1250\n",
      "rewards:  -5.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [17199.125]\n",
      "Exploiting\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 124us/step - loss: 46376.7812\n",
      "rewards:  11.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [46376.78125]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 125us/step - loss: 21707.7188\n",
      "rewards:  6.0 q-value:  0\n",
      "loss: [21707.71875]\n",
      "Exploring\n",
      "Selected action  [4 3]\n",
      "[4 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 110us/step - loss: 32449.0312\n",
      "rewards:  25.0 q-value:  0\n",
      "loss: [32449.03125]\n",
      "Exploring\n",
      "Selected action  [2 1]\n",
      "[2 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 103us/step - loss: 19316.4688\n",
      "rewards:  8.0 q-value:  0\n",
      "loss: [19316.46875]\n",
      "Exploring\n",
      "Selected action  [2 3]\n",
      "[2 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 113us/step - loss: 20059.4062\n",
      "rewards:  12.0 q-value:  0\n",
      "loss: [20059.40625]\n",
      "Exploring\n",
      "Selected action  [2 3]\n",
      "[2 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 85us/step - loss: 40018.7500\n",
      "rewards:  4.0 q-value:  0\n",
      "loss: [40018.75]\n",
      "Exploring\n",
      "Selected action  [4 0]\n",
      "[4 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 103us/step - loss: 17393.1250\n",
      "rewards:  21.0 q-value:  0\n",
      "loss: [17393.125]\n",
      "Exploiting\n",
      "Selected action  [4 0]\n",
      "[4 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 145us/step - loss: 34920.9688\n",
      "rewards:  20.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [34920.96875]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 124us/step - loss: 30188.9688\n",
      "rewards:  15.0 q-value:  0\n",
      "loss: [30188.96875]\n",
      "Exploiting\n",
      "Selected action  [1 4]\n",
      "[1 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 107us/step - loss: 22547.3125\n",
      "rewards:  -18.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [22547.3125]\n",
      "Exploiting\n",
      "Selected action  [2 3]\n",
      "[2 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 92us/step - loss: 40546.0625\n",
      "rewards:  -40.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [40546.0625]\n",
      "Exploiting\n",
      "Selected action  [4 0]\n",
      "[4 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 122us/step - loss: 27668.2812\n",
      "rewards:  -71.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [27668.28125]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 123us/step - loss: 45290.2812\n",
      "rewards:  -76.0 q-value:  0\n",
      "loss: [45290.28125]\n",
      "Exploring\n",
      "Selected action  [4 0]\n",
      "[4 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 102us/step - loss: 13579.4688\n",
      "rewards:  -79.0 q-value:  0\n",
      "loss: [13579.46875]\n",
      "Exploring\n",
      "Selected action  [4 3]\n",
      "[4 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 109us/step - loss: 18784.0312\n",
      "rewards:  -58.0 q-value:  0\n",
      "loss: [18784.03125]\n",
      "Exploiting\n",
      "Selected action  [4 3]\n",
      "[4 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 121us/step - loss: 11807.5938\n",
      "rewards:  -63.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [11807.59375]\n",
      "Exploring\n",
      "Selected action  [2 3]\n",
      "[2 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 123us/step - loss: 14518.7500\n",
      "rewards:  -69.0 q-value:  0\n",
      "loss: [14518.75]\n",
      "Exploring\n",
      "Selected action  [1 4]\n",
      "[1 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 123us/step - loss: 9223.0938\n",
      "rewards:  -71.0 q-value:  0\n",
      "loss: [9223.09375]\n",
      "Exploiting\n",
      "Selected action  [2 1]\n",
      "[2 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 105us/step - loss: 19237.0938\n",
      "rewards:  -64.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [19237.09375]\n",
      "Exploring\n",
      "Selected action  [1 4]\n",
      "[1 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 126us/step - loss: 11325.7500\n",
      "rewards:  -64.0 q-value:  0\n",
      "loss: [11325.75]\n",
      "Exploring\n",
      "Selected action  [2 1]\n",
      "[2 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 107us/step - loss: 33457.4062\n",
      "rewards:  -57.0 q-value:  0\n",
      "loss: [33457.40625]\n",
      "Exploiting\n",
      "Selected action  [2 3]\n",
      "[2 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 149us/step - loss: 11266.4375\n",
      "rewards:  -96.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [11266.4375]\n",
      "Exploiting\n",
      "Selected action  [4 3]\n",
      "[4 3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 120us/step - loss: 17132.3750\n",
      "rewards:  -98.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [17132.375]\n",
      "Exploiting\n",
      "Selected action  [4 0]\n",
      "[4 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 117us/step - loss: 26947.0625\n",
      "rewards:  -99.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [26947.0625]\n",
      "Exploring\n",
      "Selected action  [2 1]\n",
      "[2 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 107us/step - loss: 15472.1875\n",
      "rewards:  -104.0 q-value:  0\n",
      "loss: [15472.1875]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 133us/step - loss: 23313.2188\n",
      "rewards:  -109.0 q-value:  0\n",
      "loss: [23313.21875]\n",
      "Exploring\n",
      "Selected action  [3 0]\n",
      "[3 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 164us/step - loss: 9874.1875\n",
      "rewards:  -117.0 q-value:  0\n",
      "loss: [9874.1875]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 151us/step - loss: 22775.7812\n",
      "rewards:  -123.0 q-value:  0\n",
      "loss: [22775.78125]\n",
      "Exploiting\n",
      "Selected action  [2 3]\n",
      "[2 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 84us/step - loss: 14811.1875\n",
      "rewards:  -147.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [14811.1875]\n",
      "Exploring\n",
      "Selected action  [3 0]\n",
      "[3 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 111us/step - loss: 15378.2812\n",
      "rewards:  -127.0 q-value:  0\n",
      "loss: [15378.28125]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 127us/step - loss: 15290.5938\n",
      "rewards:  -132.0 q-value:  0\n",
      "loss: [15290.59375]\n",
      "Exploring\n",
      "Selected action  [2 1]\n",
      "[2 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 136us/step - loss: 17948.7500\n",
      "rewards:  -122.0 q-value:  0\n",
      "loss: [17948.75]\n",
      "Exploring\n",
      "Selected action  [1 4]\n",
      "[1 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 98us/step - loss: 27323.5938\n",
      "rewards:  -122.0 q-value:  0\n",
      "loss: [27323.59375]\n",
      "Exploring\n",
      "Selected action  [4 0]\n",
      "[4 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 113us/step - loss: 18759.2812\n",
      "rewards:  -122.0 q-value:  0\n",
      "loss: [18759.28125]\n",
      "Exploring\n",
      "Selected action  [4 3]\n",
      "[4 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 110us/step - loss: 6804.9062\n",
      "rewards:  -98.0 q-value:  0\n",
      "loss: [6804.90625]\n",
      "Exploring\n",
      "Selected action  [2 3]\n",
      "[2 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 96us/step - loss: 11145.8750\n",
      "rewards:  -98.0 q-value:  0\n",
      "loss: [11145.875]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 101us/step - loss: 11595.5938\n",
      "rewards:  -103.0 q-value:  0\n",
      "loss: [11595.59375]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 123us/step - loss: 7514.3438\n",
      "rewards:  -105.0 q-value:  0\n",
      "loss: [7514.34375]\n",
      "Exploiting\n",
      "Selected action  [3 0]\n",
      "[3 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 99us/step - loss: 15799.6562\n",
      "rewards:  -112.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [15799.65625]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 110us/step - loss: 14318.7500\n",
      "rewards:  -120.0 q-value:  0\n",
      "loss: [14318.75]\n",
      "Exploring\n",
      "Selected action  [2 3]\n",
      "[2 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 103us/step - loss: 36824.6562\n",
      "rewards:  -103.0 q-value:  0\n",
      "loss: [36824.65625]\n",
      "Exploring\n",
      "Selected action  [3 0]\n",
      "[3 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 142us/step - loss: 18382.5938\n",
      "rewards:  -99.0 q-value:  0\n",
      "loss: [18382.59375]\n",
      "Exploiting\n",
      "Selected action  [2 3]\n",
      "[2 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 135us/step - loss: 21748.2812\n",
      "rewards:  -90.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [21748.28125]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 86us/step - loss: 11666.7812\n",
      "rewards:  -95.0 q-value:  0\n",
      "loss: [11666.78125]\n",
      "Exploring\n",
      "Selected action  [4 0]\n",
      "[4 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 95us/step - loss: 19700.9062\n",
      "rewards:  -95.0 q-value:  0\n",
      "loss: [19700.90625]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 103us/step - loss: 12079.7500\n",
      "rewards:  -100.0 q-value:  0\n",
      "loss: [12079.75]\n",
      "Exploiting\n",
      "Selected action  [2 1]\n",
      "[2 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 121us/step - loss: 24817.4375\n",
      "rewards:  -91.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [24817.4375]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 109us/step - loss: 12665.7500\n",
      "rewards:  -75.0 q-value:  0\n",
      "loss: [12665.75]\n",
      "Exploring\n",
      "Selected action  [1 4]\n",
      "[1 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 120us/step - loss: 21880.6562\n",
      "rewards:  -97.0 q-value:  0\n",
      "loss: [21880.65625]\n",
      "Exploiting\n",
      "Selected action  [4 0]\n",
      "[4 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 118us/step - loss: 16597.0938\n",
      "rewards:  -93.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [16597.09375]\n",
      "Exploring\n",
      "Selected action  [2 3]\n",
      "[2 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 118us/step - loss: 16084.0625\n",
      "rewards:  -92.0 q-value:  0\n",
      "loss: [16084.0625]\n",
      "Exploiting\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 117us/step - loss: 12261.6875\n",
      "rewards:  -97.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [12261.6875]\n",
      "Exploring\n",
      "Selected action  [2 1]\n",
      "[2 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 109us/step - loss: 35790.1875\n",
      "rewards:  -104.0 q-value:  0\n",
      "loss: [35790.1875]\n",
      "Exploiting\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 99us/step - loss: 15446.2812\n",
      "rewards:  -109.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [15446.28125]\n",
      "Exploring\n",
      "Selected action  [3 0]\n",
      "[3 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 126us/step - loss: 18008.0938\n",
      "rewards:  -109.0 q-value:  0\n",
      "loss: [18008.09375]\n",
      "Exploring\n",
      "Selected action  [2 1]\n",
      "[2 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 139us/step - loss: 18713.1250\n",
      "rewards:  -116.0 q-value:  0\n",
      "loss: [18713.125]\n",
      "Exploring\n",
      "Selected action  [2 3]\n",
      "[2 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 122us/step - loss: 8926.1562\n",
      "rewards:  -148.0 q-value:  0\n",
      "loss: [8926.15625]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 98us/step - loss: 23008.5312\n",
      "rewards:  -153.0 q-value:  0\n",
      "loss: [23008.53125]\n",
      "Exploiting\n",
      "Selected action  [1 4]\n",
      "[1 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 129us/step - loss: 21153.0938\n",
      "rewards:  -151.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [21153.09375]\n",
      "Exploring\n",
      "Selected action  [2 3]\n",
      "[2 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 113us/step - loss: 24444.9688\n",
      "rewards:  -153.0 q-value:  0\n",
      "loss: [24444.96875]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 112us/step - loss: 18164.9375\n",
      "rewards:  -170.0 q-value:  0\n",
      "loss: [18164.9375]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 127us/step - loss: 19106.5312\n",
      "rewards:  -172.0 q-value:  0\n",
      "loss: [19106.53125]\n",
      "Exploiting\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 142us/step - loss: 28119.1250\n",
      "rewards:  -177.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [28119.125]\n",
      "Exploring\n",
      "Selected action  [3 0]\n",
      "[3 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 105us/step - loss: 22332.8438\n",
      "rewards:  -187.0 q-value:  0\n",
      "loss: [22332.84375]\n",
      "Number of actions available 5\n",
      "Episode : 39\n",
      "Exploring\n",
      "Selected action  [4 3]\n",
      "[4 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 168us/step - loss: 21625.5938\n",
      "rewards:  -2.0 q-value:  0\n",
      "loss: [21625.59375]\n",
      "Exploring\n",
      "Selected action  [4 3]\n",
      "[4 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 105us/step - loss: 23585.7500\n",
      "rewards:  -4.0 q-value:  0\n",
      "loss: [23585.75]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 94us/step - loss: 24947.1875\n",
      "rewards:  -9.0 q-value:  0\n",
      "loss: [24947.1875]\n",
      "Exploring\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 139us/step - loss: 17429.0938\n",
      "rewards:  -15.0 q-value:  0\n",
      "loss: [17429.09375]\n",
      "Exploring\n",
      "Selected action  [0 4]\n",
      "[0 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 116us/step - loss: 17520.7500\n",
      "rewards:  -11.0 q-value:  0\n",
      "loss: [17520.75]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 169us/step - loss: 20015.4688\n",
      "rewards:  -16.0 q-value:  0\n",
      "loss: [20015.46875]\n",
      "Exploring\n",
      "Selected action  [0 4]\n",
      "[0 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 102us/step - loss: 24297.0312\n",
      "rewards:  -12.0 q-value:  0\n",
      "loss: [24297.03125]\n",
      "Exploring\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 132us/step - loss: 12661.6562\n",
      "rewards:  -9.0 q-value:  0\n",
      "loss: [12661.65625]\n",
      "Exploring\n",
      "Selected action  [0 4]\n",
      "[0 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 160us/step - loss: 24776.6875\n",
      "rewards:  -15.0 q-value:  0\n",
      "loss: [24776.6875]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 108us/step - loss: 8932.5625\n",
      "rewards:  -47.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [8932.5625]\n",
      "Exploring\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 119us/step - loss: 30194.8438\n",
      "rewards:  -49.0 q-value:  0\n",
      "loss: [30194.84375]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 128us/step - loss: 10916.4688\n",
      "rewards:  -51.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [10916.46875]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 132us/step - loss: 11606.5625\n",
      "rewards:  -53.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [11606.5625]\n",
      "Exploring\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 106us/step - loss: 26853.5625\n",
      "rewards:  -70.0 q-value:  0\n",
      "loss: [26853.5625]\n",
      "Exploring\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 123us/step - loss: 15671.2812\n",
      "rewards:  -72.0 q-value:  0\n",
      "loss: [15671.28125]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 134us/step - loss: 18098.0312\n",
      "rewards:  -77.0 q-value:  0\n",
      "loss: [18098.03125]\n",
      "Exploring\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 104us/step - loss: 12999.7188\n",
      "rewards:  -41.0 q-value:  0\n",
      "loss: [12999.71875]\n",
      "Exploring\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 105us/step - loss: 20162.7188\n",
      "rewards:  -38.0 q-value:  0\n",
      "loss: [20162.71875]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 100us/step - loss: 20758.9688\n",
      "rewards:  -22.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [20758.96875]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 120us/step - loss: 19313.6250\n",
      "rewards:  -24.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [19313.625]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 116us/step - loss: 15460.8125\n",
      "rewards:  -26.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [15460.8125]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 129us/step - loss: 20875.2188\n",
      "rewards:  -31.0 q-value:  0\n",
      "loss: [20875.21875]\n",
      "Exploring\n",
      "Selected action  [4 3]\n",
      "[4 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 94us/step - loss: 25423.5938\n",
      "rewards:  -16.0 q-value:  0\n",
      "loss: [25423.59375]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 116us/step - loss: 26140.8750\n",
      "rewards:  -3.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [26140.875]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 85us/step - loss: 20486.8125\n",
      "rewards:  -8.0 q-value:  0\n",
      "loss: [20486.8125]\n",
      "Exploring\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 108us/step - loss: 21788.5000\n",
      "rewards:  -11.0 q-value:  0\n",
      "loss: [21788.5]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 95us/step - loss: 21477.3750\n",
      "rewards:  17.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [21477.375]\n",
      "Exploring\n",
      "Selected action  [0 4]\n",
      "[0 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 119us/step - loss: 20573.3438\n",
      "rewards:  18.0 q-value:  0\n",
      "loss: [20573.34375]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 120us/step - loss: 8695.9375\n",
      "rewards:  25.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [8695.9375]\n",
      "Exploring\n",
      "Selected action  [4 3]\n",
      "[4 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 115us/step - loss: 13723.8438\n",
      "rewards:  14.0 q-value:  0\n",
      "loss: [13723.84375]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 87us/step - loss: 12844.0000\n",
      "rewards:  28.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [12844.0]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 124us/step - loss: 20568.0000\n",
      "rewards:  22.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [20568.0]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 101us/step - loss: 24473.9375\n",
      "rewards:  17.0 q-value:  0\n",
      "loss: [24473.9375]\n",
      "Exploring\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 118us/step - loss: 29561.3750\n",
      "rewards:  14.0 q-value:  0\n",
      "loss: [29561.375]\n",
      "Exploring\n",
      "Selected action  [4 3]\n",
      "[4 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 102us/step - loss: 13871.9375\n",
      "rewards:  22.0 q-value:  0\n",
      "loss: [13871.9375]\n",
      "Exploring\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 107us/step - loss: 10908.5938\n",
      "rewards:  9.0 q-value:  0\n",
      "loss: [10908.59375]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 87us/step - loss: 20074.3750\n",
      "rewards:  37.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [20074.375]\n",
      "Exploring\n",
      "Selected action  [4 3]\n",
      "[4 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 116us/step - loss: 14681.1562\n",
      "rewards:  61.0 q-value:  0\n",
      "loss: [14681.15625]\n",
      "Exploring\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 109us/step - loss: 19785.3438\n",
      "rewards:  54.0 q-value:  0\n",
      "loss: [19785.34375]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 125us/step - loss: 15415.7188\n",
      "rewards:  52.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [15415.71875]\n",
      "Exploring\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 95us/step - loss: 20075.4062\n",
      "rewards:  45.0 q-value:  0\n",
      "loss: [20075.40625]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 90us/step - loss: 16341.7812\n",
      "rewards:  40.0 q-value:  0\n",
      "loss: [16341.78125]\n",
      "Exploring\n",
      "Selected action  [0 4]\n",
      "[0 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 134us/step - loss: 12169.5938\n",
      "rewards:  40.0 q-value:  0\n",
      "loss: [12169.59375]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 108us/step - loss: 17635.4688\n",
      "rewards:  72.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [17635.46875]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 118us/step - loss: 18563.9062\n",
      "rewards:  67.0 q-value:  0\n",
      "loss: [18563.90625]\n",
      "Exploring\n",
      "Selected action  [2 0]\n",
      "[2 0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 118us/step - loss: 13919.8438\n",
      "rewards:  64.0 q-value:  0\n",
      "loss: [13919.84375]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 114us/step - loss: 20489.3750\n",
      "rewards:  59.0 q-value:  0\n",
      "loss: [20489.375]\n",
      "Exploring\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 134us/step - loss: 10616.5312\n",
      "rewards:  87.0 q-value:  0\n",
      "loss: [10616.53125]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 98us/step - loss: 15552.9688\n",
      "rewards:  82.0 q-value:  0\n",
      "loss: [15552.96875]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 124us/step - loss: 19273.7812\n",
      "rewards:  82.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [19273.78125]\n",
      "Exploring\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 131us/step - loss: 23245.1250\n",
      "rewards:  82.0 q-value:  0\n",
      "loss: [23245.125]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 108us/step - loss: 22004.8438\n",
      "rewards:  82.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [22004.84375]\n",
      "Exploring\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 104us/step - loss: 19258.3125\n",
      "rewards:  65.0 q-value:  0\n",
      "loss: [19258.3125]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 115us/step - loss: 22105.5312\n",
      "rewards:  85.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [22105.53125]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 109us/step - loss: 16100.8125\n",
      "rewards:  81.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [16100.8125]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 119us/step - loss: 23986.9375\n",
      "rewards:  77.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [23986.9375]\n",
      "Exploring\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 106us/step - loss: 19993.4375\n",
      "rewards:  67.0 q-value:  0\n",
      "loss: [19993.4375]\n",
      "Exploring\n",
      "Selected action  [4 3]\n",
      "[4 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 100us/step - loss: 23401.5625\n",
      "rewards:  70.0 q-value:  0\n",
      "loss: [23401.5625]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 131us/step - loss: 18177.7188\n",
      "rewards:  64.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [18177.71875]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 109us/step - loss: 23516.7500\n",
      "rewards:  58.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [23516.75]\n",
      "Exploring\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 113us/step - loss: 22728.1250\n",
      "rewards:  60.0 q-value:  0\n",
      "loss: [22728.125]\n",
      "Exploring\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 88us/step - loss: 7974.3438\n",
      "rewards:  55.0 q-value:  0\n",
      "loss: [7974.34375]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 126us/step - loss: 24835.3125\n",
      "rewards:  63.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [24835.3125]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 102us/step - loss: 18477.0625\n",
      "rewards:  58.0 q-value:  0\n",
      "loss: [18477.0625]\n",
      "Exploring\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 131us/step - loss: 13360.1875\n",
      "rewards:  66.0 q-value:  0\n",
      "loss: [13360.1875]\n",
      "Exploring\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 97us/step - loss: 17463.3438\n",
      "rewards:  49.0 q-value:  0\n",
      "loss: [17463.34375]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 121us/step - loss: 21868.9688\n",
      "rewards:  85.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [21868.96875]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 113us/step - loss: 18382.7500\n",
      "rewards:  81.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [18382.75]\n",
      "Exploring\n",
      "Selected action  [4 3]\n",
      "[4 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9906.1250\n",
      "rewards:  81.0 q-value:  0\n",
      "loss: [9906.125]\n",
      "Exploring\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 126us/step - loss: 19336.5312\n",
      "rewards:  75.0 q-value:  0\n",
      "loss: [19336.53125]\n",
      "Exploring\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 139us/step - loss: 23568.8125\n",
      "rewards:  103.0 q-value:  0\n",
      "loss: [23568.8125]\n",
      "Exploring\n",
      "Selected action  [0 4]\n",
      "[0 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 124us/step - loss: 17457.9062\n",
      "rewards:  72.0 q-value:  0\n",
      "loss: [17457.90625]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 124us/step - loss: 23254.1875\n",
      "rewards:  95.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [23254.1875]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 138us/step - loss: 18321.7188\n",
      "rewards:  92.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [18321.71875]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 160us/step - loss: 13052.4688\n",
      "rewards:  87.0 q-value:  0\n",
      "loss: [13052.46875]\n",
      "Exploring\n",
      "Selected action  [0 4]\n",
      "[0 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 126us/step - loss: 16808.7812\n",
      "rewards:  91.0 q-value:  0\n",
      "loss: [16808.78125]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 177us/step - loss: 11845.6562\n",
      "rewards:  98.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [11845.65625]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 134us/step - loss: 25100.2188\n",
      "rewards:  95.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [25100.21875]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 121us/step - loss: 18467.9688\n",
      "rewards:  90.0 q-value:  0\n",
      "loss: [18467.96875]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 127us/step - loss: 23550.6250\n",
      "rewards:  126.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [23550.625]\n",
      "Exploring\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 106us/step - loss: 17305.9688\n",
      "rewards:  125.0 q-value:  0\n",
      "loss: [17305.96875]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 123us/step - loss: 14217.6875\n",
      "rewards:  149.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [14217.6875]\n",
      "Exploring\n",
      "Selected action  [4 3]\n",
      "[4 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 104us/step - loss: 27127.3125\n",
      "rewards:  147.0 q-value:  0\n",
      "loss: [27127.3125]\n",
      "Exploring\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 118us/step - loss: 18584.5938\n",
      "rewards:  134.0 q-value:  0\n",
      "loss: [18584.59375]\n",
      "Exploring\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 104us/step - loss: 23512.7500\n",
      "rewards:  131.0 q-value:  0\n",
      "loss: [23512.75]\n",
      "Exploring\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 131us/step - loss: 17379.9375\n",
      "rewards:  125.0 q-value:  0\n",
      "loss: [17379.9375]\n",
      "Exploring\n",
      "Selected action  [4 3]\n",
      "[4 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 124us/step - loss: 15196.9062\n",
      "rewards:  149.0 q-value:  0\n",
      "loss: [15196.90625]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 124us/step - loss: 32069.1562\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rewards:  142.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [32069.15625]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 139us/step - loss: 24750.7500\n",
      "rewards:  140.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [24750.75]\n",
      "Exploring\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 102us/step - loss: 18791.7500\n",
      "rewards:  117.0 q-value:  0\n",
      "loss: [18791.75]\n",
      "Exploring\n",
      "Selected action  [0 4]\n",
      "[0 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 125us/step - loss: 19060.3438\n",
      "rewards:  121.0 q-value:  0\n",
      "loss: [19060.34375]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 181us/step - loss: 18675.0000\n",
      "rewards:  144.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [18675.0]\n",
      "Exploring\n",
      "Selected action  [0 4]\n",
      "[0 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 201us/step - loss: 16492.3125\n",
      "rewards:  104.0 q-value:  0\n",
      "loss: [16492.3125]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 141us/step - loss: 27689.9062\n",
      "rewards:  136.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [27689.90625]\n",
      "Exploring\n",
      "Selected action  [4 3]\n",
      "[4 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 187us/step - loss: 17748.9062\n",
      "rewards:  152.0 q-value:  0\n",
      "loss: [17748.90625]\n",
      "Exploring\n",
      "Selected action  [0 4]\n",
      "[0 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 109us/step - loss: 19670.0625\n",
      "rewards:  159.0 q-value:  0\n",
      "loss: [19670.0625]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 141us/step - loss: 22711.7500\n",
      "rewards:  154.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [22711.75]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 105us/step - loss: 24600.2812\n",
      "rewards:  154.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [24600.28125]\n",
      "Exploring\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 124us/step - loss: 13966.7500\n",
      "rewards:  154.0 q-value:  0\n",
      "loss: [13966.75]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 125us/step - loss: 19444.6250\n",
      "rewards:  154.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [19444.625]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 149us/step - loss: 27002.2812\n",
      "rewards:  149.0 q-value:  0\n",
      "loss: [27002.28125]\n",
      "Exploring\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 96us/step - loss: 26116.6250\n",
      "rewards:  149.0 q-value:  0\n",
      "loss: [26116.625]\n",
      "Exploring\n",
      "Selected action  [4 3]\n",
      "[4 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 117us/step - loss: 14371.0000\n",
      "rewards:  152.0 q-value:  0\n",
      "loss: [14371.0]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 119us/step - loss: 14270.1562\n",
      "rewards:  147.0 q-value:  0\n",
      "loss: [14270.15625]\n",
      "Exploring\n",
      "Selected action  [4 3]\n",
      "[4 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 145us/step - loss: 12956.5312\n",
      "rewards:  150.0 q-value:  0\n",
      "loss: [12956.53125]\n",
      "Exploring\n",
      "Selected action  [4 3]\n",
      "[4 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 145us/step - loss: 19221.7812\n",
      "rewards:  146.0 q-value:  0\n",
      "loss: [19221.78125]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 114us/step - loss: 15116.9375\n",
      "rewards:  136.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [15116.9375]\n",
      "Exploring\n",
      "Selected action  [0 4]\n",
      "[0 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 133us/step - loss: 19078.9375\n",
      "rewards:  116.0 q-value:  0\n",
      "loss: [19078.9375]\n",
      "Exploring\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 177us/step - loss: 31514.9375\n",
      "rewards:  132.0 q-value:  0\n",
      "loss: [31514.9375]\n",
      "Exploring\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 135us/step - loss: 24706.8125\n",
      "rewards:  127.0 q-value:  0\n",
      "loss: [24706.8125]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 152us/step - loss: 18598.9375\n",
      "rewards:  151.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [18598.9375]\n",
      "Exploring\n",
      "Selected action  [4 3]\n",
      "[4 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 182us/step - loss: 26416.5938\n",
      "rewards:  144.0 q-value:  0\n",
      "loss: [26416.59375]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 163us/step - loss: 15751.1562\n",
      "rewards:  139.0 q-value:  0\n",
      "loss: [15751.15625]\n",
      "Exploring\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 105us/step - loss: 27461.0312\n",
      "rewards:  147.0 q-value:  0\n",
      "loss: [27461.03125]\n",
      "Exploring\n",
      "Selected action  [4 3]\n",
      "[4 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 190us/step - loss: 17112.5000\n",
      "rewards:  149.0 q-value:  0\n",
      "loss: [17112.5]\n",
      "Exploring\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 148us/step - loss: 25781.7188\n",
      "rewards:  142.0 q-value:  0\n",
      "loss: [25781.71875]\n",
      "Exploring\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 131us/step - loss: 14186.5938\n",
      "rewards:  122.0 q-value:  0\n",
      "loss: [14186.59375]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 176us/step - loss: 8336.2812\n",
      "rewards:  130.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [8336.28125]\n",
      "Exploring\n",
      "Selected action  [4 3]\n",
      "[4 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 186us/step - loss: 16584.5000\n",
      "rewards:  118.0 q-value:  0\n",
      "loss: [16584.5]\n",
      "Exploring\n",
      "Selected action  [0 4]\n",
      "[0 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 159us/step - loss: 32843.0000\n",
      "rewards:  72.0 q-value:  0\n",
      "loss: [32843.0]\n",
      "Exploring\n",
      "Selected action  [4 3]\n",
      "[4 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 131us/step - loss: 14412.8750\n",
      "rewards:  100.0 q-value:  0\n",
      "loss: [14412.875]\n",
      "Exploring\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 144us/step - loss: 12193.9062\n",
      "rewards:  63.0 q-value:  0\n",
      "loss: [12193.90625]\n",
      "Exploring\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 169us/step - loss: 22225.2812\n",
      "rewards:  79.0 q-value:  0\n",
      "loss: [22225.28125]\n",
      "Exploring\n",
      "Selected action  [4 3]\n",
      "[4 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 141us/step - loss: 30043.4688\n",
      "rewards:  79.0 q-value:  0\n",
      "loss: [30043.46875]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 256us/step - loss: 16013.1875\n",
      "rewards:  61.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [16013.1875]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 115us/step - loss: 24372.1562\n",
      "rewards:  58.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [24372.15625]\n",
      "Exploring\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 115us/step - loss: 32647.5625\n",
      "rewards:  37.0 q-value:  0\n",
      "loss: [32647.5625]\n",
      "Number of actions available 8\n",
      "Episode : 40\n",
      "Exploiting\n",
      "Selected action  [4 2]\n",
      "[4 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 142us/step - loss: 21160.5000\n",
      "rewards:  10.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [21160.5]\n",
      "Exploiting\n",
      "Selected action  [3 1]\n",
      "[3 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 114us/step - loss: 18061.0625\n",
      "rewards:  -4.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [18061.0625]\n",
      "Exploiting\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 114us/step - loss: 31316.7188\n",
      "rewards:  -4.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [31316.71875]\n",
      "Exploring\n",
      "Selected action  [1 3]\n",
      "[1 3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 120us/step - loss: 10650.2500\n",
      "rewards:  -4.0 q-value:  0\n",
      "loss: [10650.25]\n",
      "Exploring\n",
      "Selected action  [3 1]\n",
      "[3 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 155us/step - loss: 15638.5000\n",
      "rewards:  -4.0 q-value:  0\n",
      "loss: [15638.5]\n",
      "Exploring\n",
      "Selected action  [4 3]\n",
      "[4 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 138us/step - loss: 16405.7500\n",
      "rewards:  -2.0 q-value:  0\n",
      "loss: [16405.75]\n",
      "Exploiting\n",
      "Selected action  [3 1]\n",
      "[3 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 139us/step - loss: 13021.6875\n",
      "rewards:  -2.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [13021.6875]\n",
      "Exploring\n",
      "Selected action  [1 2]\n",
      "[1 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 119us/step - loss: 13111.1875\n",
      "rewards:  6.0 q-value:  0\n",
      "loss: [13111.1875]\n",
      "Exploring\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 161us/step - loss: 14816.9375\n",
      "rewards:  -4.0 q-value:  0\n",
      "loss: [14816.9375]\n",
      "Exploring\n",
      "Selected action  [3 1]\n",
      "[3 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 130us/step - loss: 9758.6875\n",
      "rewards:  -4.0 q-value:  0\n",
      "loss: [9758.6875]\n",
      "Exploring\n",
      "Selected action  [4 3]\n",
      "[4 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 167us/step - loss: 22801.1562\n",
      "rewards:  -2.0 q-value:  0\n",
      "loss: [22801.15625]\n",
      "Exploiting\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 179us/step - loss: 20089.0000\n",
      "rewards:  -7.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [20089.0]\n",
      "Exploring\n",
      "Selected action  [3 2]\n",
      "[3 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 152us/step - loss: 14556.6562\n",
      "rewards:  -14.0 q-value:  0\n",
      "loss: [14556.65625]\n",
      "Exploiting\n",
      "Selected action  [1 2]\n",
      "[1 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 172us/step - loss: 24583.4062\n",
      "rewards:  -22.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [24583.40625]\n",
      "Exploring\n",
      "Selected action  [3 2]\n",
      "[3 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 141us/step - loss: 18279.2188\n",
      "rewards:  -24.0 q-value:  0\n",
      "loss: [18279.21875]\n",
      "Exploring\n",
      "Selected action  [3 1]\n",
      "[3 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 230us/step - loss: 30965.1875\n",
      "rewards:  -30.0 q-value:  0\n",
      "loss: [30965.1875]\n",
      "Exploring\n",
      "Selected action  [4 2]\n",
      "[4 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 139us/step - loss: 21717.8750\n",
      "rewards:  -21.0 q-value:  0\n",
      "loss: [21717.875]\n",
      "Exploring\n",
      "Selected action  [1 4]\n",
      "[1 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 134us/step - loss: 27044.0938\n",
      "rewards:  -26.0 q-value:  0\n",
      "loss: [27044.09375]\n",
      "Exploring\n",
      "Selected action  [4 2]\n",
      "[4 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 142us/step - loss: 15175.9062\n",
      "rewards:  -18.0 q-value:  0\n",
      "loss: [15175.90625]\n",
      "Exploring\n",
      "Selected action  [4 2]\n",
      "[4 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 121us/step - loss: 7360.6250\n",
      "rewards:  -20.0 q-value:  0\n",
      "loss: [7360.625]\n",
      "Exploring\n",
      "Selected action  [4 2]\n",
      "[4 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 95us/step - loss: 20996.5312\n",
      "rewards:  -20.0 q-value:  0\n",
      "loss: [20996.53125]\n",
      "Exploring\n",
      "Selected action  [1 4]\n",
      "[1 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 134us/step - loss: 24124.5312\n",
      "rewards:  -29.0 q-value:  0\n",
      "loss: [24124.53125]\n",
      "Exploring\n",
      "Selected action  [1 4]\n",
      "[1 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 136us/step - loss: 21135.3750\n",
      "rewards:  -33.0 q-value:  0\n",
      "loss: [21135.375]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 133us/step - loss: 25840.8750\n",
      "rewards:  -38.0 q-value:  0\n",
      "loss: [25840.875]\n",
      "Exploiting\n",
      "Selected action  [1 2]\n",
      "[1 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 131us/step - loss: 12087.0938\n",
      "rewards:  -29.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [12087.09375]\n",
      "Exploring\n",
      "Selected action  [3 1]\n",
      "[3 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 152us/step - loss: 15722.8125\n",
      "rewards:  -46.0 q-value:  0\n",
      "loss: [15722.8125]\n",
      "Exploiting\n",
      "Selected action  [1 4]\n",
      "[1 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 115us/step - loss: 22150.2500\n",
      "rewards:  -38.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [22150.25]\n",
      "Exploiting\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 132us/step - loss: 13644.4688\n",
      "rewards:  -43.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [13644.46875]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 110us/step - loss: 26296.0938\n",
      "rewards:  -48.0 q-value:  0\n",
      "loss: [26296.09375]\n",
      "Exploring\n",
      "Selected action  [1 2]\n",
      "[1 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 118us/step - loss: 15080.2812\n",
      "rewards:  -71.0 q-value:  0\n",
      "loss: [15080.28125]\n",
      "Exploring\n",
      "Selected action  [4 2]\n",
      "[4 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 171us/step - loss: 33497.4375\n",
      "rewards:  -72.0 q-value:  0\n",
      "loss: [33497.4375]\n",
      "Exploring\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 214us/step - loss: 27441.9062\n",
      "rewards:  -79.0 q-value:  0\n",
      "loss: [27441.90625]\n",
      "Exploring\n",
      "Selected action  [4 3]\n",
      "[4 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 153us/step - loss: 15833.0938\n",
      "rewards:  -81.0 q-value:  0\n",
      "loss: [15833.09375]\n",
      "Exploring\n",
      "Selected action  [1 4]\n",
      "[1 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 139us/step - loss: 11632.4062\n",
      "rewards:  -91.0 q-value:  0\n",
      "loss: [11632.40625]\n",
      "Exploiting\n",
      "Selected action  [1 4]\n",
      "[1 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 177us/step - loss: 9798.2500\n",
      "rewards:  -91.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [9798.25]\n",
      "Exploring\n",
      "Selected action  [3 2]\n",
      "[3 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 139us/step - loss: 11188.0625\n",
      "rewards:  -85.0 q-value:  0\n",
      "loss: [11188.0625]\n",
      "Exploiting\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 142us/step - loss: 14235.8750\n",
      "rewards:  -90.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [14235.875]\n",
      "Exploring\n",
      "Selected action  [4 2]\n",
      "[4 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 165us/step - loss: 20664.8750\n",
      "rewards:  -91.0 q-value:  0\n",
      "loss: [20664.875]\n",
      "Exploring\n",
      "Selected action  [3 2]\n",
      "[3 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 146us/step - loss: 18591.7188\n",
      "rewards:  -94.0 q-value:  0\n",
      "loss: [18591.71875]\n",
      "Exploring\n",
      "Selected action  [3 2]\n",
      "[3 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 137us/step - loss: 19717.0000\n",
      "rewards:  -97.0 q-value:  0\n",
      "loss: [19717.0]\n",
      "Exploiting\n",
      "Selected action  [1 4]\n",
      "[1 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 154us/step - loss: 14983.0938\n",
      "rewards:  -89.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [14983.09375]\n",
      "Exploiting\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 121us/step - loss: 15978.3438\n",
      "rewards:  -94.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [15978.34375]\n",
      "Exploring\n",
      "Selected action  [4 3]\n",
      "[4 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 114us/step - loss: 21190.1875\n",
      "rewards:  -75.0 q-value:  0\n",
      "loss: [21190.1875]\n",
      "Exploring\n",
      "Selected action  [1 2]\n",
      "[1 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 130us/step - loss: 22164.4688\n",
      "rewards:  -52.0 q-value:  0\n",
      "loss: [22164.46875]\n",
      "Exploring\n",
      "Selected action  [3 1]\n",
      "[3 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 113us/step - loss: 19304.8125\n",
      "rewards:  -65.0 q-value:  0\n",
      "loss: [19304.8125]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 99us/step - loss: 23655.9062\n",
      "rewards:  -70.0 q-value:  0\n",
      "loss: [23655.90625]\n",
      "Exploiting\n",
      "Selected action  [4 3]\n",
      "[4 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 119us/step - loss: 14504.7812\n",
      "rewards:  -68.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [14504.78125]\n",
      "Exploiting\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 150us/step - loss: 9154.3438\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rewards:  -71.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [9154.34375]\n",
      "Exploring\n",
      "Selected action  [3 2]\n",
      "[3 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 125us/step - loss: 23134.2500\n",
      "rewards:  -47.0 q-value:  0\n",
      "loss: [23134.25]\n",
      "Exploring\n",
      "Selected action  [3 2]\n",
      "[3 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 137us/step - loss: 12908.4375\n",
      "rewards:  -47.0 q-value:  0\n",
      "loss: [12908.4375]\n",
      "Exploiting\n",
      "Selected action  [3 2]\n",
      "[3 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 135us/step - loss: 19963.3750\n",
      "rewards:  -47.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [19963.375]\n",
      "Exploring\n",
      "Selected action  [1 4]\n",
      "[1 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 206us/step - loss: 18620.3125\n",
      "rewards:  -87.0 q-value:  0\n",
      "loss: [18620.3125]\n",
      "Exploiting\n",
      "Selected action  [3 2]\n",
      "[3 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 133us/step - loss: 27783.2812\n",
      "rewards:  -117.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [27783.28125]\n",
      "Exploiting\n",
      "Selected action  [4 2]\n",
      "[4 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 128us/step - loss: 19318.7500\n",
      "rewards:  -117.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [19318.75]\n",
      "Exploring\n",
      "Selected action  [4 3]\n",
      "[4 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 131us/step - loss: 13427.2188\n",
      "rewards:  -93.0 q-value:  0\n",
      "loss: [13427.21875]\n",
      "Exploring\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 140us/step - loss: 27187.4062\n",
      "rewards:  -98.0 q-value:  0\n",
      "loss: [27187.40625]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 158us/step - loss: 10615.3125\n",
      "rewards:  -103.0 q-value:  0\n",
      "loss: [10615.3125]\n",
      "Exploiting\n",
      "Selected action  [1 4]\n",
      "[1 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 119us/step - loss: 20889.1875\n",
      "rewards:  -119.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [20889.1875]\n",
      "Exploring\n",
      "Selected action  [1 4]\n",
      "[1 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 135us/step - loss: 33471.1250\n",
      "rewards:  -121.0 q-value:  0\n",
      "loss: [33471.125]\n",
      "Exploring\n",
      "Selected action  [1 2]\n",
      "[1 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 135us/step - loss: 31799.5625\n",
      "rewards:  -127.0 q-value:  0\n",
      "loss: [31799.5625]\n",
      "Exploiting\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 112us/step - loss: 21819.5000\n",
      "rewards:  -128.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [21819.5]\n",
      "Exploring\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 135us/step - loss: 22873.2812\n",
      "rewards:  -129.0 q-value:  0\n",
      "loss: [22873.28125]\n",
      "Exploring\n",
      "Selected action  [3 1]\n",
      "[3 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 144us/step - loss: 17350.2188\n",
      "rewards:  -125.0 q-value:  0\n",
      "loss: [17350.21875]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 124us/step - loss: 27103.7500\n",
      "rewards:  -130.0 q-value:  0\n",
      "loss: [27103.75]\n",
      "Exploiting\n",
      "Selected action  [1 4]\n",
      "[1 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 117us/step - loss: 26716.1562\n",
      "rewards:  -165.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [26716.15625]\n",
      "Exploiting\n",
      "Selected action  [4 2]\n",
      "[4 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 138us/step - loss: 13049.6875\n",
      "rewards:  -165.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [13049.6875]\n",
      "Exploring\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 126us/step - loss: 37928.2812\n",
      "rewards:  -203.0 q-value:  0\n",
      "loss: [37928.28125]\n",
      "Exploring\n",
      "Selected action  [4 3]\n",
      "[4 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 97us/step - loss: 27054.5625\n",
      "rewards:  -207.0 q-value:  0\n",
      "loss: [27054.5625]\n",
      "Exploiting\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 120us/step - loss: 13072.8750\n",
      "rewards:  -211.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [13072.875]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 110us/step - loss: 20618.3125\n",
      "rewards:  -216.0 q-value:  0\n",
      "loss: [20618.3125]\n",
      "Exploiting\n",
      "Selected action  [3 1]\n",
      "[3 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 120us/step - loss: 14212.0000\n",
      "rewards:  -220.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [14212.0]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 121us/step - loss: 22981.2812\n",
      "rewards:  -225.0 q-value:  0\n",
      "loss: [22981.28125]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 103us/step - loss: 12140.2812\n",
      "rewards:  -230.0 q-value:  0\n",
      "loss: [12140.28125]\n",
      "Exploring\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 156us/step - loss: 16171.8438\n",
      "rewards:  -239.0 q-value:  0\n",
      "loss: [16171.84375]\n",
      "Exploiting\n",
      "Selected action  [3 2]\n",
      "[3 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 121us/step - loss: 16930.4688\n",
      "rewards:  -207.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [16930.46875]\n",
      "Exploring\n",
      "Selected action  [4 3]\n",
      "[4 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 116us/step - loss: 19881.7812\n",
      "rewards:  -183.0 q-value:  0\n",
      "loss: [19881.78125]\n",
      "Exploring\n",
      "Selected action  [3 1]\n",
      "[3 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 130us/step - loss: 12428.3750\n",
      "rewards:  -167.0 q-value:  0\n",
      "loss: [12428.375]\n",
      "Exploring\n",
      "Selected action  [4 2]\n",
      "[4 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 125us/step - loss: 22209.3125\n",
      "rewards:  -186.0 q-value:  0\n",
      "loss: [22209.3125]\n",
      "Exploring\n",
      "Selected action  [4 2]\n",
      "[4 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 171us/step - loss: 30275.5938\n",
      "rewards:  -190.0 q-value:  0\n",
      "loss: [30275.59375]\n",
      "Exploring\n",
      "Selected action  [4 2]\n",
      "[4 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 91us/step - loss: 17964.1875\n",
      "rewards:  -190.0 q-value:  0\n",
      "loss: [17964.1875]\n",
      "Exploring\n",
      "Selected action  [3 1]\n",
      "[3 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 146us/step - loss: 13203.7812\n",
      "rewards:  -230.0 q-value:  0\n",
      "loss: [13203.78125]\n",
      "Exploring\n",
      "Selected action  [1 4]\n",
      "[1 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 114us/step - loss: 24256.8750\n",
      "rewards:  -222.0 q-value:  0\n",
      "loss: [24256.875]\n",
      "Exploiting\n",
      "Selected action  [3 2]\n",
      "[3 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 116us/step - loss: 20531.6875\n",
      "rewards:  -205.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [20531.6875]\n",
      "Exploring\n",
      "Selected action  [1 4]\n",
      "[1 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 118us/step - loss: 18947.6562\n",
      "rewards:  -214.0 q-value:  0\n",
      "loss: [18947.65625]\n",
      "Exploring\n",
      "Selected action  [1 4]\n",
      "[1 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 128us/step - loss: 20722.8750\n",
      "rewards:  -218.0 q-value:  0\n",
      "loss: [20722.875]\n",
      "Exploring\n",
      "Selected action  [3 1]\n",
      "[3 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 88us/step - loss: 15426.5625\n",
      "rewards:  -249.0 q-value:  0\n",
      "loss: [15426.5625]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 142us/step - loss: 26327.3125\n",
      "rewards:  -254.0 q-value:  0\n",
      "loss: [26327.3125]\n",
      "Exploring\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 136us/step - loss: 20513.8750\n",
      "rewards:  -295.0 q-value:  0\n",
      "loss: [20513.875]\n",
      "Exploring\n",
      "Selected action  [3 1]\n",
      "[3 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 119us/step - loss: 10993.5938\n",
      "rewards:  -291.0 q-value:  0\n",
      "loss: [10993.59375]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 111us/step - loss: 13859.1250\n",
      "rewards:  -296.0 q-value:  0\n",
      "loss: [13859.125]\n",
      "Exploiting\n",
      "Selected action  [4 3]\n",
      "[4 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 113us/step - loss: 13217.0938\n",
      "rewards:  -275.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [13217.09375]\n",
      "Exploring\n",
      "Selected action  [1 3]\n",
      "[1 3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 113us/step - loss: 18620.3438\n",
      "rewards:  -276.0 q-value:  0\n",
      "loss: [18620.34375]\n",
      "Exploring\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 135us/step - loss: 12212.3750\n",
      "rewards:  -277.0 q-value:  0\n",
      "loss: [12212.375]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 90us/step - loss: 28790.4688\n",
      "rewards:  -282.0 q-value:  0\n",
      "loss: [28790.46875]\n",
      "Exploring\n",
      "Selected action  [3 1]\n",
      "[3 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 161us/step - loss: 20956.5312\n",
      "rewards:  -278.0 q-value:  0\n",
      "loss: [20956.53125]\n",
      "Exploiting\n",
      "Selected action  [3 1]\n",
      "[3 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 113us/step - loss: 16894.7812\n",
      "rewards:  -284.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [16894.78125]\n",
      "Exploring\n",
      "Selected action  [4 2]\n",
      "[4 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 123us/step - loss: 20760.6562\n",
      "rewards:  -274.0 q-value:  0\n",
      "loss: [20760.65625]\n",
      "Exploring\n",
      "Selected action  [4 3]\n",
      "[4 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 119us/step - loss: 34260.2812\n",
      "rewards:  -271.0 q-value:  0\n",
      "loss: [34260.28125]\n",
      "Exploring\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 109us/step - loss: 15366.8125\n",
      "rewards:  -273.0 q-value:  0\n",
      "loss: [15366.8125]\n",
      "Exploiting\n",
      "Selected action  [3 2]\n",
      "[3 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 110us/step - loss: 14349.7188\n",
      "rewards:  -257.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [14349.71875]\n",
      "Exploring\n",
      "Selected action  [4 2]\n",
      "[4 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 151us/step - loss: 16152.2500\n",
      "rewards:  -258.0 q-value:  0\n",
      "loss: [16152.25]\n",
      "Exploring\n",
      "Selected action  [3 1]\n",
      "[3 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 128us/step - loss: 15778.0000\n",
      "rewards:  -253.0 q-value:  0\n",
      "loss: [15778.0]\n",
      "Exploring\n",
      "Selected action  [1 2]\n",
      "[1 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 139us/step - loss: 52055.5000\n",
      "rewards:  -237.0 q-value:  0\n",
      "loss: [52055.5]\n",
      "Exploring\n",
      "Selected action  [4 3]\n",
      "[4 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 146us/step - loss: 28342.0000\n",
      "rewards:  -233.0 q-value:  0\n",
      "loss: [28342.0]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 119us/step - loss: 22402.4688\n",
      "rewards:  -238.0 q-value:  0\n",
      "loss: [22402.46875]\n",
      "Exploring\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 104us/step - loss: 20534.9062\n",
      "rewards:  -264.0 q-value:  0\n",
      "loss: [20534.90625]\n",
      "Exploiting\n",
      "Selected action  [3 2]\n",
      "[3 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 155us/step - loss: 17477.0625\n",
      "rewards:  -248.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [17477.0625]\n",
      "Exploiting\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 111us/step - loss: 23187.0000\n",
      "rewards:  -253.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [23187.0]\n",
      "Exploiting\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 116us/step - loss: 11614.9062\n",
      "rewards:  -279.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [11614.90625]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 109us/step - loss: 23333.2812\n",
      "rewards:  -284.0 q-value:  0\n",
      "loss: [23333.28125]\n",
      "Exploiting\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 108us/step - loss: 17441.0938\n",
      "rewards:  -289.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [17441.09375]\n",
      "Exploring\n",
      "Selected action  [3 1]\n",
      "[3 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 160us/step - loss: 19920.7812\n",
      "rewards:  -295.0 q-value:  0\n",
      "loss: [19920.78125]\n",
      "Exploiting\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 109us/step - loss: 32896.1562\n",
      "rewards:  -300.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [32896.15625]\n",
      "Exploiting\n",
      "Selected action  [4 3]\n",
      "[4 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 154us/step - loss: 30128.2188\n",
      "rewards:  -319.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [30128.21875]\n",
      "Exploiting\n",
      "Selected action  [4 2]\n",
      "[4 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 142us/step - loss: 10279.8438\n",
      "rewards:  -321.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [10279.84375]\n",
      "Exploring\n",
      "Selected action  [1 2]\n",
      "[1 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 138us/step - loss: 17976.2188\n",
      "rewards:  -328.0 q-value:  0\n",
      "loss: [17976.21875]\n",
      "Exploiting\n",
      "Selected action  [4 2]\n",
      "[4 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 137us/step - loss: 12608.9375\n",
      "rewards:  -329.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [12608.9375]\n",
      "Exploring\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 159us/step - loss: 23002.0625\n",
      "rewards:  -318.0 q-value:  0\n",
      "loss: [23002.0625]\n",
      "Exploring\n",
      "Selected action  [4 3]\n",
      "[4 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 125us/step - loss: 31821.8125\n",
      "rewards:  -324.0 q-value:  0\n",
      "loss: [31821.8125]\n",
      "Exploiting\n",
      "Selected action  [4 3]\n",
      "[4 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 128us/step - loss: 31344.5625\n",
      "rewards:  -330.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [31344.5625]\n",
      "Exploiting\n",
      "Selected action  [4 2]\n",
      "[4 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 191us/step - loss: 19106.1875\n",
      "rewards:  -341.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [19106.1875]\n",
      "Exploiting\n",
      "Selected action  [1 4]\n",
      "[1 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 101us/step - loss: 19837.6562\n",
      "rewards:  -352.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [19837.65625]\n",
      "Exploring\n",
      "Selected action  [1 4]\n",
      "[1 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 131us/step - loss: 28075.1875\n",
      "rewards:  -354.0 q-value:  0\n",
      "loss: [28075.1875]\n",
      "Exploring\n",
      "Selected action  [4 2]\n",
      "[4 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 106us/step - loss: 17814.9062\n",
      "rewards:  -346.0 q-value:  0\n",
      "loss: [17814.90625]\n",
      "Exploring\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 129us/step - loss: 16196.0312\n",
      "rewards:  -347.0 q-value:  0\n",
      "loss: [16196.03125]\n",
      "Exploiting\n",
      "Selected action  [3 1]\n",
      "[3 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 122us/step - loss: 29721.3438\n",
      "rewards:  -343.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [29721.34375]\n",
      "Exploiting\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 131us/step - loss: 20822.8750\n",
      "rewards:  -348.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [20822.875]\n",
      "Exploiting\n",
      "Selected action  [1 4]\n",
      "[1 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 140us/step - loss: 32348.7188\n",
      "rewards:  -383.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [32348.71875]\n",
      "Exploring\n",
      "Selected action  [4 2]\n",
      "[4 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 134us/step - loss: 23201.3125\n",
      "rewards:  -383.0 q-value:  0\n",
      "loss: [23201.3125]\n",
      "Exploring\n",
      "Selected action  [3 2]\n",
      "[3 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 115us/step - loss: 27856.5625\n",
      "rewards:  -389.0 q-value:  0\n",
      "loss: [27856.5625]\n",
      "Exploring\n",
      "Selected action  [1 4]\n",
      "[1 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 134us/step - loss: 29153.5625\n",
      "rewards:  -430.0 q-value:  0\n",
      "loss: [29153.5625]\n",
      "Exploring\n",
      "Selected action  [3 2]\n",
      "[3 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 185us/step - loss: 12085.3750\n",
      "rewards:  -396.0 q-value:  0\n",
      "loss: [12085.375]\n",
      "Exploring\n",
      "Selected action  [4 2]\n",
      "[4 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 222us/step - loss: 20589.1250\n",
      "rewards:  -396.0 q-value:  0\n",
      "loss: [20589.125]\n",
      "Exploring\n",
      "Selected action  [1 4]\n",
      "[1 4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 93us/step - loss: 16833.3125\n",
      "rewards:  -406.0 q-value:  0\n",
      "loss: [16833.3125]\n",
      "Exploring\n",
      "Selected action  [4 3]\n",
      "[4 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 172us/step - loss: 23205.6250\n",
      "rewards:  -382.0 q-value:  0\n",
      "loss: [23205.625]\n",
      "Exploring\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 95us/step - loss: 25533.7500\n",
      "rewards:  -384.0 q-value:  0\n",
      "loss: [25533.75]\n",
      "Number of actions available 7\n",
      "Episode : 41\n",
      "Exploring\n",
      "Selected action  [4 3]\n",
      "[4 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 141us/step - loss: 37870.7500\n",
      "rewards:  -2.0 q-value:  0\n",
      "loss: [37870.75]\n",
      "Exploiting\n",
      "Selected action  [0 3]\n",
      "[0 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 146us/step - loss: 24048.9375\n",
      "rewards:  -8.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [24048.9375]\n",
      "Exploring\n",
      "Selected action  [0 3]\n",
      "[0 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 152us/step - loss: 22450.1250\n",
      "rewards:  -11.0 q-value:  0\n",
      "loss: [22450.125]\n",
      "Exploiting\n",
      "Selected action  [0 4]\n",
      "[0 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 112us/step - loss: 27391.3750\n",
      "rewards:  -7.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [27391.375]\n",
      "Exploring\n",
      "Selected action  [3 4]\n",
      "[3 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 157us/step - loss: 21277.9375\n",
      "rewards:  -10.0 q-value:  0\n",
      "loss: [21277.9375]\n",
      "Exploring\n",
      "Selected action  [4 3]\n",
      "[4 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 116us/step - loss: 21800.3125\n",
      "rewards:  2.0 q-value:  0\n",
      "loss: [21800.3125]\n",
      "Exploring\n",
      "Selected action  [3 2]\n",
      "[3 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 200us/step - loss: 15427.7500\n",
      "rewards:  10.0 q-value:  0\n",
      "loss: [15427.75]\n",
      "Exploring\n",
      "Selected action  [0 3]\n",
      "[0 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 157us/step - loss: 15269.6250\n",
      "rewards:  -3.0 q-value:  0\n",
      "loss: [15269.625]\n",
      "Exploring\n",
      "Selected action  [4 3]\n",
      "[4 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 124us/step - loss: 19123.4688\n",
      "rewards:  -5.0 q-value:  0\n",
      "loss: [19123.46875]\n",
      "Exploring\n",
      "Selected action  [0 3]\n",
      "[0 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 152us/step - loss: 21584.5938\n",
      "rewards:  -15.0 q-value:  0\n",
      "loss: [21584.59375]\n",
      "Exploring\n",
      "Selected action  [3 2]\n",
      "[3 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 113us/step - loss: 36449.3438\n",
      "rewards:  21.0 q-value:  0\n",
      "loss: [36449.34375]\n",
      "Exploring\n",
      "Selected action  [3 4]\n",
      "[3 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 139us/step - loss: 37259.6875\n",
      "rewards:  26.0 q-value:  0\n",
      "loss: [37259.6875]\n",
      "Exploring\n",
      "Selected action  [4 3]\n",
      "[4 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 109us/step - loss: 25449.5000\n",
      "rewards:  46.0 q-value:  0\n",
      "loss: [25449.5]\n",
      "Exploring\n",
      "Selected action  [4 3]\n",
      "[4 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 134us/step - loss: 26125.0312\n",
      "rewards:  39.0 q-value:  0\n",
      "loss: [26125.03125]\n",
      "Exploring\n",
      "Selected action  [0 3]\n",
      "[0 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 123us/step - loss: 18075.0938\n",
      "rewards:  38.0 q-value:  0\n",
      "loss: [18075.09375]\n",
      "Exploiting\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 127us/step - loss: 15118.4062\n",
      "rewards:  35.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [15118.40625]\n",
      "Exploring\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 117us/step - loss: 21969.0312\n",
      "rewards:  33.0 q-value:  0\n",
      "loss: [21969.03125]\n",
      "Exploiting\n",
      "Selected action  [3 2]\n",
      "[3 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 168us/step - loss: 27777.6562\n",
      "rewards:  44.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [27777.65625]\n",
      "Exploiting\n",
      "Selected action  [0 3]\n",
      "[0 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 132us/step - loss: 20547.9062\n",
      "rewards:  51.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [20547.90625]\n",
      "Exploring\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 166us/step - loss: 6831.7812\n",
      "rewards:  60.0 q-value:  0\n",
      "loss: [6831.78125]\n",
      "Exploring\n",
      "Selected action  [0 4]\n",
      "[0 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 142us/step - loss: 14526.2500\n",
      "rewards:  64.0 q-value:  0\n",
      "loss: [14526.25]\n",
      "Exploiting\n",
      "Selected action  [4 3]\n",
      "[4 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 130us/step - loss: 21775.9688\n",
      "rewards:  88.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [21775.96875]\n",
      "Exploiting\n",
      "Selected action  [0 4]\n",
      "[0 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 159us/step - loss: 40808.7500\n",
      "rewards:  106.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [40808.75]\n",
      "Exploiting\n",
      "Selected action  [4 3]\n",
      "[4 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 112us/step - loss: 21227.8125\n",
      "rewards:  118.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [21227.8125]\n",
      "Exploring\n",
      "Selected action  [4 3]\n",
      "[4 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 120us/step - loss: 27206.6875\n",
      "rewards:  115.0 q-value:  0\n",
      "loss: [27206.6875]\n",
      "Exploiting\n",
      "Selected action  [0 3]\n",
      "[0 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 132us/step - loss: 28338.8125\n",
      "rewards:  110.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [28338.8125]\n",
      "Exploring\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 110us/step - loss: 30372.9688\n",
      "rewards:  88.0 q-value:  0\n",
      "loss: [30372.96875]\n",
      "Exploiting\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 95us/step - loss: 18492.3750\n",
      "rewards:  83.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [18492.375]\n",
      "Exploring\n",
      "Selected action  [4 3]\n",
      "[4 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 126us/step - loss: 21404.1875\n",
      "rewards:  77.0 q-value:  0\n",
      "loss: [21404.1875]\n",
      "Exploiting\n",
      "Selected action  [3 4]\n",
      "[3 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 102us/step - loss: 15086.4375\n",
      "rewards:  89.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [15086.4375]\n",
      "Exploiting\n",
      "Selected action  [0 4]\n",
      "[0 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 130us/step - loss: 25927.2188\n",
      "rewards:  88.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [25927.21875]\n",
      "Exploring\n",
      "Selected action  [0 4]\n",
      "[0 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 107us/step - loss: 21732.7812\n",
      "rewards:  87.0 q-value:  0\n",
      "loss: [21732.78125]\n",
      "Exploring\n",
      "Selected action  [3 4]\n",
      "[3 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 130us/step - loss: 22513.6875\n",
      "rewards:  82.0 q-value:  0\n",
      "loss: [22513.6875]\n",
      "Exploiting\n",
      "Selected action  [3 2]\n",
      "[3 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 92us/step - loss: 26632.7812\n",
      "rewards:  69.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [26632.78125]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 112us/step - loss: 15712.2812\n",
      "rewards:  64.0 q-value:  0\n",
      "loss: [15712.28125]\n",
      "Exploiting\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 113us/step - loss: 19397.9062\n",
      "rewards:  61.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [19397.90625]\n",
      "Exploiting\n",
      "Selected action  [3 4]\n",
      "[3 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 128us/step - loss: 18027.3438\n",
      "rewards:  66.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [18027.34375]\n",
      "Exploring\n",
      "Selected action  [0 4]\n",
      "[0 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 121us/step - loss: 23483.0625\n",
      "rewards:  63.0 q-value:  0\n",
      "loss: [23483.0625]\n",
      "Exploiting\n",
      "Selected action  [3 4]\n",
      "[3 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 151us/step - loss: 16378.1250\n",
      "rewards:  61.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [16378.125]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 143us/step - loss: 29825.3438\n",
      "rewards:  56.0 q-value:  0\n",
      "loss: [29825.34375]\n",
      "Exploiting\n",
      "Selected action  [3 2]\n",
      "[3 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 168us/step - loss: 15353.8125\n",
      "rewards:  80.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [15353.8125]\n",
      "Exploring\n",
      "Selected action  [4 3]\n",
      "[4 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 161us/step - loss: 19033.3750\n",
      "rewards:  104.0 q-value:  0\n",
      "loss: [19033.375]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 102us/step - loss: 23623.0625\n",
      "rewards:  99.0 q-value:  0\n",
      "loss: [23623.0625]\n",
      "Exploiting\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 130us/step - loss: 19455.5625\n",
      "rewards:  94.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [19455.5625]\n",
      "Exploring\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 108us/step - loss: 18308.0938\n",
      "rewards:  89.0 q-value:  0\n",
      "loss: [18308.09375]\n",
      "Exploiting\n",
      "Selected action  [3 2]\n",
      "[3 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 149us/step - loss: 30301.9688\n",
      "rewards:  95.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [30301.96875]\n",
      "Exploiting\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 149us/step - loss: 15091.7812\n",
      "rewards:  119.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [15091.78125]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 133us/step - loss: 19954.8750\n",
      "rewards:  114.0 q-value:  0\n",
      "loss: [19954.875]\n",
      "Exploiting\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 123us/step - loss: 28394.0625\n",
      "rewards:  111.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [28394.0625]\n",
      "Exploiting\n",
      "Selected action  [0 3]\n",
      "[0 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 117us/step - loss: 21038.3750\n",
      "rewards:  123.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [21038.375]\n",
      "Exploring\n",
      "Selected action  [3 4]\n",
      "[3 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 132us/step - loss: 12407.4688\n",
      "rewards:  135.0 q-value:  0\n",
      "loss: [12407.46875]\n",
      "Exploring\n",
      "Selected action  [0 3]\n",
      "[0 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 123us/step - loss: 22511.4375\n",
      "rewards:  170.0 q-value:  0\n",
      "loss: [22511.4375]\n",
      "Exploiting\n",
      "Selected action  [3 2]\n",
      "[3 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 141us/step - loss: 23861.5938\n",
      "rewards:  178.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [23861.59375]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 119us/step - loss: 13855.3438\n",
      "rewards:  173.0 q-value:  0\n",
      "loss: [13855.34375]\n",
      "Exploiting\n",
      "Selected action  [4 3]\n",
      "[4 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 122us/step - loss: 13792.5000\n",
      "rewards:  194.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [13792.5]\n",
      "Exploring\n",
      "Selected action  [4 3]\n",
      "[4 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 98us/step - loss: 31514.8750\n",
      "rewards:  189.0 q-value:  0\n",
      "loss: [31514.875]\n",
      "Exploring\n",
      "Selected action  [3 4]\n",
      "[3 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 103us/step - loss: 13927.7812\n",
      "rewards:  209.0 q-value:  0\n",
      "loss: [13927.78125]\n",
      "Exploiting\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 96us/step - loss: 27166.0312\n",
      "rewards:  208.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [27166.03125]\n",
      "Exploring\n",
      "Selected action  [3 2]\n",
      "[3 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 129us/step - loss: 28217.5312\n",
      "rewards:  215.0 q-value:  0\n",
      "loss: [28217.53125]\n",
      "Exploring\n",
      "Selected action  [0 3]\n",
      "[0 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 136us/step - loss: 17772.6875\n",
      "rewards:  204.0 q-value:  0\n",
      "loss: [17772.6875]\n",
      "Exploring\n",
      "Selected action  [3 4]\n",
      "[3 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 163us/step - loss: 16003.3438\n",
      "rewards:  212.0 q-value:  0\n",
      "loss: [16003.34375]\n",
      "Exploring\n",
      "Selected action  [3 4]\n",
      "[3 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 104us/step - loss: 20523.3750\n",
      "rewards:  210.0 q-value:  0\n",
      "loss: [20523.375]\n",
      "Exploiting\n",
      "Selected action  [3 4]\n",
      "[3 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 145us/step - loss: 34077.2812\n",
      "rewards:  208.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [34077.28125]\n",
      "Exploring\n",
      "Selected action  [4 3]\n",
      "[4 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 112us/step - loss: 20235.5625\n",
      "rewards:  212.0 q-value:  0\n",
      "loss: [20235.5625]\n",
      "Exploiting\n",
      "Selected action  [3 2]\n",
      "[3 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 131us/step - loss: 18851.5938\n",
      "rewards:  224.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [18851.59375]\n",
      "Exploring\n",
      "Selected action  [0 3]\n",
      "[0 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 94us/step - loss: 22389.7812\n",
      "rewards:  231.0 q-value:  0\n",
      "loss: [22389.78125]\n",
      "Exploiting\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 128us/step - loss: 22310.9375\n",
      "rewards:  226.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [22310.9375]\n",
      "Exploiting\n",
      "Selected action  [0 4]\n",
      "[0 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 123us/step - loss: 22587.0938\n",
      "rewards:  230.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [22587.09375]\n",
      "Exploring\n",
      "Selected action  [3 2]\n",
      "[3 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 117us/step - loss: 19958.3750\n",
      "rewards:  216.0 q-value:  0\n",
      "loss: [19958.375]\n",
      "Exploring\n",
      "Selected action  [4 3]\n",
      "[4 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 164us/step - loss: 21563.4062\n",
      "rewards:  230.0 q-value:  0\n",
      "loss: [21563.40625]\n",
      "Exploring\n",
      "Selected action  [3 2]\n",
      "[3 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 115us/step - loss: 11294.0000\n",
      "rewards:  246.0 q-value:  0\n",
      "loss: [11294.0]\n",
      "Exploiting\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 105us/step - loss: 19770.5000\n",
      "rewards:  258.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [19770.5]\n",
      "Exploring\n",
      "Selected action  [3 2]\n",
      "[3 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 189us/step - loss: 22527.9688\n",
      "rewards:  248.0 q-value:  0\n",
      "loss: [22527.96875]\n",
      "Exploring\n",
      "Selected action  [3 4]\n",
      "[3 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 137us/step - loss: 31580.4062\n",
      "rewards:  235.0 q-value:  0\n",
      "loss: [31580.40625]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 117us/step - loss: 10685.8750\n",
      "rewards:  230.0 q-value:  0\n",
      "loss: [10685.875]\n",
      "Exploiting\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 127us/step - loss: 19548.7812\n",
      "rewards:  228.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [19548.78125]\n",
      "Exploring\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 115us/step - loss: 16265.0625\n",
      "rewards:  226.0 q-value:  0\n",
      "loss: [16265.0625]\n",
      "Exploring\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 149us/step - loss: 12443.6562\n",
      "rewards:  221.0 q-value:  0\n",
      "loss: [12443.65625]\n",
      "Exploring\n",
      "Selected action  [3 2]\n",
      "[3 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 121us/step - loss: 17972.3438\n",
      "rewards:  206.0 q-value:  0\n",
      "loss: [17972.34375]\n",
      "Exploring\n",
      "Selected action  [0 3]\n",
      "[0 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 109us/step - loss: 43422.6875\n",
      "rewards:  193.0 q-value:  0\n",
      "loss: [43422.6875]\n",
      "Exploring\n",
      "Selected action  [3 4]\n",
      "[3 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 126us/step - loss: 9747.0938\n",
      "rewards:  205.0 q-value:  0\n",
      "loss: [9747.09375]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 129us/step - loss: 22656.0625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rewards:  200.0 q-value:  0\n",
      "loss: [22656.0625]\n",
      "Exploiting\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 94us/step - loss: 33081.6875\n",
      "rewards:  197.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [33081.6875]\n",
      "Exploring\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 175us/step - loss: 23047.4688\n",
      "rewards:  192.0 q-value:  0\n",
      "loss: [23047.46875]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 127us/step - loss: 32507.9688\n",
      "rewards:  187.0 q-value:  0\n",
      "loss: [32507.96875]\n",
      "Exploring\n",
      "Selected action  [0 3]\n",
      "[0 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 104us/step - loss: 31175.4375\n",
      "rewards:  199.0 q-value:  0\n",
      "loss: [31175.4375]\n",
      "Exploring\n",
      "Selected action  [4 3]\n",
      "[4 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 106us/step - loss: 30178.8125\n",
      "rewards:  194.0 q-value:  0\n",
      "loss: [30178.8125]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 129us/step - loss: 17441.1562\n",
      "rewards:  189.0 q-value:  0\n",
      "loss: [17441.15625]\n",
      "Exploring\n",
      "Selected action  [0 3]\n",
      "[0 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 115us/step - loss: 23994.3438\n",
      "rewards:  193.0 q-value:  0\n",
      "loss: [23994.34375]\n",
      "Exploring\n",
      "Selected action  [3 4]\n",
      "[3 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 121us/step - loss: 31273.0938\n",
      "rewards:  209.0 q-value:  0\n",
      "loss: [31273.09375]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 129us/step - loss: 12537.5938\n",
      "rewards:  204.0 q-value:  0\n",
      "loss: [12537.59375]\n",
      "Exploiting\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 128us/step - loss: 19250.5312\n",
      "rewards:  197.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [19250.53125]\n",
      "Exploring\n",
      "Selected action  [3 4]\n",
      "[3 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 124us/step - loss: 15310.3750\n",
      "rewards:  183.0 q-value:  0\n",
      "loss: [15310.375]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 133us/step - loss: 24813.3125\n",
      "rewards:  178.0 q-value:  0\n",
      "loss: [24813.3125]\n",
      "Exploiting\n",
      "Selected action  [4 3]\n",
      "[4 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 116us/step - loss: 16708.4688\n",
      "rewards:  202.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [16708.46875]\n",
      "Exploring\n",
      "Selected action  [0 4]\n",
      "[0 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 139us/step - loss: 19399.6875\n",
      "rewards:  191.0 q-value:  0\n",
      "loss: [19399.6875]\n",
      "Exploring\n",
      "Selected action  [4 3]\n",
      "[4 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 99us/step - loss: 24447.4375\n",
      "rewards:  215.0 q-value:  0\n",
      "loss: [24447.4375]\n",
      "Exploring\n",
      "Selected action  [0 4]\n",
      "[0 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 164us/step - loss: 23487.2500\n",
      "rewards:  189.0 q-value:  0\n",
      "loss: [23487.25]\n",
      "Exploiting\n",
      "Selected action  [3 4]\n",
      "[3 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 184us/step - loss: 18016.5625\n",
      "rewards:  187.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [18016.5625]\n",
      "Exploiting\n",
      "Selected action  [0 4]\n",
      "[0 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 120us/step - loss: 18779.0000\n",
      "rewards:  186.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [18779.0]\n",
      "Exploiting\n",
      "Selected action  [3 2]\n",
      "[3 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 112us/step - loss: 28457.9062\n",
      "rewards:  175.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [28457.90625]\n",
      "Exploring\n",
      "Selected action  [4 3]\n",
      "[4 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 110us/step - loss: 24422.3125\n",
      "rewards:  187.0 q-value:  0\n",
      "loss: [24422.3125]\n",
      "Exploiting\n",
      "Selected action  [0 3]\n",
      "[0 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 121us/step - loss: 17412.4688\n",
      "rewards:  187.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [17412.46875]\n",
      "Exploiting\n",
      "Selected action  [3 2]\n",
      "[3 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 100us/step - loss: 20239.8438\n",
      "rewards:  219.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [20239.84375]\n",
      "Exploring\n",
      "Selected action  [3 2]\n",
      "[3 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 124us/step - loss: 31454.7812\n",
      "rewards:  217.0 q-value:  0\n",
      "loss: [31454.78125]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 120us/step - loss: 12285.4688\n",
      "rewards:  212.0 q-value:  0\n",
      "loss: [12285.46875]\n",
      "Exploiting\n",
      "Selected action  [3 4]\n",
      "[3 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 123us/step - loss: 14101.9688\n",
      "rewards:  170.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [14101.96875]\n",
      "Exploring\n",
      "Selected action  [3 4]\n",
      "[3 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 113us/step - loss: 34430.8438\n",
      "rewards:  168.0 q-value:  0\n",
      "loss: [34430.84375]\n",
      "Exploring\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 115us/step - loss: 21227.1562\n",
      "rewards:  171.0 q-value:  0\n",
      "loss: [21227.15625]\n",
      "Exploring\n",
      "Selected action  [4 3]\n",
      "[4 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 190us/step - loss: 10556.5312\n",
      "rewards:  194.0 q-value:  0\n",
      "loss: [10556.53125]\n",
      "Exploring\n",
      "Selected action  [0 4]\n",
      "[0 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 97us/step - loss: 27803.5312\n",
      "rewards:  196.0 q-value:  0\n",
      "loss: [27803.53125]\n",
      "Exploiting\n",
      "Selected action  [0 3]\n",
      "[0 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 117us/step - loss: 27742.2812\n",
      "rewards:  189.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [27742.28125]\n",
      "Exploring\n",
      "Selected action  [3 2]\n",
      "[3 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 127us/step - loss: 23735.4062\n",
      "rewards:  201.0 q-value:  0\n",
      "loss: [23735.40625]\n",
      "Exploring\n",
      "Selected action  [4 3]\n",
      "[4 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 149us/step - loss: 14765.1562\n",
      "rewards:  221.0 q-value:  0\n",
      "loss: [14765.15625]\n",
      "Exploiting\n",
      "Selected action  [4 3]\n",
      "[4 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 135us/step - loss: 22256.3125\n",
      "rewards:  216.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [22256.3125]\n",
      "Exploiting\n",
      "Selected action  [3 2]\n",
      "[3 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 110us/step - loss: 24702.5625\n",
      "rewards:  236.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [24702.5625]\n",
      "Exploring\n",
      "Selected action  [0 4]\n",
      "[0 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 123us/step - loss: 20842.4375\n",
      "rewards:  225.0 q-value:  0\n",
      "loss: [20842.4375]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 87us/step - loss: 22457.6875\n",
      "rewards:  220.0 q-value:  0\n",
      "loss: [22457.6875]\n",
      "Exploiting\n",
      "Selected action  [4 3]\n",
      "[4 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 178us/step - loss: 15666.0938\n",
      "rewards:  239.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [15666.09375]\n",
      "Exploring\n",
      "Selected action  [3 4]\n",
      "[3 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 161us/step - loss: 23931.6562\n",
      "rewards:  247.0 q-value:  0\n",
      "loss: [23931.65625]\n",
      "Exploring\n",
      "Selected action  [4 3]\n",
      "[4 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 121us/step - loss: 13969.5000\n",
      "rewards:  255.0 q-value:  0\n",
      "loss: [13969.5]\n",
      "Exploring\n",
      "Selected action  [0 4]\n",
      "[0 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 115us/step - loss: 26773.6250\n",
      "rewards:  219.0 q-value:  0\n",
      "loss: [26773.625]\n",
      "Exploring\n",
      "Selected action  [0 3]\n",
      "[0 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 114us/step - loss: 23100.5625\n",
      "rewards:  246.0 q-value:  0\n",
      "loss: [23100.5625]\n",
      "Exploring\n",
      "Selected action  [0 4]\n",
      "[0 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 164us/step - loss: 25443.9375\n",
      "rewards:  218.0 q-value:  0\n",
      "loss: [25443.9375]\n",
      "Exploring\n",
      "Selected action  [3 4]\n",
      "[3 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 131us/step - loss: 29328.6250\n",
      "rewards:  212.0 q-value:  0\n",
      "loss: [29328.625]\n",
      "Number of actions available 11\n",
      "Episode : 42\n",
      "Exploiting\n",
      "Selected action  [4 3]\n",
      "[4 3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 116us/step - loss: 14796.0625\n",
      "rewards:  -2.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [14796.0625]\n",
      "Exploiting\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 116us/step - loss: 25044.5625\n",
      "rewards:  -19.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [25044.5625]\n",
      "Exploring\n",
      "Selected action  [0 4]\n",
      "[0 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 113us/step - loss: 16870.8750\n",
      "rewards:  -15.0 q-value:  0\n",
      "loss: [16870.875]\n",
      "Exploring\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 120us/step - loss: 25219.1562\n",
      "rewards:  -25.0 q-value:  0\n",
      "loss: [25219.15625]\n",
      "Exploring\n",
      "Selected action  [2 3]\n",
      "[2 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 126us/step - loss: 36372.1562\n",
      "rewards:  -33.0 q-value:  0\n",
      "loss: [36372.15625]\n",
      "Exploiting\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 156us/step - loss: 20061.6562\n",
      "rewards:  -25.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [20061.65625]\n",
      "Exploiting\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 103us/step - loss: 25335.2500\n",
      "rewards:  -30.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [25335.25]\n",
      "Exploiting\n",
      "Selected action  [4 2]\n",
      "[4 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 128us/step - loss: 18591.9062\n",
      "rewards:  -62.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [18591.90625]\n",
      "Exploring\n",
      "Selected action  [3 2]\n",
      "[3 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 124us/step - loss: 16814.6250\n",
      "rewards:  -68.0 q-value:  0\n",
      "loss: [16814.625]\n",
      "Exploring\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 124us/step - loss: 17756.9062\n",
      "rewards:  -114.0 q-value:  0\n",
      "loss: [17756.90625]\n",
      "Exploring\n",
      "Selected action  [0 4]\n",
      "[0 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 116us/step - loss: 32093.9375\n",
      "rewards:  -125.0 q-value:  0\n",
      "loss: [32093.9375]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 113us/step - loss: 28492.8438\n",
      "rewards:  -104.0 q-value:  0\n",
      "loss: [28492.84375]\n",
      "Exploring\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 125us/step - loss: 19645.9688\n",
      "rewards:  -110.0 q-value:  0\n",
      "loss: [19645.96875]\n",
      "Exploiting\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 125us/step - loss: 21108.6875\n",
      "rewards:  -115.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [21108.6875]\n",
      "Exploiting\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 155us/step - loss: 24298.8750\n",
      "rewards:  -120.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [24298.875]\n",
      "Exploiting\n",
      "Selected action  [0 4]\n",
      "[0 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 149us/step - loss: 47087.5000\n",
      "rewards:  -96.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [47087.5]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 116us/step - loss: 21827.3438\n",
      "rewards:  -96.0 q-value:  0\n",
      "loss: [21827.34375]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 106us/step - loss: 13042.3125\n",
      "rewards:  -96.0 q-value:  0\n",
      "loss: [13042.3125]\n",
      "Exploring\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 123us/step - loss: 12488.7188\n",
      "rewards:  -77.0 q-value:  0\n",
      "loss: [12488.71875]\n",
      "Exploiting\n",
      "Selected action  [3 2]\n",
      "[3 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 122us/step - loss: 23228.4375\n",
      "rewards:  -57.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [23228.4375]\n",
      "Exploring\n",
      "Selected action  [2 1]\n",
      "[2 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 104us/step - loss: 21311.7812\n",
      "rewards:  -45.0 q-value:  0\n",
      "loss: [21311.78125]\n",
      "Exploiting\n",
      "Selected action  [0 4]\n",
      "[0 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 110us/step - loss: 18291.8750\n",
      "rewards:  -76.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [18291.875]\n",
      "Exploring\n",
      "Selected action  [2 3]\n",
      "[2 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 98us/step - loss: 17536.7188\n",
      "rewards:  -69.0 q-value:  0\n",
      "loss: [17536.71875]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 151us/step - loss: 25060.5000\n",
      "rewards:  -67.0 q-value:  0\n",
      "loss: [25060.5]\n",
      "Exploring\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 114us/step - loss: 17218.8125\n",
      "rewards:  -74.0 q-value:  0\n",
      "loss: [17218.8125]\n",
      "Exploring\n",
      "Selected action  [0 4]\n",
      "[0 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 98us/step - loss: 22223.8750\n",
      "rewards:  -110.0 q-value:  0\n",
      "loss: [22223.875]\n",
      "Exploiting\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 90us/step - loss: 30903.9688\n",
      "rewards:  -95.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [30903.96875]\n",
      "Exploiting\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 104us/step - loss: 34219.6875\n",
      "rewards:  -101.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [34219.6875]\n",
      "Exploiting\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 102us/step - loss: 22456.5938\n",
      "rewards:  -98.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [22456.59375]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 128us/step - loss: 11448.2188\n",
      "rewards:  -74.0 q-value:  0\n",
      "loss: [11448.21875]\n",
      "Exploring\n",
      "Selected action  [2 3]\n",
      "[2 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 163us/step - loss: 12342.4062\n",
      "rewards:  -98.0 q-value:  0\n",
      "loss: [12342.40625]\n",
      "Exploring\n",
      "Selected action  [2 3]\n",
      "[2 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 80us/step - loss: 38277.4375\n",
      "rewards:  -103.0 q-value:  0\n",
      "loss: [38277.4375]\n",
      "Exploring\n",
      "Selected action  [4 3]\n",
      "[4 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 133us/step - loss: 37674.9062\n",
      "rewards:  -105.0 q-value:  0\n",
      "loss: [37674.90625]\n",
      "Exploring\n",
      "Selected action  [0 4]\n",
      "[0 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 135us/step - loss: 27873.0625\n",
      "rewards:  -127.0 q-value:  0\n",
      "loss: [27873.0625]\n",
      "Exploring\n",
      "Selected action  [0 4]\n",
      "[0 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 104us/step - loss: 13029.1250\n",
      "rewards:  -129.0 q-value:  0\n",
      "loss: [13029.125]\n",
      "Exploiting\n",
      "Selected action  [2 3]\n",
      "[2 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 135us/step - loss: 17770.6562\n",
      "rewards:  -134.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [17770.65625]\n",
      "Exploring\n",
      "Selected action  [0 4]\n",
      "[0 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 156us/step - loss: 20616.2812\n",
      "rewards:  -159.0 q-value:  0\n",
      "loss: [20616.28125]\n",
      "Exploring\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 123us/step - loss: 20123.8750\n",
      "rewards:  -156.0 q-value:  0\n",
      "loss: [20123.875]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 109us/step - loss: 15902.8438\n",
      "rewards:  -158.0 q-value:  0\n",
      "loss: [15902.84375]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 133us/step - loss: 23858.4688\n",
      "rewards:  -163.0 q-value:  0\n",
      "loss: [23858.46875]\n",
      "Exploiting\n",
      "Selected action  [4 2]\n",
      "[4 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 141us/step - loss: 24469.9062\n",
      "rewards:  -193.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [24469.90625]\n",
      "Exploring\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 115us/step - loss: 27416.0938\n",
      "rewards:  -173.0 q-value:  0\n",
      "loss: [27416.09375]\n",
      "Exploring\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 107us/step - loss: 30049.6875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rewards:  -188.0 q-value:  0\n",
      "loss: [30049.6875]\n",
      "Exploiting\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 111us/step - loss: 21184.1562\n",
      "rewards:  -171.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [21184.15625]\n",
      "Exploring\n",
      "Selected action  [0 4]\n",
      "[0 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 110us/step - loss: 17030.3125\n",
      "rewards:  -175.0 q-value:  0\n",
      "loss: [17030.3125]\n",
      "Exploring\n",
      "Selected action  [0 4]\n",
      "[0 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 140us/step - loss: 18850.5625\n",
      "rewards:  -178.0 q-value:  0\n",
      "loss: [18850.5625]\n",
      "Exploiting\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 126us/step - loss: 28099.7500\n",
      "rewards:  -150.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [28099.75]\n",
      "Exploring\n",
      "Selected action  [4 3]\n",
      "[4 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 132us/step - loss: 12493.5625\n",
      "rewards:  -147.0 q-value:  0\n",
      "loss: [12493.5625]\n",
      "Exploiting\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 121us/step - loss: 25156.2500\n",
      "rewards:  -125.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [25156.25]\n",
      "Exploiting\n",
      "Selected action  [4 3]\n",
      "[4 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 106us/step - loss: 19042.1562\n",
      "rewards:  -101.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [19042.15625]\n",
      "Exploiting\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 123us/step - loss: 10212.9688\n",
      "rewards:  -106.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [10212.96875]\n",
      "Exploring\n",
      "Selected action  [4 3]\n",
      "[4 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 179us/step - loss: 31574.0625\n",
      "rewards:  -103.0 q-value:  0\n",
      "loss: [31574.0625]\n",
      "Exploring\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 113us/step - loss: 39562.2500\n",
      "rewards:  -107.0 q-value:  0\n",
      "loss: [39562.25]\n",
      "Exploiting\n",
      "Selected action  [3 2]\n",
      "[3 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 127us/step - loss: 27224.8750\n",
      "rewards:  -83.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [27224.875]\n",
      "Exploiting\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 232us/step - loss: 19789.3125\n",
      "rewards:  -88.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [19789.3125]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 102us/step - loss: 17237.3438\n",
      "rewards:  -93.0 q-value:  0\n",
      "loss: [17237.34375]\n",
      "Exploiting\n",
      "Selected action  [2 3]\n",
      "[2 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 93us/step - loss: 17978.3125\n",
      "rewards:  -76.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [17978.3125]\n",
      "Exploring\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 116us/step - loss: 25808.0000\n",
      "rewards:  -66.0 q-value:  0\n",
      "loss: [25808.0]\n",
      "Exploring\n",
      "Selected action  [0 4]\n",
      "[0 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 124us/step - loss: 35338.7500\n",
      "rewards:  -62.0 q-value:  0\n",
      "loss: [35338.75]\n",
      "Exploring\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 120us/step - loss: 30133.6562\n",
      "rewards:  -62.0 q-value:  0\n",
      "loss: [30133.65625]\n",
      "Exploring\n",
      "Selected action  [3 2]\n",
      "[3 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 208us/step - loss: 23687.3125\n",
      "rewards:  -54.0 q-value:  0\n",
      "loss: [23687.3125]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 157us/step - loss: 17778.5938\n",
      "rewards:  -68.0 q-value:  0\n",
      "loss: [17778.59375]\n",
      "Exploring\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 96us/step - loss: 14021.9688\n",
      "rewards:  -74.0 q-value:  0\n",
      "loss: [14021.96875]\n",
      "Exploring\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 119us/step - loss: 26342.5312\n",
      "rewards:  -65.0 q-value:  0\n",
      "loss: [26342.53125]\n",
      "Exploiting\n",
      "Selected action  [3 2]\n",
      "[3 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 119us/step - loss: 26715.9375\n",
      "rewards:  -45.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [26715.9375]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 139us/step - loss: 16645.6562\n",
      "rewards:  -41.0 q-value:  0\n",
      "loss: [16645.65625]\n",
      "Exploiting\n",
      "Selected action  [0 4]\n",
      "[0 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 111us/step - loss: 15571.7500\n",
      "rewards:  -42.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [15571.75]\n",
      "Exploring\n",
      "Selected action  [4 2]\n",
      "[4 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 132us/step - loss: 15935.5000\n",
      "rewards:  -38.0 q-value:  0\n",
      "loss: [15935.5]\n",
      "Exploring\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 145us/step - loss: 32454.2500\n",
      "rewards:  -45.0 q-value:  0\n",
      "loss: [32454.25]\n",
      "Exploiting\n",
      "Selected action  [2 3]\n",
      "[2 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 136us/step - loss: 11656.6875\n",
      "rewards:  -48.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [11656.6875]\n",
      "Exploiting\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 163us/step - loss: 17371.9062\n",
      "rewards:  -50.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [17371.90625]\n",
      "Exploring\n",
      "Selected action  [3 2]\n",
      "[3 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 137us/step - loss: 18985.3750\n",
      "rewards:  -34.0 q-value:  0\n",
      "loss: [18985.375]\n",
      "Exploiting\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 94us/step - loss: 37387.0000\n",
      "rewards:  -47.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [37387.0]\n",
      "Exploring\n",
      "Selected action  [2 1]\n",
      "[2 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 109us/step - loss: 18952.5625\n",
      "rewards:  -52.0 q-value:  0\n",
      "loss: [18952.5625]\n",
      "Exploiting\n",
      "Selected action  [3 2]\n",
      "[3 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 137us/step - loss: 21071.6250\n",
      "rewards:  -50.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [21071.625]\n",
      "Exploring\n",
      "Selected action  [2 3]\n",
      "[2 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 103us/step - loss: 25607.0000\n",
      "rewards:  -34.0 q-value:  0\n",
      "loss: [25607.0]\n",
      "Exploiting\n",
      "Selected action  [4 3]\n",
      "[4 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 98us/step - loss: 23297.7188\n",
      "rewards:  -40.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [23297.71875]\n",
      "Exploring\n",
      "Selected action  [4 3]\n",
      "[4 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 89us/step - loss: 28291.5625\n",
      "rewards:  -44.0 q-value:  0\n",
      "loss: [28291.5625]\n",
      "Exploiting\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 109us/step - loss: 27294.3438\n",
      "rewards:  -57.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [27294.34375]\n",
      "Exploring\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 135us/step - loss: 22047.0000\n",
      "rewards:  -63.0 q-value:  0\n",
      "loss: [22047.0]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 121us/step - loss: 32327.8125\n",
      "rewards:  -69.0 q-value:  0\n",
      "loss: [32327.8125]\n",
      "Exploring\n",
      "Selected action  [2 3]\n",
      "[2 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 203us/step - loss: 22094.9688\n",
      "rewards:  -50.0 q-value:  0\n",
      "loss: [22094.96875]\n",
      "Exploring\n",
      "Selected action  [2 1]\n",
      "[2 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 97us/step - loss: 23730.7188\n",
      "rewards:  -18.0 q-value:  0\n",
      "loss: [23730.71875]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 111us/step - loss: 23799.3438\n",
      "rewards:  -49.0 q-value:  0\n",
      "loss: [23799.34375]\n",
      "Exploring\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 110us/step - loss: 24244.7500\n",
      "rewards:  -42.0 q-value:  0\n",
      "loss: [24244.75]\n",
      "Exploring\n",
      "Selected action  [0 4]\n",
      "[0 4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 164us/step - loss: 18410.4688\n",
      "rewards:  -42.0 q-value:  0\n",
      "loss: [18410.46875]\n",
      "Exploring\n",
      "Selected action  [2 1]\n",
      "[2 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 141us/step - loss: 12913.1562\n",
      "rewards:  -54.0 q-value:  0\n",
      "loss: [12913.15625]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 103us/step - loss: 20696.0938\n",
      "rewards:  -59.0 q-value:  0\n",
      "loss: [20696.09375]\n",
      "Exploring\n",
      "Selected action  [0 4]\n",
      "[0 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 133us/step - loss: 25021.1875\n",
      "rewards:  -43.0 q-value:  0\n",
      "loss: [25021.1875]\n",
      "Exploring\n",
      "Selected action  [0 4]\n",
      "[0 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 104us/step - loss: 24837.0938\n",
      "rewards:  -46.0 q-value:  0\n",
      "loss: [24837.09375]\n",
      "Exploiting\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 91us/step - loss: 29580.7500\n",
      "rewards:  -18.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [29580.75]\n",
      "Exploiting\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 108us/step - loss: 19078.8438\n",
      "rewards:  -25.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [19078.84375]\n",
      "Exploring\n",
      "Selected action  [2 3]\n",
      "[2 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 91us/step - loss: 20570.7812\n",
      "rewards:  -52.0 q-value:  0\n",
      "loss: [20570.78125]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 124us/step - loss: 10997.6875\n",
      "rewards:  -57.0 q-value:  0\n",
      "loss: [10997.6875]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 136us/step - loss: 26138.8750\n",
      "rewards:  -77.0 q-value:  0\n",
      "loss: [26138.875]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 123us/step - loss: 29786.4375\n",
      "rewards:  -61.0 q-value:  0\n",
      "loss: [29786.4375]\n",
      "Exploring\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 128us/step - loss: 26881.5000\n",
      "rewards:  -73.0 q-value:  0\n",
      "loss: [26881.5]\n",
      "Exploiting\n",
      "Selected action  [4 3]\n",
      "[4 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 105us/step - loss: 18685.4688\n",
      "rewards:  -79.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [18685.46875]\n",
      "Exploring\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 131us/step - loss: 12087.5312\n",
      "rewards:  -96.0 q-value:  0\n",
      "loss: [12087.53125]\n",
      "Exploiting\n",
      "Selected action  [2 3]\n",
      "[2 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 110us/step - loss: 26173.0000\n",
      "rewards:  -102.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [26173.0]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 124us/step - loss: 34209.1875\n",
      "rewards:  -142.0 q-value:  0\n",
      "loss: [34209.1875]\n",
      "Exploring\n",
      "Selected action  [0 4]\n",
      "[0 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 151us/step - loss: 21015.1875\n",
      "rewards:  -143.0 q-value:  0\n",
      "loss: [21015.1875]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 123us/step - loss: 15483.2188\n",
      "rewards:  -145.0 q-value:  0\n",
      "loss: [15483.21875]\n",
      "Exploring\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 125us/step - loss: 30035.4062\n",
      "rewards:  -155.0 q-value:  0\n",
      "loss: [30035.40625]\n",
      "Exploring\n",
      "Selected action  [4 2]\n",
      "[4 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 121us/step - loss: 28919.9375\n",
      "rewards:  -170.0 q-value:  0\n",
      "loss: [28919.9375]\n",
      "Exploring\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 124us/step - loss: 16659.5000\n",
      "rewards:  -158.0 q-value:  0\n",
      "loss: [16659.5]\n",
      "Exploring\n",
      "Selected action  [4 2]\n",
      "[4 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 120us/step - loss: 32099.1562\n",
      "rewards:  -190.0 q-value:  0\n",
      "loss: [32099.15625]\n",
      "Exploring\n",
      "Selected action  [0 4]\n",
      "[0 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 116us/step - loss: 19794.8125\n",
      "rewards:  -183.0 q-value:  0\n",
      "loss: [19794.8125]\n",
      "Exploring\n",
      "Selected action  [2 3]\n",
      "[2 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 111us/step - loss: 25149.4688\n",
      "rewards:  -205.0 q-value:  0\n",
      "loss: [25149.46875]\n",
      "Exploiting\n",
      "Selected action  [3 2]\n",
      "[3 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 132us/step - loss: 23563.4688\n",
      "rewards:  -197.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [23563.46875]\n",
      "Exploring\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 101us/step - loss: 15311.5312\n",
      "rewards:  -173.0 q-value:  0\n",
      "loss: [15311.53125]\n",
      "Exploiting\n",
      "Selected action  [4 3]\n",
      "[4 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 137us/step - loss: 20161.8750\n",
      "rewards:  -152.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [20161.875]\n",
      "Number of actions available 8\n",
      "Episode : 43\n",
      "Exploring\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 123us/step - loss: 19550.5625\n",
      "rewards:  -6.0 q-value:  0\n",
      "loss: [19550.5625]\n",
      "Exploring\n",
      "Selected action  [4 0]\n",
      "[4 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 106us/step - loss: 23250.4062\n",
      "rewards:  -29.0 q-value:  0\n",
      "loss: [23250.40625]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 133us/step - loss: 43259.1562\n",
      "rewards:  -21.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [43259.15625]\n",
      "Exploring\n",
      "Selected action  [4 0]\n",
      "[4 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 134us/step - loss: 28003.0000\n",
      "rewards:  -27.0 q-value:  0\n",
      "loss: [28003.0]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 138us/step - loss: 30702.2812\n",
      "rewards:  -19.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [30702.28125]\n",
      "Exploring\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 121us/step - loss: 44588.7500\n",
      "rewards:  -21.0 q-value:  0\n",
      "loss: [44588.75]\n",
      "Exploring\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 96us/step - loss: 22849.5625\n",
      "rewards:  -23.0 q-value:  0\n",
      "loss: [22849.5625]\n",
      "Exploring\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 152us/step - loss: 19889.0000\n",
      "rewards:  -25.0 q-value:  0\n",
      "loss: [19889.0]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 149us/step - loss: 29152.8750\n",
      "rewards:  -27.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [29152.875]\n",
      "Exploring\n",
      "Selected action  [3 1]\n",
      "[3 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 97us/step - loss: 18147.4688\n",
      "rewards:  -32.0 q-value:  0\n",
      "loss: [18147.46875]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 139us/step - loss: 33159.7812\n",
      "rewards:  -41.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [33159.78125]\n",
      "Exploring\n",
      "Selected action  [1 2]\n",
      "[1 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 112us/step - loss: 17945.1875\n",
      "rewards:  -37.0 q-value:  0\n",
      "loss: [17945.1875]\n",
      "Exploring\n",
      "Selected action  [0 4]\n",
      "[0 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 106us/step - loss: 21221.5000\n",
      "rewards:  -35.0 q-value:  0\n",
      "loss: [21221.5]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 120us/step - loss: 15594.5625\n",
      "rewards:  -57.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [15594.5625]\n",
      "Exploring\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 99us/step - loss: 26686.7188\n",
      "rewards:  -58.0 q-value:  0\n",
      "loss: [26686.71875]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 171us/step - loss: 23818.0625\n",
      "rewards:  -63.0 q-value:  0\n",
      "loss: [23818.0625]\n",
      "Exploring\n",
      "Selected action  [1 2]\n",
      "[1 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 131us/step - loss: 22388.0938\n",
      "rewards:  -54.0 q-value:  0\n",
      "loss: [22388.09375]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 157us/step - loss: 22489.2812\n",
      "rewards:  -59.0 q-value:  0\n",
      "loss: [22489.28125]\n",
      "Exploring\n",
      "Selected action  [1 2]\n",
      "[1 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 96us/step - loss: 24990.8750\n",
      "rewards:  -58.0 q-value:  0\n",
      "loss: [24990.875]\n",
      "Exploring\n",
      "Selected action  [4 2]\n",
      "[4 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 117us/step - loss: 26254.4062\n",
      "rewards:  -60.0 q-value:  0\n",
      "loss: [26254.40625]\n",
      "Exploring\n",
      "Selected action  [1 2]\n",
      "[1 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 142us/step - loss: 14498.3125\n",
      "rewards:  -71.0 q-value:  0\n",
      "loss: [14498.3125]\n",
      "Exploring\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 255us/step - loss: 18668.9062\n",
      "rewards:  -65.0 q-value:  0\n",
      "loss: [18668.90625]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 154us/step - loss: 18850.5000\n",
      "rewards:  -70.0 q-value:  0\n",
      "loss: [18850.5]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 111us/step - loss: 13786.2500\n",
      "rewards:  -46.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [13786.25]\n",
      "Exploring\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 116us/step - loss: 25926.6875\n",
      "rewards:  -49.0 q-value:  0\n",
      "loss: [25926.6875]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 166us/step - loss: 28407.0938\n",
      "rewards:  -21.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [28407.09375]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 141us/step - loss: 21110.7812\n",
      "rewards:  -25.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [21110.78125]\n",
      "Exploring\n",
      "Selected action  [3 1]\n",
      "[3 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 148us/step - loss: 31943.3750\n",
      "rewards:  -29.0 q-value:  0\n",
      "loss: [31943.375]\n",
      "Exploring\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 239us/step - loss: 23888.1562\n",
      "rewards:  -49.0 q-value:  0\n",
      "loss: [23888.15625]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 145us/step - loss: 31631.3125\n",
      "rewards:  -21.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [31631.3125]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 143us/step - loss: 15549.8125\n",
      "rewards:  -26.0 q-value:  0\n",
      "loss: [15549.8125]\n",
      "Exploring\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 144us/step - loss: 25597.7500\n",
      "rewards:  6.0 q-value:  0\n",
      "loss: [25597.75]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 118us/step - loss: 27975.0625\n",
      "rewards:  3.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [27975.0625]\n",
      "Exploring\n",
      "Selected action  [4 2]\n",
      "[4 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 109us/step - loss: 34818.9062\n",
      "rewards:  3.0 q-value:  0\n",
      "loss: [34818.90625]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 113us/step - loss: 21620.0000\n",
      "rewards:  11.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [21620.0]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 102us/step - loss: 18589.0938\n",
      "rewards:  11.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [18589.09375]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 99us/step - loss: 19258.4688\n",
      "rewards:  11.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [19258.46875]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 180us/step - loss: 27873.5938\n",
      "rewards:  6.0 q-value:  0\n",
      "loss: [27873.59375]\n",
      "Exploring\n",
      "Selected action  [4 2]\n",
      "[4 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 224us/step - loss: 24383.7812\n",
      "rewards:  1.0 q-value:  0\n",
      "loss: [24383.78125]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 138us/step - loss: 24452.9375\n",
      "rewards:  -34.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [24452.9375]\n",
      "Exploring\n",
      "Selected action  [3 1]\n",
      "[3 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 124us/step - loss: 19102.9375\n",
      "rewards:  -38.0 q-value:  0\n",
      "loss: [19102.9375]\n",
      "Exploring\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 133us/step - loss: 25087.4688\n",
      "rewards:  -65.0 q-value:  0\n",
      "loss: [25087.46875]\n",
      "Exploring\n",
      "Selected action  [1 2]\n",
      "[1 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 123us/step - loss: 28422.5625\n",
      "rewards:  -77.0 q-value:  0\n",
      "loss: [28422.5625]\n",
      "Exploring\n",
      "Selected action  [4 2]\n",
      "[4 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 113us/step - loss: 32365.2500\n",
      "rewards:  -77.0 q-value:  0\n",
      "loss: [32365.25]\n",
      "Exploring\n",
      "Selected action  [1 2]\n",
      "[1 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 156us/step - loss: 32401.7188\n",
      "rewards:  -79.0 q-value:  0\n",
      "loss: [32401.71875]\n",
      "Exploring\n",
      "Selected action  [0 4]\n",
      "[0 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 115us/step - loss: 24249.2500\n",
      "rewards:  -100.0 q-value:  0\n",
      "loss: [24249.25]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 144us/step - loss: 17229.6250\n",
      "rewards:  -89.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [17229.625]\n",
      "Exploring\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 124us/step - loss: 7990.8125\n",
      "rewards:  -93.0 q-value:  0\n",
      "loss: [7990.8125]\n",
      "Exploring\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 166us/step - loss: 28073.3750\n",
      "rewards:  -99.0 q-value:  0\n",
      "loss: [28073.375]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 141us/step - loss: 31433.7500\n",
      "rewards:  -105.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [31433.75]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 105us/step - loss: 17434.9688\n",
      "rewards:  -107.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [17434.96875]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 146us/step - loss: 20510.9688\n",
      "rewards:  -112.0 q-value:  0\n",
      "loss: [20510.96875]\n",
      "Exploring\n",
      "Selected action  [1 2]\n",
      "[1 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 107us/step - loss: 20200.9688\n",
      "rewards:  -114.0 q-value:  0\n",
      "loss: [20200.96875]\n",
      "Exploring\n",
      "Selected action  [4 2]\n",
      "[4 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 119us/step - loss: 27688.0938\n",
      "rewards:  -116.0 q-value:  0\n",
      "loss: [27688.09375]\n",
      "Exploring\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 100us/step - loss: 27264.0000\n",
      "rewards:  -96.0 q-value:  0\n",
      "loss: [27264.0]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 106us/step - loss: 22348.8125\n",
      "rewards:  -88.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [22348.8125]\n",
      "Exploring\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 103us/step - loss: 18377.7500\n",
      "rewards:  -90.0 q-value:  0\n",
      "loss: [18377.75]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 135us/step - loss: 35145.1562\n",
      "rewards:  -99.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [35145.15625]\n",
      "Exploring\n",
      "Selected action  [1 2]\n",
      "[1 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 102us/step - loss: 21517.1875\n",
      "rewards:  -95.0 q-value:  0\n",
      "loss: [21517.1875]\n",
      "Exploring\n",
      "Selected action  [4 2]\n",
      "[4 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 128us/step - loss: 33174.2188\n",
      "rewards:  -97.0 q-value:  0\n",
      "loss: [33174.21875]\n",
      "Exploring\n",
      "Selected action  [4 2]\n",
      "[4 2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 100us/step - loss: 38699.5000\n",
      "rewards:  -97.0 q-value:  0\n",
      "loss: [38699.5]\n",
      "Exploring\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 121us/step - loss: 17354.0000\n",
      "rewards:  -119.0 q-value:  0\n",
      "loss: [17354.0]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 207us/step - loss: 19683.5312\n",
      "rewards:  -121.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [19683.53125]\n",
      "Exploring\n",
      "Selected action  [3 1]\n",
      "[3 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 108us/step - loss: 30842.1562\n",
      "rewards:  -122.0 q-value:  0\n",
      "loss: [30842.15625]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 102us/step - loss: 25128.8125\n",
      "rewards:  -127.0 q-value:  0\n",
      "loss: [25128.8125]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 159us/step - loss: 30382.2812\n",
      "rewards:  -119.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [30382.28125]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 128us/step - loss: 13589.9688\n",
      "rewards:  -122.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [13589.96875]\n",
      "Exploring\n",
      "Selected action  [0 4]\n",
      "[0 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 147us/step - loss: 21627.1250\n",
      "rewards:  -133.0 q-value:  0\n",
      "loss: [21627.125]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 89us/step - loss: 23614.6875\n",
      "rewards:  -126.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [23614.6875]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 105us/step - loss: 20531.9375\n",
      "rewards:  -133.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [20531.9375]\n",
      "Exploring\n",
      "Selected action  [4 2]\n",
      "[4 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 122us/step - loss: 18582.3125\n",
      "rewards:  -129.0 q-value:  0\n",
      "loss: [18582.3125]\n",
      "Exploring\n",
      "Selected action  [4 2]\n",
      "[4 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 183us/step - loss: 17096.2812\n",
      "rewards:  -130.0 q-value:  0\n",
      "loss: [17096.28125]\n",
      "Exploring\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 107us/step - loss: 24640.7188\n",
      "rewards:  -118.0 q-value:  0\n",
      "loss: [24640.71875]\n",
      "Exploring\n",
      "Selected action  [0 4]\n",
      "[0 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 115us/step - loss: 22120.1250\n",
      "rewards:  -102.0 q-value:  0\n",
      "loss: [22120.125]\n",
      "Exploring\n",
      "Selected action  [1 2]\n",
      "[1 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 122us/step - loss: 14499.2500\n",
      "rewards:  -102.0 q-value:  0\n",
      "loss: [14499.25]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 129us/step - loss: 27957.0312\n",
      "rewards:  -115.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [27957.03125]\n",
      "Exploring\n",
      "Selected action  [3 1]\n",
      "[3 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 97us/step - loss: 19169.9375\n",
      "rewards:  -117.0 q-value:  0\n",
      "loss: [19169.9375]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 134us/step - loss: 16371.5625\n",
      "rewards:  -126.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [16371.5625]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 166us/step - loss: 27355.4062\n",
      "rewards:  -132.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [27355.40625]\n",
      "Exploring\n",
      "Selected action  [1 2]\n",
      "[1 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 134us/step - loss: 20188.6250\n",
      "rewards:  -104.0 q-value:  0\n",
      "loss: [20188.625]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 125us/step - loss: 20506.8438\n",
      "rewards:  -106.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [20506.84375]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 105us/step - loss: 36352.3750\n",
      "rewards:  -111.0 q-value:  0\n",
      "loss: [36352.375]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 126us/step - loss: 19006.8125\n",
      "rewards:  -95.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [19006.8125]\n",
      "Exploring\n",
      "Selected action  [1 2]\n",
      "[1 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 195us/step - loss: 24430.5938\n",
      "rewards:  -63.0 q-value:  0\n",
      "loss: [24430.59375]\n",
      "Exploring\n",
      "Selected action  [1 2]\n",
      "[1 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 149us/step - loss: 17148.2812\n",
      "rewards:  -70.0 q-value:  0\n",
      "loss: [17148.28125]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 151us/step - loss: 21916.4688\n",
      "rewards:  -63.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [21916.46875]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 113us/step - loss: 21001.8750\n",
      "rewards:  -68.0 q-value:  0\n",
      "loss: [21001.875]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 158us/step - loss: 8442.6250\n",
      "rewards:  -40.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [8442.625]\n",
      "Exploring\n",
      "Selected action  [4 0]\n",
      "[4 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 137us/step - loss: 15879.7188\n",
      "rewards:  -41.0 q-value:  0\n",
      "loss: [15879.71875]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 106us/step - loss: 25607.8750\n",
      "rewards:  -41.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [25607.875]\n",
      "Exploring\n",
      "Selected action  [4 0]\n",
      "[4 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 120us/step - loss: 35403.4688\n",
      "rewards:  -42.0 q-value:  0\n",
      "loss: [35403.46875]\n",
      "Exploring\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 136us/step - loss: 31259.3750\n",
      "rewards:  -49.0 q-value:  0\n",
      "loss: [31259.375]\n",
      "Exploring\n",
      "Selected action  [3 1]\n",
      "[3 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 98us/step - loss: 27739.9688\n",
      "rewards:  -63.0 q-value:  0\n",
      "loss: [27739.96875]\n",
      "Exploring\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 113us/step - loss: 21527.5312\n",
      "rewards:  -67.0 q-value:  0\n",
      "loss: [21527.53125]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 147us/step - loss: 33508.3438\n",
      "rewards:  -72.0 q-value:  0\n",
      "loss: [33508.34375]\n",
      "Exploring\n",
      "Selected action  [4 0]\n",
      "[4 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 148us/step - loss: 23721.7188\n",
      "rewards:  -73.0 q-value:  0\n",
      "loss: [23721.71875]\n",
      "Exploring\n",
      "Selected action  [3 1]\n",
      "[3 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 111us/step - loss: 26613.9688\n",
      "rewards:  -80.0 q-value:  0\n",
      "loss: [26613.96875]\n",
      "Exploring\n",
      "Selected action  [3 1]\n",
      "[3 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 125us/step - loss: 21154.6562\n",
      "rewards:  -82.0 q-value:  0\n",
      "loss: [21154.65625]\n",
      "Exploring\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 105us/step - loss: 19848.9375\n",
      "rewards:  -92.0 q-value:  0\n",
      "loss: [19848.9375]\n",
      "Exploring\n",
      "Selected action  [0 4]\n",
      "[0 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 123us/step - loss: 18137.6875\n",
      "rewards:  -88.0 q-value:  0\n",
      "loss: [18137.6875]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 162us/step - loss: 17528.0312\n",
      "rewards:  -69.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [17528.03125]\n",
      "Exploring\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 101us/step - loss: 20282.4375\n",
      "rewards:  -75.0 q-value:  0\n",
      "loss: [20282.4375]\n",
      "Exploring\n",
      "Selected action  [0 4]\n",
      "[0 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 108us/step - loss: 19331.6562\n",
      "rewards:  -81.0 q-value:  0\n",
      "loss: [19331.65625]\n",
      "Exploring\n",
      "Selected action  [4 2]\n",
      "[4 2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 101us/step - loss: 27615.3438\n",
      "rewards:  -73.0 q-value:  0\n",
      "loss: [27615.34375]\n",
      "Exploring\n",
      "Selected action  [1 2]\n",
      "[1 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 136us/step - loss: 26161.3750\n",
      "rewards:  -81.0 q-value:  0\n",
      "loss: [26161.375]\n",
      "Exploring\n",
      "Selected action  [4 2]\n",
      "[4 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 94us/step - loss: 35912.3125\n",
      "rewards:  -82.0 q-value:  0\n",
      "loss: [35912.3125]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 106us/step - loss: 46019.7188\n",
      "rewards:  -84.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [46019.71875]\n",
      "Exploring\n",
      "Selected action  [4 0]\n",
      "[4 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 138us/step - loss: 21234.4688\n",
      "rewards:  -95.0 q-value:  0\n",
      "loss: [21234.46875]\n",
      "Exploring\n",
      "Selected action  [0 4]\n",
      "[0 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 129us/step - loss: 31476.9688\n",
      "rewards:  -91.0 q-value:  0\n",
      "loss: [31476.96875]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 121us/step - loss: 31106.0000\n",
      "rewards:  -60.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [31106.0]\n",
      "Exploring\n",
      "Selected action  [1 2]\n",
      "[1 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 103us/step - loss: 35187.3125\n",
      "rewards:  -40.0 q-value:  0\n",
      "loss: [35187.3125]\n",
      "Number of actions available 4\n",
      "Episode : 44\n",
      "Exploring\n",
      "Selected action  [4 2]\n",
      "[4 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 118us/step - loss: 26833.6250\n",
      "rewards:  10.0 q-value:  0\n",
      "loss: [26833.625]\n",
      "Exploring\n",
      "Selected action  [3 4]\n",
      "[3 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 140us/step - loss: 24619.0312\n",
      "rewards:  8.0 q-value:  0\n",
      "loss: [24619.03125]\n",
      "Exploring\n",
      "Selected action  [3 4]\n",
      "[3 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 102us/step - loss: 26938.5312\n",
      "rewards:  5.0 q-value:  0\n",
      "loss: [26938.53125]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 116us/step - loss: 30093.0312\n",
      "rewards:  0.0 q-value:  0\n",
      "loss: [30093.03125]\n",
      "Exploiting\n",
      "Selected action  [3 4]\n",
      "[3 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 108us/step - loss: 40689.1875\n",
      "rewards:  -3.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [40689.1875]\n",
      "Exploiting\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 89us/step - loss: 24414.7500\n",
      "rewards:  -8.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [24414.75]\n",
      "Exploiting\n",
      "Selected action  [4 2]\n",
      "[4 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 118us/step - loss: 14234.0312\n",
      "rewards:  -40.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [14234.03125]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 102us/step - loss: 29088.3438\n",
      "rewards:  -45.0 q-value:  0\n",
      "loss: [29088.34375]\n",
      "Exploiting\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 121us/step - loss: 20704.5625\n",
      "rewards:  -50.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [20704.5625]\n",
      "Exploring\n",
      "Selected action  [3 4]\n",
      "[3 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 169us/step - loss: 40546.7812\n",
      "rewards:  -92.0 q-value:  0\n",
      "loss: [40546.78125]\n",
      "Exploiting\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 106us/step - loss: 18485.3438\n",
      "rewards:  -98.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [18485.34375]\n",
      "Exploring\n",
      "Selected action  [4 2]\n",
      "[4 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 120us/step - loss: 15104.0625\n",
      "rewards:  -105.0 q-value:  0\n",
      "loss: [15104.0625]\n",
      "Exploring\n",
      "Selected action  [4 2]\n",
      "[4 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 107us/step - loss: 20554.2188\n",
      "rewards:  -107.0 q-value:  0\n",
      "loss: [20554.21875]\n",
      "Exploring\n",
      "Selected action  [4 2]\n",
      "[4 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 175us/step - loss: 36063.4375\n",
      "rewards:  -109.0 q-value:  0\n",
      "loss: [36063.4375]\n",
      "Exploring\n",
      "Selected action  [3 4]\n",
      "[3 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 116us/step - loss: 27094.7500\n",
      "rewards:  -104.0 q-value:  0\n",
      "loss: [27094.75]\n",
      "Exploiting\n",
      "Selected action  [3 4]\n",
      "[3 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 129us/step - loss: 22705.9375\n",
      "rewards:  -109.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [22705.9375]\n",
      "Exploring\n",
      "Selected action  [4 2]\n",
      "[4 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 126us/step - loss: 13809.5312\n",
      "rewards:  -109.0 q-value:  0\n",
      "loss: [13809.53125]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 105us/step - loss: 21392.0312\n",
      "rewards:  -114.0 q-value:  0\n",
      "loss: [21392.03125]\n",
      "Exploiting\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 122us/step - loss: 21412.5938\n",
      "rewards:  -120.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [21412.59375]\n",
      "Exploring\n",
      "Selected action  [4 2]\n",
      "[4 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 92us/step - loss: 20998.3750\n",
      "rewards:  -105.0 q-value:  0\n",
      "loss: [20998.375]\n",
      "Exploiting\n",
      "Selected action  [4 2]\n",
      "[4 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 105us/step - loss: 24872.9062\n",
      "rewards:  -106.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [24872.90625]\n",
      "Exploring\n",
      "Selected action  [4 2]\n",
      "[4 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 136us/step - loss: 17866.0625\n",
      "rewards:  -107.0 q-value:  0\n",
      "loss: [17866.0625]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 116us/step - loss: 23251.5000\n",
      "rewards:  -112.0 q-value:  0\n",
      "loss: [23251.5]\n",
      "Exploring\n",
      "Selected action  [4 2]\n",
      "[4 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 135us/step - loss: 26243.0000\n",
      "rewards:  -113.0 q-value:  0\n",
      "loss: [26243.0]\n",
      "Exploring\n",
      "Selected action  [4 2]\n",
      "[4 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 112us/step - loss: 29393.5000\n",
      "rewards:  -115.0 q-value:  0\n",
      "loss: [29393.5]\n",
      "Exploring\n",
      "Selected action  [3 4]\n",
      "[3 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 135us/step - loss: 18221.5938\n",
      "rewards:  -127.0 q-value:  0\n",
      "loss: [18221.59375]\n",
      "Exploiting\n",
      "Selected action  [4 2]\n",
      "[4 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 120us/step - loss: 15811.2500\n",
      "rewards:  -119.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [15811.25]\n",
      "Exploiting\n",
      "Selected action  [4 2]\n",
      "[4 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 110us/step - loss: 26972.5625\n",
      "rewards:  -120.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [26972.5625]\n",
      "Exploiting\n",
      "Selected action  [3 4]\n",
      "[3 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 112us/step - loss: 15721.0000\n",
      "rewards:  -131.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [15721.0]\n",
      "Exploring\n",
      "Selected action  [3 4]\n",
      "[3 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 127us/step - loss: 25687.2812\n",
      "rewards:  -132.0 q-value:  0\n",
      "loss: [25687.28125]\n",
      "Exploring\n",
      "Selected action  [3 4]\n",
      "[3 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 127us/step - loss: 21373.5938\n",
      "rewards:  -133.0 q-value:  0\n",
      "loss: [21373.59375]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 116us/step - loss: 14395.2188\n",
      "rewards:  -138.0 q-value:  0\n",
      "loss: [14395.21875]\n",
      "Exploiting\n",
      "Selected action  [4 2]\n",
      "[4 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 149us/step - loss: 7102.7500\n",
      "rewards:  -139.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [7102.75]\n",
      "Exploiting\n",
      "Selected action  [3 4]\n",
      "[3 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 137us/step - loss: 22873.7500\n",
      "rewards:  -150.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [22873.75]\n",
      "Exploring\n",
      "Selected action  [3 4]\n",
      "[3 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 136us/step - loss: 10518.4688\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rewards:  -156.0 q-value:  0\n",
      "loss: [10518.46875]\n",
      "Exploiting\n",
      "Selected action  [3 4]\n",
      "[3 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 113us/step - loss: 18490.9062\n",
      "rewards:  -162.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [18490.90625]\n",
      "Exploiting\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 96us/step - loss: 12918.7812\n",
      "rewards:  -140.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [12918.78125]\n",
      "Exploring\n",
      "Selected action  [3 4]\n",
      "[3 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 98us/step - loss: 36536.1250\n",
      "rewards:  -157.0 q-value:  0\n",
      "loss: [36536.125]\n",
      "Exploring\n",
      "Selected action  [4 2]\n",
      "[4 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 95us/step - loss: 15324.3438\n",
      "rewards:  -149.0 q-value:  0\n",
      "loss: [15324.34375]\n",
      "Exploiting\n",
      "Selected action  [4 2]\n",
      "[4 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 96us/step - loss: 18673.2188\n",
      "rewards:  -154.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [18673.21875]\n",
      "Exploring\n",
      "Selected action  [4 2]\n",
      "[4 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 120us/step - loss: 20338.1562\n",
      "rewards:  -159.0 q-value:  0\n",
      "loss: [20338.15625]\n",
      "Exploiting\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 110us/step - loss: 18467.8125\n",
      "rewards:  -151.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [18467.8125]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 114us/step - loss: 23253.7812\n",
      "rewards:  -156.0 q-value:  0\n",
      "loss: [23253.78125]\n",
      "Exploring\n",
      "Selected action  [4 2]\n",
      "[4 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 128us/step - loss: 16489.0312\n",
      "rewards:  -186.0 q-value:  0\n",
      "loss: [16489.03125]\n",
      "Exploiting\n",
      "Selected action  [4 2]\n",
      "[4 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 132us/step - loss: 20667.2812\n",
      "rewards:  -186.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [20667.28125]\n",
      "Exploring\n",
      "Selected action  [4 2]\n",
      "[4 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 112us/step - loss: 14691.2500\n",
      "rewards:  -186.0 q-value:  0\n",
      "loss: [14691.25]\n",
      "Exploiting\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 113us/step - loss: 27113.5938\n",
      "rewards:  -191.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [27113.59375]\n",
      "Exploring\n",
      "Selected action  [3 4]\n",
      "[3 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 103us/step - loss: 22533.0000\n",
      "rewards:  -182.0 q-value:  0\n",
      "loss: [22533.0]\n",
      "Exploiting\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 156us/step - loss: 15639.1250\n",
      "rewards:  -175.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [15639.125]\n",
      "Exploring\n",
      "Selected action  [3 4]\n",
      "[3 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 121us/step - loss: 17329.8125\n",
      "rewards:  -198.0 q-value:  0\n",
      "loss: [17329.8125]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 101us/step - loss: 25211.4375\n",
      "rewards:  -203.0 q-value:  0\n",
      "loss: [25211.4375]\n",
      "Exploiting\n",
      "Selected action  [4 2]\n",
      "[4 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 121us/step - loss: 21001.3125\n",
      "rewards:  -171.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [21001.3125]\n",
      "Exploring\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 134us/step - loss: 14236.9688\n",
      "rewards:  -159.0 q-value:  0\n",
      "loss: [14236.96875]\n",
      "Exploring\n",
      "Selected action  [3 4]\n",
      "[3 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 119us/step - loss: 13060.2812\n",
      "rewards:  -154.0 q-value:  0\n",
      "loss: [13060.28125]\n",
      "Exploring\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 117us/step - loss: 22687.7812\n",
      "rewards:  -138.0 q-value:  0\n",
      "loss: [22687.78125]\n",
      "Exploiting\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 134us/step - loss: 20455.3438\n",
      "rewards:  -145.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [20455.34375]\n",
      "Exploring\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 100us/step - loss: 16017.9688\n",
      "rewards:  -152.0 q-value:  0\n",
      "loss: [16017.96875]\n",
      "Exploring\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 144us/step - loss: 15527.0625\n",
      "rewards:  -156.0 q-value:  0\n",
      "loss: [15527.0625]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 127us/step - loss: 9767.5625\n",
      "rewards:  -161.0 q-value:  0\n",
      "loss: [9767.5625]\n",
      "Exploring\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 115us/step - loss: 16769.9062\n",
      "rewards:  -166.0 q-value:  0\n",
      "loss: [16769.90625]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 141us/step - loss: 13879.8438\n",
      "rewards:  -171.0 q-value:  0\n",
      "loss: [13879.84375]\n",
      "Exploiting\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 95us/step - loss: 25623.2188\n",
      "rewards:  -178.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [25623.21875]\n",
      "Exploiting\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 95us/step - loss: 24632.4375\n",
      "rewards:  -183.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [24632.4375]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 129us/step - loss: 31132.6875\n",
      "rewards:  -188.0 q-value:  0\n",
      "loss: [31132.6875]\n",
      "Exploring\n",
      "Selected action  [3 4]\n",
      "[3 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 123us/step - loss: 39161.2188\n",
      "rewards:  -175.0 q-value:  0\n",
      "loss: [39161.21875]\n",
      "Exploiting\n",
      "Selected action  [3 4]\n",
      "[3 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 157us/step - loss: 11235.7188\n",
      "rewards:  -178.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [11235.71875]\n",
      "Exploiting\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 109us/step - loss: 27640.1562\n",
      "rewards:  -168.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [27640.15625]\n",
      "Exploring\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 108us/step - loss: 27227.5938\n",
      "rewards:  -173.0 q-value:  0\n",
      "loss: [27227.59375]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 110us/step - loss: 16668.9375\n",
      "rewards:  -178.0 q-value:  0\n",
      "loss: [16668.9375]\n",
      "Exploring\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 111us/step - loss: 13412.7188\n",
      "rewards:  -180.0 q-value:  0\n",
      "loss: [13412.71875]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 89us/step - loss: 14966.3438\n",
      "rewards:  -185.0 q-value:  0\n",
      "loss: [14966.34375]\n",
      "Exploiting\n",
      "Selected action  [3 4]\n",
      "[3 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 123us/step - loss: 26520.5000\n",
      "rewards:  -172.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [26520.5]\n",
      "Exploiting\n",
      "Selected action  [3 4]\n",
      "[3 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 112us/step - loss: 19884.6250\n",
      "rewards:  -181.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [19884.625]\n",
      "Exploiting\n",
      "Selected action  [3 4]\n",
      "[3 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 116us/step - loss: 17760.3438\n",
      "rewards:  -186.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [17760.34375]\n",
      "Exploring\n",
      "Selected action  [3 4]\n",
      "[3 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 120us/step - loss: 15393.3750\n",
      "rewards:  -191.0 q-value:  0\n",
      "loss: [15393.375]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 99us/step - loss: 22054.7812\n",
      "rewards:  -196.0 q-value:  0\n",
      "loss: [22054.78125]\n",
      "Exploring\n",
      "Selected action  [3 4]\n",
      "[3 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 98us/step - loss: 15629.2812\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rewards:  -183.0 q-value:  0\n",
      "loss: [15629.28125]\n",
      "Exploiting\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 146us/step - loss: 20984.3438\n",
      "rewards:  -176.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [20984.34375]\n",
      "Exploring\n",
      "Selected action  [3 4]\n",
      "[3 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 124us/step - loss: 21914.2188\n",
      "rewards:  -173.0 q-value:  0\n",
      "loss: [21914.21875]\n",
      "Exploring\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 83us/step - loss: 19151.5312\n",
      "rewards:  -175.0 q-value:  0\n",
      "loss: [19151.53125]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 115us/step - loss: 12349.7500\n",
      "rewards:  -180.0 q-value:  0\n",
      "loss: [12349.75]\n",
      "Exploring\n",
      "Selected action  [4 2]\n",
      "[4 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 96us/step - loss: 14537.0312\n",
      "rewards:  -192.0 q-value:  0\n",
      "loss: [14537.03125]\n",
      "Exploring\n",
      "Selected action  [3 4]\n",
      "[3 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 132us/step - loss: 18160.9375\n",
      "rewards:  -203.0 q-value:  0\n",
      "loss: [18160.9375]\n",
      "Exploring\n",
      "Selected action  [3 4]\n",
      "[3 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 184us/step - loss: 32679.6562\n",
      "rewards:  -204.0 q-value:  0\n",
      "loss: [32679.65625]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 128us/step - loss: 22260.6562\n",
      "rewards:  -209.0 q-value:  0\n",
      "loss: [22260.65625]\n",
      "Exploring\n",
      "Selected action  [4 2]\n",
      "[4 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 134us/step - loss: 13274.3438\n",
      "rewards:  -210.0 q-value:  0\n",
      "loss: [13274.34375]\n",
      "Exploiting\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 149us/step - loss: 26263.8125\n",
      "rewards:  -190.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [26263.8125]\n",
      "Exploring\n",
      "Selected action  [3 4]\n",
      "[3 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 108us/step - loss: 13751.4688\n",
      "rewards:  -206.0 q-value:  0\n",
      "loss: [13751.46875]\n",
      "Exploring\n",
      "Selected action  [3 4]\n",
      "[3 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 143us/step - loss: 16004.0625\n",
      "rewards:  -212.0 q-value:  0\n",
      "loss: [16004.0625]\n",
      "Exploring\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 103us/step - loss: 14633.6875\n",
      "rewards:  -190.0 q-value:  0\n",
      "loss: [14633.6875]\n",
      "Exploring\n",
      "Selected action  [4 2]\n",
      "[4 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 122us/step - loss: 11094.6250\n",
      "rewards:  -182.0 q-value:  0\n",
      "loss: [11094.625]\n",
      "Exploiting\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 159us/step - loss: 21364.0938\n",
      "rewards:  -158.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [21364.09375]\n",
      "Exploiting\n",
      "Selected action  [4 2]\n",
      "[4 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 120us/step - loss: 19562.7500\n",
      "rewards:  -154.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [19562.75]\n",
      "Exploiting\n",
      "Selected action  [3 4]\n",
      "[3 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 120us/step - loss: 12581.9375\n",
      "rewards:  -160.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [12581.9375]\n",
      "Exploring\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 95us/step - loss: 18127.4375\n",
      "rewards:  -140.0 q-value:  0\n",
      "loss: [18127.4375]\n",
      "Exploring\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 135us/step - loss: 22724.3438\n",
      "rewards:  -143.0 q-value:  0\n",
      "loss: [22724.34375]\n",
      "Exploiting\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 126us/step - loss: 24545.1875\n",
      "rewards:  -146.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [24545.1875]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 105us/step - loss: 16920.4688\n",
      "rewards:  -151.0 q-value:  0\n",
      "loss: [16920.46875]\n",
      "Exploring\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 139us/step - loss: 14147.2188\n",
      "rewards:  -156.0 q-value:  0\n",
      "loss: [14147.21875]\n",
      "Exploring\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 116us/step - loss: 10541.2188\n",
      "rewards:  -161.0 q-value:  0\n",
      "loss: [10541.21875]\n",
      "Exploring\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 149us/step - loss: 15769.4688\n",
      "rewards:  -164.0 q-value:  0\n",
      "loss: [15769.46875]\n",
      "Exploring\n",
      "Selected action  [3 4]\n",
      "[3 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 109us/step - loss: 17218.9375\n",
      "rewards:  -153.0 q-value:  0\n",
      "loss: [17218.9375]\n",
      "Exploiting\n",
      "Selected action  [3 4]\n",
      "[3 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 122us/step - loss: 11877.9375\n",
      "rewards:  -157.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [11877.9375]\n",
      "Exploiting\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 105us/step - loss: 18145.2812\n",
      "rewards:  -162.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [18145.28125]\n",
      "Exploring\n",
      "Selected action  [4 2]\n",
      "[4 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 90us/step - loss: 19491.6250\n",
      "rewards:  -167.0 q-value:  0\n",
      "loss: [19491.625]\n",
      "Exploiting\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 167us/step - loss: 15817.7500\n",
      "rewards:  -139.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [15817.75]\n",
      "Exploring\n",
      "Selected action  [4 2]\n",
      "[4 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 109us/step - loss: 13853.3125\n",
      "rewards:  -107.0 q-value:  0\n",
      "loss: [13853.3125]\n",
      "Exploring\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 118us/step - loss: 20446.7500\n",
      "rewards:  -87.0 q-value:  0\n",
      "loss: [20446.75]\n",
      "Exploring\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 130us/step - loss: 10710.5625\n",
      "rewards:  -92.0 q-value:  0\n",
      "loss: [10710.5625]\n",
      "Exploiting\n",
      "Selected action  [4 2]\n",
      "[4 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 188us/step - loss: 18704.7188\n",
      "rewards:  -77.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [18704.71875]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 154us/step - loss: 20321.0625\n",
      "rewards:  -82.0 q-value:  0\n",
      "loss: [20321.0625]\n",
      "Exploring\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 112us/step - loss: 32784.8750\n",
      "rewards:  -88.0 q-value:  0\n",
      "loss: [32784.875]\n",
      "Exploring\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 100us/step - loss: 13083.7812\n",
      "rewards:  -91.0 q-value:  0\n",
      "loss: [13083.78125]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 132us/step - loss: 18892.7188\n",
      "rewards:  -96.0 q-value:  0\n",
      "loss: [18892.71875]\n",
      "Exploiting\n",
      "Selected action  [3 4]\n",
      "[3 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 146us/step - loss: 19049.6875\n",
      "rewards:  -99.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [19049.6875]\n",
      "Exploiting\n",
      "Selected action  [4 2]\n",
      "[4 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 127us/step - loss: 24661.5000\n",
      "rewards:  -91.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [24661.5]\n",
      "Exploiting\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 137us/step - loss: 24459.6875\n",
      "rewards:  -71.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [24459.6875]\n",
      "Exploiting\n",
      "Selected action  [3 4]\n",
      "[3 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 138us/step - loss: 18398.0312\n",
      "rewards:  -113.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [18398.03125]\n",
      "Exploiting\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 112us/step - loss: 19649.7500\n",
      "rewards:  -118.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [19649.75]\n",
      "Exploiting\n",
      "Selected action  [0 0]\n",
      "[0 0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 137us/step - loss: 7025.0312\n",
      "rewards:  -123.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [7025.03125]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 152us/step - loss: 19173.4062\n",
      "rewards:  -128.0 q-value:  0\n",
      "loss: [19173.40625]\n",
      "Exploring\n",
      "Selected action  [3 4]\n",
      "[3 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 99us/step - loss: 20900.9375\n",
      "rewards:  -115.0 q-value:  0\n",
      "loss: [20900.9375]\n",
      "Exploring\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 135us/step - loss: 19044.9062\n",
      "rewards:  -117.0 q-value:  0\n",
      "loss: [19044.90625]\n",
      "Exploring\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 109us/step - loss: 9047.4375\n",
      "rewards:  -119.0 q-value:  0\n",
      "loss: [9047.4375]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 132us/step - loss: 9155.2812\n",
      "rewards:  -124.0 q-value:  0\n",
      "loss: [9155.28125]\n",
      "Exploring\n",
      "Selected action  [3 4]\n",
      "[3 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 141us/step - loss: 17945.9375\n",
      "rewards:  -98.0 q-value:  0\n",
      "loss: [17945.9375]\n",
      "Number of actions available 9\n",
      "Episode : 45\n",
      "Exploring\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 133us/step - loss: 31071.2500\n",
      "rewards:  -4.0 q-value:  0\n",
      "loss: [31071.25]\n",
      "Exploring\n",
      "Selected action  [1 4]\n",
      "[1 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 118us/step - loss: 14299.4688\n",
      "rewards:  4.0 q-value:  0\n",
      "loss: [14299.46875]\n",
      "Exploring\n",
      "Selected action  [0 3]\n",
      "[0 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 106us/step - loss: 16762.5312\n",
      "rewards:  -1.0 q-value:  0\n",
      "loss: [16762.53125]\n",
      "Exploring\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 120us/step - loss: 25249.8125\n",
      "rewards:  -29.0 q-value:  0\n",
      "loss: [25249.8125]\n",
      "Exploring\n",
      "Selected action  [3 1]\n",
      "[3 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 95us/step - loss: 8463.9688\n",
      "rewards:  -29.0 q-value:  0\n",
      "loss: [8463.96875]\n",
      "Exploiting\n",
      "Selected action  [3 1]\n",
      "[3 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 129us/step - loss: 16830.6250\n",
      "rewards:  -29.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [16830.625]\n",
      "Exploring\n",
      "Selected action  [3 1]\n",
      "[3 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 145us/step - loss: 19246.8438\n",
      "rewards:  -29.0 q-value:  0\n",
      "loss: [19246.84375]\n",
      "Exploiting\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 118us/step - loss: 20347.5625\n",
      "rewards:  -29.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [20347.5625]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 86us/step - loss: 13433.7812\n",
      "rewards:  -21.0 q-value:  0\n",
      "loss: [13433.78125]\n",
      "Exploiting\n",
      "Selected action  [3 1]\n",
      "[3 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 137us/step - loss: 14491.2812\n",
      "rewards:  -36.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [14491.28125]\n",
      "Exploiting\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 167us/step - loss: 16576.7812\n",
      "rewards:  -41.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [16576.78125]\n",
      "Exploring\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 167us/step - loss: 15864.3750\n",
      "rewards:  -46.0 q-value:  0\n",
      "loss: [15864.375]\n",
      "Exploring\n",
      "Selected action  [1 4]\n",
      "[1 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 90us/step - loss: 11674.5625\n",
      "rewards:  -40.0 q-value:  0\n",
      "loss: [11674.5625]\n",
      "Exploring\n",
      "Selected action  [0 3]\n",
      "[0 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 117us/step - loss: 16527.4062\n",
      "rewards:  -5.0 q-value:  0\n",
      "loss: [16527.40625]\n",
      "Exploring\n",
      "Selected action  [0 2]\n",
      "[0 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 124us/step - loss: 25660.0000\n",
      "rewards:  -7.0 q-value:  0\n",
      "loss: [25660.0]\n",
      "Exploring\n",
      "Selected action  [0 3]\n",
      "[0 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 183us/step - loss: 20442.0625\n",
      "rewards:  -9.0 q-value:  0\n",
      "loss: [20442.0625]\n",
      "Exploring\n",
      "Selected action  [0 3]\n",
      "[0 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 121us/step - loss: 15384.1875\n",
      "rewards:  -9.0 q-value:  0\n",
      "loss: [15384.1875]\n",
      "Exploring\n",
      "Selected action  [0 3]\n",
      "[0 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 125us/step - loss: 15694.5312\n",
      "rewards:  -9.0 q-value:  0\n",
      "loss: [15694.53125]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 105us/step - loss: 26052.5312\n",
      "rewards:  -14.0 q-value:  0\n",
      "loss: [26052.53125]\n",
      "Exploiting\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 135us/step - loss: 8874.5312\n",
      "rewards:  -20.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [8874.53125]\n",
      "Exploiting\n",
      "Selected action  [3 1]\n",
      "[3 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 142us/step - loss: 19399.2812\n",
      "rewards:  -16.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [19399.28125]\n",
      "Exploiting\n",
      "Selected action  [0 3]\n",
      "[0 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 128us/step - loss: 14582.0312\n",
      "rewards:  -26.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [14582.03125]\n",
      "Exploring\n",
      "Selected action  [2 3]\n",
      "[2 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 123us/step - loss: 8628.2500\n",
      "rewards:  -29.0 q-value:  0\n",
      "loss: [8628.25]\n",
      "Exploring\n",
      "Selected action  [0 2]\n",
      "[0 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 103us/step - loss: 17121.2812\n",
      "rewards:  -5.0 q-value:  0\n",
      "loss: [17121.28125]\n",
      "Exploiting\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 123us/step - loss: 12357.3438\n",
      "rewards:  -23.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [12357.34375]\n",
      "Exploiting\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 105us/step - loss: 20182.7500\n",
      "rewards:  -29.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [20182.75]\n",
      "Exploring\n",
      "Selected action  [2 3]\n",
      "[2 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 94us/step - loss: 15011.0000\n",
      "rewards:  -32.0 q-value:  0\n",
      "loss: [15011.0]\n",
      "Exploring\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 117us/step - loss: 14719.2188\n",
      "rewards:  -34.0 q-value:  0\n",
      "loss: [14719.21875]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 148us/step - loss: 26844.1250\n",
      "rewards:  -32.0 q-value:  0\n",
      "loss: [26844.125]\n",
      "Exploring\n",
      "Selected action  [1 4]\n",
      "[1 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 138us/step - loss: 22264.6875\n",
      "rewards:  -47.0 q-value:  0\n",
      "loss: [22264.6875]\n",
      "Exploiting\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 101us/step - loss: 15479.1875\n",
      "rewards:  -52.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [15479.1875]\n",
      "Exploring\n",
      "Selected action  [3 1]\n",
      "[3 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 154us/step - loss: 14406.9062\n",
      "rewards:  -49.0 q-value:  0\n",
      "loss: [14406.90625]\n",
      "Exploiting\n",
      "Selected action  [1 4]\n",
      "[1 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 148us/step - loss: 25647.5938\n",
      "rewards:  -33.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [25647.59375]\n",
      "Exploiting\n",
      "Selected action  [2 3]\n",
      "[2 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 118us/step - loss: 17893.7500\n",
      "rewards:  -26.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [17893.75]\n",
      "Exploring\n",
      "Selected action  [0 2]\n",
      "[0 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 146us/step - loss: 18830.2188\n",
      "rewards:  -42.0 q-value:  0\n",
      "loss: [18830.21875]\n",
      "Exploiting\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 146us/step - loss: 15903.6562\n",
      "rewards:  -47.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [15903.65625]\n",
      "Exploring\n",
      "Selected action  [1 4]\n",
      "[1 4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 115us/step - loss: 17317.5938\n",
      "rewards:  -77.0 q-value:  0\n",
      "loss: [17317.59375]\n",
      "Exploring\n",
      "Selected action  [3 1]\n",
      "[3 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 98us/step - loss: 26899.3438\n",
      "rewards:  -103.0 q-value:  0\n",
      "loss: [26899.34375]\n",
      "Exploring\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 119us/step - loss: 18327.4375\n",
      "rewards:  -104.0 q-value:  0\n",
      "loss: [18327.4375]\n",
      "Exploring\n",
      "Selected action  [3 1]\n",
      "[3 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 146us/step - loss: 12998.3125\n",
      "rewards:  -110.0 q-value:  0\n",
      "loss: [12998.3125]\n",
      "Exploring\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 110us/step - loss: 30510.2188\n",
      "rewards:  -106.0 q-value:  0\n",
      "loss: [30510.21875]\n",
      "Exploring\n",
      "Selected action  [0 3]\n",
      "[0 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 114us/step - loss: 18108.7812\n",
      "rewards:  -108.0 q-value:  0\n",
      "loss: [18108.78125]\n",
      "Exploiting\n",
      "Selected action  [0 3]\n",
      "[0 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 107us/step - loss: 11672.5000\n",
      "rewards:  -110.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [11672.5]\n",
      "Exploiting\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 132us/step - loss: 11809.4688\n",
      "rewards:  -98.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [11809.46875]\n",
      "Exploring\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 156us/step - loss: 15971.9375\n",
      "rewards:  -111.0 q-value:  0\n",
      "loss: [15971.9375]\n",
      "Exploring\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 224us/step - loss: 8381.5625\n",
      "rewards:  -114.0 q-value:  0\n",
      "loss: [8381.5625]\n",
      "Exploring\n",
      "Selected action  [0 2]\n",
      "[0 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 136us/step - loss: 12289.6875\n",
      "rewards:  -120.0 q-value:  0\n",
      "loss: [12289.6875]\n",
      "Exploring\n",
      "Selected action  [0 2]\n",
      "[0 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 141us/step - loss: 18945.5000\n",
      "rewards:  -122.0 q-value:  0\n",
      "loss: [18945.5]\n",
      "Exploring\n",
      "Selected action  [0 3]\n",
      "[0 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 122us/step - loss: 12448.8438\n",
      "rewards:  -135.0 q-value:  0\n",
      "loss: [12448.84375]\n",
      "Exploiting\n",
      "Selected action  [3 1]\n",
      "[3 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 158us/step - loss: 17433.0938\n",
      "rewards:  -131.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [17433.09375]\n",
      "Exploring\n",
      "Selected action  [0 3]\n",
      "[0 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 108us/step - loss: 20829.6250\n",
      "rewards:  -129.0 q-value:  0\n",
      "loss: [20829.625]\n",
      "Exploring\n",
      "Selected action  [0 3]\n",
      "[0 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 146us/step - loss: 19182.7188\n",
      "rewards:  -136.0 q-value:  0\n",
      "loss: [19182.71875]\n",
      "Exploring\n",
      "Selected action  [0 3]\n",
      "[0 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 182us/step - loss: 22464.1562\n",
      "rewards:  -137.0 q-value:  0\n",
      "loss: [22464.15625]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 168us/step - loss: 16427.6250\n",
      "rewards:  -120.0 q-value:  0\n",
      "loss: [16427.625]\n",
      "Exploring\n",
      "Selected action  [1 4]\n",
      "[1 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 141us/step - loss: 11822.3750\n",
      "rewards:  -155.0 q-value:  0\n",
      "loss: [11822.375]\n",
      "Exploring\n",
      "Selected action  [0 3]\n",
      "[0 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 132us/step - loss: 23484.3750\n",
      "rewards:  -166.0 q-value:  0\n",
      "loss: [23484.375]\n",
      "Exploiting\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 112us/step - loss: 14266.1875\n",
      "rewards:  -180.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [14266.1875]\n",
      "Exploring\n",
      "Selected action  [2 3]\n",
      "[2 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 123us/step - loss: 15966.1250\n",
      "rewards:  -176.0 q-value:  0\n",
      "loss: [15966.125]\n",
      "Exploiting\n",
      "Selected action  [3 1]\n",
      "[3 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 121us/step - loss: 18880.0000\n",
      "rewards:  -160.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [18880.0]\n",
      "Exploring\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 128us/step - loss: 21447.0938\n",
      "rewards:  -144.0 q-value:  0\n",
      "loss: [21447.09375]\n",
      "Exploiting\n",
      "Selected action  [1 4]\n",
      "[1 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 138us/step - loss: 23126.7812\n",
      "rewards:  -154.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [23126.78125]\n",
      "Exploiting\n",
      "Selected action  [0 2]\n",
      "[0 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 129us/step - loss: 23883.2188\n",
      "rewards:  -138.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [23883.21875]\n",
      "Exploiting\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 135us/step - loss: 17028.7812\n",
      "rewards:  -122.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [17028.78125]\n",
      "Exploring\n",
      "Selected action  [3 1]\n",
      "[3 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 120us/step - loss: 14839.5625\n",
      "rewards:  -129.0 q-value:  0\n",
      "loss: [14839.5625]\n",
      "Exploiting\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 123us/step - loss: 11222.5312\n",
      "rewards:  -113.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [11222.53125]\n",
      "Exploiting\n",
      "Selected action  [0 2]\n",
      "[0 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 117us/step - loss: 27174.4375\n",
      "rewards:  -85.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [27174.4375]\n",
      "Exploiting\n",
      "Selected action  [1 4]\n",
      "[1 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 114us/step - loss: 13698.4688\n",
      "rewards:  -77.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [13698.46875]\n",
      "Exploring\n",
      "Selected action  [0 3]\n",
      "[0 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 101us/step - loss: 10698.6562\n",
      "rewards:  -82.0 q-value:  0\n",
      "loss: [10698.65625]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 105us/step - loss: 10236.6562\n",
      "rewards:  -87.0 q-value:  0\n",
      "loss: [10236.65625]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 102us/step - loss: 12115.9062\n",
      "rewards:  -89.0 q-value:  0\n",
      "loss: [12115.90625]\n",
      "Exploiting\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 104us/step - loss: 17376.4375\n",
      "rewards:  -94.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [17376.4375]\n",
      "Exploiting\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 136us/step - loss: 25813.8438\n",
      "rewards:  -104.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [25813.84375]\n",
      "Exploiting\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 126us/step - loss: 24687.6875\n",
      "rewards:  -96.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [24687.6875]\n",
      "Exploiting\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 101us/step - loss: 25682.6562\n",
      "rewards:  -101.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [25682.65625]\n",
      "Exploring\n",
      "Selected action  [0 3]\n",
      "[0 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 136us/step - loss: 15060.4688\n",
      "rewards:  -61.0 q-value:  0\n",
      "loss: [15060.46875]\n",
      "Exploring\n",
      "Selected action  [0 3]\n",
      "[0 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 123us/step - loss: 20530.1562\n",
      "rewards:  -63.0 q-value:  0\n",
      "loss: [20530.15625]\n",
      "Exploring\n",
      "Selected action  [0 2]\n",
      "[0 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 184us/step - loss: 29156.1250\n",
      "rewards:  -65.0 q-value:  0\n",
      "loss: [29156.125]\n",
      "Exploiting\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 98us/step - loss: 19942.0312\n",
      "rewards:  -57.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [19942.03125]\n",
      "Exploiting\n",
      "Selected action  [2 3]\n",
      "[2 3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 143us/step - loss: 13826.1562\n",
      "rewards:  -75.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [13826.15625]\n",
      "Exploring\n",
      "Selected action  [2 3]\n",
      "[2 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 161us/step - loss: 17963.7188\n",
      "rewards:  -78.0 q-value:  0\n",
      "loss: [17963.71875]\n",
      "Exploring\n",
      "Selected action  [0 3]\n",
      "[0 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 159us/step - loss: 16680.3750\n",
      "rewards:  -84.0 q-value:  0\n",
      "loss: [16680.375]\n",
      "Exploring\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 106us/step - loss: 18493.0625\n",
      "rewards:  -86.0 q-value:  0\n",
      "loss: [18493.0625]\n",
      "Exploiting\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 121us/step - loss: 19490.0938\n",
      "rewards:  -68.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [19490.09375]\n",
      "Exploring\n",
      "Selected action  [2 3]\n",
      "[2 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 127us/step - loss: 20237.0312\n",
      "rewards:  -71.0 q-value:  0\n",
      "loss: [20237.03125]\n",
      "Exploiting\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 103us/step - loss: 27931.3750\n",
      "rewards:  -73.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [27931.375]\n",
      "Exploring\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 127us/step - loss: 12298.9688\n",
      "rewards:  -75.0 q-value:  0\n",
      "loss: [12298.96875]\n",
      "Exploring\n",
      "Selected action  [0 2]\n",
      "[0 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 145us/step - loss: 18688.9688\n",
      "rewards:  -72.0 q-value:  0\n",
      "loss: [18688.96875]\n",
      "Exploiting\n",
      "Selected action  [2 3]\n",
      "[2 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 107us/step - loss: 25849.6562\n",
      "rewards:  -60.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [25849.65625]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 107us/step - loss: 17943.8125\n",
      "rewards:  -73.0 q-value:  0\n",
      "loss: [17943.8125]\n",
      "Exploiting\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 143us/step - loss: 15772.1562\n",
      "rewards:  -79.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [15772.15625]\n",
      "Exploring\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 128us/step - loss: 21012.0938\n",
      "rewards:  -80.0 q-value:  0\n",
      "loss: [21012.09375]\n",
      "Exploiting\n",
      "Selected action  [2 3]\n",
      "[2 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 159us/step - loss: 29920.8438\n",
      "rewards:  -69.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [29920.84375]\n",
      "Exploring\n",
      "Selected action  [1 4]\n",
      "[1 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 144us/step - loss: 14634.3438\n",
      "rewards:  -74.0 q-value:  0\n",
      "loss: [14634.34375]\n",
      "Exploring\n",
      "Selected action  [0 3]\n",
      "[0 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 129us/step - loss: 20248.9375\n",
      "rewards:  -71.0 q-value:  0\n",
      "loss: [20248.9375]\n",
      "Exploiting\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 128us/step - loss: 12556.4062\n",
      "rewards:  -76.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [12556.40625]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 165us/step - loss: 16122.8125\n",
      "rewards:  -81.0 q-value:  0\n",
      "loss: [16122.8125]\n",
      "Exploiting\n",
      "Selected action  [3 1]\n",
      "[3 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 126us/step - loss: 29188.9375\n",
      "rewards:  -87.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [29188.9375]\n",
      "Exploring\n",
      "Selected action  [1 4]\n",
      "[1 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 111us/step - loss: 9212.8438\n",
      "rewards:  -75.0 q-value:  0\n",
      "loss: [9212.84375]\n",
      "Exploring\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 111us/step - loss: 20732.3750\n",
      "rewards:  -86.0 q-value:  0\n",
      "loss: [20732.375]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 129us/step - loss: 26926.5625\n",
      "rewards:  -91.0 q-value:  0\n",
      "loss: [26926.5625]\n",
      "Exploiting\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 136us/step - loss: 17268.3750\n",
      "rewards:  -104.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [17268.375]\n",
      "Exploring\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 135us/step - loss: 15122.5938\n",
      "rewards:  -117.0 q-value:  0\n",
      "loss: [15122.59375]\n",
      "Exploiting\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 151us/step - loss: 16772.0938\n",
      "rewards:  -124.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [16772.09375]\n",
      "Exploiting\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 144us/step - loss: 17115.0312\n",
      "rewards:  -128.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [17115.03125]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 116us/step - loss: 10648.4062\n",
      "rewards:  -132.0 q-value:  0\n",
      "loss: [10648.40625]\n",
      "Exploring\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 140us/step - loss: 20535.7812\n",
      "rewards:  -137.0 q-value:  0\n",
      "loss: [20535.78125]\n",
      "Exploring\n",
      "Selected action  [0 3]\n",
      "[0 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 129us/step - loss: 9596.2188\n",
      "rewards:  -109.0 q-value:  0\n",
      "loss: [9596.21875]\n",
      "Exploring\n",
      "Selected action  [3 1]\n",
      "[3 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 129us/step - loss: 9755.2188\n",
      "rewards:  -97.0 q-value:  0\n",
      "loss: [9755.21875]\n",
      "Exploiting\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 108us/step - loss: 19986.8125\n",
      "rewards:  -85.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [19986.8125]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 166us/step - loss: 15117.4688\n",
      "rewards:  -90.0 q-value:  0\n",
      "loss: [15117.46875]\n",
      "Exploring\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 177us/step - loss: 13329.3438\n",
      "rewards:  -93.0 q-value:  0\n",
      "loss: [13329.34375]\n",
      "Exploiting\n",
      "Selected action  [1 4]\n",
      "[1 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 109us/step - loss: 25275.5000\n",
      "rewards:  -128.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [25275.5]\n",
      "Exploiting\n",
      "Selected action  [2 3]\n",
      "[2 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 137us/step - loss: 12954.9688\n",
      "rewards:  -104.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [12954.96875]\n",
      "Exploring\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 114us/step - loss: 14487.2188\n",
      "rewards:  -108.0 q-value:  0\n",
      "loss: [14487.21875]\n",
      "Exploring\n",
      "Selected action  [0 3]\n",
      "[0 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 97us/step - loss: 19599.9375\n",
      "rewards:  -112.0 q-value:  0\n",
      "loss: [19599.9375]\n",
      "Exploring\n",
      "Selected action  [1 4]\n",
      "[1 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 150us/step - loss: 21359.1562\n",
      "rewards:  -112.0 q-value:  0\n",
      "loss: [21359.15625]\n",
      "Exploring\n",
      "Selected action  [3 1]\n",
      "[3 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 121us/step - loss: 19614.3750\n",
      "rewards:  -134.0 q-value:  0\n",
      "loss: [19614.375]\n",
      "Exploring\n",
      "Selected action  [0 3]\n",
      "[0 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 186us/step - loss: 17807.6562\n",
      "rewards:  -138.0 q-value:  0\n",
      "loss: [17807.65625]\n",
      "Exploring\n",
      "Selected action  [0 2]\n",
      "[0 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 121us/step - loss: 19783.5938\n",
      "rewards:  -133.0 q-value:  0\n",
      "loss: [19783.59375]\n",
      "Exploiting\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 149us/step - loss: 10731.1250\n",
      "rewards:  -152.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [10731.125]\n",
      "Exploiting\n",
      "Selected action  [1 4]\n",
      "[1 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 117us/step - loss: 13201.2812\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rewards:  -164.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [13201.28125]\n",
      "Exploring\n",
      "Selected action  [0 2]\n",
      "[0 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 145us/step - loss: 13002.5625\n",
      "rewards:  -155.0 q-value:  0\n",
      "loss: [13002.5625]\n",
      "Exploring\n",
      "Selected action  [0 3]\n",
      "[0 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 145us/step - loss: 22028.8125\n",
      "rewards:  -170.0 q-value:  0\n",
      "loss: [22028.8125]\n",
      "Exploring\n",
      "Selected action  [3 1]\n",
      "[3 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 132us/step - loss: 16549.9688\n",
      "rewards:  -170.0 q-value:  0\n",
      "loss: [16549.96875]\n",
      "Exploring\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 111us/step - loss: 15553.8125\n",
      "rewards:  -170.0 q-value:  0\n",
      "loss: [15553.8125]\n",
      "Exploiting\n",
      "Selected action  [0 3]\n",
      "[0 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 96us/step - loss: 18589.0625\n",
      "rewards:  -170.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [18589.0625]\n",
      "Exploiting\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 136us/step - loss: 12562.1875\n",
      "rewards:  -170.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [12562.1875]\n",
      "Exploring\n",
      "Selected action  [0 2]\n",
      "[0 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 115us/step - loss: 15406.6875\n",
      "rewards:  -158.0 q-value:  0\n",
      "loss: [15406.6875]\n",
      "Exploring\n",
      "Selected action  [2 3]\n",
      "[2 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 148us/step - loss: 11147.0625\n",
      "rewards:  -126.0 q-value:  0\n",
      "loss: [11147.0625]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 116us/step - loss: 14872.4375\n",
      "rewards:  -118.0 q-value:  0\n",
      "loss: [14872.4375]\n",
      "Exploring\n",
      "Selected action  [0 3]\n",
      "[0 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 122us/step - loss: 20353.7500\n",
      "rewards:  -78.0 q-value:  0\n",
      "loss: [20353.75]\n",
      "Exploring\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 125us/step - loss: 22666.0312\n",
      "rewards:  -79.0 q-value:  0\n",
      "loss: [22666.03125]\n",
      "Exploiting\n",
      "Selected action  [2 3]\n",
      "[2 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 117us/step - loss: 24363.5312\n",
      "rewards:  -88.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [24363.53125]\n",
      "Exploring\n",
      "Selected action  [1 3]\n",
      "[1 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 135us/step - loss: 21105.3125\n",
      "rewards:  -89.0 q-value:  0\n",
      "loss: [21105.3125]\n",
      "Exploring\n",
      "Selected action  [0 2]\n",
      "[0 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 212us/step - loss: 28510.3438\n",
      "rewards:  -65.0 q-value:  0\n",
      "loss: [28510.34375]\n",
      "Exploring\n",
      "Selected action  [1 4]\n",
      "[1 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 139us/step - loss: 16963.0000\n",
      "rewards:  -91.0 q-value:  0\n",
      "loss: [16963.0]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 173us/step - loss: 25269.5000\n",
      "rewards:  -84.0 q-value:  0\n",
      "loss: [25269.5]\n",
      "Number of actions available 7\n",
      "Episode : 46\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 127us/step - loss: 11918.0312\n",
      "rewards:  -6.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [11918.03125]\n",
      "Exploring\n",
      "Selected action  [0 2]\n",
      "[0 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 158us/step - loss: 16828.6562\n",
      "rewards:  -12.0 q-value:  0\n",
      "loss: [16828.65625]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 129us/step - loss: 7699.7188\n",
      "rewards:  -19.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [7699.71875]\n",
      "Exploring\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 116us/step - loss: 19541.1875\n",
      "rewards:  -17.0 q-value:  0\n",
      "loss: [19541.1875]\n",
      "Exploring\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 109us/step - loss: 27719.3750\n",
      "rewards:  -9.0 q-value:  0\n",
      "loss: [27719.375]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 103us/step - loss: 14815.2500\n",
      "rewards:  -11.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [14815.25]\n",
      "Exploring\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 150us/step - loss: 23169.6875\n",
      "rewards:  -13.0 q-value:  0\n",
      "loss: [23169.6875]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 116us/step - loss: 24949.9688\n",
      "rewards:  -15.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [24949.96875]\n",
      "Exploring\n",
      "Selected action  [1 4]\n",
      "[1 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 142us/step - loss: 31864.4062\n",
      "rewards:  1.0 q-value:  0\n",
      "loss: [31864.40625]\n",
      "Exploring\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 121us/step - loss: 15761.4688\n",
      "rewards:  32.0 q-value:  0\n",
      "loss: [15761.46875]\n",
      "Exploring\n",
      "Selected action  [4 2]\n",
      "[4 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 145us/step - loss: 18954.8438\n",
      "rewards:  40.0 q-value:  0\n",
      "loss: [18954.84375]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 125us/step - loss: 10746.0625\n",
      "rewards:  18.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [10746.0625]\n",
      "Exploring\n",
      "Selected action  [0 2]\n",
      "[0 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 106us/step - loss: 13669.4688\n",
      "rewards:  32.0 q-value:  0\n",
      "loss: [13669.46875]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 116us/step - loss: 17529.5938\n",
      "rewards:  14.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [17529.59375]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 106us/step - loss: 16464.5938\n",
      "rewards:  7.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [16464.59375]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 137us/step - loss: 16259.4375\n",
      "rewards:  2.0 q-value:  0\n",
      "loss: [16259.4375]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 122us/step - loss: 22717.0000\n",
      "rewards:  30.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [22717.0]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 145us/step - loss: 19988.5312\n",
      "rewards:  27.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [19988.53125]\n",
      "Exploring\n",
      "Selected action  [1 4]\n",
      "[1 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 170us/step - loss: 12740.6562\n",
      "rewards:  27.0 q-value:  0\n",
      "loss: [12740.65625]\n",
      "Exploring\n",
      "Selected action  [4 2]\n",
      "[4 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 135us/step - loss: 14177.7812\n",
      "rewards:  35.0 q-value:  0\n",
      "loss: [14177.78125]\n",
      "Exploring\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 115us/step - loss: 16240.4688\n",
      "rewards:  55.0 q-value:  0\n",
      "loss: [16240.46875]\n",
      "Exploring\n",
      "Selected action  [0 2]\n",
      "[0 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 152us/step - loss: 18502.5938\n",
      "rewards:  79.0 q-value:  0\n",
      "loss: [18502.59375]\n",
      "Exploring\n",
      "Selected action  [0 2]\n",
      "[0 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 131us/step - loss: 11290.4375\n",
      "rewards:  78.0 q-value:  0\n",
      "loss: [11290.4375]\n",
      "Exploring\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 112us/step - loss: 13674.3125\n",
      "rewards:  97.0 q-value:  0\n",
      "loss: [13674.3125]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 126us/step - loss: 20786.9062\n",
      "rewards:  91.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [20786.90625]\n",
      "Exploring\n",
      "Selected action  [3 2]\n",
      "[3 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 133us/step - loss: 25232.7812\n",
      "rewards:  96.0 q-value:  0\n",
      "loss: [25232.78125]\n",
      "Exploring\n",
      "Selected action  [0 2]\n",
      "[0 2]\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 136us/step - loss: 17273.0312\n",
      "rewards:  90.0 q-value:  0\n",
      "loss: [17273.03125]\n",
      "Exploring\n",
      "Selected action  [3 2]\n",
      "[3 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 157us/step - loss: 16354.6875\n",
      "rewards:  84.0 q-value:  0\n",
      "loss: [16354.6875]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 121us/step - loss: 12459.9062\n",
      "rewards:  67.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [12459.90625]\n",
      "Exploring\n",
      "Selected action  [3 2]\n",
      "[3 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 145us/step - loss: 12026.0312\n",
      "rewards:  62.0 q-value:  0\n",
      "loss: [12026.03125]\n",
      "Exploring\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 94us/step - loss: 10256.0312\n",
      "rewards:  82.0 q-value:  0\n",
      "loss: [10256.03125]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 117us/step - loss: 15038.6562\n",
      "rewards:  110.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [15038.65625]\n",
      "Exploring\n",
      "Selected action  [1 4]\n",
      "[1 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 115us/step - loss: 11426.6250\n",
      "rewards:  134.0 q-value:  0\n",
      "loss: [11426.625]\n",
      "Exploring\n",
      "Selected action  [4 2]\n",
      "[4 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 116us/step - loss: 13594.7500\n",
      "rewards:  142.0 q-value:  0\n",
      "loss: [13594.75]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 185us/step - loss: 23150.2188\n",
      "rewards:  137.0 q-value:  0\n",
      "loss: [23150.21875]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 146us/step - loss: 25075.6562\n",
      "rewards:  149.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [25075.65625]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 172us/step - loss: 16783.9688\n",
      "rewards:  142.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [16783.96875]\n",
      "Exploring\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 130us/step - loss: 17706.0312\n",
      "rewards:  125.0 q-value:  0\n",
      "loss: [17706.03125]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 105us/step - loss: 14808.4688\n",
      "rewards:  145.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [14808.46875]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 116us/step - loss: 24603.7188\n",
      "rewards:  141.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [24603.71875]\n",
      "Exploring\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 128us/step - loss: 28919.5312\n",
      "rewards:  137.0 q-value:  0\n",
      "loss: [28919.53125]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 105us/step - loss: 21601.5312\n",
      "rewards:  133.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [21601.53125]\n",
      "Exploring\n",
      "Selected action  [3 2]\n",
      "[3 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 128us/step - loss: 10570.6250\n",
      "rewards:  149.0 q-value:  0\n",
      "loss: [10570.625]\n",
      "Exploring\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 153us/step - loss: 18583.3750\n",
      "rewards:  173.0 q-value:  0\n",
      "loss: [18583.375]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 142us/step - loss: 13978.0625\n",
      "rewards:  181.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [13978.0625]\n",
      "Exploring\n",
      "Selected action  [0 2]\n",
      "[0 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 107us/step - loss: 19435.0312\n",
      "rewards:  191.0 q-value:  0\n",
      "loss: [19435.03125]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 111us/step - loss: 18585.0000\n",
      "rewards:  189.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [18585.0]\n",
      "Exploring\n",
      "Selected action  [0 2]\n",
      "[0 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 153us/step - loss: 17449.5312\n",
      "rewards:  187.0 q-value:  0\n",
      "loss: [17449.53125]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 99us/step - loss: 14124.0000\n",
      "rewards:  185.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [14124.0]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 138us/step - loss: 14988.2188\n",
      "rewards:  176.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [14988.21875]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 152us/step - loss: 29931.4062\n",
      "rewards:  172.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [29931.40625]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 113us/step - loss: 31371.8125\n",
      "rewards:  170.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [31371.8125]\n",
      "Exploring\n",
      "Selected action  [1 4]\n",
      "[1 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 150us/step - loss: 23747.8438\n",
      "rewards:  186.0 q-value:  0\n",
      "loss: [23747.84375]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 111us/step - loss: 14200.6875\n",
      "rewards:  193.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [14200.6875]\n",
      "Exploring\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 123us/step - loss: 15243.7188\n",
      "rewards:  187.0 q-value:  0\n",
      "loss: [15243.71875]\n",
      "Exploring\n",
      "Selected action  [0 2]\n",
      "[0 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 180us/step - loss: 17297.5625\n",
      "rewards:  211.0 q-value:  0\n",
      "loss: [17297.5625]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 114us/step - loss: 15845.0938\n",
      "rewards:  224.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [15845.09375]\n",
      "Exploring\n",
      "Selected action  [1 4]\n",
      "[1 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 131us/step - loss: 16136.5625\n",
      "rewards:  224.0 q-value:  0\n",
      "loss: [16136.5625]\n",
      "Exploring\n",
      "Selected action  [0 2]\n",
      "[0 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 109us/step - loss: 15960.2812\n",
      "rewards:  212.0 q-value:  0\n",
      "loss: [15960.28125]\n",
      "Exploring\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 120us/step - loss: 12983.1250\n",
      "rewards:  232.0 q-value:  0\n",
      "loss: [12983.125]\n",
      "Exploring\n",
      "Selected action  [3 2]\n",
      "[3 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 111us/step - loss: 14878.4062\n",
      "rewards:  204.0 q-value:  0\n",
      "loss: [14878.40625]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 131us/step - loss: 16663.2812\n",
      "rewards:  199.0 q-value:  0\n",
      "loss: [16663.28125]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 144us/step - loss: 20714.0938\n",
      "rewards:  235.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [20714.09375]\n",
      "Exploring\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 157us/step - loss: 17120.3125\n",
      "rewards:  229.0 q-value:  0\n",
      "loss: [17120.3125]\n",
      "Exploring\n",
      "Selected action  [4 2]\n",
      "[4 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 116us/step - loss: 33270.4062\n",
      "rewards:  227.0 q-value:  0\n",
      "loss: [33270.40625]\n",
      "Exploring\n",
      "Selected action  [4 2]\n",
      "[4 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 155us/step - loss: 17257.3750\n",
      "rewards:  225.0 q-value:  0\n",
      "loss: [17257.375]\n",
      "Exploring\n",
      "Selected action  [3 2]\n",
      "[3 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 117us/step - loss: 22439.5000\n",
      "rewards:  220.0 q-value:  0\n",
      "loss: [22439.5]\n",
      "Exploring\n",
      "Selected action  [1 4]\n",
      "[1 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 137us/step - loss: 6564.1875\n",
      "rewards:  194.0 q-value:  0\n",
      "loss: [6564.1875]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 119us/step - loss: 24052.0000\n",
      "rewards:  189.0 q-value:  0\n",
      "loss: [24052.0]\n",
      "Exploring\n",
      "Selected action  [1 4]\n",
      "[1 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 129us/step - loss: 16915.3125\n",
      "rewards:  169.0 q-value:  0\n",
      "loss: [16915.3125]\n",
      "Exploring\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 164us/step - loss: 15870.3438\n",
      "rewards:  185.0 q-value:  0\n",
      "loss: [15870.34375]\n",
      "Exploring\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 128us/step - loss: 13947.3125\n",
      "rewards:  183.0 q-value:  0\n",
      "loss: [13947.3125]\n",
      "Exploring\n",
      "Selected action  [4 2]\n",
      "[4 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 117us/step - loss: 17256.3750\n",
      "rewards:  183.0 q-value:  0\n",
      "loss: [17256.375]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 171us/step - loss: 12155.6562\n",
      "rewards:  166.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [12155.65625]\n",
      "Exploring\n",
      "Selected action  [1 4]\n",
      "[1 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 133us/step - loss: 14977.9062\n",
      "rewards:  166.0 q-value:  0\n",
      "loss: [14977.90625]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 112us/step - loss: 17619.4375\n",
      "rewards:  144.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [17619.4375]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 109us/step - loss: 16426.0312\n",
      "rewards:  137.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [16426.03125]\n",
      "Exploring\n",
      "Selected action  [0 2]\n",
      "[0 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 129us/step - loss: 21244.5625\n",
      "rewards:  117.0 q-value:  0\n",
      "loss: [21244.5625]\n",
      "Exploring\n",
      "Selected action  [1 4]\n",
      "[1 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 114us/step - loss: 12533.7812\n",
      "rewards:  120.0 q-value:  0\n",
      "loss: [12533.78125]\n",
      "Exploring\n",
      "Selected action  [1 4]\n",
      "[1 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 173us/step - loss: 14093.0000\n",
      "rewards:  118.0 q-value:  0\n",
      "loss: [14093.0]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 100us/step - loss: 22066.2500\n",
      "rewards:  113.0 q-value:  0\n",
      "loss: [22066.25]\n",
      "Exploring\n",
      "Selected action  [1 4]\n",
      "[1 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 152us/step - loss: 7698.5938\n",
      "rewards:  106.0 q-value:  0\n",
      "loss: [7698.59375]\n",
      "Exploring\n",
      "Selected action  [0 2]\n",
      "[0 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 101us/step - loss: 10919.7812\n",
      "rewards:  107.0 q-value:  0\n",
      "loss: [10919.78125]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 168us/step - loss: 15713.9688\n",
      "rewards:  115.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [15713.96875]\n",
      "Exploring\n",
      "Selected action  [0 2]\n",
      "[0 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 106us/step - loss: 14452.0000\n",
      "rewards:  118.0 q-value:  0\n",
      "loss: [14452.0]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 207us/step - loss: 10953.5312\n",
      "rewards:  113.0 q-value:  0\n",
      "loss: [10953.53125]\n",
      "Exploring\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 102us/step - loss: 10604.1250\n",
      "rewards:  109.0 q-value:  0\n",
      "loss: [10604.125]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 135us/step - loss: 15141.6875\n",
      "rewards:  125.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [15141.6875]\n",
      "Exploring\n",
      "Selected action  [0 2]\n",
      "[0 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 117us/step - loss: 19738.7188\n",
      "rewards:  125.0 q-value:  0\n",
      "loss: [19738.71875]\n",
      "Exploring\n",
      "Selected action  [3 2]\n",
      "[3 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 124us/step - loss: 11962.2812\n",
      "rewards:  116.0 q-value:  0\n",
      "loss: [11962.28125]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 143us/step - loss: 14500.7500\n",
      "rewards:  110.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [14500.75]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 133us/step - loss: 16614.9375\n",
      "rewards:  108.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [16614.9375]\n",
      "Exploring\n",
      "Selected action  [3 2]\n",
      "[3 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 185us/step - loss: 14200.5000\n",
      "rewards:  116.0 q-value:  0\n",
      "loss: [14200.5]\n",
      "Exploring\n",
      "Selected action  [1 4]\n",
      "[1 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 120us/step - loss: 13287.2500\n",
      "rewards:  88.0 q-value:  0\n",
      "loss: [13287.25]\n",
      "Exploring\n",
      "Selected action  [1 4]\n",
      "[1 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 118us/step - loss: 25322.8750\n",
      "rewards:  84.0 q-value:  0\n",
      "loss: [25322.875]\n",
      "Exploring\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 118us/step - loss: 23474.2500\n",
      "rewards:  87.0 q-value:  0\n",
      "loss: [23474.25]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 128us/step - loss: 17996.0312\n",
      "rewards:  123.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [17996.03125]\n",
      "Exploring\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 127us/step - loss: 18252.1562\n",
      "rewards:  126.0 q-value:  0\n",
      "loss: [18252.15625]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 132us/step - loss: 7444.9688\n",
      "rewards:  142.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [7444.96875]\n",
      "Exploring\n",
      "Selected action  [3 2]\n",
      "[3 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 146us/step - loss: 20185.8438\n",
      "rewards:  149.0 q-value:  0\n",
      "loss: [20185.84375]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 123us/step - loss: 15788.7188\n",
      "rewards:  131.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [15788.71875]\n",
      "Exploring\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 119us/step - loss: 18668.0000\n",
      "rewards:  125.0 q-value:  0\n",
      "loss: [18668.0]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 120us/step - loss: 16109.9375\n",
      "rewards:  120.0 q-value:  0\n",
      "loss: [16109.9375]\n",
      "Exploring\n",
      "Selected action  [1 4]\n",
      "[1 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 113us/step - loss: 13947.2812\n",
      "rewards:  93.0 q-value:  0\n",
      "loss: [13947.28125]\n",
      "Exploring\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 139us/step - loss: 24079.5625\n",
      "rewards:  92.0 q-value:  0\n",
      "loss: [24079.5625]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 139us/step - loss: 14655.7188\n",
      "rewards:  120.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [14655.71875]\n",
      "Number of actions available 10\n",
      "Episode : 47\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 165us/step - loss: 21853.3125\n",
      "rewards:  -6.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [21853.3125]\n",
      "Exploring\n",
      "Selected action  [2 1]\n",
      "[2 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 121us/step - loss: 12232.3438\n",
      "rewards:  -10.0 q-value:  0\n",
      "loss: [12232.34375]\n",
      "Exploring\n",
      "Selected action  [3 1]\n",
      "[3 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 137us/step - loss: 9799.7812\n",
      "rewards:  -10.0 q-value:  0\n",
      "loss: [9799.78125]\n",
      "Exploring\n",
      "Selected action  [2 3]\n",
      "[2 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 165us/step - loss: 13411.6875\n",
      "rewards:  12.0 q-value:  0\n",
      "loss: [13411.6875]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 193us/step - loss: 21818.1562\n",
      "rewards:  5.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [21818.15625]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 166us/step - loss: 13527.0312\n",
      "rewards:  3.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [13527.03125]\n",
      "Exploring\n",
      "Selected action  [4 3]\n",
      "[4 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 115us/step - loss: 23425.0000\n",
      "rewards:  -9.0 q-value:  0\n",
      "loss: [23425.0]\n",
      "Exploring\n",
      "Selected action  [3 1]\n",
      "[3 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 129us/step - loss: 15215.0625\n",
      "rewards:  11.0 q-value:  0\n",
      "loss: [15215.0625]\n",
      "Exploring\n",
      "Selected action  [4 3]\n",
      "[4 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 127us/step - loss: 23660.6250\n",
      "rewards:  24.0 q-value:  0\n",
      "loss: [23660.625]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 158us/step - loss: 24333.4688\n",
      "rewards:  30.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [24333.46875]\n",
      "Exploring\n",
      "Selected action  [3 4]\n",
      "[3 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 131us/step - loss: 24941.7500\n",
      "rewards:  45.0 q-value:  0\n",
      "loss: [24941.75]\n",
      "Exploring\n",
      "Selected action  [2 1]\n",
      "[2 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 122us/step - loss: 14031.5312\n",
      "rewards:  69.0 q-value:  0\n",
      "loss: [14031.53125]\n",
      "Exploring\n",
      "Selected action  [2 1]\n",
      "[2 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 112us/step - loss: 19065.0000\n",
      "rewards:  60.0 q-value:  0\n",
      "loss: [19065.0]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 112us/step - loss: 18528.1250\n",
      "rewards:  53.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [18528.125]\n",
      "Exploring\n",
      "Selected action  [0 2]\n",
      "[0 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 127us/step - loss: 16604.3750\n",
      "rewards:  46.0 q-value:  0\n",
      "loss: [16604.375]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 109us/step - loss: 17255.1250\n",
      "rewards:  33.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [17255.125]\n",
      "Exploring\n",
      "Selected action  [0 2]\n",
      "[0 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 140us/step - loss: 16293.9375\n",
      "rewards:  38.0 q-value:  0\n",
      "loss: [16293.9375]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 103us/step - loss: 22113.7188\n",
      "rewards:  44.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [22113.71875]\n",
      "Exploring\n",
      "Selected action  [4 3]\n",
      "[4 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 114us/step - loss: 18396.3750\n",
      "rewards:  68.0 q-value:  0\n",
      "loss: [18396.375]\n",
      "Exploring\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 107us/step - loss: 26436.8750\n",
      "rewards:  80.0 q-value:  0\n",
      "loss: [26436.875]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 101us/step - loss: 21026.5312\n",
      "rewards:  108.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [21026.53125]\n",
      "Exploring\n",
      "Selected action  [3 1]\n",
      "[3 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 104us/step - loss: 19043.6250\n",
      "rewards:  104.0 q-value:  0\n",
      "loss: [19043.625]\n",
      "Exploring\n",
      "Selected action  [2 1]\n",
      "[2 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 139us/step - loss: 11228.2500\n",
      "rewards:  96.0 q-value:  0\n",
      "loss: [11228.25]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 97us/step - loss: 14940.8750\n",
      "rewards:  91.0 q-value:  0\n",
      "loss: [14940.875]\n",
      "Exploring\n",
      "Selected action  [3 1]\n",
      "[3 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 107us/step - loss: 26817.1250\n",
      "rewards:  76.0 q-value:  0\n",
      "loss: [26817.125]\n",
      "Exploring\n",
      "Selected action  [1 2]\n",
      "[1 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 123us/step - loss: 9967.6250\n",
      "rewards:  104.0 q-value:  0\n",
      "loss: [9967.625]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 120us/step - loss: 15146.1250\n",
      "rewards:  101.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [15146.125]\n",
      "Exploring\n",
      "Selected action  [1 2]\n",
      "[1 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 124us/step - loss: 13711.5625\n",
      "rewards:  105.0 q-value:  0\n",
      "loss: [13711.5625]\n",
      "Exploring\n",
      "Selected action  [0 2]\n",
      "[0 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 154us/step - loss: 20872.0312\n",
      "rewards:  101.0 q-value:  0\n",
      "loss: [20872.03125]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 151us/step - loss: 20887.2812\n",
      "rewards:  109.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [20887.28125]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 144us/step - loss: 21651.8750\n",
      "rewards:  104.0 q-value:  0\n",
      "loss: [21651.875]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 187us/step - loss: 20815.6562\n",
      "rewards:  104.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [20815.65625]\n",
      "Exploring\n",
      "Selected action  [3 1]\n",
      "[3 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 182us/step - loss: 19811.2500\n",
      "rewards:  100.0 q-value:  0\n",
      "loss: [19811.25]\n",
      "Exploring\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 166us/step - loss: 20484.1875\n",
      "rewards:  95.0 q-value:  0\n",
      "loss: [20484.1875]\n",
      "Exploring\n",
      "Selected action  [2 1]\n",
      "[2 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 136us/step - loss: 19194.6250\n",
      "rewards:  93.0 q-value:  0\n",
      "loss: [19194.625]\n",
      "Exploring\n",
      "Selected action  [3 1]\n",
      "[3 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 162us/step - loss: 20184.0938\n",
      "rewards:  91.0 q-value:  0\n",
      "loss: [20184.09375]\n",
      "Exploring\n",
      "Selected action  [3 4]\n",
      "[3 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 143us/step - loss: 10540.0312\n",
      "rewards:  105.0 q-value:  0\n",
      "loss: [10540.03125]\n",
      "Exploring\n",
      "Selected action  [4 3]\n",
      "[4 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 127us/step - loss: 14626.2188\n",
      "rewards:  113.0 q-value:  0\n",
      "loss: [14626.21875]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 154us/step - loss: 16622.6250\n",
      "rewards:  107.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [16622.625]\n",
      "Exploring\n",
      "Selected action  [1 2]\n",
      "[1 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 167us/step - loss: 14976.9688\n",
      "rewards:  123.0 q-value:  0\n",
      "loss: [14976.96875]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 173us/step - loss: 18437.2812\n",
      "rewards:  116.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [18437.28125]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 132us/step - loss: 23131.1875\n",
      "rewards:  114.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [23131.1875]\n",
      "Exploring\n",
      "Selected action  [1 2]\n",
      "[1 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 160us/step - loss: 16988.5938\n",
      "rewards:  122.0 q-value:  0\n",
      "loss: [16988.59375]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 161us/step - loss: 16151.0938\n",
      "rewards:  105.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [16151.09375]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 109us/step - loss: 17005.9375\n",
      "rewards:  103.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [17005.9375]\n",
      "Exploring\n",
      "Selected action  [4 3]\n",
      "[4 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 153us/step - loss: 16253.5625\n",
      "rewards:  100.0 q-value:  0\n",
      "loss: [16253.5625]\n",
      "Exploring\n",
      "Selected action  [2 3]\n",
      "[2 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 165us/step - loss: 26128.3438\n",
      "rewards:  94.0 q-value:  0\n",
      "loss: [26128.34375]\n",
      "Exploring\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 138us/step - loss: 14718.5312\n",
      "rewards:  108.0 q-value:  0\n",
      "loss: [14718.53125]\n",
      "Exploring\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 146us/step - loss: 24834.6250\n",
      "rewards:  106.0 q-value:  0\n",
      "loss: [24834.625]\n",
      "Exploring\n",
      "Selected action  [2 3]\n",
      "[2 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 114us/step - loss: 22796.4375\n",
      "rewards:  132.0 q-value:  0\n",
      "loss: [22796.4375]\n",
      "Exploring\n",
      "Selected action  [1 2]\n",
      "[1 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 162us/step - loss: 21970.0312\n",
      "rewards:  126.0 q-value:  0\n",
      "loss: [21970.03125]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 136us/step - loss: 24750.9062\n",
      "rewards:  121.0 q-value:  0\n",
      "loss: [24750.90625]\n",
      "Exploring\n",
      "Selected action  [0 2]\n",
      "[0 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 183us/step - loss: 12675.5000\n",
      "rewards:  145.0 q-value:  0\n",
      "loss: [12675.5]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 148us/step - loss: 18786.9375\n",
      "rewards:  158.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [18786.9375]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 160us/step - loss: 17752.2812\n",
      "rewards:  155.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [17752.28125]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 122us/step - loss: 17254.0625\n",
      "rewards:  150.0 q-value:  0\n",
      "loss: [17254.0625]\n",
      "Exploring\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 127us/step - loss: 14535.6250\n",
      "rewards:  162.0 q-value:  0\n",
      "loss: [14535.625]\n",
      "Exploring\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 149us/step - loss: 16438.9375\n",
      "rewards:  159.0 q-value:  0\n",
      "loss: [16438.9375]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 129us/step - loss: 17291.6562\n",
      "rewards:  156.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [17291.65625]\n",
      "Exploring\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 142us/step - loss: 14889.8438\n",
      "rewards:  160.0 q-value:  0\n",
      "loss: [14889.84375]\n",
      "Exploring\n",
      "Selected action  [2 3]\n",
      "[2 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 122us/step - loss: 19063.0625\n",
      "rewards:  171.0 q-value:  0\n",
      "loss: [19063.0625]\n",
      "Exploring\n",
      "Selected action  [0 2]\n",
      "[0 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 157us/step - loss: 22580.6562\n",
      "rewards:  165.0 q-value:  0\n",
      "loss: [22580.65625]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 120us/step - loss: 32507.7188\n",
      "rewards:  149.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [32507.71875]\n",
      "Exploring\n",
      "Selected action  [3 1]\n",
      "[3 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 126us/step - loss: 11318.4375\n",
      "rewards:  146.0 q-value:  0\n",
      "loss: [11318.4375]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 139us/step - loss: 17204.8750\n",
      "rewards:  141.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [17204.875]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 124us/step - loss: 21718.0312\n",
      "rewards:  134.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [21718.03125]\n",
      "Exploring\n",
      "Selected action  [0 2]\n",
      "[0 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 164us/step - loss: 19795.4375\n",
      "rewards:  122.0 q-value:  0\n",
      "loss: [19795.4375]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 132us/step - loss: 26260.5312\n",
      "rewards:  128.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [26260.53125]\n",
      "Exploring\n",
      "Selected action  [2 3]\n",
      "[2 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 171us/step - loss: 12863.6250\n",
      "rewards:  88.0 q-value:  0\n",
      "loss: [12863.625]\n",
      "Exploring\n",
      "Selected action  [4 3]\n",
      "[4 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 102us/step - loss: 16401.5000\n",
      "rewards:  82.0 q-value:  0\n",
      "loss: [16401.5]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 132us/step - loss: 20070.1250\n",
      "rewards:  75.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [20070.125]\n",
      "Exploring\n",
      "Selected action  [3 1]\n",
      "[3 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 130us/step - loss: 18596.7188\n",
      "rewards:  72.0 q-value:  0\n",
      "loss: [18596.71875]\n",
      "Exploring\n",
      "Selected action  [3 1]\n",
      "[3 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 122us/step - loss: 25588.9062\n",
      "rewards:  71.0 q-value:  0\n",
      "loss: [25588.90625]\n",
      "Exploring\n",
      "Selected action  [3 1]\n",
      "[3 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 127us/step - loss: 18728.6562\n",
      "rewards:  70.0 q-value:  0\n",
      "loss: [18728.65625]\n",
      "Exploring\n",
      "Selected action  [3 1]\n",
      "[3 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 130us/step - loss: 19689.0938\n",
      "rewards:  69.0 q-value:  0\n",
      "loss: [19689.09375]\n",
      "Exploring\n",
      "Selected action  [4 3]\n",
      "[4 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 143us/step - loss: 16155.6250\n",
      "rewards:  79.0 q-value:  0\n",
      "loss: [16155.625]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 129us/step - loss: 23129.1562\n",
      "rewards:  102.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [23129.15625]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 138us/step - loss: 16985.9375\n",
      "rewards:  102.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [16985.9375]\n",
      "Exploring\n",
      "Selected action  [3 4]\n",
      "[3 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 153us/step - loss: 25196.2500\n",
      "rewards:  90.0 q-value:  0\n",
      "loss: [25196.25]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 123us/step - loss: 12770.7812\n",
      "rewards:  110.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [12770.78125]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 126us/step - loss: 13763.7812\n",
      "rewards:  105.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [13763.78125]\n",
      "Exploring\n",
      "Selected action  [2 1]\n",
      "[2 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 187us/step - loss: 17299.0000\n",
      "rewards:  103.0 q-value:  0\n",
      "loss: [17299.0]\n",
      "Exploring\n",
      "Selected action  [2 3]\n",
      "[2 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 138us/step - loss: 19716.6250\n",
      "rewards:  93.0 q-value:  0\n",
      "loss: [19716.625]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 119us/step - loss: 10077.0938\n",
      "rewards:  94.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [10077.09375]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 126us/step - loss: 17268.1875\n",
      "rewards:  88.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [17268.1875]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 134us/step - loss: 16891.6875\n",
      "rewards:  82.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [16891.6875]\n",
      "Exploring\n",
      "Selected action  [4 3]\n",
      "[4 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 172us/step - loss: 19722.6562\n",
      "rewards:  84.0 q-value:  0\n",
      "loss: [19722.65625]\n",
      "Exploring\n",
      "Selected action  [3 4]\n",
      "[3 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 139us/step - loss: 6782.5938\n",
      "rewards:  96.0 q-value:  0\n",
      "loss: [6782.59375]\n",
      "Exploring\n",
      "Selected action  [3 4]\n",
      "[3 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 142us/step - loss: 13969.5938\n",
      "rewards:  93.0 q-value:  0\n",
      "loss: [13969.59375]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 135us/step - loss: 18065.3438\n",
      "rewards:  96.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [18065.34375]\n",
      "Exploring\n",
      "Selected action  [1 2]\n",
      "[1 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 116us/step - loss: 26217.4062\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rewards:  116.0 q-value:  0\n",
      "loss: [26217.40625]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 130us/step - loss: 22280.9688\n",
      "rewards:  111.0 q-value:  0\n",
      "loss: [22280.96875]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 142us/step - loss: 18053.7500\n",
      "rewards:  147.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [18053.75]\n",
      "Exploring\n",
      "Selected action  [2 3]\n",
      "[2 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 134us/step - loss: 13565.6562\n",
      "rewards:  178.0 q-value:  0\n",
      "loss: [13565.65625]\n",
      "Exploring\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 118us/step - loss: 24894.4375\n",
      "rewards:  160.0 q-value:  0\n",
      "loss: [24894.4375]\n",
      "Exploring\n",
      "Selected action  [1 2]\n",
      "[1 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 102us/step - loss: 15872.6562\n",
      "rewards:  184.0 q-value:  0\n",
      "loss: [15872.65625]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 165us/step - loss: 17600.0312\n",
      "rewards:  182.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [17600.03125]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 143us/step - loss: 20862.7500\n",
      "rewards:  175.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [20862.75]\n",
      "Exploiting\n",
      "Selected action  [0 1]\n",
      "[0 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 130us/step - loss: 20611.3750\n",
      "rewards:  172.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [20611.375]\n",
      "Exploring\n",
      "Selected action  [3 4]\n",
      "[3 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 147us/step - loss: 12844.3438\n",
      "rewards:  151.0 q-value:  0\n",
      "loss: [12844.34375]\n",
      "Number of actions available 7\n",
      "Episode : 48\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 124us/step - loss: 14203.2500\n",
      "rewards:  -5 q-value:  0\n",
      "loss: [14203.25]\n",
      "Exploring\n",
      "Selected action  [3 4]\n",
      "[3 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 131us/step - loss: 20920.0938\n",
      "rewards:  -27.0 q-value:  0\n",
      "loss: [20920.09375]\n",
      "Exploiting\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 167us/step - loss: 17457.0312\n",
      "rewards:  -32.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [17457.03125]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 147us/step - loss: 13428.7188\n",
      "rewards:  -37.0 q-value:  0\n",
      "loss: [13428.71875]\n",
      "Exploring\n",
      "Selected action  [0 4]\n",
      "[0 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 143us/step - loss: 16438.1250\n",
      "rewards:  -25.0 q-value:  0\n",
      "loss: [16438.125]\n",
      "Exploring\n",
      "Selected action  [4 2]\n",
      "[4 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 148us/step - loss: 16793.4375\n",
      "rewards:  -25.0 q-value:  0\n",
      "loss: [16793.4375]\n",
      "Exploring\n",
      "Selected action  [3 4]\n",
      "[3 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 104us/step - loss: 18205.2812\n",
      "rewards:  -53.0 q-value:  0\n",
      "loss: [18205.28125]\n",
      "Exploiting\n",
      "Selected action  [3 4]\n",
      "[3 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 137us/step - loss: 20986.7812\n",
      "rewards:  -56.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [20986.78125]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 142us/step - loss: 20480.6875\n",
      "rewards:  -58.0 q-value:  0\n",
      "loss: [20480.6875]\n",
      "Exploiting\n",
      "Selected action  [0 4]\n",
      "[0 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 154us/step - loss: 12769.3438\n",
      "rewards:  -66.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [12769.34375]\n",
      "Exploiting\n",
      "Selected action  [3 4]\n",
      "[3 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 181us/step - loss: 14507.5625\n",
      "rewards:  -68.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [14507.5625]\n",
      "Exploiting\n",
      "Selected action  [4 2]\n",
      "[4 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 168us/step - loss: 14701.4062\n",
      "rewards:  -44.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [14701.40625]\n",
      "Exploiting\n",
      "Selected action  [2 1]\n",
      "[2 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 105us/step - loss: 12732.2188\n",
      "rewards:  -40.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [12732.21875]\n",
      "Exploring\n",
      "Selected action  [4 2]\n",
      "[4 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 135us/step - loss: 12954.5312\n",
      "rewards:  -32.0 q-value:  0\n",
      "loss: [12954.53125]\n",
      "Exploring\n",
      "Selected action  [1 2]\n",
      "[1 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 163us/step - loss: 17654.5625\n",
      "rewards:  -33.0 q-value:  0\n",
      "loss: [17654.5625]\n",
      "Exploring\n",
      "Selected action  [3 4]\n",
      "[3 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 112us/step - loss: 8408.0938\n",
      "rewards:  -42.0 q-value:  0\n",
      "loss: [8408.09375]\n",
      "Exploring\n",
      "Selected action  [3 4]\n",
      "[3 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 195us/step - loss: 25380.6250\n",
      "rewards:  -47.0 q-value:  0\n",
      "loss: [25380.625]\n",
      "Exploring\n",
      "Selected action  [1 2]\n",
      "[1 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 143us/step - loss: 16656.9375\n",
      "rewards:  -21.0 q-value:  0\n",
      "loss: [16656.9375]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 129us/step - loss: 12665.8438\n",
      "rewards:  -26.0 q-value:  0\n",
      "loss: [12665.84375]\n",
      "Exploring\n",
      "Selected action  [1 2]\n",
      "[1 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 135us/step - loss: 9946.9688\n",
      "rewards:  -49.0 q-value:  0\n",
      "loss: [9946.96875]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 128us/step - loss: 19301.8125\n",
      "rewards:  -54.0 q-value:  0\n",
      "loss: [19301.8125]\n",
      "Exploring\n",
      "Selected action  [3 4]\n",
      "[3 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 118us/step - loss: 23775.7188\n",
      "rewards:  -51.0 q-value:  0\n",
      "loss: [23775.71875]\n",
      "Exploring\n",
      "Selected action  [4 2]\n",
      "[4 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 139us/step - loss: 19420.1250\n",
      "rewards:  -43.0 q-value:  0\n",
      "loss: [19420.125]\n",
      "Exploiting\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 122us/step - loss: 16593.9375\n",
      "rewards:  -35.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [16593.9375]\n",
      "Exploiting\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 173us/step - loss: 17025.5938\n",
      "rewards:  -40.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [17025.59375]\n",
      "Exploring\n",
      "Selected action  [0 4]\n",
      "[0 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 151us/step - loss: 18684.3125\n",
      "rewards:  -36.0 q-value:  0\n",
      "loss: [18684.3125]\n",
      "Exploiting\n",
      "Selected action  [2 1]\n",
      "[2 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 133us/step - loss: 20807.2188\n",
      "rewards:  -21.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [20807.21875]\n",
      "Exploring\n",
      "Selected action  [2 1]\n",
      "[2 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 132us/step - loss: 17277.3750\n",
      "rewards:  -25.0 q-value:  0\n",
      "loss: [17277.375]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 134us/step - loss: 15063.9375\n",
      "rewards:  -29.0 q-value:  0\n",
      "loss: [15063.9375]\n",
      "Exploring\n",
      "Selected action  [0 4]\n",
      "[0 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 183us/step - loss: 16729.2812\n",
      "rewards:  -30.0 q-value:  0\n",
      "loss: [16729.28125]\n",
      "Exploring\n",
      "Selected action  [3 4]\n",
      "[3 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 111us/step - loss: 11145.0938\n",
      "rewards:  -36.0 q-value:  0\n",
      "loss: [11145.09375]\n",
      "Exploiting\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 146us/step - loss: 15233.6250\n",
      "rewards:  -41.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [15233.625]\n",
      "Exploring\n",
      "Selected action  [3 4]\n",
      "[3 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 117us/step - loss: 13660.7812\n",
      "rewards:  -35.0 q-value:  0\n",
      "loss: [13660.78125]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 112us/step - loss: 18844.6562\n",
      "rewards:  -37.0 q-value:  0\n",
      "loss: [18844.65625]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 123us/step - loss: 14180.7500\n",
      "rewards:  -42.0 q-value:  0\n",
      "loss: [14180.75]\n",
      "Exploring\n",
      "Selected action  [0 4]\n",
      "[0 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 105us/step - loss: 25200.9375\n",
      "rewards:  -42.0 q-value:  0\n",
      "loss: [25200.9375]\n",
      "Exploiting\n",
      "Selected action  [4 2]\n",
      "[4 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 177us/step - loss: 11875.2500\n",
      "rewards:  -34.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [11875.25]\n",
      "Exploring\n",
      "Selected action  [2 1]\n",
      "[2 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 110us/step - loss: 20382.7500\n",
      "rewards:  6.0 q-value:  0\n",
      "loss: [20382.75]\n",
      "Exploring\n",
      "Selected action  [4 2]\n",
      "[4 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9542.3750\n",
      "rewards:  10.0 q-value:  0\n",
      "loss: [9542.375]\n",
      "Exploring\n",
      "Selected action  [2 1]\n",
      "[2 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 152us/step - loss: 10227.8438\n",
      "rewards:  14.0 q-value:  0\n",
      "loss: [10227.84375]\n",
      "Exploring\n",
      "Selected action  [2 1]\n",
      "[2 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 107us/step - loss: 18233.9062\n",
      "rewards:  6.0 q-value:  0\n",
      "loss: [18233.90625]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 165us/step - loss: 19536.9375\n",
      "rewards:  1.0 q-value:  0\n",
      "loss: [19536.9375]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 118us/step - loss: 14655.6562\n",
      "rewards:  -10.0 q-value:  0\n",
      "loss: [14655.65625]\n",
      "Exploring\n",
      "Selected action  [0 4]\n",
      "[0 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 146us/step - loss: 18249.3125\n",
      "rewards:  -11.0 q-value:  0\n",
      "loss: [18249.3125]\n",
      "Exploiting\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 143us/step - loss: 21759.6875\n",
      "rewards:  -12.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [21759.6875]\n",
      "Exploring\n",
      "Selected action  [2 1]\n",
      "[2 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 186us/step - loss: 18593.5000\n",
      "rewards:  11.0 q-value:  0\n",
      "loss: [18593.5]\n",
      "Exploring\n",
      "Selected action  [0 4]\n",
      "[0 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 182us/step - loss: 16702.3125\n",
      "rewards:  12.0 q-value:  0\n",
      "loss: [16702.3125]\n",
      "Exploring\n",
      "Selected action  [2 1]\n",
      "[2 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 132us/step - loss: 9816.7812\n",
      "rewards:  6.0 q-value:  0\n",
      "loss: [9816.78125]\n",
      "Exploring\n",
      "Selected action  [2 1]\n",
      "[2 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 161us/step - loss: 18772.1875\n",
      "rewards:  5.0 q-value:  0\n",
      "loss: [18772.1875]\n",
      "Exploiting\n",
      "Selected action  [0 4]\n",
      "[0 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 118us/step - loss: 22654.9375\n",
      "rewards:  -18.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [22654.9375]\n",
      "Exploring\n",
      "Selected action  [1 2]\n",
      "[1 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 109us/step - loss: 16725.0938\n",
      "rewards:  22.0 q-value:  0\n",
      "loss: [16725.09375]\n",
      "Exploiting\n",
      "Selected action  [3 4]\n",
      "[3 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 141us/step - loss: 21481.1250\n",
      "rewards:  28.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [21481.125]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 108us/step - loss: 26128.0938\n",
      "rewards:  23.0 q-value:  0\n",
      "loss: [26128.09375]\n",
      "Exploiting\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 142us/step - loss: 15412.6875\n",
      "rewards:  18.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [15412.6875]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 116us/step - loss: 18176.8750\n",
      "rewards:  13.0 q-value:  0\n",
      "loss: [18176.875]\n",
      "Exploiting\n",
      "Selected action  [4 2]\n",
      "[4 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 127us/step - loss: 13202.4375\n",
      "rewards:  45.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [13202.4375]\n",
      "Exploiting\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 130us/step - loss: 12830.4688\n",
      "rewards:  40.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [12830.46875]\n",
      "Exploiting\n",
      "Selected action  [2 1]\n",
      "[2 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 133us/step - loss: 14672.6562\n",
      "rewards:  39.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [14672.65625]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 115us/step - loss: 10586.9375\n",
      "rewards:  34.0 q-value:  0\n",
      "loss: [10586.9375]\n",
      "Exploring\n",
      "Selected action  [3 4]\n",
      "[3 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 156us/step - loss: 17413.6875\n",
      "rewards:  12.0 q-value:  0\n",
      "loss: [17413.6875]\n",
      "Exploring\n",
      "Selected action  [4 2]\n",
      "[4 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 120us/step - loss: 26399.3125\n",
      "rewards:  32.0 q-value:  0\n",
      "loss: [26399.3125]\n",
      "Exploring\n",
      "Selected action  [0 4]\n",
      "[0 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 149us/step - loss: 11646.0312\n",
      "rewards:  14.0 q-value:  0\n",
      "loss: [11646.03125]\n",
      "Exploring\n",
      "Selected action  [0 4]\n",
      "[0 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 107us/step - loss: 37586.8438\n",
      "rewards:  11.0 q-value:  0\n",
      "loss: [37586.84375]\n",
      "Exploiting\n",
      "Selected action  [0 4]\n",
      "[0 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 156us/step - loss: 18820.8438\n",
      "rewards:  10.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [18820.84375]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 146us/step - loss: 11354.7188\n",
      "rewards:  5.0 q-value:  0\n",
      "loss: [11354.71875]\n",
      "Exploring\n",
      "Selected action  [2 1]\n",
      "[2 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 160us/step - loss: 28462.6562\n",
      "rewards:  -2.0 q-value:  0\n",
      "loss: [28462.65625]\n",
      "Exploring\n",
      "Selected action  [1 2]\n",
      "[1 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 138us/step - loss: 21013.1875\n",
      "rewards:  6.0 q-value:  0\n",
      "loss: [21013.1875]\n",
      "Exploiting\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 146us/step - loss: 14653.3125\n",
      "rewards:  1.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [14653.3125]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 145us/step - loss: 11556.0312\n",
      "rewards:  -4.0 q-value:  0\n",
      "loss: [11556.03125]\n",
      "Exploring\n",
      "Selected action  [3 4]\n",
      "[3 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 195us/step - loss: 13783.5938\n",
      "rewards:  -7.0 q-value:  0\n",
      "loss: [13783.59375]\n",
      "Exploring\n",
      "Selected action  [4 2]\n",
      "[4 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 206us/step - loss: 13765.9688\n",
      "rewards:  1.0 q-value:  0\n",
      "loss: [13765.96875]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 198us/step - loss: 12842.3438\n",
      "rewards:  -4.0 q-value:  0\n",
      "loss: [12842.34375]\n",
      "Exploiting\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 127us/step - loss: 19259.1562\n",
      "rewards:  -9.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [19259.15625]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 125us/step - loss: 17108.3125\n",
      "rewards:  -15.0 q-value:  0\n",
      "loss: [17108.3125]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 143us/step - loss: 17889.2812\n",
      "rewards:  -20.0 q-value:  0\n",
      "loss: [17889.28125]\n",
      "Exploiting\n",
      "Selected action  [1 2]\n",
      "[1 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 149us/step - loss: 21203.5625\n",
      "rewards:  -10.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [21203.5625]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 129us/step - loss: 19936.7188\n",
      "rewards:  -15.0 q-value:  0\n",
      "loss: [19936.71875]\n",
      "Exploring\n",
      "Selected action  [3 4]\n",
      "[3 4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 124us/step - loss: 22233.9062\n",
      "rewards:  -2.0 q-value:  0\n",
      "loss: [22233.90625]\n",
      "Exploiting\n",
      "Selected action  [2 1]\n",
      "[2 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 155us/step - loss: 12186.9375\n",
      "rewards:  -8.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [12186.9375]\n",
      "Exploring\n",
      "Selected action  [3 4]\n",
      "[3 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 125us/step - loss: 10781.5625\n",
      "rewards:  23.0 q-value:  0\n",
      "loss: [10781.5625]\n",
      "Exploiting\n",
      "Selected action  [1 2]\n",
      "[1 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 142us/step - loss: 14510.0312\n",
      "rewards:  23.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [14510.03125]\n",
      "Exploiting\n",
      "Selected action  [0 4]\n",
      "[0 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 95us/step - loss: 24331.8125\n",
      "rewards:  -3.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [24331.8125]\n",
      "Exploring\n",
      "Selected action  [1 2]\n",
      "[1 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 130us/step - loss: 29958.5938\n",
      "rewards:  16.0 q-value:  0\n",
      "loss: [29958.59375]\n",
      "Exploiting\n",
      "Selected action  [2 1]\n",
      "[2 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 143us/step - loss: 29882.2812\n",
      "rewards:  52.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [29882.28125]\n",
      "Exploiting\n",
      "Selected action  [1 2]\n",
      "[1 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 156us/step - loss: 12928.7500\n",
      "rewards:  96.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [12928.75]\n",
      "Exploring\n",
      "Selected action  [2 1]\n",
      "[2 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 151us/step - loss: 12097.7188\n",
      "rewards:  112.0 q-value:  0\n",
      "loss: [12097.71875]\n",
      "Exploiting\n",
      "Selected action  [2 1]\n",
      "[2 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 120us/step - loss: 16075.2500\n",
      "rewards:  108.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [16075.25]\n",
      "Exploiting\n",
      "Selected action  [1 2]\n",
      "[1 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 130us/step - loss: 17069.5000\n",
      "rewards:  112.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [17069.5]\n",
      "Exploring\n",
      "Selected action  [3 4]\n",
      "[3 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 140us/step - loss: 12609.6875\n",
      "rewards:  116.0 q-value:  0\n",
      "loss: [12609.6875]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 152us/step - loss: 26579.0625\n",
      "rewards:  114.0 q-value:  0\n",
      "loss: [26579.0625]\n",
      "Exploring\n",
      "Selected action  [3 4]\n",
      "[3 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 200us/step - loss: 14423.1562\n",
      "rewards:  112.0 q-value:  0\n",
      "loss: [14423.15625]\n",
      "Exploiting\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 125us/step - loss: 17458.0938\n",
      "rewards:  110.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [17458.09375]\n",
      "Exploiting\n",
      "Selected action  [2 1]\n",
      "[2 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 138us/step - loss: 15831.3750\n",
      "rewards:  128.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [15831.375]\n",
      "Exploring\n",
      "Selected action  [1 2]\n",
      "[1 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 116us/step - loss: 8531.4375\n",
      "rewards:  168.0 q-value:  0\n",
      "loss: [8531.4375]\n",
      "Exploring\n",
      "Selected action  [0 4]\n",
      "[0 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 159us/step - loss: 17956.0000\n",
      "rewards:  167.0 q-value:  0\n",
      "loss: [17956.0]\n",
      "Exploring\n",
      "Selected action  [0 4]\n",
      "[0 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 147us/step - loss: 9158.5625\n",
      "rewards:  166.0 q-value:  0\n",
      "loss: [9158.5625]\n",
      "Exploiting\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 117us/step - loss: 15246.3438\n",
      "rewards:  165.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [15246.34375]\n",
      "Exploiting\n",
      "Selected action  [4 2]\n",
      "[4 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 119us/step - loss: 8825.7812\n",
      "rewards:  169.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [8825.78125]\n",
      "Exploiting\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 142us/step - loss: 11096.4062\n",
      "rewards:  201.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [11096.40625]\n",
      "Exploiting\n",
      "Selected action  [4 2]\n",
      "[4 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 123us/step - loss: 15872.7188\n",
      "rewards:  209.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [15872.71875]\n",
      "Exploring\n",
      "Selected action  [2 1]\n",
      "[2 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 120us/step - loss: 18099.5625\n",
      "rewards:  213.0 q-value:  0\n",
      "loss: [18099.5625]\n",
      "Exploring\n",
      "Selected action  [2 1]\n",
      "[2 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 129us/step - loss: 11701.1250\n",
      "rewards:  212.0 q-value:  0\n",
      "loss: [11701.125]\n",
      "Exploring\n",
      "Selected action  [4 2]\n",
      "[4 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 130us/step - loss: 10657.7188\n",
      "rewards:  212.0 q-value:  0\n",
      "loss: [10657.71875]\n",
      "Exploiting\n",
      "Selected action  [4 2]\n",
      "[4 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 153us/step - loss: 15051.2500\n",
      "rewards:  212.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [15051.25]\n",
      "Exploiting\n",
      "Selected action  [0 4]\n",
      "[0 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 114us/step - loss: 10091.3125\n",
      "rewards:  204.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [10091.3125]\n",
      "Exploring\n",
      "Selected action  [2 1]\n",
      "[2 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 211us/step - loss: 14432.5000\n",
      "rewards:  244.0 q-value:  0\n",
      "loss: [14432.5]\n",
      "Exploring\n",
      "Selected action  [4 2]\n",
      "[4 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 167us/step - loss: 11901.7812\n",
      "rewards:  251.0 q-value:  0\n",
      "loss: [11901.78125]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 180us/step - loss: 23419.7812\n",
      "rewards:  246.0 q-value:  0\n",
      "loss: [23419.78125]\n",
      "Exploring\n",
      "Selected action  [0 4]\n",
      "[0 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 139us/step - loss: 15963.4062\n",
      "rewards:  246.0 q-value:  0\n",
      "loss: [15963.40625]\n",
      "Exploring\n",
      "Selected action  [0 4]\n",
      "[0 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 124us/step - loss: 14117.8750\n",
      "rewards:  246.0 q-value:  0\n",
      "loss: [14117.875]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 175us/step - loss: 14808.6875\n",
      "rewards:  246.0 q-value:  0\n",
      "loss: [14808.6875]\n",
      "Exploiting\n",
      "Selected action  [2 1]\n",
      "[2 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 164us/step - loss: 15383.2812\n",
      "rewards:  254.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [15383.28125]\n",
      "Exploring\n",
      "Selected action  [3 4]\n",
      "[3 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 133us/step - loss: 13512.1875\n",
      "rewards:  268.0 q-value:  0\n",
      "loss: [13512.1875]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 126us/step - loss: 24692.2500\n",
      "rewards:  263.0 q-value:  0\n",
      "loss: [24692.25]\n",
      "Exploiting\n",
      "Selected action  [3 4]\n",
      "[3 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 144us/step - loss: 16489.0938\n",
      "rewards:  272.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [16489.09375]\n",
      "Exploring\n",
      "Selected action  [0 4]\n",
      "[0 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 117us/step - loss: 15706.1562\n",
      "rewards:  271.0 q-value:  0\n",
      "loss: [15706.15625]\n",
      "Exploiting\n",
      "Selected action  [3 4]\n",
      "[3 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 154us/step - loss: 17573.7188\n",
      "rewards:  264.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [17573.71875]\n",
      "Exploiting\n",
      "Selected action  [2 1]\n",
      "[2 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 120us/step - loss: 18636.3750\n",
      "rewards:  272.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [18636.375]\n",
      "Exploiting\n",
      "Selected action  [1 2]\n",
      "[1 2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 159us/step - loss: 11341.8750\n",
      "rewards:  280.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [11341.875]\n",
      "Exploring\n",
      "Selected action  [0 4]\n",
      "[0 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 127us/step - loss: 14451.8438\n",
      "rewards:  269.0 q-value:  0\n",
      "loss: [14451.84375]\n",
      "Exploiting\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 151us/step - loss: 17851.4375\n",
      "rewards:  264.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [17851.4375]\n",
      "Exploiting\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 107us/step - loss: 15738.0625\n",
      "rewards:  259.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [15738.0625]\n",
      "Exploiting\n",
      "Selected action  [1 2]\n",
      "[1 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 134us/step - loss: 24677.1875\n",
      "rewards:  281.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [24677.1875]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 179us/step - loss: 15124.0000\n",
      "rewards:  285.0 q-value:  0\n",
      "loss: [15124.0]\n",
      "Exploring\n",
      "Selected action  [0 4]\n",
      "[0 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 126us/step - loss: 14642.5938\n",
      "rewards:  284.0 q-value:  0\n",
      "loss: [14642.59375]\n",
      "Exploiting\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 163us/step - loss: 20977.1250\n",
      "rewards:  283.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [20977.125]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 139us/step - loss: 10737.1875\n",
      "rewards:  282.0 q-value:  0\n",
      "loss: [10737.1875]\n",
      "Exploring\n",
      "Selected action  [1 2]\n",
      "[1 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 129us/step - loss: 15948.3125\n",
      "rewards:  307.0 q-value:  0\n",
      "loss: [15948.3125]\n",
      "Exploiting\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 141us/step - loss: 16802.3438\n",
      "rewards:  302.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [16802.34375]\n",
      "Exploiting\n",
      "Selected action  [3 4]\n",
      "[3 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 120us/step - loss: 22336.8438\n",
      "rewards:  328.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [22336.84375]\n",
      "Exploring\n",
      "Selected action  [4 2]\n",
      "[4 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 141us/step - loss: 11212.2500\n",
      "rewards:  328.0 q-value:  0\n",
      "loss: [11212.25]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 177us/step - loss: 23539.2812\n",
      "rewards:  328.0 q-value:  0\n",
      "loss: [23539.28125]\n",
      "Exploring\n",
      "Selected action  [0 4]\n",
      "[0 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 131us/step - loss: 14030.0312\n",
      "rewards:  327.0 q-value:  0\n",
      "loss: [14030.03125]\n",
      "Exploiting\n",
      "Selected action  [4 2]\n",
      "[4 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 134us/step - loss: 14884.5625\n",
      "rewards:  327.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [14884.5625]\n",
      "Exploiting\n",
      "Selected action  [1 2]\n",
      "[1 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 134us/step - loss: 17070.0625\n",
      "rewards:  321.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [17070.0625]\n",
      "Exploring\n",
      "Selected action  [4 2]\n",
      "[4 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 165us/step - loss: 7134.4062\n",
      "rewards:  316.0 q-value:  0\n",
      "loss: [7134.40625]\n",
      "Exploiting\n",
      "Selected action  [4 2]\n",
      "[4 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 145us/step - loss: 13598.5625\n",
      "rewards:  315.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [13598.5625]\n",
      "Exploiting\n",
      "Selected action  [1 2]\n",
      "[1 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 115us/step - loss: 15006.7812\n",
      "rewards:  312.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [15006.78125]\n",
      "Exploring\n",
      "Selected action  [1 2]\n",
      "[1 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 142us/step - loss: 12527.5000\n",
      "rewards:  309.0 q-value:  0\n",
      "loss: [12527.5]\n",
      "Exploring\n",
      "Selected action  [0 4]\n",
      "[0 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 132us/step - loss: 18454.0312\n",
      "rewards:  315.0 q-value:  0\n",
      "loss: [18454.03125]\n",
      "Exploring\n",
      "Selected action  [1 2]\n",
      "[1 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 139us/step - loss: 10656.8750\n",
      "rewards:  315.0 q-value:  0\n",
      "loss: [10656.875]\n",
      "Number of actions available 12\n",
      "Episode : 49\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 109us/step - loss: 16886.8438\n",
      "rewards:  -25.0 q-value:  0\n",
      "loss: [16886.84375]\n",
      "Exploiting\n",
      "Selected action  [0 4]\n",
      "[0 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 171us/step - loss: 12459.2500\n",
      "rewards:  -28.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [12459.25]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 136us/step - loss: 12056.5625\n",
      "rewards:  -32.0 q-value:  0\n",
      "loss: [12056.5625]\n",
      "Exploiting\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 139us/step - loss: 11170.2500\n",
      "rewards:  -32.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [11170.25]\n",
      "Exploring\n",
      "Selected action  [0 4]\n",
      "[0 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 130us/step - loss: 13724.2812\n",
      "rewards:  -33.0 q-value:  0\n",
      "loss: [13724.28125]\n",
      "Exploiting\n",
      "Selected action  [0 3]\n",
      "[0 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 123us/step - loss: 12824.2188\n",
      "rewards:  -38.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [12824.21875]\n",
      "Exploring\n",
      "Selected action  [4 1]\n",
      "[4 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 118us/step - loss: 11654.8438\n",
      "rewards:  -45.0 q-value:  0\n",
      "loss: [11654.84375]\n",
      "Exploring\n",
      "Selected action  [0 3]\n",
      "[0 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 151us/step - loss: 18525.0938\n",
      "rewards:  -43.0 q-value:  0\n",
      "loss: [18525.09375]\n",
      "Exploring\n",
      "Selected action  [3 4]\n",
      "[3 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 161us/step - loss: 17533.8750\n",
      "rewards:  -31.0 q-value:  0\n",
      "loss: [17533.875]\n",
      "Exploiting\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 161us/step - loss: 12421.0312\n",
      "rewards:  -43.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [12421.03125]\n",
      "Exploiting\n",
      "Selected action  [3 1]\n",
      "[3 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 161us/step - loss: 10491.8750\n",
      "rewards:  -73.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [10491.875]\n",
      "Exploiting\n",
      "Selected action  [3 4]\n",
      "[3 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 176us/step - loss: 13934.7812\n",
      "rewards:  -50.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [13934.78125]\n",
      "Exploiting\n",
      "Selected action  [0 3]\n",
      "[0 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 123us/step - loss: 13069.0938\n",
      "rewards:  -57.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [13069.09375]\n",
      "Exploring\n",
      "Selected action  [3 4]\n",
      "[3 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 132us/step - loss: 13111.1250\n",
      "rewards:  -21.0 q-value:  0\n",
      "loss: [13111.125]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 153us/step - loss: 19172.3438\n",
      "rewards:  -21.0 q-value:  0\n",
      "loss: [19172.34375]\n",
      "Exploring\n",
      "Selected action  [0 3]\n",
      "[0 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 141us/step - loss: 10419.5938\n",
      "rewards:  -2.0 q-value:  0\n",
      "loss: [10419.59375]\n",
      "Exploiting\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 124us/step - loss: 8797.4688\n",
      "rewards:  -3.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [8797.46875]\n",
      "Exploiting\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 146us/step - loss: 24621.3750\n",
      "rewards:  -10.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [24621.375]\n",
      "Exploring\n",
      "Selected action  [2 1]\n",
      "[2 1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 131us/step - loss: 18165.1875\n",
      "rewards:  24.0 q-value:  0\n",
      "loss: [18165.1875]\n",
      "Exploring\n",
      "Selected action  [2 1]\n",
      "[2 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 184us/step - loss: 16954.2812\n",
      "rewards:  20.0 q-value:  0\n",
      "loss: [16954.28125]\n",
      "Exploring\n",
      "Selected action  [0 3]\n",
      "[0 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 111us/step - loss: 7137.7812\n",
      "rewards:  7.0 q-value:  0\n",
      "loss: [7137.78125]\n",
      "Exploiting\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 144us/step - loss: 17323.2188\n",
      "rewards:  -5.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [17323.21875]\n",
      "Exploring\n",
      "Selected action  [4 1]\n",
      "[4 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 210us/step - loss: 19685.4375\n",
      "rewards:  7.0 q-value:  0\n",
      "loss: [19685.4375]\n",
      "Exploiting\n",
      "Selected action  [4 1]\n",
      "[4 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 154us/step - loss: 9752.2188\n",
      "rewards:  5.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [9752.21875]\n",
      "Exploiting\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 166us/step - loss: 17919.1562\n",
      "rewards:  -22.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [17919.15625]\n",
      "Exploiting\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 134us/step - loss: 23129.8125\n",
      "rewards:  -12.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [23129.8125]\n",
      "Exploring\n",
      "Selected action  [4 0]\n",
      "[4 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 119us/step - loss: 18971.3438\n",
      "rewards:  -14.0 q-value:  0\n",
      "loss: [18971.34375]\n",
      "Exploring\n",
      "Selected action  [4 1]\n",
      "[4 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 169us/step - loss: 12090.3125\n",
      "rewards:  0.0 q-value:  0\n",
      "loss: [12090.3125]\n",
      "Exploiting\n",
      "Selected action  [4 2]\n",
      "[4 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 123us/step - loss: 10820.9375\n",
      "rewards:  4.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [10820.9375]\n",
      "Exploiting\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 199us/step - loss: 10196.8438\n",
      "rewards:  4.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [10196.84375]\n",
      "Exploring\n",
      "Selected action  [0 3]\n",
      "[0 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 129us/step - loss: 11362.4375\n",
      "rewards:  -14.0 q-value:  0\n",
      "loss: [11362.4375]\n",
      "Exploring\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 97us/step - loss: 13667.5625\n",
      "rewards:  6.0 q-value:  0\n",
      "loss: [13667.5625]\n",
      "Exploring\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 112us/step - loss: 14658.8125\n",
      "rewards:  3.0 q-value:  0\n",
      "loss: [14658.8125]\n",
      "Exploiting\n",
      "Selected action  [4 1]\n",
      "[4 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 140us/step - loss: 14171.0625\n",
      "rewards:  10.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [14171.0625]\n",
      "Exploiting\n",
      "Selected action  [4 2]\n",
      "[4 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 135us/step - loss: 15494.5625\n",
      "rewards:  12.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [15494.5625]\n",
      "Exploring\n",
      "Selected action  [4 2]\n",
      "[4 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 114us/step - loss: 9717.9375\n",
      "rewards:  10.0 q-value:  0\n",
      "loss: [9717.9375]\n",
      "Exploring\n",
      "Selected action  [4 0]\n",
      "[4 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 118us/step - loss: 15392.9375\n",
      "rewards:  22.0 q-value:  0\n",
      "loss: [15392.9375]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 133us/step - loss: 11479.0938\n",
      "rewards:  2.0 q-value:  0\n",
      "loss: [11479.09375]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 209us/step - loss: 8944.4062\n",
      "rewards:  30.0 q-value:  0\n",
      "loss: [8944.40625]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 137us/step - loss: 10002.5938\n",
      "rewards:  25.0 q-value:  0\n",
      "loss: [10002.59375]\n",
      "Exploiting\n",
      "Selected action  [2 1]\n",
      "[2 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 124us/step - loss: 17613.4062\n",
      "rewards:  26.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [17613.40625]\n",
      "Exploring\n",
      "Selected action  [4 1]\n",
      "[4 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 105us/step - loss: 11106.2500\n",
      "rewards:  26.0 q-value:  0\n",
      "loss: [11106.25]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 128us/step - loss: 13997.9062\n",
      "rewards:  21.0 q-value:  0\n",
      "loss: [13997.90625]\n",
      "Exploiting\n",
      "Selected action  [4 0]\n",
      "[4 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 110us/step - loss: 5334.4062\n",
      "rewards:  21.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [5334.40625]\n",
      "Exploring\n",
      "Selected action  [4 0]\n",
      "[4 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 142us/step - loss: 11881.2500\n",
      "rewards:  21.0 q-value:  0\n",
      "loss: [11881.25]\n",
      "Exploring\n",
      "Selected action  [4 0]\n",
      "[4 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 136us/step - loss: 16887.8438\n",
      "rewards:  21.0 q-value:  0\n",
      "loss: [16887.84375]\n",
      "Exploiting\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 119us/step - loss: 10224.7188\n",
      "rewards:  17.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [10224.71875]\n",
      "Exploiting\n",
      "Selected action  [0 3]\n",
      "[0 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 135us/step - loss: 8074.3125\n",
      "rewards:  33.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [8074.3125]\n",
      "Exploiting\n",
      "Selected action  [0 3]\n",
      "[0 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 153us/step - loss: 11851.8750\n",
      "rewards:  30.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [11851.875]\n",
      "Exploiting\n",
      "Selected action  [0 4]\n",
      "[0 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 121us/step - loss: 9566.6250\n",
      "rewards:  4.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [9566.625]\n",
      "Exploring\n",
      "Selected action  [2 1]\n",
      "[2 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 126us/step - loss: 10821.9375\n",
      "rewards:  7.0 q-value:  0\n",
      "loss: [10821.9375]\n",
      "Exploring\n",
      "Selected action  [4 1]\n",
      "[4 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 353us/step - loss: 11785.2500\n",
      "rewards:  0.0 q-value:  0\n",
      "loss: [11785.25]\n",
      "Exploring\n",
      "Selected action  [3 4]\n",
      "[3 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 141us/step - loss: 13832.3438\n",
      "rewards:  12.0 q-value:  0\n",
      "loss: [13832.34375]\n",
      "Exploring\n",
      "Selected action  [4 0]\n",
      "[4 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 124us/step - loss: 24356.6250\n",
      "rewards:  44.0 q-value:  0\n",
      "loss: [24356.625]\n",
      "Exploiting\n",
      "Selected action  [4 1]\n",
      "[4 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 110us/step - loss: 10870.6875\n",
      "rewards:  55.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [10870.6875]\n",
      "Exploring\n",
      "Selected action  [4 1]\n",
      "[4 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 121us/step - loss: 7227.3750\n",
      "rewards:  52.0 q-value:  0\n",
      "loss: [7227.375]\n",
      "Exploring\n",
      "Selected action  [0 4]\n",
      "[0 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 196us/step - loss: 11884.5312\n",
      "rewards:  11.0 q-value:  0\n",
      "loss: [11884.53125]\n",
      "Exploiting\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 141us/step - loss: 11483.2500\n",
      "rewards:  5.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [11483.25]\n",
      "Exploiting\n",
      "Selected action  [0 4]\n",
      "[0 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 125us/step - loss: 12359.0312\n",
      "rewards:  17.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [12359.03125]\n",
      "Exploiting\n",
      "Selected action  [3 1]\n",
      "[3 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 147us/step - loss: 8044.2812\n",
      "rewards:  -4.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [8044.28125]\n",
      "Exploring\n",
      "Selected action  [0 4]\n",
      "[0 4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 145us/step - loss: 15201.3125\n",
      "rewards:  10.0 q-value:  0\n",
      "loss: [15201.3125]\n",
      "Exploring\n",
      "Selected action  [3 4]\n",
      "[3 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 166us/step - loss: 24263.7188\n",
      "rewards:  5.0 q-value:  0\n",
      "loss: [24263.71875]\n",
      "Exploiting\n",
      "Selected action  [2 1]\n",
      "[2 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 108us/step - loss: 5072.7188\n",
      "rewards:  16.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [5072.71875]\n",
      "Exploiting\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 159us/step - loss: 9551.9062\n",
      "rewards:  44.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [9551.90625]\n",
      "Exploring\n",
      "Selected action  [0 4]\n",
      "[0 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 120us/step - loss: 12428.4375\n",
      "rewards:  60.0 q-value:  0\n",
      "loss: [12428.4375]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 124us/step - loss: 12386.9062\n",
      "rewards:  52.0 q-value:  0\n",
      "loss: [12386.90625]\n",
      "Exploiting\n",
      "Selected action  [0 3]\n",
      "[0 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 118us/step - loss: 5957.0312\n",
      "rewards:  84.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [5957.03125]\n",
      "Exploiting\n",
      "Selected action  [0 3]\n",
      "[0 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 147us/step - loss: 12138.7812\n",
      "rewards:  82.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [12138.78125]\n",
      "Exploring\n",
      "Selected action  [2 1]\n",
      "[2 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 131us/step - loss: 14886.4062\n",
      "rewards:  66.0 q-value:  0\n",
      "loss: [14886.40625]\n",
      "Exploring\n",
      "Selected action  [4 1]\n",
      "[4 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 138us/step - loss: 19013.6250\n",
      "rewards:  66.0 q-value:  0\n",
      "loss: [19013.625]\n",
      "Exploiting\n",
      "Selected action  [3 1]\n",
      "[3 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 113us/step - loss: 9861.8750\n",
      "rewards:  65.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [9861.875]\n",
      "Exploiting\n",
      "Selected action  [3 4]\n",
      "[3 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 151us/step - loss: 25222.2500\n",
      "rewards:  76.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [25222.25]\n",
      "Exploring\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 116us/step - loss: 21564.5625\n",
      "rewards:  98.0 q-value:  0\n",
      "loss: [21564.5625]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 122us/step - loss: 10669.1250\n",
      "rewards:  93.0 q-value:  0\n",
      "loss: [10669.125]\n",
      "Exploring\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 166us/step - loss: 15158.7500\n",
      "rewards:  87.0 q-value:  0\n",
      "loss: [15158.75]\n",
      "Exploiting\n",
      "Selected action  [0 4]\n",
      "[0 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 128us/step - loss: 9627.6250\n",
      "rewards:  87.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [9627.625]\n",
      "Exploiting\n",
      "Selected action  [0 3]\n",
      "[0 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 143us/step - loss: 16276.5625\n",
      "rewards:  107.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [16276.5625]\n",
      "Exploiting\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 123us/step - loss: 11277.7500\n",
      "rewards:  103.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [11277.75]\n",
      "Exploiting\n",
      "Selected action  [0 3]\n",
      "[0 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 141us/step - loss: 19503.8438\n",
      "rewards:  115.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [19503.84375]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 141us/step - loss: 8304.5625\n",
      "rewards:  118.0 q-value:  0\n",
      "loss: [8304.5625]\n",
      "Exploiting\n",
      "Selected action  [3 4]\n",
      "[3 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 178us/step - loss: 11002.0312\n",
      "rewards:  133.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [11002.03125]\n",
      "Exploring\n",
      "Selected action  [0 4]\n",
      "[0 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 130us/step - loss: 11841.3125\n",
      "rewards:  129.0 q-value:  0\n",
      "loss: [11841.3125]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 151us/step - loss: 12354.6250\n",
      "rewards:  131.0 q-value:  0\n",
      "loss: [12354.625]\n",
      "Exploiting\n",
      "Selected action  [0 4]\n",
      "[0 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 165us/step - loss: 17709.5938\n",
      "rewards:  143.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [17709.59375]\n",
      "Exploring\n",
      "Selected action  [4 0]\n",
      "[4 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 137us/step - loss: 15007.9062\n",
      "rewards:  155.0 q-value:  0\n",
      "loss: [15007.90625]\n",
      "Exploring\n",
      "Selected action  [4 1]\n",
      "[4 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 147us/step - loss: 15060.1875\n",
      "rewards:  154.0 q-value:  0\n",
      "loss: [15060.1875]\n",
      "Exploring\n",
      "Selected action  [3 1]\n",
      "[3 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 121us/step - loss: 14752.9375\n",
      "rewards:  150.0 q-value:  0\n",
      "loss: [14752.9375]\n",
      "Exploiting\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 122us/step - loss: 13294.9062\n",
      "rewards:  123.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [13294.90625]\n",
      "Exploiting\n",
      "Selected action  [4 1]\n",
      "[4 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 136us/step - loss: 18476.2812\n",
      "rewards:  123.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [18476.28125]\n",
      "Exploiting\n",
      "Selected action  [0 4]\n",
      "[0 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 132us/step - loss: 8845.6250\n",
      "rewards:  103.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [8845.625]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 205us/step - loss: 22534.0000\n",
      "rewards:  98.0 q-value:  0\n",
      "loss: [22534.0]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 151us/step - loss: 10163.2812\n",
      "rewards:  78.0 q-value:  0\n",
      "loss: [10163.28125]\n",
      "Exploiting\n",
      "Selected action  [3 1]\n",
      "[3 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 136us/step - loss: 11331.7500\n",
      "rewards:  56.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [11331.75]\n",
      "Exploring\n",
      "Selected action  [0 4]\n",
      "[0 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 132us/step - loss: 11287.4375\n",
      "rewards:  36.0 q-value:  0\n",
      "loss: [11287.4375]\n",
      "Exploring\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 129us/step - loss: 20429.5312\n",
      "rewards:  52.0 q-value:  0\n",
      "loss: [20429.53125]\n",
      "Exploiting\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 193us/step - loss: 11185.0625\n",
      "rewards:  27.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [11185.0625]\n",
      "Exploring\n",
      "Selected action  [4 2]\n",
      "[4 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 134us/step - loss: 7348.4688\n",
      "rewards:  27.0 q-value:  0\n",
      "loss: [7348.46875]\n",
      "Exploring\n",
      "Selected action  [0 3]\n",
      "[0 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 135us/step - loss: 8648.6562\n",
      "rewards:  14.0 q-value:  0\n",
      "loss: [8648.65625]\n",
      "Exploring\n",
      "Selected action  [2 1]\n",
      "[2 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 128us/step - loss: 15647.5312\n",
      "rewards:  13.0 q-value:  0\n",
      "loss: [15647.53125]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 144us/step - loss: 13794.9062\n",
      "rewards:  8.0 q-value:  0\n",
      "loss: [13794.90625]\n",
      "Exploring\n",
      "Selected action  [4 1]\n",
      "[4 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 148us/step - loss: 11912.7188\n",
      "rewards:  11.0 q-value:  0\n",
      "loss: [11912.71875]\n",
      "Exploring\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 165us/step - loss: 10498.0312\n",
      "rewards:  15.0 q-value:  0\n",
      "loss: [10498.03125]\n",
      "Exploring\n",
      "Selected action  [2 0]\n",
      "[2 0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 143us/step - loss: 11122.1875\n",
      "rewards:  12.0 q-value:  0\n",
      "loss: [11122.1875]\n",
      "Exploiting\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 163us/step - loss: 15729.5938\n",
      "rewards:  7.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [15729.59375]\n",
      "Exploiting\n",
      "Selected action  [3 1]\n",
      "[3 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 144us/step - loss: 12709.9062\n",
      "rewards:  7.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [12709.90625]\n",
      "Exploiting\n",
      "Selected action  [3 1]\n",
      "[3 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 133us/step - loss: 9501.3438\n",
      "rewards:  7.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [9501.34375]\n",
      "Exploring\n",
      "Selected action  [1 0]\n",
      "[1 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 224us/step - loss: 11317.5000\n",
      "rewards:  15.0 q-value:  0\n",
      "loss: [11317.5]\n",
      "Exploring\n",
      "Selected action  [0 4]\n",
      "[0 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 133us/step - loss: 13718.2812\n",
      "rewards:  19.0 q-value:  0\n",
      "loss: [13718.28125]\n",
      "Exploiting\n",
      "Selected action  [4 0]\n",
      "[4 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 134us/step - loss: 13639.4375\n",
      "rewards:  51.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [13639.4375]\n",
      "Exploring\n",
      "Selected action  [2 4]\n",
      "[2 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 150us/step - loss: 11037.5312\n",
      "rewards:  45.0 q-value:  0\n",
      "loss: [11037.53125]\n",
      "Exploiting\n",
      "Selected action  [3 1]\n",
      "[3 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 122us/step - loss: 12142.7500\n",
      "rewards:  55.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [12142.75]\n",
      "Exploiting\n",
      "Selected action  [0 3]\n",
      "[0 3]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 183us/step - loss: 7236.2812\n",
      "rewards:  22.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [7236.28125]\n",
      "Exploiting\n",
      "Selected action  [4 2]\n",
      "[4 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 164us/step - loss: 9941.3438\n",
      "rewards:  11.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [9941.34375]\n",
      "Exploring\n",
      "Selected action  [4 2]\n",
      "[4 2]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 119us/step - loss: 20073.5938\n",
      "rewards:  9.0 q-value:  0\n",
      "loss: [20073.59375]\n",
      "Exploring\n",
      "Selected action  [3 1]\n",
      "[3 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 162us/step - loss: 18116.2812\n",
      "rewards:  -2.0 q-value:  0\n",
      "loss: [18116.28125]\n",
      "Exploiting\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 181us/step - loss: 10537.0938\n",
      "rewards:  -3.0 q-value:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "loss: [10537.09375]\n",
      "Exploring\n",
      "Selected action  [2 0]\n",
      "[2 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 165us/step - loss: 15071.0938\n",
      "rewards:  -9.0 q-value:  0\n",
      "loss: [15071.09375]\n",
      "Exploring\n",
      "Selected action  [3 1]\n",
      "[3 1]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 159us/step - loss: 19839.3125\n",
      "rewards:  -16.0 q-value:  0\n",
      "loss: [19839.3125]\n",
      "Exploring\n",
      "Selected action  [0 4]\n",
      "[0 4]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 184us/step - loss: 15654.5938\n",
      "rewards:  -47.0 q-value:  0\n",
      "loss: [15654.59375]\n",
      "Exploring\n",
      "Selected action  [0 0]\n",
      "[0 0]\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 204us/step - loss: 9774.2812\n",
      "rewards:  -52.0 q-value:  0\n",
      "loss: [9774.28125]\n"
     ]
    }
   ],
   "source": [
    " # Call all the initialised variables of the environment\n",
    "env = CabDriver()\n",
    "#Call the DQN agent\n",
    "dqn = DQNAgent(env.state_size, env.action_size)\n",
    "\n",
    "for episode in range(n_episodes):\n",
    "\n",
    "    # Write code here\n",
    "    # Call the environment\n",
    "   \n",
    "    _,_,curr_state = env.reset()\n",
    "    state_size = env.state_size\n",
    "    pos_act_ind, actions = env.requests(curr_state)\n",
    "    action = random.choice(actions)\n",
    "    #action_size = len(actions)\n",
    "    reward = 0\n",
    "    curr_time = 0\n",
    "    q_val_list = []\n",
    "    #print(curr_state)\n",
    "    \n",
    "    \n",
    "    terminal_state = False\n",
    "    print(\"Episode :\", episode)\n",
    "    \n",
    "    while not terminal_state:\n",
    "        # Write your code here\n",
    "        # 1. Pick epsilon-greedy action from possible actions for the current state\n",
    "        encoded_state = env.state_encod_arch1(curr_state)\n",
    "        #encoded_state = np.reshape(encoded_state, [1, env.state_size])\n",
    "        action, q_value = dqn.get_action(encoded_state, env.action_space, pos_act_ind)\n",
    "        # 2. Evaluate your reward and next state\n",
    "        reward = reward + env.reward_func(curr_state, action, Time_matrix)\n",
    "        next_state = env.next_state_func(curr_state,action,Time_matrix)\n",
    "        \n",
    "        q_val_list.append(q_value)\n",
    "        \n",
    "        p = action[0]\n",
    "        q = action[1]\n",
    "        i = curr_state[0]\n",
    "        time = curr_state[1]\n",
    "        day = curr_state[2]\n",
    "        print(action)\n",
    "        curr_time = curr_time + Time_matrix[i][p][time][day]\n",
    "        \n",
    "        \n",
    "        day = int((day+int(time/24)) % 7)\n",
    "        time = int(time % 24)\n",
    "        \n",
    "        curr_time = curr_time + Time_matrix[p][q][time][day]\n",
    "        day = int((day+int(time/24)) % 7)\n",
    "        time = int(time % 24)\n",
    "        # 3. Append the experience to the memory\n",
    "        dqn.append_sample(curr_state, action, reward, next_state, terminal_state)\n",
    "        curr_state = next_state\n",
    "        \n",
    "        # 4. Train the model by calling function agent.train_model\n",
    "        history = dqn.train_model()\n",
    "        # 5. Keep a track of rewards, Q-values, loss\n",
    "        \n",
    "        if history:\n",
    "            print('rewards: ', reward, 'q-value: ', q_value)\n",
    "            print('loss:', history.history['loss'])\n",
    "        \n",
    "        if curr_time >= 24*30:\n",
    "            terminal_state = True\n",
    "    \n",
    "        # store total reward obtained in this episode\n",
    "    rewards_per_episode.append(reward)\n",
    "    episodes.append(episode)\n",
    "        \n",
    "    if dqn.epsilon_max > dqn.epsilon_min:\n",
    "        dqn.epsilon_max *= dqn.epsilon_decay        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make directory\n",
    "if not os.path.exists(\"saved_pickle_files\"):\n",
    "    os.mkdir(\"saved_pickle_files\")\n",
    "\n",
    "# save rewards_per_episode\n",
    "save_pickle(rewards_per_episode, \"saved_pickle_files/rewards_per_episode\")\n",
    "\n",
    "\n",
    "# plot results\n",
    "with open('saved_pickle_files/rewards_per_episode.pkl', 'rb') as f:\n",
    "    rewards_per_episode = pickle.load(f)\n",
    "\n",
    "plt.plot(list(range(len(rewards_per_episode))), rewards_per_episode)\n",
    "plt.xlabel(\"episode number\")\n",
    "plt.ylabel(\"reward per episode\")\n",
    "\n",
    "# save plots in saved_plots/ directory\n",
    "plt.savefig('rewards.png')\n",
    "\n",
    "print(\"Average reward of last 100 episodes is {0}\".format(np.mean(rewards_per_episode[-100:])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tracking Convergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Epsilon-decay sample function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "Try building a similar epsilon-decay function for your model.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time = np.arange(0,10000)\n",
    "epsilon = []\n",
    "for i in range(0,10000):\n",
    "    epsilon.append(0 + (1 - 0) * np.exp(-0.0009*i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(time, epsilon)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
