{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## POS tagging using modified Viterbi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Importing libraries\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# reading the Treebank tagged sentences\n",
    "nltk_data = list(nltk.corpus.treebank.tagged_sents(tagset='universal'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('Pierre', 'NOUN'),\n",
       "  ('Vinken', 'NOUN'),\n",
       "  (',', '.'),\n",
       "  ('61', 'NUM'),\n",
       "  ('years', 'NOUN'),\n",
       "  ('old', 'ADJ'),\n",
       "  (',', '.'),\n",
       "  ('will', 'VERB'),\n",
       "  ('join', 'VERB'),\n",
       "  ('the', 'DET'),\n",
       "  ('board', 'NOUN'),\n",
       "  ('as', 'ADP'),\n",
       "  ('a', 'DET'),\n",
       "  ('nonexecutive', 'ADJ'),\n",
       "  ('director', 'NOUN'),\n",
       "  ('Nov.', 'NOUN'),\n",
       "  ('29', 'NUM'),\n",
       "  ('.', '.')],\n",
       " [('Mr.', 'NOUN'),\n",
       "  ('Vinken', 'NOUN'),\n",
       "  ('is', 'VERB'),\n",
       "  ('chairman', 'NOUN'),\n",
       "  ('of', 'ADP'),\n",
       "  ('Elsevier', 'NOUN'),\n",
       "  ('N.V.', 'NOUN'),\n",
       "  (',', '.'),\n",
       "  ('the', 'DET'),\n",
       "  ('Dutch', 'NOUN'),\n",
       "  ('publishing', 'VERB'),\n",
       "  ('group', 'NOUN'),\n",
       "  ('.', '.')],\n",
       " [('Rudolph', 'NOUN'),\n",
       "  ('Agnew', 'NOUN'),\n",
       "  (',', '.'),\n",
       "  ('55', 'NUM'),\n",
       "  ('years', 'NOUN'),\n",
       "  ('old', 'ADJ'),\n",
       "  ('and', 'CONJ'),\n",
       "  ('former', 'ADJ'),\n",
       "  ('chairman', 'NOUN'),\n",
       "  ('of', 'ADP'),\n",
       "  ('Consolidated', 'NOUN'),\n",
       "  ('Gold', 'NOUN'),\n",
       "  ('Fields', 'NOUN'),\n",
       "  ('PLC', 'NOUN'),\n",
       "  (',', '.'),\n",
       "  ('was', 'VERB'),\n",
       "  ('named', 'VERB'),\n",
       "  ('*-1', 'X'),\n",
       "  ('a', 'DET'),\n",
       "  ('nonexecutive', 'ADJ'),\n",
       "  ('director', 'NOUN'),\n",
       "  ('of', 'ADP'),\n",
       "  ('this', 'DET'),\n",
       "  ('British', 'ADJ'),\n",
       "  ('industrial', 'ADJ'),\n",
       "  ('conglomerate', 'NOUN'),\n",
       "  ('.', '.')],\n",
       " [('A', 'DET'),\n",
       "  ('form', 'NOUN'),\n",
       "  ('of', 'ADP'),\n",
       "  ('asbestos', 'NOUN'),\n",
       "  ('once', 'ADV'),\n",
       "  ('used', 'VERB'),\n",
       "  ('*', 'X'),\n",
       "  ('*', 'X'),\n",
       "  ('to', 'PRT'),\n",
       "  ('make', 'VERB'),\n",
       "  ('Kent', 'NOUN'),\n",
       "  ('cigarette', 'NOUN'),\n",
       "  ('filters', 'NOUN'),\n",
       "  ('has', 'VERB'),\n",
       "  ('caused', 'VERB'),\n",
       "  ('a', 'DET'),\n",
       "  ('high', 'ADJ'),\n",
       "  ('percentage', 'NOUN'),\n",
       "  ('of', 'ADP'),\n",
       "  ('cancer', 'NOUN'),\n",
       "  ('deaths', 'NOUN'),\n",
       "  ('among', 'ADP'),\n",
       "  ('a', 'DET'),\n",
       "  ('group', 'NOUN'),\n",
       "  ('of', 'ADP'),\n",
       "  ('workers', 'NOUN'),\n",
       "  ('exposed', 'VERB'),\n",
       "  ('*', 'X'),\n",
       "  ('to', 'PRT'),\n",
       "  ('it', 'PRON'),\n",
       "  ('more', 'ADV'),\n",
       "  ('than', 'ADP'),\n",
       "  ('30', 'NUM'),\n",
       "  ('years', 'NOUN'),\n",
       "  ('ago', 'ADP'),\n",
       "  (',', '.'),\n",
       "  ('researchers', 'NOUN'),\n",
       "  ('reported', 'VERB'),\n",
       "  ('0', 'X'),\n",
       "  ('*T*-1', 'X'),\n",
       "  ('.', '.')],\n",
       " [('The', 'DET'),\n",
       "  ('asbestos', 'NOUN'),\n",
       "  ('fiber', 'NOUN'),\n",
       "  (',', '.'),\n",
       "  ('crocidolite', 'NOUN'),\n",
       "  (',', '.'),\n",
       "  ('is', 'VERB'),\n",
       "  ('unusually', 'ADV'),\n",
       "  ('resilient', 'ADJ'),\n",
       "  ('once', 'ADP'),\n",
       "  ('it', 'PRON'),\n",
       "  ('enters', 'VERB'),\n",
       "  ('the', 'DET'),\n",
       "  ('lungs', 'NOUN'),\n",
       "  (',', '.'),\n",
       "  ('with', 'ADP'),\n",
       "  ('even', 'ADV'),\n",
       "  ('brief', 'ADJ'),\n",
       "  ('exposures', 'NOUN'),\n",
       "  ('to', 'PRT'),\n",
       "  ('it', 'PRON'),\n",
       "  ('causing', 'VERB'),\n",
       "  ('symptoms', 'NOUN'),\n",
       "  ('that', 'DET'),\n",
       "  ('*T*-1', 'X'),\n",
       "  ('show', 'VERB'),\n",
       "  ('up', 'PRT'),\n",
       "  ('decades', 'NOUN'),\n",
       "  ('later', 'ADJ'),\n",
       "  (',', '.'),\n",
       "  ('researchers', 'NOUN'),\n",
       "  ('said', 'VERB'),\n",
       "  ('0', 'X'),\n",
       "  ('*T*-2', 'X'),\n",
       "  ('.', '.')]]"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk_data[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100676\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('Pierre', 'NOUN'),\n",
       " ('Vinken', 'NOUN'),\n",
       " (',', '.'),\n",
       " ('61', 'NUM'),\n",
       " ('years', 'NOUN'),\n",
       " ('old', 'ADJ'),\n",
       " (',', '.'),\n",
       " ('will', 'VERB'),\n",
       " ('join', 'VERB'),\n",
       " ('the', 'DET')]"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# converting the list of sents to a list of (word, pos tag) tuples\n",
    "tagged_words = [tup for sent in nltk_data for tup in sent]\n",
    "print(len(tagged_words))\n",
    "tagged_words[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3718\n",
      "196\n",
      "[[('They', 'PRON'), ('argue', 'VERB'), ('that', 'ADP'), ('U.S.', 'NOUN'), ('investors', 'NOUN'), ('often', 'ADV'), ('can', 'VERB'), ('buy', 'VERB'), ('American', 'ADJ'), ('depositary', 'ADJ'), ('receipts', 'NOUN'), ('on', 'ADP'), ('the', 'DET'), ('big', 'ADJ'), ('stocks', 'NOUN'), ('in', 'ADP'), ('many', 'ADJ'), ('funds', 'NOUN'), (';', '.'), ('these', 'DET'), ('so-called', 'ADJ'), ('ADRs', 'NOUN'), ('represent', 'VERB'), ('shares', 'NOUN'), ('of', 'ADP'), ('foreign', 'ADJ'), ('companies', 'NOUN'), ('traded', 'VERB'), ('*', 'X'), ('in', 'ADP'), ('the', 'DET'), ('U.S.', 'NOUN'), ('.', '.')], [('Mr.', 'NOUN'), ('Stearn', 'NOUN'), (',', '.'), ('who', 'PRON'), ('*T*-196', 'X'), ('had', 'VERB'), ('been', 'VERB'), ('with', 'ADP'), ('the', 'DET'), ('company', 'NOUN'), ('more', 'ADJ'), ('than', 'ADP'), ('20', 'NUM'), ('years', 'NOUN'), ('and', 'CONJ'), ('had', 'VERB'), ('been', 'VERB'), ('president', 'NOUN'), ('since', 'ADP'), ('1984', 'NUM'), (',', '.'), ('will', 'VERB'), ('act', 'VERB'), ('as', 'ADP'), ('a', 'DET'), ('consultant', 'NOUN'), ('to', 'PRT'), ('Hudson', 'NOUN'), ('General', 'NOUN'), ('.', '.')]]\n"
     ]
    }
   ],
   "source": [
    "# Splitting into train and test\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "random.seed(1234)\n",
    "train_set, test_set = train_test_split(nltk_data,test_size=0.05)\n",
    "\n",
    "print(len(train_set))\n",
    "print(len(test_set))\n",
    "print(train_set[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "95610"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting list of tagged words\n",
    "train_tagged_words = [tup for sent in train_set for tup in sent]\n",
    "len(train_tagged_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['They', 'argue', 'that', 'U.S.', 'investors']"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tokens \n",
    "tokens = [pair[0] for pair in train_tagged_words]\n",
    "tokens[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12075\n"
     ]
    }
   ],
   "source": [
    "# vocabulary\n",
    "V = set(tokens)\n",
    "print(len(V))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of tags\n",
    "T = set([pair[1] for pair in train_tagged_words])\n",
    "len(T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the vanilla Viterbi based POS tagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# computing P(w/t) and storing in T x V matrix\n",
    "t = len(T)\n",
    "v = len(V)\n",
    "w_given_t = np.zeros((t, v))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# compute word given tag: Emission Probability\n",
    "def word_given_tag(word, tag, train_bag = train_tagged_words):\n",
    "    tag_list = [pair for pair in train_bag if pair[1]==tag]\n",
    "    count_tag = len(tag_list)\n",
    "    w_given_tag_list = [pair[0] for pair in tag_list if pair[0]==word]\n",
    "    count_w_given_tag = len(w_given_tag_list)\n",
    "    \n",
    "    return (count_w_given_tag, count_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# compute tag given tag: tag2(t2) given tag1 (t1), i.e. Transition Probability\n",
    "\n",
    "def t2_given_t1(t2, t1, train_bag = train_tagged_words):\n",
    "    tags = [pair[1] for pair in train_bag]\n",
    "    count_t1 = len([t for t in tags if t==t1])\n",
    "    count_t2_t1 = 0\n",
    "    for index in range(len(tags)-1):\n",
    "        if tags[index]==t1 and tags[index+1] == t2:\n",
    "            count_t2_t1 += 1\n",
    "    return (count_t2_t1, count_t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# creating t x t transition matrix of tags\n",
    "# each column is t2, each row is t1\n",
    "# thus M(i, j) represents P(tj given ti)\n",
    "\n",
    "tags_matrix = np.zeros((len(T), len(T)), dtype='float32')\n",
    "for i, t1 in enumerate(list(T)):\n",
    "    for j, t2 in enumerate(list(T)): \n",
    "        tags_matrix[i, j] = t2_given_t1(t2, t1)[0]/t2_given_t1(t2, t1)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# convert the matrix to a df for better readability\n",
    "tags_df = pd.DataFrame(tags_matrix, columns = list(T), index=list(T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Viterbi Heuristic\n",
    "def Viterbi(words, train_bag = train_tagged_words):\n",
    "    state = []\n",
    "    T = list(set([pair[1] for pair in train_bag]))\n",
    "    \n",
    "    for key, word in enumerate(words):\n",
    "        #initialise list of probability column for a given observation\n",
    "        p = [] \n",
    "        for tag in T:\n",
    "            if key == 0:\n",
    "                transition_p = tags_df.loc['.', tag]\n",
    "            else:\n",
    "                transition_p = tags_df.loc[state[-1], tag]\n",
    "                \n",
    "            # compute emission and state probabilities\n",
    "            emission_p = word_given_tag(words[key], tag)[0]/word_given_tag(words[key], tag)[1]\n",
    "            state_probability = emission_p * transition_p    \n",
    "            p.append(state_probability)\n",
    "            \n",
    "        pmax = max(p)\n",
    "        # getting state for which probability is maximum\n",
    "        state_max = T[p.index(pmax)] \n",
    "        state.append(state_max)\n",
    "    return list(zip(words, state))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Running on entire test dataset would take more than 3-4hrs. \n",
    "# Let's test our Viterbi algorithm on a few sample sentences of test dataset\n",
    "\n",
    "random.seed(1234)\n",
    "\n",
    "# choose random 5 sents\n",
    "rndom = [random.randint(1,len(test_set)) for x in range(5)]\n",
    "\n",
    "# list of sents\n",
    "test_run = [test_set[i] for i in rndom]\n",
    "\n",
    "# list of tagged words\n",
    "test_run_base = [tup for sent in test_run for tup in sent]\n",
    "\n",
    "# list of untagged words\n",
    "test_tagged_words = [tup[0] for sent in test_run for tup in sent]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tagged_seq_viterbi = Viterbi(test_tagged_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solve the problem of unknown words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First solution by handling all unknowns as nouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Viterbi Heuristic with handle for unknown words\n",
    "def Viterbi_handle_unknown(words, train_bag = train_tagged_words):\n",
    "    state = []\n",
    "    T = list(set([pair[1] for pair in train_bag]))\n",
    "    \n",
    "    for key, word in enumerate(words):\n",
    "        #initialise list of probability column for a given observation\n",
    "        p = [] \n",
    "        for tag in T:\n",
    "            if key == 0:\n",
    "                transition_p = tags_df.loc['.', tag]\n",
    "            else:\n",
    "                transition_p = tags_df.loc[state[-1], tag]\n",
    "\n",
    "            # compute emission and state probabilities\n",
    "            emission_p = word_given_tag(words[key], tag)[0]/word_given_tag(words[key], tag)[1]\n",
    "            state_probability = emission_p * transition_p    \n",
    "            p.append(state_probability)\n",
    "\n",
    "        pmax = max(p)\n",
    "        # getting state for which probability is maximum\n",
    "        state_max = T[p.index(pmax)] \n",
    "        state.append(state_max)\n",
    "    viterbi_expression = list(zip(words, state))\n",
    "    handled_viterbi_expression = []\n",
    "    #identifying words that are not there in the training set and assigning noun tag since most of the nouns will be missed\n",
    "    for word, state in viterbi_expression:\n",
    "        if word in tokens:\n",
    "            handled_viterbi_expression.append((word,state))\n",
    "        else:\n",
    "            handled_viterbi_expression.append((word,'NOUN'))\n",
    "    return handled_viterbi_expression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Running on entire test dataset would take more than 3-4hrs. \n",
    "# Let's test our Viterbi algorithm on a few sample sentences of test dataset\n",
    "\n",
    "random.seed(1234)\n",
    "\n",
    "# choose random 5 sents\n",
    "rndom = [random.randint(1,len(test_set)) for x in range(5)]\n",
    "\n",
    "# list of sents\n",
    "test_run = [test_set[i] for i in rndom]\n",
    "\n",
    "# list of tagged words\n",
    "test_run_base = [tup for sent in test_run for tup in sent]\n",
    "\n",
    "# list of untagged words\n",
    "test_tagged_words = [tup[0] for sent in test_run for tup in sent]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tagged_seq_viterbi_handle_unknown = Viterbi_handle_unknown(test_tagged_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Second solution by using combination of lexicon and rule based"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lexicon(Unigram) Tagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9030793525463877"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lexicon (or unigram tagger)\n",
    "unigram_tagger = nltk.UnigramTagger(train_set)\n",
    "unigram_tagger.evaluate(test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rule based Tagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# specify patterns for tagging\n",
    "# example from the NLTK book\n",
    "patterns = [\n",
    "    (r'.*ing$', 'VERB'),              # gerund\n",
    "    (r'.*ed$', 'VERB'),               # past tense\n",
    "    (r'.*es$', 'VERB'),               # 3rd singular present\n",
    "    (r'.*ould$', 'VERB'),              # modals\n",
    "    (r'.*\\'s$', 'NOUN$'),              # possessive nouns\n",
    "    (r'.*s$', 'NOUN'),                # plural nouns\n",
    "    (r'^-?[0-9]+(.[0-9]+)?$', 'NUM'), # cardinal numbers\n",
    "    (r'.*', 'NOUN')                    # nouns\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "regexp_tagger = nltk.RegexpTagger(patterns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3337939202526648"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regexp_tagger.evaluate(test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluating tagging accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy of Vanila Viterbi Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8833333333333333"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# accuracy\n",
    "check = [i for i, j in zip(tagged_seq_viterbi, test_run_base) if i == j] \n",
    "accuracy = len(check)/len(tagged_seq_viterbi)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy of tagger with unknown words tagged as nouns as most of the nouns are wrongly tagged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# accuracy\n",
    "check = [i for i, j in zip(tagged_seq_viterbi_handle_unknown, test_run_base) if i == j] \n",
    "accuracy = len(check)/len(tagged_seq_viterbi_handle_unknown)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy of two taggers combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9476904855902092"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# rule based tagger\n",
    "rule_based_tagger = nltk.RegexpTagger(patterns)\n",
    "\n",
    "# lexicon backed up by the rule-based tagger\n",
    "lexicon_tagger = nltk.UnigramTagger(train_set, backoff=rule_based_tagger)\n",
    "\n",
    "lexicon_tagger.evaluate(test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare the tagging accuracies of the modifications with the vanilla Viterbi algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tagging Accuracy of multiple Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vanila Viterbi Algorithm:  [('Android', 'PRT'), ('is', 'VERB'), ('a', 'DET'), ('mobile', 'ADJ'), ('operating', 'NOUN'), ('system', 'NOUN'), ('developed', 'VERB'), ('by', 'ADP'), ('Google', 'PRT'), ('.', '.')]\n",
      "-----------------------------------------------\n",
      "Viterbi Algorithm with unknown handled:  [('Android', 'NOUN'), ('is', 'VERB'), ('a', 'DET'), ('mobile', 'ADJ'), ('operating', 'NOUN'), ('system', 'NOUN'), ('developed', 'VERB'), ('by', 'ADP'), ('Google', 'NOUN'), ('.', '.')]\n",
      "-----------------------------------------------\n",
      "Lexicon tagger:  [[('Android', 'NOUN'), ('is', 'VERB'), ('a', 'DET'), ('mobile', 'ADJ'), ('operating', 'NOUN'), ('system', 'NOUN'), ('developed', 'VERB'), ('by', 'ADP'), ('Google', 'NOUN'), ('.', '.')]]\n",
      "-----------------------------------------------\n",
      "*************************************************************************************************\n",
      "Vanila Viterbi Algorithm:  [('Android', 'PRT'), ('has', 'VERB'), ('been', 'VERB'), ('the', 'DET'), ('best-selling', 'ADJ'), ('OS', 'PRT'), ('worldwide', 'PRT'), ('on', 'ADP'), ('smartphones', 'PRT'), ('since', 'ADP'), ('2011', 'PRT'), ('and', 'CONJ'), ('on', 'ADP'), ('tablets', 'NOUN'), ('since', 'ADP'), ('2013', 'PRT'), ('.', '.')]\n",
      "-----------------------------------------------\n",
      "Viterbi Algorithm with unknown handled:  [('Android', 'NOUN'), ('has', 'VERB'), ('been', 'VERB'), ('the', 'DET'), ('best-selling', 'ADJ'), ('OS', 'NOUN'), ('worldwide', 'NOUN'), ('on', 'ADP'), ('smartphones', 'NOUN'), ('since', 'ADP'), ('2011', 'NOUN'), ('and', 'CONJ'), ('on', 'ADP'), ('tablets', 'NOUN'), ('since', 'ADP'), ('2013', 'NOUN'), ('.', '.')]\n",
      "-----------------------------------------------\n",
      "Lexicon tagger:  [[('Android', 'NOUN'), ('has', 'VERB'), ('been', 'VERB'), ('the', 'DET'), ('best-selling', 'ADJ'), ('OS', 'NOUN'), ('worldwide', 'NOUN'), ('on', 'ADP'), ('smartphones', 'VERB'), ('since', 'ADP'), ('2011', 'NUM'), ('and', 'CONJ'), ('on', 'ADP'), ('tablets', 'NOUN'), ('since', 'ADP'), ('2013', 'NUM'), ('.', '.')]]\n",
      "-----------------------------------------------\n",
      "*************************************************************************************************\n",
      "Vanila Viterbi Algorithm:  [('Google', 'PRT'), ('and', 'CONJ'), ('Twitter', 'PRT'), ('made', 'VERB'), ('a', 'DET'), ('deal', 'NOUN'), ('in', 'ADP'), ('2015', 'PRT'), ('that', 'DET'), ('gave', 'VERB'), ('Google', 'PRT'), ('access', 'NOUN'), ('to', 'PRT'), ('Twitter', 'PRT'), (\"'s\", 'VERB'), ('firehose', 'PRT'), ('.', '.')]\n",
      "-----------------------------------------------\n",
      "Viterbi Algorithm with unknown handled:  [('Google', 'NOUN'), ('and', 'CONJ'), ('Twitter', 'NOUN'), ('made', 'VERB'), ('a', 'DET'), ('deal', 'NOUN'), ('in', 'ADP'), ('2015', 'NOUN'), ('that', 'DET'), ('gave', 'VERB'), ('Google', 'NOUN'), ('access', 'NOUN'), ('to', 'PRT'), ('Twitter', 'NOUN'), (\"'s\", 'VERB'), ('firehose', 'NOUN'), ('.', '.')]\n",
      "-----------------------------------------------\n",
      "Lexicon tagger:  [[('Google', 'NOUN'), ('and', 'CONJ'), ('Twitter', 'NOUN'), ('made', 'VERB'), ('a', 'DET'), ('deal', 'NOUN'), ('in', 'ADP'), ('2015', 'NUM'), ('that', 'ADP'), ('gave', 'VERB'), ('Google', 'NOUN'), ('access', 'NOUN'), ('to', 'PRT'), ('Twitter', 'NOUN'), (\"'s\", 'PRT'), ('firehose', 'NOUN'), ('.', '.')]]\n",
      "-----------------------------------------------\n",
      "*************************************************************************************************\n",
      "Vanila Viterbi Algorithm:  [('Twitter', 'PRT'), ('is', 'VERB'), ('an', 'DET'), ('online', 'PRT'), ('news', 'NOUN'), ('and', 'CONJ'), ('social', 'ADJ'), ('networking', 'NOUN'), ('service', 'NOUN'), ('on', 'ADP'), ('which', 'DET'), ('users', 'NOUN'), ('post', 'NOUN'), ('and', 'CONJ'), ('interact', 'PRT'), ('with', 'ADP'), ('messages', 'PRT'), ('known', 'VERB'), ('as', 'ADP'), ('tweets', 'PRT'), ('.', '.')]\n",
      "-----------------------------------------------\n",
      "Viterbi Algorithm with unknown handled:  [('Twitter', 'NOUN'), ('is', 'VERB'), ('an', 'DET'), ('online', 'NOUN'), ('news', 'NOUN'), ('and', 'CONJ'), ('social', 'ADJ'), ('networking', 'NOUN'), ('service', 'NOUN'), ('on', 'ADP'), ('which', 'DET'), ('users', 'NOUN'), ('post', 'NOUN'), ('and', 'CONJ'), ('interact', 'NOUN'), ('with', 'ADP'), ('messages', 'NOUN'), ('known', 'VERB'), ('as', 'ADP'), ('tweets', 'NOUN'), ('.', '.')]\n",
      "-----------------------------------------------\n",
      "Lexicon tagger:  [[('Twitter', 'NOUN'), ('is', 'VERB'), ('an', 'DET'), ('online', 'NOUN'), ('news', 'NOUN'), ('and', 'CONJ'), ('social', 'ADJ'), ('networking', 'NOUN'), ('service', 'NOUN'), ('on', 'ADP'), ('which', 'DET'), ('users', 'NOUN'), ('post', 'NOUN'), ('and', 'CONJ'), ('interact', 'NOUN'), ('with', 'ADP'), ('messages', 'VERB'), ('known', 'VERB'), ('as', 'ADP'), ('tweets', 'NOUN'), ('.', '.')]]\n",
      "-----------------------------------------------\n",
      "*************************************************************************************************\n",
      "Vanila Viterbi Algorithm:  [('Before', 'ADP'), ('entering', 'VERB'), ('politics', 'NOUN'), (',', '.'), ('Donald', 'NOUN'), ('Trump', 'NOUN'), ('was', 'VERB'), ('a', 'DET'), ('domineering', 'PRT'), ('businessman', 'NOUN'), ('and', 'CONJ'), ('a', 'DET'), ('television', 'NOUN'), ('personality', 'PRT'), ('.', '.')]\n",
      "-----------------------------------------------\n",
      "Viterbi Algorithm with unknown handled:  [('Before', 'ADP'), ('entering', 'VERB'), ('politics', 'NOUN'), (',', '.'), ('Donald', 'NOUN'), ('Trump', 'NOUN'), ('was', 'VERB'), ('a', 'DET'), ('domineering', 'NOUN'), ('businessman', 'NOUN'), ('and', 'CONJ'), ('a', 'DET'), ('television', 'NOUN'), ('personality', 'NOUN'), ('.', '.')]\n",
      "-----------------------------------------------\n",
      "Lexicon tagger:  [[('Before', 'ADP'), ('entering', 'VERB'), ('politics', 'NOUN'), (',', '.'), ('Donald', 'NOUN'), ('Trump', 'NOUN'), ('was', 'VERB'), ('a', 'DET'), ('domineering', 'VERB'), ('businessman', 'NOUN'), ('and', 'CONJ'), ('a', 'DET'), ('television', 'NOUN'), ('personality', 'NOUN'), ('.', '.')]]\n",
      "-----------------------------------------------\n",
      "*************************************************************************************************\n",
      "Vanila Viterbi Algorithm:  [('The', 'DET'), ('2018', 'PRT'), ('FIFA', 'PRT'), ('World', 'NOUN'), ('Cup', 'PRT'), ('is', 'VERB'), ('the', 'DET'), ('21st', 'PRT'), ('FIFA', 'PRT'), ('World', 'NOUN'), ('Cup', 'PRT'), (',', '.'), ('an', 'DET'), ('international', 'ADJ'), ('football', 'NOUN'), ('tournament', 'PRT'), ('contested', 'PRT'), ('once', 'ADV'), ('every', 'DET'), ('four', 'NUM'), ('years', 'NOUN'), ('.', '.')]\n",
      "-----------------------------------------------\n",
      "Viterbi Algorithm with unknown handled:  [('The', 'DET'), ('2018', 'NOUN'), ('FIFA', 'NOUN'), ('World', 'NOUN'), ('Cup', 'NOUN'), ('is', 'VERB'), ('the', 'DET'), ('21st', 'NOUN'), ('FIFA', 'NOUN'), ('World', 'NOUN'), ('Cup', 'NOUN'), (',', '.'), ('an', 'DET'), ('international', 'ADJ'), ('football', 'NOUN'), ('tournament', 'NOUN'), ('contested', 'NOUN'), ('once', 'ADV'), ('every', 'DET'), ('four', 'NUM'), ('years', 'NOUN'), ('.', '.')]\n",
      "-----------------------------------------------\n",
      "Lexicon tagger:  [[('The', 'DET'), ('2018', 'NUM'), ('FIFA', 'NOUN'), ('World', 'NOUN'), ('Cup', 'NOUN'), ('is', 'VERB'), ('the', 'DET'), ('21st', 'NOUN'), ('FIFA', 'NOUN'), ('World', 'NOUN'), ('Cup', 'NOUN'), (',', '.'), ('an', 'DET'), ('international', 'ADJ'), ('football', 'NOUN'), ('tournament', 'NOUN'), ('contested', 'VERB'), ('once', 'ADV'), ('every', 'DET'), ('four', 'NUM'), ('years', 'NOUN'), ('.', '.')]]\n",
      "-----------------------------------------------\n",
      "*************************************************************************************************\n",
      "Vanila Viterbi Algorithm:  [('This', 'DET'), ('is', 'VERB'), ('the', 'DET'), ('first', 'ADJ'), ('World', 'NOUN'), ('Cup', 'PRT'), ('to', 'PRT'), ('be', 'VERB'), ('held', 'VERB'), ('in', 'ADP'), ('Eastern', 'NOUN'), ('Europe', 'NOUN'), ('and', 'CONJ'), ('the', 'DET'), ('11th', 'ADJ'), ('time', 'NOUN'), ('that', 'ADP'), ('it', 'PRON'), ('has', 'VERB'), ('been', 'VERB'), ('held', 'VERB'), ('in', 'ADP'), ('Europe', 'NOUN'), ('.', '.')]\n",
      "-----------------------------------------------\n",
      "Viterbi Algorithm with unknown handled:  [('This', 'DET'), ('is', 'VERB'), ('the', 'DET'), ('first', 'ADJ'), ('World', 'NOUN'), ('Cup', 'NOUN'), ('to', 'PRT'), ('be', 'VERB'), ('held', 'VERB'), ('in', 'ADP'), ('Eastern', 'NOUN'), ('Europe', 'NOUN'), ('and', 'CONJ'), ('the', 'DET'), ('11th', 'ADJ'), ('time', 'NOUN'), ('that', 'ADP'), ('it', 'PRON'), ('has', 'VERB'), ('been', 'VERB'), ('held', 'VERB'), ('in', 'ADP'), ('Europe', 'NOUN'), ('.', '.')]\n",
      "-----------------------------------------------\n",
      "Lexicon tagger:  [[('This', 'DET'), ('is', 'VERB'), ('the', 'DET'), ('first', 'ADJ'), ('World', 'NOUN'), ('Cup', 'NOUN'), ('to', 'PRT'), ('be', 'VERB'), ('held', 'VERB'), ('in', 'ADP'), ('Eastern', 'NOUN'), ('Europe', 'NOUN'), ('and', 'CONJ'), ('the', 'DET'), ('11th', 'ADJ'), ('time', 'NOUN'), ('that', 'ADP'), ('it', 'PRON'), ('has', 'VERB'), ('been', 'VERB'), ('held', 'VERB'), ('in', 'ADP'), ('Europe', 'NOUN'), ('.', '.')]]\n",
      "-----------------------------------------------\n",
      "*************************************************************************************************\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vanila Viterbi Algorithm:  [('Show', 'NOUN'), ('me', 'PRON'), ('the', 'DET'), ('cheapest', 'ADJ'), ('round', 'NOUN'), ('trips', 'PRT'), ('from', 'ADP'), ('Dallas', 'NOUN'), ('to', 'PRT'), ('Atlanta', 'NOUN'), ('I', 'PRON'), ('would', 'VERB'), ('like', 'ADP'), ('to', 'PRT'), ('see', 'VERB'), ('flights', 'NOUN'), ('from', 'ADP'), ('Denver', 'NOUN'), ('to', 'PRT'), ('Philadelphia', 'NOUN'), ('.', '.')]\n",
      "-----------------------------------------------\n",
      "Viterbi Algorithm with unknown handled:  [('Show', 'NOUN'), ('me', 'PRON'), ('the', 'DET'), ('cheapest', 'ADJ'), ('round', 'NOUN'), ('trips', 'NOUN'), ('from', 'ADP'), ('Dallas', 'NOUN'), ('to', 'PRT'), ('Atlanta', 'NOUN'), ('I', 'PRON'), ('would', 'VERB'), ('like', 'ADP'), ('to', 'PRT'), ('see', 'VERB'), ('flights', 'NOUN'), ('from', 'ADP'), ('Denver', 'NOUN'), ('to', 'PRT'), ('Philadelphia', 'NOUN'), ('.', '.')]\n",
      "-----------------------------------------------\n",
      "Lexicon tagger:  [[('Show', 'NOUN'), ('me', 'PRON'), ('the', 'DET'), ('cheapest', 'ADJ'), ('round', 'NOUN'), ('trips', 'NOUN'), ('from', 'ADP'), ('Dallas', 'NOUN'), ('to', 'PRT'), ('Atlanta', 'NOUN'), ('I', 'PRON'), ('would', 'VERB'), ('like', 'ADP'), ('to', 'PRT'), ('see', 'VERB'), ('flights', 'NOUN'), ('from', 'ADP'), ('Denver', 'NOUN'), ('to', 'PRT'), ('Philadelphia', 'NOUN'), ('.', '.')]]\n",
      "-----------------------------------------------\n",
      "*************************************************************************************************\n",
      "Vanila Viterbi Algorithm:  [('Show', 'NOUN'), ('me', 'PRON'), ('the', 'DET'), ('price', 'NOUN'), ('of', 'ADP'), ('the', 'DET'), ('flights', 'NOUN'), ('leaving', 'VERB'), ('Atlanta', 'NOUN'), ('at', 'ADP'), ('about', 'ADP'), ('3', 'NUM'), ('in', 'ADP'), ('the', 'DET'), ('afternoon', 'NOUN'), ('and', 'CONJ'), ('arriving', 'PRT'), ('in', 'ADP'), ('San', 'NOUN'), ('Francisco', 'NOUN'), ('.', '.')]\n",
      "-----------------------------------------------\n",
      "Viterbi Algorithm with unknown handled:  [('Show', 'NOUN'), ('me', 'PRON'), ('the', 'DET'), ('price', 'NOUN'), ('of', 'ADP'), ('the', 'DET'), ('flights', 'NOUN'), ('leaving', 'VERB'), ('Atlanta', 'NOUN'), ('at', 'ADP'), ('about', 'ADP'), ('3', 'NUM'), ('in', 'ADP'), ('the', 'DET'), ('afternoon', 'NOUN'), ('and', 'CONJ'), ('arriving', 'NOUN'), ('in', 'ADP'), ('San', 'NOUN'), ('Francisco', 'NOUN'), ('.', '.')]\n",
      "-----------------------------------------------\n",
      "Lexicon tagger:  [[('Show', 'NOUN'), ('me', 'PRON'), ('the', 'DET'), ('price', 'NOUN'), ('of', 'ADP'), ('the', 'DET'), ('flights', 'NOUN'), ('leaving', 'VERB'), ('Atlanta', 'NOUN'), ('at', 'ADP'), ('about', 'ADP'), ('3', 'NUM'), ('in', 'ADP'), ('the', 'DET'), ('afternoon', 'NOUN'), ('and', 'CONJ'), ('arriving', 'VERB'), ('in', 'ADP'), ('San', 'NOUN'), ('Francisco', 'NOUN'), ('.', '.')]]\n",
      "-----------------------------------------------\n",
      "*************************************************************************************************\n",
      "Vanila Viterbi Algorithm:  [('NASA', 'PRT'), ('invited', 'PRT'), ('social', 'ADJ'), ('media', 'NOUN'), ('users', 'NOUN'), ('to', 'PRT'), ('experience', 'NOUN'), ('the', 'DET'), ('launch', 'NOUN'), ('of', 'ADP'), ('ICESAT-2', 'PRT'), ('Satellite', 'PRT'), ('.', '.')]\n",
      "-----------------------------------------------\n",
      "Viterbi Algorithm with unknown handled:  [('NASA', 'NOUN'), ('invited', 'NOUN'), ('social', 'ADJ'), ('media', 'NOUN'), ('users', 'NOUN'), ('to', 'PRT'), ('experience', 'NOUN'), ('the', 'DET'), ('launch', 'NOUN'), ('of', 'ADP'), ('ICESAT-2', 'NOUN'), ('Satellite', 'NOUN'), ('.', '.')]\n",
      "-----------------------------------------------\n",
      "Lexicon tagger:  [[('NASA', 'NOUN'), ('invited', 'VERB'), ('social', 'ADJ'), ('media', 'NOUN'), ('users', 'NOUN'), ('to', 'PRT'), ('experience', 'NOUN'), ('the', 'DET'), ('launch', 'NOUN'), ('of', 'ADP'), ('ICESAT-2', 'NOUN'), ('Satellite', 'NOUN'), ('.', '.')]]\n",
      "-----------------------------------------------\n",
      "*************************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "## Testing\n",
    "from nltk.tokenize import word_tokenize\n",
    "sentences = nltk.sent_tokenize(open('Test_sentences.txt').read())\n",
    "for sentence in sentences:\n",
    "    words = word_tokenize(sentence)\n",
    "    tagged_seq_sent_viterbi = Viterbi(words)\n",
    "    tagged_seq_sent_handle_unk = Viterbi_handle_unknown(words)\n",
    "    tagged_seq_sent_lexicon = lexicon_tagger.tag_sents([words])\n",
    "    print(\"Vanila Viterbi Algorithm: \",tagged_seq_sent_viterbi)\n",
    "    print(\"-----------------------------------------------\")\n",
    "    print(\"Viterbi Algorithm with unknown handled: \",tagged_seq_sent_handle_unk)\n",
    "    print(\"-----------------------------------------------\")\n",
    "    print(\"Lexicon tagger: \",tagged_seq_sent_lexicon)\n",
    "    print(\"-----------------------------------------------\")\n",
    "    print(\"*************************************************************************************************\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List down cases which were incorrectly tagged by original POS tagger and got corrected by your modifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence  1  :  Android is a mobile operating system developed by Google.\n",
      "Word , Algo1_tag , Algo2_tag , Algo3_tag\n",
      "Android PRT NOUN NOUN\n",
      "is VERB VERB VERB\n",
      "a DET DET DET\n",
      "mobile ADJ ADJ ADJ\n",
      "operating NOUN NOUN NOUN\n",
      "system NOUN NOUN NOUN\n",
      "developed VERB VERB VERB\n",
      "by ADP ADP ADP\n",
      "Google PRT NOUN NOUN\n",
      ". . . .\n",
      "**********************************************************************************************\n",
      "Sentence  2  :  Android has been the best-selling OS worldwide on smartphones since 2011 and on tablets since 2013.\n",
      "Word , Algo1_tag , Algo2_tag , Algo3_tag\n",
      "Android PRT NOUN NOUN\n",
      "has VERB VERB VERB\n",
      "been VERB VERB VERB\n",
      "the DET DET DET\n",
      "best-selling ADJ ADJ ADJ\n",
      "OS PRT NOUN NOUN\n",
      "worldwide PRT NOUN NOUN\n",
      "on ADP ADP ADP\n",
      "smartphones PRT NOUN VERB\n",
      "since ADP ADP ADP\n",
      "2011 PRT NOUN NUM\n",
      "and CONJ CONJ CONJ\n",
      "on ADP ADP ADP\n",
      "tablets NOUN NOUN NOUN\n",
      "since ADP ADP ADP\n",
      "2013 PRT NOUN NUM\n",
      ". . . .\n",
      "**********************************************************************************************\n",
      "Sentence  3  :  Google and Twitter made a deal in 2015 that gave Google access to Twitter's firehose.\n",
      "Word , Algo1_tag , Algo2_tag , Algo3_tag\n",
      "Google PRT NOUN NOUN\n",
      "and CONJ CONJ CONJ\n",
      "Twitter PRT NOUN NOUN\n",
      "made VERB VERB VERB\n",
      "a DET DET DET\n",
      "deal NOUN NOUN NOUN\n",
      "in ADP ADP ADP\n",
      "2015 PRT NOUN NUM\n",
      "that DET DET ADP\n",
      "gave VERB VERB VERB\n",
      "Google PRT NOUN NOUN\n",
      "access NOUN NOUN NOUN\n",
      "to PRT PRT PRT\n",
      "Twitter PRT NOUN NOUN\n",
      "'s VERB VERB PRT\n",
      "firehose PRT NOUN NOUN\n",
      ". . . .\n",
      "**********************************************************************************************\n",
      "Sentence  4  :  Twitter is an online news and social networking service on which users post and interact with messages known as tweets.\n",
      "Word , Algo1_tag , Algo2_tag , Algo3_tag\n",
      "Twitter PRT NOUN NOUN\n",
      "is VERB VERB VERB\n",
      "an DET DET DET\n",
      "online PRT NOUN NOUN\n",
      "news NOUN NOUN NOUN\n",
      "and CONJ CONJ CONJ\n",
      "social ADJ ADJ ADJ\n",
      "networking NOUN NOUN NOUN\n",
      "service NOUN NOUN NOUN\n",
      "on ADP ADP ADP\n",
      "which DET DET DET\n",
      "users NOUN NOUN NOUN\n",
      "post NOUN NOUN NOUN\n",
      "and CONJ CONJ CONJ\n",
      "interact PRT NOUN NOUN\n",
      "with ADP ADP ADP\n",
      "messages PRT NOUN VERB\n",
      "known VERB VERB VERB\n",
      "as ADP ADP ADP\n",
      "tweets PRT NOUN NOUN\n",
      ". . . .\n",
      "**********************************************************************************************\n",
      "Sentence  5  :  Before entering politics, Donald Trump was a domineering businessman and a television personality.\n",
      "Word , Algo1_tag , Algo2_tag , Algo3_tag\n",
      "Before ADP ADP ADP\n",
      "entering VERB VERB VERB\n",
      "politics NOUN NOUN NOUN\n",
      ", . . .\n",
      "Donald NOUN NOUN NOUN\n",
      "Trump NOUN NOUN NOUN\n",
      "was VERB VERB VERB\n",
      "a DET DET DET\n",
      "domineering PRT NOUN VERB\n",
      "businessman NOUN NOUN NOUN\n",
      "and CONJ CONJ CONJ\n",
      "a DET DET DET\n",
      "television NOUN NOUN NOUN\n",
      "personality PRT NOUN NOUN\n",
      ". . . .\n",
      "**********************************************************************************************\n",
      "Sentence  6  :  The 2018 FIFA World Cup is the 21st FIFA World Cup, an international football tournament contested once every four years.\n",
      "Word , Algo1_tag , Algo2_tag , Algo3_tag\n",
      "The DET DET DET\n",
      "2018 PRT NOUN NUM\n",
      "FIFA PRT NOUN NOUN\n",
      "World NOUN NOUN NOUN\n",
      "Cup PRT NOUN NOUN\n",
      "is VERB VERB VERB\n",
      "the DET DET DET\n",
      "21st PRT NOUN NOUN\n",
      "FIFA PRT NOUN NOUN\n",
      "World NOUN NOUN NOUN\n",
      "Cup PRT NOUN NOUN\n",
      ", . . .\n",
      "an DET DET DET\n",
      "international ADJ ADJ ADJ\n",
      "football NOUN NOUN NOUN\n",
      "tournament PRT NOUN NOUN\n",
      "contested PRT NOUN VERB\n",
      "once ADV ADV ADV\n",
      "every DET DET DET\n",
      "four NUM NUM NUM\n",
      "years NOUN NOUN NOUN\n",
      ". . . .\n",
      "**********************************************************************************************\n",
      "Sentence  7  :  This is the first World Cup to be held in Eastern Europe and the 11th time that it has been held in Europe.\n",
      "Word , Algo1_tag , Algo2_tag , Algo3_tag\n",
      "This DET DET DET\n",
      "is VERB VERB VERB\n",
      "the DET DET DET\n",
      "first ADJ ADJ ADJ\n",
      "World NOUN NOUN NOUN\n",
      "Cup PRT NOUN NOUN\n",
      "to PRT PRT PRT\n",
      "be VERB VERB VERB\n",
      "held VERB VERB VERB\n",
      "in ADP ADP ADP\n",
      "Eastern NOUN NOUN NOUN\n",
      "Europe NOUN NOUN NOUN\n",
      "and CONJ CONJ CONJ\n",
      "the DET DET DET\n",
      "11th ADJ ADJ ADJ\n",
      "time NOUN NOUN NOUN\n",
      "that ADP ADP ADP\n",
      "it PRON PRON PRON\n",
      "has VERB VERB VERB\n",
      "been VERB VERB VERB\n",
      "held VERB VERB VERB\n",
      "in ADP ADP ADP\n",
      "Europe NOUN NOUN NOUN\n",
      ". . . .\n",
      "**********************************************************************************************\n",
      "Sentence  8  :  Show me the cheapest round trips from Dallas to Atlanta\n",
      "I would like to see flights from Denver to Philadelphia.\n",
      "Word , Algo1_tag , Algo2_tag , Algo3_tag\n",
      "Show NOUN NOUN NOUN\n",
      "me PRON PRON PRON\n",
      "the DET DET DET\n",
      "cheapest ADJ ADJ ADJ\n",
      "round NOUN NOUN NOUN\n",
      "trips PRT NOUN NOUN\n",
      "from ADP ADP ADP\n",
      "Dallas NOUN NOUN NOUN\n",
      "to PRT PRT PRT\n",
      "Atlanta NOUN NOUN NOUN\n",
      "I PRON PRON PRON\n",
      "would VERB VERB VERB\n",
      "like ADP ADP ADP\n",
      "to PRT PRT PRT\n",
      "see VERB VERB VERB\n",
      "flights NOUN NOUN NOUN\n",
      "from ADP ADP ADP\n",
      "Denver NOUN NOUN NOUN\n",
      "to PRT PRT PRT\n",
      "Philadelphia NOUN NOUN NOUN\n",
      ". . . .\n",
      "**********************************************************************************************\n",
      "Sentence  9  :  Show me the price of the flights leaving Atlanta at about 3 in the afternoon and arriving in San Francisco.\n",
      "Word , Algo1_tag , Algo2_tag , Algo3_tag\n",
      "Show NOUN NOUN NOUN\n",
      "me PRON PRON PRON\n",
      "the DET DET DET\n",
      "price NOUN NOUN NOUN\n",
      "of ADP ADP ADP\n",
      "the DET DET DET\n",
      "flights NOUN NOUN NOUN\n",
      "leaving VERB VERB VERB\n",
      "Atlanta NOUN NOUN NOUN\n",
      "at ADP ADP ADP\n",
      "about ADP ADP ADP\n",
      "3 NUM NUM NUM\n",
      "in ADP ADP ADP\n",
      "the DET DET DET\n",
      "afternoon NOUN NOUN NOUN\n",
      "and CONJ CONJ CONJ\n",
      "arriving PRT NOUN VERB\n",
      "in ADP ADP ADP\n",
      "San NOUN NOUN NOUN\n",
      "Francisco NOUN NOUN NOUN\n",
      ". . . .\n",
      "**********************************************************************************************\n",
      "Sentence  10  :  NASA invited social media users to experience the launch of ICESAT-2 Satellite.\n",
      "Word , Algo1_tag , Algo2_tag , Algo3_tag\n",
      "NASA PRT NOUN NOUN\n",
      "invited PRT NOUN VERB\n",
      "social ADJ ADJ ADJ\n",
      "media NOUN NOUN NOUN\n",
      "users NOUN NOUN NOUN\n",
      "to PRT PRT PRT\n",
      "experience NOUN NOUN NOUN\n",
      "the DET DET DET\n",
      "launch NOUN NOUN NOUN\n",
      "of ADP ADP ADP\n",
      "ICESAT-2 PRT NOUN NOUN\n",
      "Satellite PRT NOUN NOUN\n",
      ". . . .\n",
      "**********************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "## instances with different tags by the algorithm\n",
    "from nltk.tokenize import word_tokenize\n",
    "sentences = nltk.sent_tokenize(open('Test_sentences.txt').read())\n",
    "for sent_id, sentence in enumerate(sentences):\n",
    "    words = word_tokenize(sentence)\n",
    "    tagged_seq_sent_viterbi = Viterbi(words)\n",
    "    tagged_seq_sent_handle_unk = Viterbi_handle_unknown(words)\n",
    "    tagged_seq_sent_lexicon = lexicon_tagger.tag_sents([words])\n",
    "    print(\"Sentence \",sent_id+1,\" : \",sentence)\n",
    "    print(\"Word , Algo1_tag , Algo2_tag , Algo3_tag\")\n",
    "    for idx, (word, tag) in enumerate(tagged_seq_sent_viterbi):\n",
    "        print(word,tagged_seq_sent_viterbi[idx][1],tagged_seq_sent_handle_unk[idx][1],tagged_seq_sent_lexicon[0][idx][1])\n",
    "    print(\"**********************************************************************************************\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Comparison between Vanila viterbi algorithm, Viterbi algorithm with unknown words handle and Ensemble of lexicon and rule based tagger"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "As we can see, we have a set of 9 sentences for testing the tagging accuracies of the three different taggers that's built as a part of this assignment.\n",
    "\n",
    "Stats(Accuracy):\n",
    "Vanila Viterbi Algorithm : 0.8833\n",
    "Viterbi with handle for unknown words : 0.9\n",
    "Ensemble of Lexicon and rule based tagger : 0.9476\n",
    "\n",
    "Note: \n",
    "\n",
    "1) There accuracy scores are generated on a randomly generated test set, so the scores might not remain the same when the code is re-run, but rest assured, it will be in the same range of +/- 0.05.\n",
    "\n",
    "2) Another observation to be made is how the performance of the tagger increases by switching from the Vanila Viterbi to the Viterbi with handle for unknown words to the ensemble of the Lexicon and the Rule Based tagger\n",
    "\n",
    "This can be noticed in a few examples from the test set.\n",
    "\n",
    "\n",
    "The format of the output in the above cell: \n",
    "The first line shows the sentence that is being tagged\n",
    "The second line is the header of the table where the first column is the word, second column is the tag of the 1st algorithm, third column is the tag of the 2nd algorithm and the 4th column is the tag of the 3rd algorithm\n",
    "\n",
    "Inferences:\n",
    "\n",
    "1) Most of the nouns in the Vanila Viterbi are tagger wrong as the algorithm return the first tag in the emission list if the word is not found in the training data. For example, In sentence 1, Android is tagged as \"PRT\" but should have been tagged as a \"NOUN\". This is corrected by using the missing word handle or the ensemble of the rule based and lexicon tagger\n",
    "\n",
    "2) There are a few incorrect tags assosciated since the accuracy cannot reach a 100%. But a noticable change is that the ensemble model has a better predictive ability based on the semantics of the sentence as seen in Sentence 9; The word arriving was tagged as a \"PRT\" with the 1st algorithm, \"NOUN\" with the 2nd algorithm but the 3rd was able to properly tag it as a verb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
